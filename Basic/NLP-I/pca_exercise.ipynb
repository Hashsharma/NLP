{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab8fcd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is ‚ÄúDimensionality‚Äù?\n",
    "\n",
    "# A dimension is just a feature.\n",
    "# Examples:\n",
    "# A person described by\n",
    "# (height, weight) ‚Üí 2 dimensions\n",
    "\n",
    "# A house described by\n",
    "# (size, rooms, age, price) ‚Üí 4 dimensions\n",
    "# An image of size 64√ó64 ‚Üí 4096 dimensions (each pixel)\n",
    "\n",
    "# High dimensions cause problems:\n",
    "\n",
    "# Hard to visualize\n",
    "# Slower computation\n",
    "# Models overfit\n",
    "# Many features are redundant\n",
    "# This is known as the curse of dimensionality\n",
    "\n",
    "# Redundancy Example\n",
    "\n",
    "# Suppose you collect:\n",
    "\n",
    "# Height in cm\n",
    "# Height in inches\n",
    "# These are different features but carry the same information.\n",
    "\n",
    "# üëâ PCA finds a smaller set of new features that keeps most of the information.\n",
    "# Covariance\n",
    "# https://www.youtube.com/watch?v=fsTSLXhz4uQ Best to understand PCAS's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4698210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | Model       | Tokenizer Algorithm          | Key Idea                           |\n",
    "# | ----------- | ---------------------------- | ---------------------------------- |\n",
    "# | **BERT**    | **WordPiece**                | Split words into frequent subwords |\n",
    "# | **GPT**     | **BPE (Byte Pair Encoding)** | Merge frequent character sequences |\n",
    "# | **RoBERTa** | **BPE (byte-level)**         | GPT-style BPE but more robust      |\n",
    "# Transformer Architecture\n",
    "\n",
    "# Core blocks:\n",
    "\n",
    "# Self-Attention\n",
    "# Feed Forward Network\n",
    "# Positional Encoding\n",
    "# Why revolutionary: No recurrence, faster training, better context\n",
    "\n",
    "# 4. Classical vs Deep NLP (Very Important)\n",
    "\n",
    "# Classical NLP\n",
    "# TF-IDF + Logistic Regression / SVM\n",
    "# Fast, interpretable\n",
    "# Needs feature engineering\n",
    "# Deep NLP\n",
    "# Embeddings + LSTM / Transformer\n",
    "# Better accuracy\n",
    "# Needs more data + compute\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatterbox_venv",
   "language": "python",
   "name": "chatterbox_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
