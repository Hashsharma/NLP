{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDFNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pymupdf-1.25.4-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: sentence-transformers in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from sentence-transformers) (4.50.0)\n",
      "Requirement already satisfied: tqdm in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from sentence-transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: Pillow in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from sentence-transformers) (4.13.0)\n",
      "Requirement already satisfied: filelock in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading pymupdf-1.25.4-cp39-abi3-win_amd64.whl (16.6 MB)\n",
      "   ---------------------------------------- 0.0/16.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/16.6 MB 11.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.6/16.6 MB 6.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 10.0/16.6 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.5/16.6 MB 20.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.5/16.6 MB 20.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.6/16.6 MB 14.1 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.25.4\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mr_document\\all_venv\\rag_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Sentence Transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # You can choose a different model if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    # Open the PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Extract text from each page\n",
    "    pdf_text = \"\"\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc.load_page(page_num)\n",
    "        pdf_text += page.get_text()\n",
    "    \n",
    "    return pdf_text\n",
    "\n",
    "# Function to get sentence embeddings using Sentence Transformer\n",
    "def get_embeddings(text):\n",
    "    # Split the text into sentences\n",
    "    sentences = text.split(\". \")\n",
    "    \n",
    "    # Get embeddings for each sentence\n",
    "    embeddings = model.encode(sentences)\n",
    "    \n",
    "    return sentences, embeddings\n",
    "\n",
    "# Main function\n",
    "def process_pdf_and_get_embeddings(pdf_path):\n",
    "    # Step 1: Extract text from the PDF\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Step 2: Get embeddings from the extracted text\n",
    "    sentences, embeddings = get_embeddings(pdf_text)\n",
    "    \n",
    "    # Example: store or print the embeddings and sentences (Here we print)\n",
    "    for sentence, embedding in zip(sentences, embeddings):\n",
    "        print(f\"Sentence: {sentence}\")\n",
    "        print(f\"Embedding: {embedding[:10]}...\")  # Print first 10 elements of the embedding for brevity\n",
    "\n",
    "    # You can save embeddings to a file or a database if needed.\n",
    "    # For example, you can save them as numpy arrays or in a CSV file.\n",
    "    \n",
    "    # Optionally save embeddings to a file (e.g., .npy for numpy arrays)\n",
    "    np.save('embeddings.npy', embeddings)  # Save embeddings to a file for later use.\n",
    "\n",
    "    return sentences, embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Neural Networks with TensorFlow and Keras\n",
      "Philip Hua\n",
      "Neural Networks with\n",
      "TensorFlow and Keras\n",
      "Training, Generative Models,\n",
      "and Reinforcement Learning\n",
      "Philip Hua\n",
      "Guildford, UK\n",
      "ISBN-13 (pbk): 979-8-8688-1019-0\n",
      "ISBN-13 (electronic): 979-8-8688-1020-6\n",
      "https://doi.org/10.1007/979-8-8688-1020-6\n",
      "Copyright © 2024 by Philip Hua\n",
      "This work is subject to copyright\n",
      "Embedding: [-0.06783275 -0.1206085   0.08715834 -0.06901836 -0.04243773  0.05971199\n",
      "  0.01415725 -0.09227199 -0.05685356 -0.05088716]...\n",
      "Sentence: All rights are reserved by the Publisher, whether the whole or part of\n",
      "the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,\n",
      "broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information\n",
      "storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology\n",
      "now known or hereafter developed.\n",
      "Trademarked names, logos, and images may appear in this book\n",
      "Embedding: [-0.03637617  0.02243257 -0.08503982 -0.10413267 -0.01634174 -0.02329526\n",
      " -0.02941148  0.00412004  0.01332458 -0.01598789]...\n",
      "Sentence: Rather than use a trademark symbol\n",
      "with every occurrence of a trademarked name, logo, or image we use the names, logos, and images only\n",
      "in an editorial fashion and to the beneﬁt of the trademark owner, with no intention of infringement of the\n",
      "trademark.\n",
      "The use in this publication of trade names, trademarks, service marks, and similar terms, even if they are\n",
      "not identiﬁed as such, is not to be taken as an expression of opinion as to whether or not they are subject\n",
      "to proprietary rights.\n",
      "While the advice and information in this book are believed to be true and accurate at the date of\n",
      "publication, neither the authors nor the editors nor the publisher can accept any legal responsibility for\n",
      "any errors or omissions that may be made\n",
      "Embedding: [-0.08538715  0.05149275 -0.00978644 -0.0620817  -0.02673548 -0.00648734\n",
      "  0.03172178  0.04326495  0.01041606 -0.05091419]...\n",
      "Sentence: The publisher makes no warranty, express or implied, with\n",
      "respect to the material contained herein.\n",
      "Managing Director, Apress Media LLC: Welmoed Spahr\n",
      "Acquisitions Editor: Celestin Suresh John\n",
      "Development Editor: Laura Berendson\n",
      "Coordinating Editor: Kripa Joseph\n",
      "Cover designed by eStudioCalamar\n",
      "Cover image designed by Unsplash\n",
      "Distributed to the book trade worldwide by Springer Science+Business Media New York, 233 Spring\n",
      "Street, 6th Floor, New York, NY 10013\n",
      "Embedding: [-0.07985933 -0.0011567   0.03214643  0.03491283  0.0075022   0.03105904\n",
      " -0.05263365  0.01582603  0.07534089  0.07293829]...\n",
      "Sentence: Phone 1-800-SPRINGER, fax (201) 348-4505, e-mail orders-\n",
      "ny@springer-sbm.com, or visit www.springeronline.com\n",
      "Embedding: [-0.04379566 -0.05291042  0.03794397 -0.0128979  -0.0560519  -0.0121939\n",
      " -0.03513051  0.0768479   0.00024671 -0.07176939]...\n",
      "Sentence: Apress Media, LLC is a California LLC and\n",
      "the sole member (owner) is Springer Science+Business Media Finance Inc (SSBM Finance Inc)\n",
      "Embedding: [ 0.03414907 -0.08776426 -0.05605547  0.00200951  0.04135929  0.01077822\n",
      "  0.03709454 -0.02014792  0.11883173 -0.01372357]...\n",
      "Sentence: SSBM\n",
      "Finance Inc is a Delaware corporation.\n",
      "For information on translations, please e-mail booktranslations@springernature.com; for reprint, paper-\n",
      "back, or audio rights, please e-mail bookpermissions@springernature.com.\n",
      "Apress titles may be purchased in bulk for academic, corporate, or promotional use\n",
      "Embedding: [-0.00695351 -0.01164818 -0.05460817  0.02119972 -0.04056416  0.03971109\n",
      " -0.01346978  0.02560215  0.06080656 -0.03479111]...\n",
      "Sentence: eBook versions and\n",
      "licenses are also available for most titles\n",
      "Embedding: [-0.02456094 -0.01538574  0.00364015 -0.07488438  0.00785835  0.03768185\n",
      " -0.07453083 -0.01724263  0.09655292  0.02018622]...\n",
      "Sentence: For more information, reference our Print and eBook Bulk\n",
      "Sales web page at http://www.apress.com/bulk-sales.\n",
      "Any source code or other supplementary material referenced by the author in this book can be found\n",
      "here: https://www.apress.com/gp/services/source-code.\n",
      "If disposing of this product, please recycle the paper\n",
      "To Kim Mai and Anson: Live a worthwhile\n",
      "and happy life.\n",
      "Contents\n",
      "1\n",
      "Introduction ..................................................................\n",
      "1\n",
      "2\n",
      "Using Tensors.................................................................\n",
      "3\n",
      "2.1\n",
      "Tensors and NumPy ...................................................\n",
      "4\n",
      "2.1.1\n",
      "Array and Scalar .............................................\n",
      "5\n",
      "2.1.2\n",
      "Arrays with Different Dimensions ..........................\n",
      "5\n",
      "2.1.3\n",
      "Arrays with the Same Number of Dimensions .............\n",
      "5\n",
      "2.2\n",
      "Basic Tensor Operations...............................................\n",
      "6\n",
      "2.2.1\n",
      "Creating Tensors .............................................\n",
      "6\n",
      "2.2.2\n",
      "Mathematical Operations ....................................\n",
      "6\n",
      "2.2.3\n",
      "Reshaping Tensors ...........................................\n",
      "7\n",
      "2.3\n",
      "Parallelism .............................................................\n",
      "9\n",
      "2.4\n",
      "Machine Learning Environment ......................................\n",
      "10\n",
      "Part I\n",
      "Concepts and Basics of Machine Learning\n",
      "3\n",
      "How Machine Learns Using Neural Network.............................\n",
      "15\n",
      "3.1\n",
      "Components of a Neural Network ....................................\n",
      "17\n",
      "3.1.1\n",
      "Neurons: The Building Blocks ..............................\n",
      "19\n",
      "3.1.2\n",
      "Neuron Initialization .........................................\n",
      "25\n",
      "3.2\n",
      "Network Layers: Building a Hierarchy ...............................\n",
      "27\n",
      "3.3\n",
      "The Optimizer and the Loss Function ................................\n",
      "28\n",
      "3.3.1\n",
      "The Loss Function ...........................................\n",
      "29\n",
      "3.3.2\n",
      "Loss Function for Regression ...............................\n",
      "30\n",
      "3.3.3\n",
      "Mean Squared Error .........................................\n",
      "30\n",
      "3.3.4\n",
      "Cosine Similarity.............................................\n",
      "31\n",
      "3.4\n",
      "Probabilistic Losses ...................................................\n",
      "33\n",
      "3.4.1\n",
      "Binary Cross-Entropy........................................\n",
      "33\n",
      "3.4.2\n",
      "Categorical Cross-Entropy ..................................\n",
      "33\n",
      "3.4.3\n",
      "Sparse Categorical Cross-Entropy ..........................\n",
      "34\n",
      "3.5\n",
      "Network Optimizer ....................................................\n",
      "34\n",
      "3.6\n",
      "Generalization Errors ..................................................\n",
      "37\n",
      "3.7\n",
      "TensorBoard ...........................................................\n",
      "37\n",
      "3.8\n",
      "Using TensorBoard in Colab ..........................................\n",
      "42\n",
      "vii\n",
      "viii\n",
      "Contents\n",
      "4\n",
      "Network Layers ..............................................................\n",
      "43\n",
      "4.1\n",
      "Dense (Fully Connected) Layers......................................\n",
      "43\n",
      "4.2\n",
      "Normalization Layers..................................................\n",
      "46\n",
      "4.3\n",
      "Dropout Layers ........................................................\n",
      "47\n",
      "4.3.1\n",
      "Flattening Layers.............................................\n",
      "47\n",
      "4.3.2\n",
      "Pooling Layers ...............................................\n",
      "47\n",
      "4.3.3\n",
      "Convolutional Layers ........................................\n",
      "49\n",
      "4.3.4\n",
      "CNN As an Input Layer .....................................\n",
      "51\n",
      "4.3.5\n",
      "Multiple CNN Layers........................................\n",
      "52\n",
      "4.3.6\n",
      "Embedding Layers ...........................................\n",
      "54\n",
      "4.3.7\n",
      "Residual Layers ..............................................\n",
      "55\n",
      "4.3.8\n",
      "Recurrent Layers .............................................\n",
      "55\n",
      "4.3.9\n",
      "Activation Function ..........................................\n",
      "58\n",
      "4.3.10\n",
      "Recurrent Activation .........................................\n",
      "59\n",
      "4.3.11\n",
      "Other Layers..................................................\n",
      "59\n",
      "Part II\n",
      "Implementation Examples\n",
      "5\n",
      "The Training Process ........................................................\n",
      "63\n",
      "5.1\n",
      "Data Loading...........................................................\n",
      "63\n",
      "5.1.1\n",
      "Loading Images ..............................................\n",
      "66\n",
      "5.2\n",
      "Data Processing ........................................................\n",
      "67\n",
      "5.2.1\n",
      "Splitting the Dataset: Training, Development, Test ........\n",
      "68\n",
      "5.2.2\n",
      "Categorical Data .............................................\n",
      "68\n",
      "5.2.3\n",
      "Preprocessing Images ........................................\n",
      "70\n",
      "5.2.4\n",
      "Normalization and Standardization .........................\n",
      "72\n",
      "5.2.5\n",
      "Missing Data .................................................\n",
      "74\n",
      "5.2.6\n",
      "Data Augmentation ..........................................\n",
      "76\n",
      "5.3\n",
      "Tuning Our Network...................................................\n",
      "79\n",
      "5.4\n",
      "Customizations ........................................................\n",
      "84\n",
      "5.5\n",
      "Functional API.........................................................\n",
      "84\n",
      "5.6\n",
      "Custom Models ........................................................\n",
      "85\n",
      "5.7\n",
      "Model Selection........................................................\n",
      "88\n",
      "5.8\n",
      "Model Depth and Complexity.........................................\n",
      "89\n",
      "5.9\n",
      "Neural Networks Applications ........................................\n",
      "89\n",
      "5.10\n",
      "Dense Network: Detection of Handwritten Digits Using\n",
      "MNIST Dataset ........................................................\n",
      "91\n",
      "5.11\n",
      "RNN Network: Modeling an AutoRegressive Integrated\n",
      "Moving Average (ARIMA) Process ..................................\n",
      "93\n",
      "5.12\n",
      "LSTM Network: BachBot .............................................\n",
      "97\n",
      "5.12.1\n",
      "Background...................................................\n",
      "97\n",
      "5.12.2\n",
      "Preprocessing.................................................\n",
      "98\n",
      "5.12.3\n",
      "Model Implementation and Training.......................\n",
      "Embedding: [-0.10169461 -0.033982   -0.11830142 -0.02004656 -0.00695789  0.01196936\n",
      "  0.01942173  0.03673341 -0.11911569 -0.01534085]...\n",
      "Sentence: 100\n",
      "5.12.4\n",
      "Teacher Forcing .............................................\n",
      "Embedding: [ 0.0198489   0.09518997  0.05586599 -0.02334316 -0.0506494  -0.01838193\n",
      "  0.00678226 -0.01641201 -0.01991536  0.11898811]...\n",
      "Sentence: 100\n",
      "5.12.5\n",
      "BachBot Model .............................................\n",
      "Embedding: [-0.0708995  -0.02267149 -0.05034701 -0.02199225 -0.11145848  0.06911648\n",
      " -0.01840389  0.11101282 -0.03739294 -0.07063414]...\n",
      "Sentence: 102\n",
      "Contents\n",
      "ix\n",
      "6\n",
      "Generative Models ..........................................................\n",
      "Embedding: [-0.0913623  -0.02497396  0.03680066 -0.04636211 -0.05052005  0.03805415\n",
      " -0.04874229  0.03435626  0.00163989  0.02555517]...\n",
      "Sentence: 105\n",
      "6.1\n",
      "Variational Autoencoders.............................................\n",
      "Embedding: [-0.06516766 -0.02954542  0.02957907 -0.0567619  -0.07777624  0.0257744\n",
      "  0.02928654 -0.0069776  -0.06763169 -0.05093201]...\n",
      "Sentence: 105\n",
      "6.1.1\n",
      "Preprocessing................................................\n",
      "Embedding: [-0.05775823  0.06654793 -0.07470649 -0.07346234 -0.0678061  -0.02053451\n",
      "  0.03787402  0.03345803 -0.11951142  0.02984309]...\n",
      "Sentence: 106\n",
      "6.1.2\n",
      "VAE Architecture ...........................................\n",
      "Embedding: [ 0.02808625  0.09649508 -0.02427466 -0.07768724 -0.10246823 -0.02954575\n",
      " -0.0453425   0.00800104 -0.0804139  -0.01422876]...\n",
      "Sentence: 107\n",
      "6.1.3\n",
      "Morphing Images ...........................................\n",
      "Embedding: [ 0.02963839  0.03816617  0.02946659 -0.06172891 -0.01559973 -0.04998131\n",
      "  0.01056139  0.02722005 -0.02516344 -0.01516179]...\n",
      "Sentence: 111\n",
      "6.1.4\n",
      "Feature Disentanglement ...................................\n",
      "Embedding: [-0.00586695  0.06028833  0.00753544 -0.03602511 -0.02089794  0.03847602\n",
      "  0.04805017 -0.04356717 -0.03452595 -0.06944095]...\n",
      "Sentence: 112\n",
      "6.2\n",
      "CartoonGAN ..........................................................\n",
      "Embedding: [-0.03319149  0.00259801 -0.04000999 -0.0966315  -0.10655709  0.03873869\n",
      "  0.03283402  0.05771942 -0.04596507 -0.04510118]...\n",
      "Sentence: 115\n",
      "6.2.1\n",
      "GAN .........................................................\n",
      "Embedding: [-0.09107301  0.04163563 -0.04814535  0.00252578 -0.10833478 -0.05972484\n",
      "  0.03505621  0.01396568 -0.0554123  -0.04448222]...\n",
      "Sentence: 115\n",
      "6.2.2\n",
      "Data Preparation ............................................\n",
      "Embedding: [-0.00840394  0.0218282  -0.06273097 -0.04192889 -0.08148738 -0.11683788\n",
      " -0.05291645  0.0782899  -0.10848831  0.02355126]...\n",
      "Sentence: 116\n",
      "6.2.3\n",
      "Preprocessing CartoonGAN ................................\n",
      "Embedding: [-0.01588799  0.03491662 -0.06229682 -0.10690638 -0.09196646  0.02564145\n",
      "  0.03076597  0.03999114 -0.05156228 -0.03253277]...\n",
      "Sentence: 117\n",
      "6.2.4\n",
      "The Discriminator Model...................................\n",
      "Embedding: [-0.01966419 -0.0028266  -0.08142844 -0.05025611 -0.08523397  0.05544709\n",
      "  0.066598    0.06050941 -0.05047702  0.02198186]...\n",
      "Sentence: 118\n",
      "6.2.5\n",
      "The Generator Model .......................................\n",
      "Embedding: [-0.11378839  0.08484165 -0.09354601  0.02205516 -0.08418471 -0.01629723\n",
      " -0.04713679  0.05899527 -0.06610274 -0.06496356]...\n",
      "Sentence: 120\n",
      "6.3\n",
      "Stable Diffusion.......................................................\n",
      "Embedding: [-0.01095556 -0.0884955  -0.02450971 -0.01068544 -0.02538757 -0.0497821\n",
      "  0.00574872  0.08159292  0.01339256  0.00396783]...\n",
      "Sentence: 122\n",
      "6.3.1\n",
      "Text Embedding in Stable Diffusion .......................\n",
      "Embedding: [ 0.0163562  -0.08152255  0.03480801  0.01768107  0.04188696  0.01478904\n",
      " -0.01864539 -0.02579123  0.06358143 -0.00221037]...\n",
      "Sentence: 123\n",
      "6.3.2\n",
      "Gaussian Noise Injection and Removal ....................\n",
      "Embedding: [-0.05353887 -0.01208837  0.03249156 -0.10012958 -0.04553026 -0.06973289\n",
      "  0.09532115 -0.11233094 -0.0891424  -0.10965601]...\n",
      "Sentence: 124\n",
      "6.3.3\n",
      "The U-Net Model ...........................................\n",
      "Embedding: [-0.02105548 -0.09411822 -0.06597275 -0.04783576 -0.04818658 -0.00088893\n",
      "  0.03061707  0.05092226 -0.00764707  0.01125866]...\n",
      "Sentence: 127\n",
      "7\n",
      "Reinforcement Learning ...................................................\n",
      "Embedding: [-0.04478     0.02559335 -0.01091044  0.01029904 -0.09118832  0.0138391\n",
      "  0.0351373  -0.01952243 -0.05562413  0.0268298 ]...\n",
      "Sentence: 131\n",
      "7.1\n",
      "Explanations of Reinforcement Learning ...........................\n",
      "Embedding: [-0.06124554  0.01118616  0.07473395  0.0412089   0.00871089  0.06256125\n",
      "  0.07525996 -0.01002085 -0.03253961  0.06619983]...\n",
      "Sentence: 131\n",
      "7.2\n",
      "Gymnasium Library ..................................................\n",
      "Embedding: [ 0.0193735  -0.00720126 -0.06022758 -0.08353408 -0.06608537  0.04163922\n",
      "  0.01127742  0.00254259 -0.02468222 -0.02804029]...\n",
      "Sentence: 132\n",
      "7.2.1\n",
      "Installing Gymnasium ......................................\n",
      "Embedding: [ 0.05429456  0.05590949 -0.03569144 -0.05117965 -0.10178654  0.01330574\n",
      "  0.01002301  0.03898742 -0.0726993  -0.05273622]...\n",
      "Sentence: 133\n",
      "7.2.2\n",
      "Gymnasium .................................................\n",
      "Embedding: [ 0.09343798  0.01330934 -0.0191072  -0.0335287  -0.10531243 -0.00089256\n",
      "  0.00492718  0.03649558 -0.0325374  -0.05515224]...\n",
      "Sentence: 133\n",
      "7.2.3\n",
      "Explaining the Gymnasium Environment..................\n",
      "Embedding: [ 0.09697082  0.0606312  -0.0057143   0.00384479 -0.03016751  0.00613755\n",
      "  0.03157043  0.02994403 -0.03352955 -0.06755948]...\n",
      "Sentence: 134\n",
      "7.2.4\n",
      "The Agent ...................................................\n",
      "Embedding: [ 0.00741058  0.01809095 -0.13649912 -0.04824238 -0.09278163  0.07975321\n",
      "  0.08358911  0.100382    0.01690478  0.00910428]...\n",
      "Sentence: 137\n",
      "7.2.5\n",
      "Memory Replay .............................................\n",
      "Embedding: [-0.00456856  0.04235488 -0.07535347 -0.08875509 -0.04222902  0.0693224\n",
      "  0.05698982  0.05717703  0.0078077  -0.00543631]...\n",
      "Sentence: 139\n",
      "8\n",
      "Using Pretrained Networks ................................................\n",
      "Embedding: [ 0.00926937 -0.06135797 -0.04050238 -0.02330206 -0.09527687  0.04300737\n",
      "  0.00193223  0.0653974  -0.03820036 -0.05872101]...\n",
      "Sentence: 143\n",
      "8.1\n",
      "GPT-4 .................................................................\n",
      "Embedding: [-0.00148362 -0.01855001 -0.01189038 -0.01110613 -0.0513707  -0.04893594\n",
      "  0.10140681  0.09837089 -0.06093154 -0.06936467]...\n",
      "Sentence: 143\n",
      "8.1.1\n",
      "Fine-Tuning ChatGPT ......................................\n",
      "Embedding: [-0.0087067  -0.04968709  0.03182857 -0.0198846  -0.08257068 -0.05748736\n",
      "  0.1261756   0.03681093 -0.02244944 -0.04488045]...\n",
      "Sentence: 145\n",
      "8.2\n",
      "VGG ...................................................................\n",
      "Embedding: [-0.01067969  0.09055    -0.08738599  0.00540619 -0.05625125 -0.05331476\n",
      " -0.00614869  0.08821925 -0.03479573 -0.0558799 ]...\n",
      "Sentence: 147\n",
      "8.3\n",
      "YOLO .................................................................\n",
      "Embedding: [ 0.07002974  0.09203473 -0.07012548 -0.02192425 -0.07249746 -0.00562961\n",
      "  0.02329791  0.07447904 -0.05403981  0.04711996]...\n",
      "Sentence: 148\n",
      "8.3.1\n",
      "Converting YOLO Weights to Keras .......................\n",
      "Embedding: [-0.03815535  0.038021   -0.02487653 -0.00810151 -0.10005239 -0.03847636\n",
      "  0.02016059  0.05702317 -0.04751535 -0.10613118]...\n",
      "Sentence: 149\n",
      "8.4\n",
      "Hugging Face .........................................................\n",
      "Embedding: [ 0.02965632  0.12015087  0.02219617  0.01096889 -0.05869927 -0.02095822\n",
      "  0.03430656  0.00304135 -0.02455775 -0.05080455]...\n",
      "Sentence: 150\n",
      "8.5\n",
      "Prompt Engineering ..................................................\n",
      "Embedding: [-0.01868972  0.02871284 -0.00901693 -0.07055821 -0.06705201 -0.09322508\n",
      "  0.00607339  0.10729664 -0.09006409 -0.01391582]...\n",
      "Sentence: 150\n",
      "8.5.1\n",
      "Zero-Shot Learning .........................................\n",
      "Embedding: [ 0.01611345  0.01341726  0.00273454 -0.01479282 -0.03876482 -0.00079544\n",
      "  0.06800915  0.00223344 -0.04409973  0.00874552]...\n",
      "Sentence: 150\n",
      "8.5.2\n",
      "Few-Shot Learning..........................................\n",
      "Embedding: [ 0.04471208  0.019158    0.00326056 -0.0247077  -0.05408488  0.03069437\n",
      "  0.05356513  0.01444352 -0.07253049  0.03716579]...\n",
      "Sentence: 151\n",
      "8.5.3\n",
      "One-Shot Learning..........................................\n",
      "Embedding: [ 0.04250785  0.00675721  0.02905341 -0.03676631 -0.06089433  0.01509876\n",
      "  0.07818575  0.00332216 -0.05764852  0.04042373]...\n",
      "Sentence: 151\n",
      "8.5.4\n",
      "Chain-of-Thought Prompting ..............................\n",
      "Embedding: [ 0.03683978  0.10237347  0.0427081  -0.09125082 -0.04738091 -0.02523769\n",
      "  0.05408657  0.07955088 -0.01535562  0.00341044]...\n",
      "Sentence: 151\n",
      "8.5.5\n",
      "Role-Playing ................................................\n",
      "Embedding: [ 0.04713789  0.00875565  0.00748795 -0.12043999 -0.1142199   0.09568421\n",
      "  0.07180563  0.05671946 -0.05495318  0.04678252]...\n",
      "Sentence: 152\n",
      "8.5.6\n",
      "Embedding Prompts ........................................\n",
      "Embedding: [ 0.0057717  -0.04186914  0.00947222 -0.08569793 -0.01245816  0.0416531\n",
      " -0.03360091  0.0320283   0.02237728 -0.06473612]...\n",
      "Sentence: 152\n",
      "8.5.7\n",
      "Knowledge Graphs..........................................\n",
      "Embedding: [ 0.056092    0.00891988 -0.04970285 -0.02495289 -0.03476679 -0.0382572\n",
      "  0.02083385  0.05975464 -0.04912404  0.08366794]...\n",
      "Sentence: 153\n",
      "8.6\n",
      "Retrieval-Augmented LLM ..........................................\n",
      "Embedding: [-0.02236847 -0.0042311  -0.03537804 -0.02653341 -0.06496271  0.0062788\n",
      "  0.06821451  0.06408437 -0.0601499  -0.04253252]...\n",
      "Sentence: 154\n",
      "8.7\n",
      "Best Practices for Prompt Engineering ..............................\n",
      "Embedding: [-0.0036879   0.08121008  0.01265862 -0.09134696 -0.0659792  -0.05626303\n",
      "  0.02584892  0.09543781 -0.09803021 -0.00974379]...\n",
      "Sentence: 155\n",
      "8.7.1\n",
      "Parameters ...................................................\n",
      "Embedding: [ 0.03767769  0.02159947 -0.08093702 -0.06858217 -0.12424409 -0.02530237\n",
      " -0.01033823  0.08676536 -0.05748962 -0.06911303]...\n",
      "Sentence: 157\n",
      "8.8\n",
      "Coding an AI Agent Using LangChain ..............................\n",
      "Embedding: [-0.07597705  0.04634013 -0.03258633 -0.05037439 -0.04925819  0.03514885\n",
      "  0.09128793  0.04149903 -0.02418986 -0.00509398]...\n",
      "Sentence: 157\n",
      "8.8.1\n",
      "Indexing Using VectorDB ..................................\n",
      "Embedding: [ 0.07961585  0.00803674 -0.04186581  0.01209519 -0.01557367  0.02642015\n",
      "  0.04250923  0.03131943 -0.09972722 -0.00298874]...\n",
      "Sentence: 158\n",
      "x\n",
      "Contents\n",
      "8.8.2\n",
      "Retrieval Mechanism in LangChain........................\n",
      "Embedding: [-0.01949344  0.02116426 -0.00453329 -0.02657837 -0.05973451 -0.0212543\n",
      "  0.02594302  0.06787818  0.0432124   0.00035159]...\n",
      "Sentence: 160\n",
      "8.9\n",
      "Company Chatbot Using LangChain ................................\n",
      "Embedding: [-0.10066997 -0.00167857 -0.00330432 -0.08263105 -0.061722   -0.05196235\n",
      "  0.05639824  0.04271459  0.01497954 -0.09213116]...\n",
      "Sentence: 162\n",
      "8.10\n",
      "Other AI Agent Software.............................................\n",
      "Embedding: [-0.03951785 -0.01388559 -0.09067477 -0.07352594 -0.01901475  0.00638327\n",
      "  0.02353298  0.02391007 -0.03621949 -0.02620131]...\n",
      "Sentence: 168\n",
      "8.11\n",
      "Concluding Remarks .................................................\n",
      "Embedding: [-0.0828908   0.11003389  0.0315407  -0.03244294 -0.01089587  0.04376904\n",
      "  0.01298489  0.02924755 -0.02873012 -0.03239755]...\n",
      "Sentence: 169\n",
      "Bibliography .....................................................................\n",
      "Embedding: [-0.01209179  0.05610359 -0.06171946 -0.11495727 -0.11507356  0.0246897\n",
      "  0.00103709  0.0523918  -0.0388145  -0.02667131]...\n",
      "Sentence: 171\n",
      "Index..............................................................................\n",
      "Embedding: [ 0.06085255  0.02717446 -0.06542155 -0.06380586 -0.02712905 -0.01351529\n",
      "  0.07817449  0.08144712 -0.02417007 -0.04816469]...\n",
      "Sentence: 173\n",
      "About the Author\n",
      "Philip Hua brings over 30 years of experience\n",
      "in investment, risk management, and IT\n",
      "Embedding: [ 0.09187455 -0.02869777 -0.06301821  0.05895919 -0.02175385 -0.01982429\n",
      "  0.0406234   0.0188782  -0.03615876  0.05356791]...\n",
      "Sentence: He has\n",
      "held senior positions as a partner at a hedge fund,\n",
      "led risk and IT departments at both large and\n",
      "boutique ﬁrms, and cofounded a successful ﬁn-\n",
      "tech company\n",
      "Embedding: [ 0.0068265  -0.01063662 -0.03716529 -0.01921553 -0.02408589 -0.01112233\n",
      "  0.03649604  0.02642523 -0.06552976 -0.05380721]...\n",
      "Sentence: Alongside Dr\n",
      "Embedding: [-0.01308921  0.04101253  0.00902877  0.04152415 -0.04283451  0.02975617\n",
      "  0.01015049  0.06595684  0.00404825 -0.04146878]...\n",
      "Sentence: Paul Wilmott, he\n",
      "developed the CrashMetrics methodology, a crucial\n",
      "tool for evaluating severe market risk in portfolios.\n",
      "Philip holds a PhD in Applied Mathematics from\n",
      "Imperial College London, an MBA, and a BSc in\n",
      "Engineering.\n",
      "xi\n",
      "About the Technical Reviewer\n",
      "Shibsankar Das is currently working as a Senior\n",
      "Data Scientist at Microsoft\n",
      "Embedding: [-0.03331097  0.02714671 -0.05619044 -0.05293192  0.02000539 -0.02113583\n",
      "  0.02275619  0.15685259  0.00259894  0.07605119]...\n",
      "Sentence: He has 10+ years of\n",
      "experience working in IT where he has led several\n",
      "data science initiatives, and in 2019, he was recog-\n",
      "nized as one of the top 40 data scientists in India.\n",
      "His core strength is in GenAI, deep learning, NLP,\n",
      "and graph neural networks\n",
      "Embedding: [-0.01140101 -0.07207234 -0.014417   -0.00881625 -0.0522831  -0.03496001\n",
      "  0.02977283  0.04115366 -0.13239528 -0.03718325]...\n",
      "Sentence: Currently, he is focus-\n",
      "ing on his research on GraphRAG, a framework\n",
      "that leverages RAG along with a knowledge graph\n",
      "to solve business problems\n",
      "Embedding: [ 0.0214171   0.03886677 -0.07381921 -0.01609707 -0.03648816 -0.02033534\n",
      "  0.03790594  0.06343088 -0.13546748  0.07334215]...\n",
      "Sentence: He has experience\n",
      "working in the domain of foundational research,\n",
      "ﬁntech, and ecommerce.\n",
      "Before Microsoft, he worked at Optum, Wal-\n",
      "mart, Envestnet, Microsoft Research, and Capgem-\n",
      "ini\n",
      "Embedding: [ 0.03814759 -0.05586904 -0.02953419  0.01100185  0.01705586 -0.01947082\n",
      "  0.08515919 -0.01285211 -0.07824722 -0.03926154]...\n",
      "Sentence: He pursued a master’s from the Indian Institute\n",
      "of Technology, Bangalore.\n",
      "xiii\n",
      "1\n",
      "Introduction\n",
      "Machine learning has become an integral part of our lives, inﬂuencing various\n",
      "aspects from virtual chatbots and voice assistants like Siri and Alexa to Tesla’s\n",
      "autonomous vehicles and even the creative realms of music composition\n",
      "Embedding: [-0.05341829 -0.05306604  0.02144531 -0.02267385 -0.05525346  0.00389225\n",
      " -0.01833666 -0.0669771  -0.08287932 -0.00805459]...\n",
      "Sentence: Its\n",
      "applications extend to personalized advertisements, product recommendations, and\n",
      "investment advice\n",
      "Embedding: [-0.05994423 -0.02128363 -0.0575243  -0.00417091  0.07648244  0.03155741\n",
      "  0.09327879  0.0950169  -0.04506653 -0.08328529]...\n",
      "Sentence: One of its remarkable achievements is DeepMind’s AlphaGo,\n",
      "which showcases the ever-expanding capabilities of artiﬁcial intelligence (AI)\n",
      "Embedding: [-0.05203031 -0.05933213 -0.04087422 -0.00060534  0.00679492 -0.00630211\n",
      "  0.00050742 -0.05887073 -0.0237651   0.04560958]...\n",
      "Sentence: In\n",
      "this rapidly evolving ﬁeld, researchers are relentlessly pursuing the ultimate goal of\n",
      "AI: creating machines capable of thinking and learning, potentially rivaling human\n",
      "intelligence.\n",
      "However, for those new to coding machine learning with Python, the plethora\n",
      "of online articles and concepts can be daunting\n",
      "Embedding: [-0.0709728  -0.04259049 -0.02300911  0.03511956  0.02299852 -0.06063557\n",
      "  0.00102753 -0.02396188 -0.04932178 -0.03787008]...\n",
      "Sentence: Machine learning, unlike many\n",
      "traditional ﬁelds, fundamentally relies on mathematics, presenting a signiﬁcant\n",
      "challenge for those without a strong mathematical background.\n",
      "For experienced software developers and data scientists, however, it is entirely\n",
      "possible to apply machine learning techniques to complex data challenges without\n",
      "delving deeply into mathematical complexities\n",
      "Embedding: [-0.0591011   0.03143053  0.06108365 -0.00219127 -0.01454568 -0.06533664\n",
      " -0.05440306 -0.05008584 -0.09081259 -0.02771894]...\n",
      "Sentence: The vast amount of available data\n",
      "today enables the development of highly accurate machine learning models\n",
      "Embedding: [-0.01519967 -0.08645272  0.06543383  0.05197635  0.05165724 -0.01862418\n",
      " -0.10383537 -0.06579012 -0.04543115 -0.00525843]...\n",
      "Sentence: The\n",
      "key challenge lies in designing analytical workﬂows that extract insights from raw\n",
      "data, a domain where machine learning algorithms excel\n",
      "Embedding: [-0.0664776   0.01534547 -0.03414358  0.0253114   0.05113736 -0.0543834\n",
      " -0.09188463 -0.04516323 -0.0095878   0.02056609]...\n",
      "Sentence: Python, with its extensive\n",
      "numerical libraries, data preparation tools, diverse models, and robust environment,\n",
      "is an invaluable tool for training and scaling models for practical applications.\n",
      "In this book, I aim to guide you through the fundamental concepts to advanced\n",
      "techniques and algorithms in machine learning\n",
      "Embedding: [-0.03353738 -0.04768026  0.00619798 -0.0131775  -0.00622395 -0.07295881\n",
      " -0.02721575 -0.04000412 -0.11002678 -0.07135464]...\n",
      "Sentence: The initial chapters will clarify key\n",
      "concepts and deﬁnitions, helping you understand the Python code in the subsequent\n",
      "sections\n",
      "Embedding: [-0.09714124  0.01005386 -0.03678494 -0.03368548  0.01259796 -0.06242235\n",
      " -0.04368057  0.04787595 -0.08623937 -0.03428458]...\n",
      "Sentence: This book is not a guide to building deep neural networks from scratch,\n",
      "as that requires more advanced knowledge\n",
      "Embedding: [-0.09227826 -0.14532886  0.04249036 -0.02817208 -0.07096387 -0.01999992\n",
      " -0.0875707  -0.06701544 -0.09840823 -0.04839931]...\n",
      "Sentence: Instead, it equips you with the skills to\n",
      "effectively use machine learning algorithms and workﬂows in Python for complex\n",
      "data problems.\n",
      "© Philip Hua 2024\n",
      "P\n",
      "Embedding: [-0.05592646  0.05691441  0.02372457  0.02248216 -0.04049841 -0.15838471\n",
      " -0.02594367 -0.05776723 -0.11692459 -0.00953705]...\n",
      "Sentence: Hua, Neural Networks with TensorFlow and Keras,\n",
      "https://doi.org/10.1007/979-8-8688-1020-6_1\n",
      "1\n",
      "2\n",
      "1\n",
      "Introduction\n",
      "Assuming a basic familiarity with Python, this book will introduce you to impor-\n",
      "tant libraries such as NumPy, Pandas, the deep learning framework TensorFlow, and\n",
      "Keras\n",
      "Embedding: [-0.12570828 -0.08734708  0.05050546 -0.03012956  0.00489565 -0.07451827\n",
      "  0.06278076  0.02048232 -0.05590007 -0.05747586]...\n",
      "Sentence: For more sophisticated applications, we will explore commercial software\n",
      "APIs and models such as GPT-4 and VGG\n",
      "Embedding: [-0.11065982 -0.01783848 -0.06032429 -0.01243065  0.07992526 -0.12298436\n",
      " -0.05670678  0.11837913 -0.016588   -0.04395074]...\n",
      "Sentence: These are built on state-of-the-art models\n",
      "trained on extensive datasets, offering practical solutions for speciﬁc needs rather\n",
      "than modifying their internal mechanics.\n",
      "Wherever possible, I will utilize Google’s Colab, a free service providing\n",
      "accessible computing resources, including GPUs and TPUs, for training machine\n",
      "learning models\n",
      "Embedding: [-0.11822388 -0.13571684  0.03064921 -0.00899663  0.05021628 -0.07950867\n",
      " -0.07427645 -0.00133398 -0.05267613 -0.00715461]...\n",
      "Sentence: In situations where Colab is not suitable, I will use the PyCharm\n",
      "IDE with a local GPU\n",
      "Embedding: [-0.06709353 -0.10346413  0.0191298  -0.02438779  0.00298662 -0.02515224\n",
      " -0.08199763  0.07442276 -0.0191108  -0.06369863]...\n",
      "Sentence: You are encouraged to use your preferred IDE\n",
      "Embedding: [-0.02602785 -0.01718736  0.02965264 -0.0347795   0.02170126  0.01465377\n",
      "  0.15713294  0.10643234  0.01977336 -0.02664647]...\n",
      "Sentence: I recommend\n",
      "PyCharm for its reliability and its availability in both free and paid versions\n",
      "Embedding: [-0.07290803 -0.09112076  0.0024792  -0.00598104  0.04897114  0.01756452\n",
      " -0.05683663  0.05008215  0.01464562 -0.01735913]...\n",
      "Sentence: For\n",
      "machine learning coding, having a powerful laptop or PC with an external GPU is\n",
      "beneﬁcial, as these algorithms require substantial computational resources, and a\n",
      "CPU alone may be insufﬁcient for anything but the simplest tasks.\n",
      "Throughout this book, I have extensively used ChatGPT-4 to explain concepts,\n",
      "programming syntax, and boilerplate code\n",
      "Embedding: [-0.03591892 -0.05249531  0.00637944  0.00452241  0.02125495 -0.08504809\n",
      "  0.01901959  0.0396684  -0.0557798  -0.00355223]...\n",
      "Sentence: While OpenAI’s GPT-4 is a highly\n",
      "advanced tool, it is not always the perfect ﬁt for every complex project\n",
      "Embedding: [-0.04140861  0.01447069 -0.02982321  0.00325066  0.10152993 -0.12802334\n",
      " -0.03000808  0.05417198  0.0203338  -0.03735767]...\n",
      "Sentence: However, it\n",
      "remains an invaluable resource for assistance, offering code that, even if not always\n",
      "ﬂawless, can serve as a faster starting point than writing from scratch.\n",
      "Let’s begin your journey into machine learning with Python.\n",
      "2\n",
      "Using Tensors\n",
      "The advent of deep learning has revolutionized the ﬁeld of artiﬁcial intelligence,\n",
      "allowing machines to process vast amounts of data and solve problems that were\n",
      "once considered too complex\n",
      "Embedding: [-0.07367142 -0.06472038  0.01393333  0.04262202  0.01705942 -0.06105125\n",
      " -0.08244206 -0.03773366 -0.14517133 -0.02720856]...\n",
      "Sentence: As models grew larger and datasets more expansive,\n",
      "the computational demands of training deep learning models began to outpace\n",
      "the capabilities of traditional computing systems\n",
      "Embedding: [-0.01900222 -0.0997493   0.03192434  0.0403693   0.04992146 -0.0206587\n",
      " -0.16399767  0.01774955 -0.02373996 -0.06791969]...\n",
      "Sentence: This challenge gave rise to the\n",
      "need for parallel computing—a method where multiple calculations are carried out\n",
      "simultaneously across different processors.\n",
      "Parallel computing allowed deep learning models to scale, but it also demanded\n",
      "new ways to efﬁciently represent and process data across multiple dimensions\n",
      "Embedding: [-0.04855287 -0.05193333 -0.02346806  0.01264848 -0.05086923 -0.0372849\n",
      " -0.10263304 -0.04758055 -0.01934259 -0.05773836]...\n",
      "Sentence: This\n",
      "is where tensors come into play.\n",
      "Tensors are mathematical structures that generalize the concept of vectors and\n",
      "matrices to higher dimensions, enabling efﬁcient computations over large-scale\n",
      "data\n",
      "Embedding: [-0.01259414 -0.09210435 -0.04769852 -0.03768656 -0.00243824 -0.06053602\n",
      " -0.07492434 -0.08297028  0.02136876 -0.01399242]...\n",
      "Sentence: In deep learning, tensors allow for data to be represented as multidimensional\n",
      "arrays, with each dimension corresponding to a particular aspect of the data—\n",
      "whether it be pixels in an image, time steps in a sequence, or features in a dataset.\n",
      "What sets tensors apart from standard arrays used in programming languages\n",
      "is their optimization for parallel processing\n",
      "Embedding: [ 0.01797502 -0.05654322 -0.0195908  -0.05509616 -0.02642874  0.01409396\n",
      " -0.04399747 -0.0906595  -0.03909548 -0.09564769]...\n",
      "Sentence: They are designed to perform high-\n",
      "performance numerical computations, which makes them ideal for deep learning\n",
      "tasks that require intensive calculations across millions of parameters\n",
      "Embedding: [-0.13720648 -0.02051927 -0.00578751  0.00713268 -0.06412879 -0.09865745\n",
      " -0.06834981 -0.0025746  -0.00859505 -0.03056013]...\n",
      "Sentence: By utilizing\n",
      "tensors, machine learning models can be trained on large datasets with a speed and\n",
      "efﬁciency that would be impossible with traditional data structures.\n",
      "In this chapter, we will introduce tensors and their fundamental operations, laying\n",
      "the groundwork for building complex machine learning models\n",
      "Embedding: [-0.02092724 -0.07860487  0.03288669 -0.02273355  0.02002877 -0.03121336\n",
      " -0.04371549 -0.09453525 -0.08794273 -0.0958965 ]...\n",
      "Sentence: You’ll learn how\n",
      "tensors can efﬁciently represent and manipulate data across multiple dimensions,\n",
      "making them an indispensable tool in the world of deep learning.\n",
      "TensorFlow and Keras take full advantage of tensors, enabling automatic differ-\n",
      "entiation and the ability to distribute computations across multiple devices, such\n",
      "as GPUs and TPUs\n",
      "Embedding: [-0.04637334 -0.08689956  0.00288486 -0.04178976 -0.00915785 -0.02928456\n",
      " -0.1032576  -0.07276175 -0.03463911 -0.05195297]...\n",
      "Sentence: These frameworks provide extensive support for manipulating\n",
      "tensors through parallel operations, allowing for faster data processing and more\n",
      "© Philip Hua 2024\n",
      "P\n",
      "Embedding: [-0.0133916  -0.05366584 -0.03754817 -0.01379292 -0.0104084  -0.02053719\n",
      " -0.07178373 -0.08728416 -0.05152814 -0.00567053]...\n",
      "Sentence: Hua, Neural Networks with TensorFlow and Keras,\n",
      "https://doi.org/10.1007/979-8-8688-1020-6_2\n",
      "3\n",
      "4\n",
      "2\n",
      "Using Tensors\n",
      "efﬁcient memory usage\n",
      "Embedding: [ 0.0156555  -0.11930755 -0.02551319  0.01166551  0.00072746  0.06896619\n",
      " -0.02314977 -0.04313932 -0.05772129 -0.07931495]...\n",
      "Sentence: These features are key to building scalable machine\n",
      "learning models that handle large datasets, making tensors a powerful alternative\n",
      "to conventional arrays.\n",
      "2.1\n",
      "Tensors and NumPy\n",
      "Before we start discussing tensors, some comparisons between tensors and NumPy\n",
      "arrays are warranted as these two are often used interchangeably in code.\n",
      "Tensors, as used in TensorFlow, and NumPy arrays are both powerful tools for\n",
      "handling multidimensional data, and they share many similarities\n",
      "Embedding: [ 0.0167315  -0.08198386 -0.00353703 -0.0231334   0.0711694  -0.01762852\n",
      " -0.05367818 -0.06370688 -0.05580692 -0.07936151]...\n",
      "Sentence: However, there\n",
      "are key differences that make them suitable for different applications, especially in\n",
      "the context of machine learning and deep learning\n",
      "Embedding: [-0.07128003 -0.10306119 -0.01633918 -0.06192468  0.03454438 -0.06906166\n",
      " -0.12104543  0.02651507  0.01078207 -0.06052786]...\n",
      "Sentence: Here are some key differences\n",
      "and commonality between the two libraries:\n",
      "1\n",
      "Embedding: [-0.09636619 -0.11555216 -0.11884759 -0.03358738  0.06151216 -0.02372449\n",
      " -0.04090785  0.11516418  0.01678654 -0.0509763 ]...\n",
      "Sentence: GPU Support: NumPy arrays are primarily designed for CPU-based computing,\n",
      "which means they rely on single-threaded or multithreaded CPU operations.\n",
      "However, deep learning models often require large-scale computations that are\n",
      "far more efﬁcient when distributed across multiple processors\n",
      "Embedding: [-0.03481357 -0.08795288  0.00918289 -0.02934543  0.02151845 -0.05859627\n",
      " -0.11751017 -0.07195541 -0.04255335 -0.05683818]...\n",
      "Sentence: This is where\n",
      "parallel computing with GPUs becomes crucial\n",
      "Embedding: [-0.06949582  0.01457777 -0.05267835  0.02170494  0.01777303 -0.10106812\n",
      " -0.06416467 -0.00038785 -0.03465968 -0.02352569]...\n",
      "Sentence: GPUs, with their thousands of\n",
      "smaller cores, are speciﬁcally built to handle many operations simultaneously,\n",
      "making them ideal for the matrix and tensor operations common in deep learning.\n",
      "Tensors, in contrast to NumPy arrays, are optimized for parallel computing\n",
      "Embedding: [-0.04267265 -0.06152969 -0.06611483 -0.00277784 -0.01693855 -0.07211943\n",
      " -0.05807911 -0.04496985 -0.04483636 -0.02277483]...\n",
      "Sentence: They\n",
      "can efﬁciently distribute and run computations across GPUs and TPUs\n",
      "Embedding: [-0.08790441 -0.02403146 -0.04656481 -0.03484121 -0.01445762 -0.13812323\n",
      " -0.07723451  0.0095336   0.02121535  0.02303498]...\n",
      "Sentence: This\n",
      "allows for the simultaneous processing of multiple data points and operations,\n",
      "dramatically accelerating the training of large models\n",
      "Embedding: [-0.02065711 -0.07476193  0.0046689   0.03069022  0.03849703 -0.05927727\n",
      " -0.09670389 -0.06838003  0.04544954 -0.02693978]...\n",
      "Sentence: By leveraging the par-\n",
      "allelism of GPUs, tensors make it feasible to handle the complex, large-scale\n",
      "calculations that deep learning requires, signiﬁcantly improving efﬁciency and\n",
      "scalability.\n",
      "2\n",
      "Embedding: [-0.06793195 -0.08966346  0.00133852 -0.01568324 -0.01807356 -0.02746757\n",
      " -0.08860203 -0.04028528 -0.0841825  -0.06208521]...\n",
      "Sentence: Mutable: NumPy arrays are mutable, meaning that their values can be changed\n",
      "after they are created\n",
      "Embedding: [ 0.04431796 -0.02549497 -0.01294023 -0.03290882  0.00418205 -0.10124215\n",
      "  0.0242805  -0.09581161  0.0061407  -0.02050257]...\n",
      "Sentence: In TensorFlow, tensors are typically immutable but can\n",
      "by mutable as well\n",
      "Embedding: [ 0.02721716 -0.09084253 -0.00669749 -0.0534908   0.03069065 -0.06057302\n",
      "  0.01777788 -0.08896464  0.00379743 -0.06034681]...\n",
      "Sentence: If deﬁned as immutable, once created, their values cannot\n",
      "be changed\n",
      "Embedding: [-0.0441042   0.02734945 -0.05324357 -0.0062383  -0.08730486 -0.0194582\n",
      "  0.08311979 -0.05672028  0.04207528  0.00252194]...\n",
      "Sentence: This immutability is beneﬁcial for optimization in computational\n",
      "graphs of the deep neural network.\n",
      "3\n",
      "Embedding: [-0.07871062 -0.02597799  0.00997332 -0.04365383 -0.04032462  0.02111169\n",
      "  0.02251622 -0.05382295 -0.0449266  -0.04102923]...\n",
      "Sentence: Gradient Computation: Although NumPy is not inherently a deep learning\n",
      "library, it integrates well with various deep learning frameworks but lacks the\n",
      "ability to compute gradients, which are essential in training neural networks.\n",
      "TensorFlow’s tensors are fully integrated with the TensorFlow ecosystem, allow-\n",
      "ing for automatic differentiation, which is essential for backpropagation in neural\n",
      "network training.\n",
      "4\n",
      "Embedding: [-0.1005387  -0.09757575 -0.01792902 -0.05738652  0.02805069  0.00123278\n",
      " -0.04182251 -0.06472816 -0.06061307 -0.0642717 ]...\n",
      "Sentence: Eager Execution: It executes operations immediately (eager execution) in a\n",
      "procedural manner\n",
      "Embedding: [-0.0559105   0.08664358  0.02224889  0.03575266 -0.03540632 -0.11099275\n",
      " -0.02015205 -0.03536421 -0.00280823  0.05757658]...\n",
      "Sentence: TensorFlow supports both eager execution (like NumPy)\n",
      "and graph execution\n",
      "Embedding: [-0.07502327 -0.00981306  0.0147196   0.01567519  0.04001859 -0.07084096\n",
      " -0.11169977 -0.03273636 -0.06732475  0.03132507]...\n",
      "Sentence: In graph execution, operations are deﬁned as a part of a\n",
      "computational graph that can be optimized and run efﬁciently, which is a key\n",
      "feature for deep learning models.\n",
      "2.1\n",
      "Tensors and NumPy\n",
      "5\n",
      "5\n",
      "Embedding: [-0.05188456 -0.01650878  0.0194213  -0.00354379 -0.01717684 -0.09554575\n",
      " -0.05912473 -0.06857596 -0.06672622  0.02489497]...\n",
      "Sentence: Broadcasting: Both NumPy array and tensor support broadcasting\n",
      "Embedding: [ 0.01921921 -0.06171385 -0.03691731 -0.04342317  0.0888357   0.02026754\n",
      "  0.00857074 -0.11902867 -0.07224236 -0.02315498]...\n",
      "Sentence: Broadcasting\n",
      "is a mechanism that allows us to work with arrays of different shapes when\n",
      "performing arithmetic operations\n",
      "Embedding: [ 0.04478076  0.00997514 -0.05133393 -0.06581903 -0.08158613 -0.07098065\n",
      "  0.03781203 -0.07724033  0.07308995  0.00667353]...\n",
      "Sentence: Fundamentally, broadcasting automates the\n",
      "expansion of the smaller array so that it matches the shape of the larger array.\n",
      "For broadcasting to work, the size of the trailing dimensions of the arrays must\n",
      "either be the same or one of them must be one\n",
      "Embedding: [ 0.08221269  0.00274293 -0.04634638 -0.06792571  0.02449732 -0.00300789\n",
      "  0.04170365 -0.09106203  0.00407285 -0.01326721]...\n",
      "Sentence: If this condition is not met, a\n",
      "broadcasting error is raised\n",
      "Embedding: [ 0.01180493  0.00872653  0.06314575 -0.0078706   0.03241959  0.01314084\n",
      "  0.04215536 -0.0062357  -0.0009545   0.05318203]...\n",
      "Sentence: If the two arrays are suitable, broadcasting will stretch\n",
      "the dimensions of the two arrays to match, as shown in the following examples:\n",
      "2.1.1\n",
      "Array and Scalar\n",
      "When performing operations between an array and a scalar value, broadcasting\n",
      "allows the scalar to be “stretched” to match the shape of the array\n",
      "Embedding: [ 0.0318004  -0.01723686 -0.05514482 -0.06730812  0.0007661  -0.03429394\n",
      "  0.02561869 -0.06638183 -0.01297113 -0.09067098]...\n",
      "Sentence: Example:\n",
      "numpy_array + 3\n",
      "Embedding: [ 0.00678671 -0.00215989 -0.11555935 -0.03636443  0.03281746 -0.10335835\n",
      " -0.00731412 -0.09340819 -0.04468358  0.00454932]...\n",
      "Sentence: Here, the scalar 3 is broadcasted to the shape of numpy_array.\n",
      "2.1.2\n",
      "Arrays with Different Dimensions\n",
      "If one array has fewer dimensions than the other, it is padded with ones on its leading\n",
      "(left) side\n",
      "Embedding: [ 0.01029937 -0.05011162 -0.08005752 -0.02453097  0.04768387 -0.10108231\n",
      " -0.04353693 -0.11545161 -0.02100531 -0.07880107]...\n",
      "Sentence: Example: If A has shape (3, 5) and B has shape (5,), then B is treated as\n",
      "if it had the shape (1, 5)\n",
      "Embedding: [ 0.0293866   0.03179165  0.02612887 -0.02922103  0.02271704 -0.00239057\n",
      " -0.05586259 -0.13500708  0.01566239  0.01433001]...\n",
      "Sentence: During the operation, B is broadcasted to the shape (3, 5)\n",
      "by repeating the same row.\n",
      "2.1.3\n",
      "Arrays with the Same Number of Dimensions\n",
      "Broadcasting compares their shapes element-wise\n",
      "Embedding: [ 0.02698088 -0.0351456  -0.08097895 -0.07247572 -0.02694682 -0.06199186\n",
      "  0.01766867 -0.11395891  0.01277512 -0.03690924]...\n",
      "Sentence: A dimension of length 1 can be\n",
      "stretched to match the other shape\n",
      "Embedding: [-0.00728602 -0.01057446  0.01604897 -0.00783455  0.03979354 -0.02822456\n",
      " -0.0276734   0.02357055 -0.03803503 -0.11704492]...\n",
      "Sentence: Example: If A has shape (2, 3, 1) and B has\n",
      "shape (1, 3, 4), the shapes are compatible\n",
      "Embedding: [ 0.09570162 -0.06095406 -0.05632024 -0.08171403 -0.01567962  0.01285139\n",
      " -0.09274568 -0.10856619 -0.0443376  -0.09616929]...\n",
      "Sentence: They can be broadcasted to a common\n",
      "shape of (2, 3, 4).\n",
      "Even though tensors should be used for machine learning, there are occasions\n",
      "when NumPy arrays are needed, particularly when integrating TensorFlow-based\n",
      "models with data processing pipelines that utilize NumPy\n",
      "Embedding: [ 0.06177098 -0.11736676 -0.03527694 -0.0751912   0.04778605 -0.0305743\n",
      " -0.07975131 -0.14273173 -0.03159013 -0.07220846]...\n",
      "Sentence: Conversion between\n",
      "tensors and NumPy arrays is straightforward\n",
      "Embedding: [ 0.04538338 -0.0547601  -0.03654512 -0.02470639  0.03776401 -0.04442206\n",
      " -0.00979456 -0.1037458  -0.12281881 -0.04741653]...\n",
      "Sentence: To convert a NumPy array to a\n",
      "TensorFlow tensor, we can use tf.convert_to_tensor or simply pass a NumPy array\n",
      "to TensorFlow operations, as most of them can automatically convert NumPy arrays\n",
      "to tensors.\n",
      "The following is a sample code to convert a NumPy array to a tensor:\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "# Create a NumPy array\n",
      "numpy_array = np.array([1, 2, 3, 4, 5])\n",
      "6\n",
      "2\n",
      "Using Tensors\n",
      "# Convert to TensorFlow tensor\n",
      "tensor_from_numpy = tf.convert_to_tensor(numpy_array)\n",
      "# or simply\n",
      "tensor_from_numpy = tf.constant(numpy_array)\n",
      "To convert a TensorFlow tensor back to a NumPy array, we can use the .numpy()\n",
      "method of a tensor object\n",
      "Embedding: [ 0.06411189 -0.07485399 -0.02843292 -0.02300877 -0.00116487 -0.05723408\n",
      " -0.03774365 -0.05685717 -0.07457355 -0.03880781]...\n",
      "Sentence: This method is available if TensorFlow is executing in\n",
      "eager mode, which is the default mode since TensorFlow 2.0\n",
      "Embedding: [-0.02001054 -0.04709422  0.03423443  0.01826567  0.02726633 -0.01199164\n",
      " -0.03573976 -0.03540075 -0.08467206 -0.03734073]...\n",
      "Sentence: When converting\n",
      "between NumPy arrays and TensorFlow tensors, a deep copy is typically performed.\n",
      "This means the original and the converted objects do not share memory, and\n",
      "changing one will not affect the other\n",
      "Embedding: [ 0.02603852 -0.0557654  -0.06198716 -0.0004066   0.05758756 -0.1013173\n",
      " -0.05990658 -0.10689711 -0.04728369 -0.06151674]...\n",
      "Sentence: The .numpy() method for tensors is available\n",
      "in TensorFlow 2.x\n",
      "Embedding: [-0.01766687 -0.11263901 -0.01617681 -0.01735715  0.05058499 -0.00422819\n",
      " -0.09036511 -0.02931346 -0.07593483 -0.03925746]...\n",
      "Sentence: In TensorFlow 1.x, the conversion process is less straightforward\n",
      "as it involves running a session to evaluate the tensor.\n",
      "While converting, ensure that the data types are compatible; otherwise, an error\n",
      "will occur\n",
      "Embedding: [ 0.06055157 -0.09075844 -0.00900564 -0.02203479  0.06284521 -0.04628237\n",
      " -0.0370631  -0.03238467 -0.07112107 -0.06067048]...\n",
      "Sentence: TensorFlow has its own set of data types, but they are largely compatible\n",
      "with NumPy’s data types.\n",
      "The following is a sample code to convert a tensor to a NumPy array using a\n",
      "built-in method.\n",
      "# Create a TensorFlow tensor\n",
      "tensor = tf.constant([1, 2, 3, 4, 5])\n",
      "# Convert to NumPy array\n",
      "numpy_from_tensor = tensor.numpy()\n",
      "# numpy_from_tensor is now a NumPy array\n",
      "2.2\n",
      "Basic Tensor Operations\n",
      "2.2.1\n",
      "Creating Tensors\n",
      "import tensorflow as tf\n",
      "# Creating a constant tensor\n",
      "tensor_const = tf.constant([[1, 2], [3, 4]])\n",
      "# Creating a variable tensor\n",
      "tensor_var = tf.Variable([[1, 2], [3, 4]])\n",
      "2.2.2\n",
      "Mathematical Operations\n",
      "Mathematical Operations TensorFlow supports element-wise mathematical opera-\n",
      "tions, such as addition, subtraction, multiplication, and division.\n",
      "# Element-wise addition\n",
      "tensor_add = tf.add(tensor_const, tensor_var)\n",
      "2.2\n",
      "Basic Tensor Operations\n",
      "7\n",
      "2.2.3\n",
      "Reshaping Tensors\n",
      "Reshaping and slicing are crucial for preparing data for various types of neural\n",
      "network layers\n",
      "Embedding: [ 0.04702134 -0.10356274  0.01291646 -0.04318256 -0.01167414 -0.07693505\n",
      " -0.03019959 -0.05845056 -0.08215088 -0.04237966]...\n",
      "Sentence: It is important to understand this section well.\n",
      "Reshaping a tensor from one shape to another while keeping the total number of\n",
      "elements the same:\n",
      "import tensorflow as tf\n",
      "tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "reshaped_tensor = tf.reshape(tensor, [3, 2])\n",
      "# Original shape: (2, 3)\n",
      "# New shape: (3, 2)\n",
      "Flattening converts a tensor to a 1D tensor\n",
      "Embedding: [ 0.03991399 -0.08209322  0.03793209 -0.03014808  0.00150556 -0.05405941\n",
      " -0.04580372 -0.05716145 -0.04542807 -0.03898152]...\n",
      "Sentence: This is often used when transitioning\n",
      "from convolutional layers to dense layers within a neural network:\n",
      "flattened_tensor = tf.reshape(tensor, [-1])\n",
      "# Original shape: (2, 3)\n",
      "# New shape: (6,)\n",
      "Adding a dimension is useful for adding a batch dimension or expanding dimensions\n",
      "for compatibility with certain operations, like broadcasting\n",
      "Embedding: [-0.02219377 -0.08671387  0.01546016  0.01723255 -0.01593115  0.00183663\n",
      " -0.06057096 -0.00239145  0.00150253 -0.07551454]...\n",
      "Sentence: When feeding a neural\n",
      "network data, the ﬁrst dimension is the number of batches, so this operation is used\n",
      "very frequently:\n",
      "expanded_tensor = tf.expand_dims(tensor, axis=0)\n",
      "# Original shape: (2, 3)\n",
      "# New shape: (1, 2, 3)\n",
      "Removing dimensions of size 1\n",
      "Embedding: [ 0.01934235 -0.07826275  0.01316586  0.03822844 -0.03570407 -0.0069265\n",
      " -0.04808829 -0.00556802 -0.00968806 -0.06239323]...\n",
      "Sentence: This is often used after operations like\n",
      "tf.reduce_sum with keepdims=True:\n",
      "reduced_tensor = tf.reduce_sum(tensor, axis=1, keepdims=True)\n",
      "squeezed_tensor = tf.squeeze(reduced_tensor)\n",
      "# Original shape of reduced_tensor: (2, 1)\n",
      "# New shape after squeeze: (2,)\n",
      "Often used in sequence models like RNNs where the input needs to be reshaped into\n",
      "[batch_size, time steps, features]:\n",
      "sequence_tensor = tf.reshape(tensor, [1, 2, 3])\n",
      "# Original shape: (2, 3)\n",
      "# New shape: (1, 2, 3) - 1 batch, 2 time steps, 3 features\n",
      "In the context of convolutional neural networks (CNNs), channels refer to the\n",
      "different layers of information in an image\n",
      "Embedding: [-0.0534733  -0.0326662   0.01674557 -0.00098858 -0.00962658  0.00415216\n",
      " -0.03026033 -0.0125453   0.01882635 -0.07883125]...\n",
      "Sentence: For example, a typical color image\n",
      "has three channels: red, green, and blue (RGB)\n",
      "Embedding: [ 0.08670036 -0.11807482 -0.07650031 -0.12083381  0.02489239  0.00530567\n",
      "  0.03122961 -0.0552953   0.0747354  -0.02976021]...\n",
      "Sentence: Each channel contains data that\n",
      "represents the intensity of that color at every pixel in the image.\n",
      "8\n",
      "2\n",
      "Using Tensors\n",
      "When a CNN processes an image, it analyzes these channels separately to learn\n",
      "patterns and features\n",
      "Embedding: [ 0.03861024 -0.07020443  0.03454446 -0.05693138  0.04305691  0.02617991\n",
      "  0.04560538 -0.04318279 -0.03105197 -0.08499072]...\n",
      "Sentence: The terms “channel last” and “channel ﬁrst” describe how the\n",
      "image data is arranged in memory.\n",
      "Channel last is a format where the image data is stored as (height, width,\n",
      "channels), with the channels (such as RGB) being the last element\n",
      "Embedding: [ 0.11463904 -0.04357533 -0.0537669  -0.03299475  0.03245018  0.01481552\n",
      "  0.01660402  0.05695507  0.06025606 -0.0196303 ]...\n",
      "Sentence: Channel ﬁrst\n",
      "refers to the format where the data is organized as (channels, height, width),\n",
      "meaning the channels come ﬁrst in the sequence.\n",
      "To switch between these formats, a technique called transposing is used, which\n",
      "rearranges the order of the dimensions\n",
      "Embedding: [ 0.05432506 -0.04033655 -0.0314644  -0.04505929 -0.07911886 -0.01352992\n",
      "  0.0021831   0.03398392  0.00924246 -0.02458432]...\n",
      "Sentence: This step is often necessary when working\n",
      "with different machine learning frameworks that use different conventions for\n",
      "handling image data:\n",
      "transposed_tensor = tf.transpose(tensor, perm=[1, 0])\n",
      "# Original shape: (2, 3)\n",
      "# New shape after transpose: (3, 2)\n",
      "The parameter perm=[1, 0] deﬁnes the new order of the dimensions\n",
      "Embedding: [ 0.06557399 -0.08659168  0.02717537 -0.04310556 -0.01166313 -0.04252315\n",
      " -0.06423341 -0.05287611 -0.03854934 -0.00765492]...\n",
      "Sentence: In TensorFlow,\n",
      "dimensions are indexed starting from 0\n",
      "Embedding: [ 0.07050941 -0.06247132  0.01357282  0.04811892  0.00071922  0.00791984\n",
      " -0.0146216  -0.04207141  0.04251288 -0.09671718]...\n",
      "Sentence: So, in a 2D tensor (like a matrix), 0 refers\n",
      "to the rows, and 1 refers to the columns.\n",
      "perm=[1, 0] means that the ﬁrst dimension of the transposed tensor should be\n",
      "the second dimension (columns) of the original tensor, and the second dimension\n",
      "of the transposed tensor should be the ﬁrst dimension (rows) of the original tensor.\n",
      "The tf.transpose operation rearranges the tensor according to the perm parameter.\n",
      "Essentially, it switches the rows and columns of the tensor.\n",
      "For example, if we have the following 2D tensor:\n",
      "[[1, 2, 3], [4, 5, 6]]\n",
      "After applying tf.transpose(tensor, perm=[1, 0]), the tensor would be rearranged\n",
      "to\n",
      "[[1, 4], [2, 5], [3, 6]]\n",
      "For more complex neural network architectures, we might need to perform\n",
      "custom reshaping:\n",
      "complex_tensor = tf.reshape(tensor, [3, -1, 1])\n",
      "# Original shape: (2, 3)\n",
      "# New shape: (3, 1, 1) - unspecified middle dimension\n",
      "[3, –1, 1]: This is the new shape we want to give to the tensor\n",
      "Embedding: [ 0.02695465 -0.10118753 -0.01740896 -0.01707872 -0.03040756 -0.01934788\n",
      " -0.0713807  -0.00573456 -0.03009579 -0.03767649]...\n",
      "Sentence: Here’s what each\n",
      "element in this shape array represents:\n",
      "3: The ﬁrst dimension of the reshaped tensor will have a size of 3.\n",
      "–1: This is a special value in TensorFlow’s reshape operation\n",
      "Embedding: [ 0.03035003 -0.03724862 -0.0148823   0.0050891   0.00782826 -0.01634574\n",
      " -0.01118273 -0.03934524 -0.0312998  -0.09369392]...\n",
      "Sentence: When we specify\n",
      "–1 for a dimension, TensorFlow automatically calculates the size of the second\n",
      "dimension based on the total size of the tensor and the size of the other dimensions.\n",
      "It ensures that the total number of elements in the reshaped tensor is the same as the\n",
      "original tensor\n",
      "Embedding: [-0.01050054 -0.07414944  0.04009385  0.02043629  0.04044625 -0.03512159\n",
      " -0.0380455  -0.03581568  0.01897056 -0.09585336]...\n",
      "Sentence: This is very useful when we are not sure about the size of a particular\n",
      "dimension, but we know the sizes of the other dimensions.\n",
      "2.3\n",
      "Parallelism\n",
      "9\n",
      "1: The third dimension of the reshaped tensor will have a size of 1.\n",
      "For example:\n",
      "[[1, 2], [3, 4], [5, 6]]\n",
      "This is a tensor of shape (3,2) with three rows and two columns\n",
      "Embedding: [ 0.0026495  -0.09256856 -0.03777863 -0.04062358  0.02928635 -0.0094808\n",
      " -0.09985846 -0.01054011 -0.03602965 -0.05695715]...\n",
      "Sentence: After applying\n",
      "tf.reshape(tensor, [3, –1, 1]), the tensor would be reshaped to [[[1]], [[2]], [[3]], [[4]],\n",
      "[[5]], [[6]]]\n",
      "which is (6,1,1)\n",
      "Embedding: [ 0.04228465 -0.06715447 -0.00645769 -0.06590276  0.00764819 -0.02492156\n",
      " -0.00736933 -0.06327097 -0.05395757 -0.03695556]...\n",
      "Sentence: The reshape function kept the original number of elements 3 ×\n",
      "2 =6 and created a 3D tensor with the last dimension size one as required.\n",
      "2.3\n",
      "Parallelism\n",
      "Achieving maximum parallelism in TensorFlow generally involves leveraging its\n",
      "built-in capabilities for distributed computing and optimizing our code to utilize\n",
      "the available hardware resources effectively\n",
      "Embedding: [-0.0462148  -0.0639718  -0.0549591  -0.04315145 -0.01239463 -0.06603429\n",
      " -0.09056585 -0.02451298 -0.03978968 -0.03385286]...\n",
      "Sentence: This means using the built-in tensor\n",
      "operations as much as possible and avoiding manual computations\n",
      "Embedding: [-0.06697198 -0.00330401 -0.03167209  0.00364501 -0.07301254 -0.04785035\n",
      " -0.08064713 -0.04974304 -0.04648394 -0.02100094]...\n",
      "Sentence: For example,\n",
      "use Tensor matrix multiplication instead of writing a loop to perform element-wise\n",
      "multiplication\n",
      "Embedding: [-0.02854293 -0.01015913 -0.10014324 -0.00840252 -0.09590163 -0.09602419\n",
      " -0.01282256 -0.01910305 -0.03263886 -0.03219481]...\n",
      "Sentence: Similarly, it pays to spend time thinking about how to manipulate\n",
      "arrays using TensorFlow rather than writing our own code\n",
      "Embedding: [-0.00774407 -0.05138256 -0.04266569  0.01596626  0.00277386 -0.07930627\n",
      " -0.03532952 -0.01838553  0.05684931 -0.02150398]...\n",
      "Sentence: TensorFlow is optimized\n",
      "to run these operations efﬁciently, often leveraging parallelism on available hard-\n",
      "ware, such as GPUs or TPUs.\n",
      "For example, batch matrix multiplication is a common operation in deep learning.\n",
      "TensorFlow’s tf.matmul or tf.linalg.matmul function can be used to perform matrix\n",
      "multiplications in parallel across batches:\n",
      "# Create two batched tensors of shape (batch_size, n, m)\n",
      "# and (batch_size, m, p)\n",
      "batch_tensor1 = tf.random.normal([64, 10, 20])\n",
      "batch_tensor2 = tf.random.normal([64, 20, 30])\n",
      "# Batch matrix multiplication\n",
      "result_batch_matmul = tf.matmul(batch_tensor1, batch_tensor2)\n",
      "# TensorFlow will perform these matrix multiplications\n",
      "# in parallel across the batch\n",
      "Achieving maximum parallelism in TensorFlow also involves leveraging its built-\n",
      "in capabilities for distributed computing and optimizing our code to utilize the\n",
      "available hardware resources effectively\n",
      "Embedding: [-0.01727219 -0.05221172 -0.09529725 -0.02798175 -0.03892628 -0.10522817\n",
      " -0.05544093 -0.05012432 -0.01341694 -0.03295372]...\n",
      "Sentence: Here are some steps and code examples\n",
      "to help write TensorFlow code for maximum parallelism:\n",
      "1\n",
      "Embedding: [-0.0140115  -0.10006242 -0.04619328 -0.09049071 -0.01987031 -0.01100945\n",
      " -0.07346208 -0.02357921 -0.14045054 -0.03723468]...\n",
      "Sentence: Using Distributed Strategies\n",
      "TensorFlow offers several distributed strategies to parallelize the com-\n",
      "putation\n",
      "Embedding: [ 0.00579766 -0.10085929 -0.01287836 -0.06344446 -0.01981574  0.0233149\n",
      " -0.06522621 -0.04307976 -0.03910359 -0.03616499]...\n",
      "Sentence: The simplest one for single-machine, multi-GPU setups is the\n",
      "tf.distribute.MirroredStrategy\n",
      "Embedding: [-0.00156444 -0.07335597 -0.03094131 -0.04273033 -0.0455534  -0.10060094\n",
      " -0.1226009   0.02707778 -0.11794369 -0.02123669]...\n",
      "Sentence: Here’s an example of how to use it:\n",
      "10\n",
      "2\n",
      "Using Tensors\n",
      "import tensorflow as tf\n",
      "# Define the distribution strategy\n",
      "strategy = tf.distribute.MirroredStrategy()\n",
      "# Apply the strategy to a model creation\n",
      "with strategy.scope():\n",
      "model = tf.keras.Sequential([\n",
      "tf.keras.layers.Dense(512, activation=’relu’),\n",
      "tf.keras.layers.Dense(10, activation=’softmax’)\n",
      "])\n",
      "model.compile(optimizer=’adam’,\n",
      "loss=’sparse_categorical_crossentropy’,\n",
      "metrics=[’accuracy’])\n",
      "...\n",
      "2\n",
      "Embedding: [ 0.00083756 -0.13707872 -0.01978594 -0.08918279 -0.0876231   0.04052818\n",
      " -0.06440897 -0.01326212 -0.11460567 -0.06941418]...\n",
      "Sentence: Optimize Data Input Pipeline\n",
      "To ensure that the data input pipeline does not become a bottleneck, use\n",
      "the tf.data API for efﬁcient data loading and preprocessing\n",
      "Embedding: [ 0.01572548 -0.00118598 -0.03634776 -0.03954403 -0.0451468  -0.09773122\n",
      " -0.05360474  0.01348678 -0.04806926  0.00198165]...\n",
      "Sentence: Caching with\n",
      "AUTOTUNE is used frequently, although, in some cases, this does not work\n",
      "100% correctly, and some other methods need to be substituted.\n",
      "# Create a dataset\n",
      "dataset = tf.data.Dataset.from_tensor_slices(\n",
      "train_images, train_labels)\n",
      "# Parallelize data preprocessing\n",
      "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
      "dataset = dataset.cache().shuffle(1000).batch(64).\n",
      "prefetch(buffer_size=AUTOTUNE)\n",
      "3\n",
      "Embedding: [-0.00793822 -0.0547548  -0.04112187 -0.00835797 -0.03828287 -0.02996754\n",
      "  0.01438459  0.0046221  -0.07741802 -0.0572935 ]...\n",
      "Sentence: Utilize GPUs Efﬁciently\n",
      "Ensure that TensorFlow is set up to use GPUs\n",
      "Embedding: [-0.02522283 -0.05804802 -0.03574952  0.02896528 -0.00285662 -0.03226797\n",
      " -0.01668452 -0.05785495 -0.05373444 -0.08353177]...\n",
      "Sentence: TensorFlow will automatically\n",
      "distribute operations across available GPUs unless explicitly directed otherwise.\n",
      "# Check if GPUs are available\n",
      "print(\"Num GPUs Available: \",\n",
      "len(tf.config.experimental.list_physical_devices(’GPU’)))\n",
      "# TensorFlow will automatically use GPU if available\n",
      "2.4\n",
      "Machine Learning Environment\n",
      "These are my personal preferences when setting up a machine learning (ML)\n",
      "environment\n",
      "Embedding: [ 0.05581091 -0.10447874 -0.02309164  0.0171584   0.04526213 -0.06999654\n",
      " -0.05350174 -0.08813671 -0.04301264 -0.04553093]...\n",
      "Sentence: If you are familiar or happy with your current setup, then please feel\n",
      "free not to follow the setup below:\n",
      "2.4\n",
      "Machine Learning Environment\n",
      "11\n",
      "1\n",
      "Embedding: [-0.03165868 -0.07346494  0.03767337 -0.02554043  0.0385585   0.0025098\n",
      " -0.10505888 -0.09969934 -0.14878395 -0.04114209]...\n",
      "Sentence: Hardware Requirements\n",
      "CPU: Buy the fastest CPU with maximum RAM\n",
      "Embedding: [ 0.00966651  0.05258271 -0.03068071 -0.02425885 -0.03626161 -0.01453172\n",
      "  0.00375101  0.02000583 -0.07642205 -0.03149639]...\n",
      "Sentence: You should have at least 16 GB\n",
      "but ideally 32 GB or more\n",
      "Embedding: [ 0.07486451 -0.0202756  -0.05462963 -0.0611159   0.02159518  0.01538041\n",
      " -0.07277081  0.05125943 -0.00420484  0.04262268]...\n",
      "Sentence: GPU Support: For more intensive tasks, a GPU can\n",
      "signiﬁcantly accelerate the training of machine learning models\n",
      "Embedding: [-0.05375715 -0.1036163  -0.00478458  0.03373122  0.07154015 -0.03963112\n",
      " -0.09813698 -0.07874817 -0.0953512  -0.07767563]...\n",
      "Sentence: NVIDIA GPUs\n",
      "are widely supported\n",
      "Embedding: [-0.03347102 -0.04014922 -0.02315963 -0.00974113  0.01528084 -0.00251933\n",
      " -0.07824528  0.01904251 -0.04706907 -0.04220663]...\n",
      "Sentence: Ensure you have a CUDA-compatible GPU with a rating\n",
      "of 8+ and a minimum of 16 GB\n",
      "Embedding: [ 0.04878381 -0.04946113 -0.02244882 -0.00866751  0.00730505 -0.05095221\n",
      " -0.13679236 -0.01483419 -0.04498922 -0.02277364]...\n",
      "Sentence: However, my RTX 3080 graphics card only has\n",
      "12 GB.\n",
      "2\n",
      "Embedding: [ 0.08061165  0.01663762 -0.05753661  0.01254276  0.00375065 -0.09209226\n",
      " -0.00777935  0.01143981  0.01801968 -0.00377473]...\n",
      "Sentence: Operating System\n",
      "TensorFlow is compatible with Windows, macOS, and Linux\n",
      "Embedding: [ 0.01122162 -0.11365426 -0.01073114 -0.02549561  0.04997748  0.00218701\n",
      " -0.05922148 -0.02520829 -0.05192759 -0.09843225]...\n",
      "Sentence: Although Win-\n",
      "dows is the most popular, using GPUs with it can be challenging due to the\n",
      "deprecation of certain libraries\n",
      "Embedding: [-0.10229676 -0.04976147 -0.06810909 -0.02810933  0.02946932 -0.03198333\n",
      " -0.03932477  0.05313731 -0.06621753 -0.00882337]...\n",
      "Sentence: Linux, especially Ubuntu is often preferred for\n",
      "deep learning tasks due to better support for GPUs and ease of environment setup.\n",
      "3\n",
      "Embedding: [-0.01764911 -0.1264965  -0.00514472 -0.02744773  0.03894901 -0.03607569\n",
      " -0.10569428  0.06422942 -0.01548464 -0.02248292]...\n",
      "Sentence: TensorFlow Installation:\n",
      "Install TensorFlow using pip: pip install tensorﬂow\n",
      "Embedding: [ 0.04114626 -0.10450262  0.02172046  0.02067335  0.00606     0.03530168\n",
      "  0.00078992 -0.04918195 -0.04944206 -0.06065614]...\n",
      "Sentence: This command installs the\n",
      "latest version\n",
      "Embedding: [ 0.0071309   0.01262668 -0.03257452 -0.06704637  0.07753295 -0.06757612\n",
      "  0.03084896 -0.02529157 -0.03814619 -0.00076623]...\n",
      "Sentence: If you have a compatible NVIDIA GPU, install the GPU version\n",
      "using pip install tensorﬂow-gpu\n",
      "Embedding: [ 0.03909833 -0.08222523 -0.01226283  0.00071904  0.01406306 -0.03101399\n",
      " -0.1283536  -0.01147365 -0.1054649  -0.05991701]...\n",
      "Sentence: I use pip for all packages in this book, but it\n",
      "could also be done using Conda.\n",
      "4\n",
      "Embedding: [ 0.01336844 -0.05649619 -0.07997947 -0.07305052 -0.0060648  -0.05364855\n",
      " -0.03867583  0.04896745 -0.08069615  0.03392841]...\n",
      "Sentence: Integrated Development Environment (IDE)\n",
      "Use an IDE or text editor that you’re comfortable with\n",
      "Embedding: [ 0.02155557 -0.01885279  0.0133997   0.00940426  0.0366588  -0.07185256\n",
      " -0.01369495  0.10881482  0.00927645  0.04596271]...\n",
      "Sentence: Popular choices include\n",
      "Jupyter Notebook (great for experiments and visualization) or PyCharm\n",
      "Embedding: [-0.0314467  -0.05741152  0.00603552 -0.00326359  0.01379826 -0.0184383\n",
      " -0.09131268  0.05846951  0.01490508  0.05836515]...\n",
      "Sentence: I ﬁnd\n",
      "PyCharm community, which is free, is adequate for learning purposes.\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "The Universal Approximation Theorem, ﬁrst demonstrated by George Cybenko in\n",
      "1989 and later reﬁned by Kurt Hornik in 1991, forms the theoretical foundation\n",
      "of machine learning\n",
      "Embedding: [-0.11939109 -0.10089     0.02228641 -0.01221961 -0.02120899  0.03805117\n",
      " -0.02821435  0.02623644 -0.05820633  0.0551266 ]...\n",
      "Sentence: This theorem states that a feedforward neural network with a\n",
      "single hidden layer can approximate any continuous function to arbitrary precision,\n",
      "given the right activation function and a sufﬁcient number of neurons in the hidden\n",
      "layer.\n",
      "The important consequence of the theorem is that a machine can theoretically\n",
      "learn to produce almost any output from the input set of data\n",
      "Embedding: [-1.29312426e-01 -5.97312227e-02  1.66092273e-02  5.48211075e-02\n",
      "  1.27914995e-02  7.48435706e-02  8.83385260e-03 -3.18372995e-02\n",
      "  4.17621668e-05  1.48700401e-02]...\n",
      "Sentence: Even in the cases of\n",
      "discontinuous functions, the neural network can still learn an approximation of the\n",
      "function.\n",
      "Understanding how a machine learns is the key to understand how to create\n",
      "applications that can solve complex problems\n",
      "Embedding: [-0.06369559 -0.04434953  0.02995831  0.04659799 -0.01013906 -0.02561193\n",
      " -0.02309241  0.00102276  0.0157283  -0.0213435 ]...\n",
      "Sentence: A machine learning algorithm is\n",
      "different from a classical algorithm.\n",
      "Instead of explicitly deﬁning rules or logic to produce an output from input data,\n",
      "a machine learning algorithm learns the underlying patterns by itself\n",
      "Embedding: [-0.02850554 -0.02191308 -0.0094627   0.00677889  0.01236983 -0.07185532\n",
      " -0.09781609 -0.0522867  -0.06186397  0.01478108]...\n",
      "Sentence: The algorithm\n",
      "takes a set of input and corresponding output samples, then iteratively adjusts its\n",
      "internal parameters to minimize the difference between its predicted output and the\n",
      "actual output\n",
      "Embedding: [-0.09391252  0.00259221 -0.04957343  0.00829846  0.02356421 -0.07894568\n",
      " -0.05537817 -0.0138653  -0.04438942 -0.04701147]...\n",
      "Sentence: This process of minimizing the error or “loss” allows the algorithm\n",
      "to automatically discover the rules or logic needed to generate the desired results,\n",
      "without the programmer needing to specify them manually.\n",
      "To make this idea concrete, let’s take the following example\n",
      "Embedding: [-0.04311555  0.11788893  0.01331638  0.06156184  0.05624361 -0.03334867\n",
      " -0.023986    0.03396091  0.02521082  0.01348066]...\n",
      "Sentence: Suppose we are\n",
      "presented with a set of input numbers, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, and the\n",
      "corresponding set of output numbers, 0, 1, 4, 9, 16, 25, 36, 49, 64, 81, and 100.\n",
      "The task is to predict the output number for an input number of 11.\n",
      "Normally, one would write the following function to solve this problem in\n",
      "Python:\n",
      "def predict(x): return x*x\n",
      "print(’output=’,predict(11))\n",
      "output= 121\n",
      "© Philip Hua 2024\n",
      "P\n",
      "Embedding: [-0.04887163  0.01516466 -0.04908896 -0.01576517 -0.01016685 -0.00828805\n",
      "  0.02662831  0.01231935 -0.06040934 -0.03393241]...\n",
      "Sentence: Hua, Neural Networks with TensorFlow and Keras,\n",
      "https://doi.org/10.1007/979-8-8688-1020-6_3\n",
      "15\n",
      "16\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "In this example, we guess from the list of input and output numbers that the correct\n",
      "mapping function may be x →x2\n",
      "Embedding: [-0.01345133 -0.12464036  0.03971429 -0.02102316 -0.00958523  0.00700196\n",
      "  0.00259946 -0.04935959 -0.04337411 -0.03017596]...\n",
      "Sentence: In this speciﬁc case, identifying the correct\n",
      "function was an educated guess\n",
      "Embedding: [-0.03356969  0.09272636  0.00702902  0.0135009  -0.01105337 -0.02272933\n",
      "  0.0365281   0.04889596 -0.00101136  0.07497677]...\n",
      "Sentence: Had we use machine learning, the machine would\n",
      "learn that the correct mapping might be x →x2\n",
      "Embedding: [ 0.02426961 -0.05495718  0.0415298  -0.05481648 -0.04265868 -0.0705664\n",
      " -0.04850525 -0.07323154 -0.00926461 -0.00889393]...\n",
      "Sentence: The deduction process, however,\n",
      "would be more general and would take the following form:\n",
      "•\n",
      "Create and conﬁgure a neural network as “supervised learning.”\n",
      "•\n",
      "Feed the neural network with the corresponding pairs of input and output\n",
      "numbers\n",
      "Embedding: [-0.08093132 -0.01694179  0.00577982  0.00271572  0.01348334  0.03887787\n",
      " -0.04932631 -0.02121911 -0.0514968   0.02980393]...\n",
      "Sentence: For example, {0,0},{1,1},{2,4},\n",
      "Embedding: [ 0.10240668 -0.01816052 -0.07167856 -0.03741618 -0.01583602 -0.0021765\n",
      " -0.07020865 -0.10558797  0.03766795 -0.04624242]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: .,{10,100}.\n",
      "•\n",
      "Train the neural network.\n",
      "•\n",
      "Use the trained neural network to predict the output using 11 as an input.\n",
      "To further differentiate between traditional and machine learning algorithms, let’s\n",
      "extend this example by adding another set of data to the problem above\n",
      "Embedding: [-0.03869303  0.04857423 -0.05505451 -0.04667795 -0.03150323  0.02696848\n",
      " -0.02374083  0.00024122 -0.04530997 -0.05642044]...\n",
      "Sentence: Let’s say\n",
      "that we have another set of data so that\n",
      "Dataset 1: {0,1,2,3,4,5,6,7,8,9} →{0,1,4,9,16,25,36,49,64,81}\n",
      "Dataset 2: {0,1,2,3,4,5,6,7,8} →{0,1,8,27,64,125,216,343,512}\n",
      "This problem is now a lot more interesting\n",
      "Embedding: [-0.04220085  0.02800335  0.03622621 -0.03178507  0.03614085 -0.04544631\n",
      " -0.00856031 -0.05895283 -0.05223444 -0.01381302]...\n",
      "Sentence: The function y = x2 ﬁts the ﬁrst\n",
      "dataset perfectly, while the second dataset has the mapping of the form y = x3.\n",
      "The graphs of y = x3 and y = x2 are shown in Figure 3-1\n",
      "Embedding: [ 0.01312621 -0.05234932 -0.05994778 -0.08415652  0.00644701 -0.07742383\n",
      " -0.01026894 -0.01145118 -0.03215167 -0.05989999]...\n",
      "Sentence: If we have to modify\n",
      "our predict function above to ﬁt both datasets, we may decide on a curve between\n",
      "y = x3 and y = x2 which may be of the form y = xn, where n is to be decided.\n",
      "Clearly, whichever parameter n is chosen, we cannot ﬁt both curves at the same\n",
      "time, so a decision has to be made how to select n to give the “best” curve.\n",
      "Figure 3-1 y = x3 and y = x2\n",
      "3.1\n",
      "Components of a Neural Network\n",
      "17\n",
      "One possible idea is to choose n to ﬁt between the two curves to minimize the\n",
      "differences (or the error) between the chosen function at x = {1, 2, \n",
      "Embedding: [-0.03186043 -0.07307117 -0.00032858 -0.02912593  0.00280273  0.0101575\n",
      " -0.01056693  0.01970467 -0.00997248 -0.0946505 ]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: , 10} to the\n",
      "two curves y = x3 and y = x2.\n",
      "A similar process takes place in our machine learning algorithm\n",
      "Embedding: [-0.05130161 -0.08848058 -0.06992567 -0.03451451  0.02780925 -0.07512803\n",
      " -0.03905253 -0.02277778 -0.01074185 -0.04640992]...\n",
      "Sentence: At a high\n",
      "level, a neural network can be considered a universal function approximator; it\n",
      "can approximate any given mathematical function using layers of computational\n",
      "“nodes” or “neurons.” These nodes interact with each other to produce a function\n",
      "which would match the output values as much as possible from the set of input data.\n",
      "It does this by updating the weight of each node to reduce the value of the error\n",
      "function in a similar vein to what we have to do in our traditional algorithm\n",
      "Embedding: [-0.07887065 -0.00968949  0.03419043 -0.0200637  -0.05384691 -0.02105011\n",
      " -0.05178139 -0.00638246  0.02030125 -0.04901613]...\n",
      "Sentence: The\n",
      "main difference is that the process of choosing the weights for the nodes is iterative.\n",
      "The system updates the weights for the nodes iteratively for each pair of input and\n",
      "output data, {0, 0}, {1, 1}, {2, 4}..{10, 100} and {0, 0}, {1, 1}, {2, 8}, ..{10, 1000}.\n",
      "Well, that is the theory anyway\n",
      "Embedding: [-0.05513822 -0.00370662 -0.05252674 -0.00608139  0.05120769 -0.04868361\n",
      " -0.0493179   0.00770729  0.02157565 -0.04224151]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: In practice, if we execute the code written in\n",
      "Keras using a simple neural network to solve the problem above, we will need to\n",
      "supply the model with many data points before it could approximate the function\n",
      "closely (Code 3-1).\n",
      "The results from the neural network are shown in Figure 3-2 For the time being,\n",
      "there is no need to worry about the details of the code\n",
      "Embedding: [-0.06056957 -0.04497918  0.00648555 -0.05282921 -0.04940885 -0.0416113\n",
      " -0.1206927  -0.01797351 -0.01935129 -0.02486916]...\n",
      "Sentence: Simply note that setting up\n",
      "and training a network in Python requires only a few lines of code\n",
      "Embedding: [-0.00409108 -0.04920591 -0.02222706  0.03681164 -0.06045306 -0.06036685\n",
      " -0.05135497  0.00756721 -0.1264232  -0.06162858]...\n",
      "Sentence: Also, note that the\n",
      "network will initially approximate a problem with straight lines; the reason for this\n",
      "will become apparent when we examine the internal structure later on\n",
      "Embedding: [-0.09132653 -0.06990681  0.04888056  0.00240048 -0.01378202 -0.12602244\n",
      " -0.13277824  0.00888451  0.03877154 -0.03085174]...\n",
      "Sentence: Of course,\n",
      "the power of machine learning is not limited to numerically approximating a simple\n",
      "function\n",
      "Embedding: [-0.0551335  -0.00981237  0.02680774  0.00824283 -0.00182042 -0.08272035\n",
      " -0.14135066 -0.0075769  -0.03195862  0.03956578]...\n",
      "Sentence: At a high level, the neural network has just been trained to ﬁnd something\n",
      "“similar” to the input data\n",
      "Embedding: [-0.05770919 -0.06865365  0.00431625  0.0234032   0.0274893   0.04654014\n",
      " -0.0789341  -0.05017021  0.00358104 -0.10400152]...\n",
      "Sentence: As long as we can express the problem numerically, the\n",
      "same procedure can be used to classify images, text, sounds, translate languages, etc.\n",
      "We may have to use different neural network topologies to solve speciﬁc problems,\n",
      "but it does not invalidate the idea of using a universal numerical approximator as a\n",
      "“learner.”\n",
      "3.1\n",
      "Components of a Neural Network\n",
      "This section delves into the intricate components that constitute a neural network.\n",
      "We wish to understand each element’s role and how they collectively contribute to\n",
      "the network’s ability to learn from data and make intelligent predictions or decisions.\n",
      "Our exploration will cover the architecture of neurons and the building blocks of\n",
      "neural networks and extend to the various layers and connections that form these\n",
      "complex systems.\n",
      "We will dissect the core components, including input layers that receive data,\n",
      "hidden layers that perform computations, and output layers that provide the ﬁnal\n",
      "decision or prediction\n",
      "Embedding: [-0.06191447 -0.0937191   0.02264092 -0.0494635  -0.03036579  0.00563881\n",
      " -0.02251103 -0.02414227 -0.00635195 -0.06241076]...\n",
      "Sentence: We will also shed light on the weights and biases, crucial\n",
      "parameters that the network adjusts during training to improve its performance.\n",
      "Additionally, we will examine activation functions, which introduce nonlinear\n",
      "properties essential for the network’s ability to solve complex problems.\n",
      "18\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "Code 3-1 Approximating y = x2 code\n",
      "Furthermore, we will discuss the signiﬁcance of network architecture and\n",
      "how different designs can be tailored to speciﬁc types of problems, from simple\n",
      "binary classiﬁcations to intricate tasks, like image recognition and natural language\n",
      "processing\n",
      "Embedding: [-0.02681331 -0.08327643  0.01806713  0.00536315 -0.04582267 -0.02150068\n",
      " -0.01053846 -0.02702621 -0.03980269 -0.04156788]...\n",
      "Sentence: We will explore how these components are trained using algorithms like\n",
      "backpropagation and optimized through methods such as gradient descent.\n",
      "This section is designed to provide a comprehensive understanding of the\n",
      "components of a neural network, laying a solid foundation for grasping how these\n",
      "3.1\n",
      "Components of a Neural Network\n",
      "19\n",
      "Figure 3-2 Approximating y = x2 using a neural network\n",
      "extraordinary systems function and are engineered to tackle some of the most\n",
      "challenging problems.\n",
      "3.1.1\n",
      "Neurons: The Building Blocks\n",
      "At the core of a neural network are its neurons\n",
      "Embedding: [ 0.00623351 -0.11119676 -0.00830255 -0.0039499   0.00724177  0.02872506\n",
      "  0.02064934 -0.02389144 -0.03381017 -0.08424532]...\n",
      "Sentence: These artiﬁcial neurons are inspired\n",
      "by the biological transmitters and receptors found in the human brain and play\n",
      "a pivotal role in processing and transmitting information within the network\n",
      "Embedding: [ 0.0077886  -0.07535724 -0.01281319 -0.02241298 -0.02842952  0.05215582\n",
      "  0.07465329 -0.00668528  0.11081721  0.018248  ]...\n",
      "Sentence: In\n",
      "a typical neural network, particularly for image processing, we may encounter\n",
      "hundreds of thousands or millions of these neurons\n",
      "Embedding: [ 0.02660114 -0.07190587  0.00146199 -0.02213485  0.01527642 -0.00772205\n",
      " -0.00570437 -0.00954929  0.11194948 -0.00217758]...\n",
      "Sentence: Although each neuron can\n",
      "be thought of as the basic computing unit in a neural network, we rarely discuss\n",
      "individual neurons as such\n",
      "Embedding: [-0.0137969  -0.11346336 -0.02021424 -0.02178572 -0.04609323 -0.04207081\n",
      "  0.00843343 -0.04204646  0.06477734 -0.02728758]...\n",
      "Sentence: Instead, we concentrate on getting the correct weights\n",
      "and bias terms of all the neurons in the network simultaneously:\n",
      "•\n",
      "Input Weights: Neurons receive multiple inputs from other neurons or external\n",
      "data sources\n",
      "Embedding: [-0.04503321 -0.09031688 -0.00949481 -0.02420336 -0.01305444  0.045449\n",
      "  0.02143199 -0.04723132  0.08649065 -0.00877905]...\n",
      "Sentence: These inputs are not processed equally; instead, they are associated\n",
      "20\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "with individual weights\n",
      "Embedding: [-0.00579558 -0.10450444 -0.00618991  0.01160736 -0.01602357 -0.00855326\n",
      " -0.03153929 -0.05420505  0.05479113 -0.06042108]...\n",
      "Sentence: These weights determine the strength of the connections\n",
      "between neurons\n",
      "Embedding: [-0.04746046 -0.09399047 -0.03925691  0.00016108 -0.07149631  0.02583155\n",
      "  0.05644328  0.02366885  0.0788928  -0.01099526]...\n",
      "Sentence: During training, the network adjusts these weights to learn and\n",
      "adapt to the underlying patterns in the data.\n",
      "•\n",
      "Activation Function: After receiving weighted inputs, a neuron applies an acti-\n",
      "vation function\n",
      "Embedding: [-0.04354182 -0.03210252  0.03500926  0.01946193 -0.0339434   0.0437807\n",
      "  0.06009513 -0.03315768  0.07544458 -0.0188969 ]...\n",
      "Sentence: This function introduces nonlinearity into the neural network,\n",
      "enabling it to capture complex relationships within the data\n",
      "Embedding: [-0.12352286 -0.03632909 -0.00765507 -0.00539867 -0.03428959  0.03154318\n",
      " -0.03911005 -0.07968904 -0.00035992 -0.04978174]...\n",
      "Sentence: Activation functions\n",
      "transform the neuron’s input into an output value, which is then passed on to\n",
      "subsequent neurons\n",
      "Embedding: [-0.03828983 -0.01862824  0.01737263  0.01393367 -0.03803277  0.05781321\n",
      "  0.05114628 -0.05094377  0.08630601  0.01920916]...\n",
      "Sentence: Common activation functions include the sigmoid function,\n",
      "hyperbolic tangent (tanh), and rectiﬁed linear unit (ReLU).\n",
      "•\n",
      "Bias Term: In addition to input weights and activation functions, each neuron\n",
      "typically includes a bias term\n",
      "Embedding: [-0.04423782 -0.11049867  0.02115148 -0.0902027  -0.00392052  0.0434358\n",
      "  0.05745115  0.00489922  0.03307692  0.0372201 ]...\n",
      "Sentence: The bias term allows the network to account\n",
      "for possible offsets or biases in the data\n",
      "Embedding: [-0.03505471 -0.02817098 -0.02042468  0.00616898  0.08994785  0.03987241\n",
      " -0.01296105 -0.04659825  0.09455194 -0.00677945]...\n",
      "Sentence: It provides ﬂexibility by allowing the\n",
      "network to ﬁt the data more accurately.\n",
      "A stylized diagram for a neuron is shown in Figure 3.1.1\n",
      "Embedding: [-0.04053817 -0.07539777  0.01342859 -0.00081544 -0.02816934 -0.00582909\n",
      " -0.01666192 -0.04578318  0.08780545 -0.01784063]...\n",
      "Sentence: In this example,\n",
      "there are three inputs x1, x2, x3\n",
      "Embedding: [ 0.02554789 -0.02203387 -0.10691392 -0.0594633  -0.01485273 -0.00667127\n",
      " -0.00231465 -0.06585377  0.02659198 -0.03512075]...\n",
      "Sentence: Each input can either be the data from an external\n",
      "source, such as the pixel values of an image, or the output from a preceding neuron.\n",
      "The main purpose when training the network is to ﬁnd the values for the weights\n",
      "w1, w2, w3 such that the output y is correct\n",
      "Embedding: [-0.06425173 -0.05071374 -0.04758798  0.00013332 -0.00498684  0.01858987\n",
      "  0.01230387 -0.04553645  0.08985402 -0.08010712]...\n",
      "Sentence: In mathematical terms\n",
      "y = f (w1 ∗x1 + w2 ∗x2 + w3 ∗x3 + b)\n",
      "The activation function f plays an important role to introduce nonlinearity into the\n",
      "network; otherwise, the output is simply a linear weighted sum of the input values.\n",
      "This is why f is always one of the nonlinear functions shown in Figure 3-3.\n",
      "The choice of activation functions, such as sigmoid, tanh, ReLU, and Leaky\n",
      "ReLU, depends on the neural network’s architecture and the problem being\n",
      "addressed\n",
      "Embedding: [-0.06987622 -0.08006895  0.02405945  0.01900736 -0.02049243  0.04752811\n",
      "  0.04667315 -0.04328967  0.038158   -0.0069685 ]...\n",
      "Sentence: These four activation functions are very popular, and most network will\n",
      "use one or more of these activation functions.\n",
      "3.1\n",
      "Components of a Neural Network\n",
      "21\n",
      "Figure 3-3 Commonly used activation functions include the sigmoid σ(z) and the hyperbolic\n",
      "tangent tanh(z)\n",
      "Embedding: [-4.9468488e-03 -1.0401817e-01  2.7431855e-02 -5.8036108e-02\n",
      "  1.6192611e-02  6.7539036e-02  7.0988305e-02 -8.1839012e-03\n",
      "  4.1401491e-02 -4.2861695e-05]...\n",
      "Sentence: More recently used activation functions are the RELU and Leaky RELU\n",
      "The Sigmoid Function\n",
      "The formula for the sigmoid function is σ(x) =\n",
      "1\n",
      "1+e−x \n",
      "Embedding: [-0.07518097 -0.05794211  0.09496011  0.01116502  0.00887017 -0.00560903\n",
      "  0.06815214  0.11553235  0.01069078  0.01942152]...\n",
      "Sentence: This function outputs\n",
      "values between 0 and 1, making it suitable for models that predict probabilities,\n",
      "such as in binary classiﬁcation\n",
      "Embedding: [-0.03622348  0.0052121  -0.092888   -0.00034817 -0.02358218 -0.0235057\n",
      "  0.03340966  0.01560769 -0.004762    0.00483079]...\n",
      "Sentence: It is often used in the ﬁnal layer of a binary\n",
      "classiﬁcation network to represent the probability of the predicted label being\n",
      "correct\n",
      "Embedding: [-0.06414487 -0.0118916  -0.076662   -0.00088928  0.02695201  0.03900731\n",
      "  0.04681218  0.02789198  0.05188145 -0.06586355]...\n",
      "Sentence: For example, if we feed an image of a dog through a canine image detection\n",
      "network, an output value of 0.8 means that the model predicts that the image is a\n",
      "dog with 80% certainty.\n",
      "One drawback of the sigmoid function is that it is prone to the “vanishing gradient\n",
      "problem.”\n",
      "To train this network, we need to adjust the weights of the neurons based on\n",
      "feedback regarding the accuracy of the predicted values compared to the actual\n",
      "outputs\n",
      "Embedding: [-0.01510055 -0.06019775  0.05645685  0.00146832  0.02277204  0.00033023\n",
      "  0.0014055   0.02624547  0.01915893 -0.05448553]...\n",
      "Sentence: This adjustment is done by gradients, which are essentially signals sent\n",
      "back through the network telling each layer how to change the weights of its neurons\n",
      "to improve the network’s performance.\n",
      "The vanishing gradient problem occurs when these gradient signals get increas-\n",
      "ingly smaller as they are passed back through each layer\n",
      "Embedding: [-0.01459059  0.02830992  0.05309503  0.04295056 -0.01563037  0.0220463\n",
      " -0.04227196 -0.02401939  0.03748767 -0.05213616]...\n",
      "Sentence: Imagine if the message\n",
      "we are sending back through each layer gets fainter and fainter, so by the time it\n",
      "reaches the ﬁrst layers, it is almost nonexistent\n",
      "Embedding: [-0.01604994 -0.04920096  0.0824791   0.08226912  0.05713443 -0.03373876\n",
      " -0.00894149 -0.04174915  0.12430014 -0.08604165]...\n",
      "Sentence: This issue arises because the earlier\n",
      "layers, which often capture fundamental information, receive minimal guidance on\n",
      "adjusting their weights.\n",
      "22\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "If the layers of the network do not receive strong enough signals to learn, the\n",
      "entire network doesn’t learn effectively\n",
      "Embedding: [ 0.01659802 -0.07727673  0.09226039  0.05572719  0.01228832 -0.00047572\n",
      " -0.02666442  0.00309297  0.03554459 -0.04960556]...\n",
      "Sentence: This is especially problematic in deep\n",
      "networks with many layers, where the early layers might not learn well, leading\n",
      "to poor overall performance.\n",
      "The Tanh Function\n",
      "An alternative to the sigmoid function, particularly popular in neural networks, is\n",
      "the tanh function, also known as the hyperbolic tangent\n",
      "Embedding: [-0.03788081 -0.01041682  0.0356334  -0.02979646  0.00156141  0.00297086\n",
      "  0.02569403  0.00073446  0.05041727 -0.03369261]...\n",
      "Sentence: This has the formula:\n",
      "tanh(x) = ex −e−x\n",
      "ex + e−x\n",
      "(3.1)\n",
      "The tanh function is similar to the sigmoid function; however, it outputs values\n",
      "between –1 and 1\n",
      "Embedding: [ 0.01969223  0.00527972  0.01969661 -0.0288063   0.03450786 -0.07012697\n",
      "  0.03763516  0.05817205  0.0060612   0.01311221]...\n",
      "Sentence: This means the outputs are zero-centered, which makes the\n",
      "training of the model easier and more efﬁcient\n",
      "Embedding: [ 0.0160295  -0.08253168 -0.10342222  0.03316547  0.03113512  0.04559758\n",
      " -0.09876275 -0.00227385  0.11356448 -0.03083731]...\n",
      "Sentence: It is often used in hidden layers\n",
      "of a neural network as it can model complex relationships more effectively than\n",
      "the sigmoid\n",
      "Embedding: [-0.1009468  -0.00057392 -0.01985763  0.00612125  0.04989459  0.01517883\n",
      " -0.03604158  0.02116373  0.10626354 -0.0820374 ]...\n",
      "Sentence: However, like the sigmoid, the tanh function also suffers from the\n",
      "vanishing gradient problem.\n",
      "The ReLU (Rectiﬁed Linear Unit) Function\n",
      "The formula for the ReLU function is very simple: it is x if x > 0 and zero for\n",
      "values of x ≤0\n",
      "Embedding: [-0.00647719  0.01144688  0.04737194 -0.02474741  0.01541921  0.00348133\n",
      "  0.0145078   0.00397285 -0.01506898 -0.02176252]...\n",
      "Sentence: The function has gained considerable popularity, and it is the most\n",
      "widely used activation function for training deep neural networks and convolutional\n",
      "neural networks (image processing) because of its simplicity and efﬁciency.\n",
      "ReLU (rectiﬁed linear unit) helps mitigate the vanishing gradient problem by\n",
      "maintaining a nonzero gradient for positive input values during backpropagation,\n",
      "which ensures that gradients do not shrink too rapidly as they propagate through the\n",
      "network.\n",
      "In the ReLU function, for any input value greater than zero, the gradient is\n",
      "constant and equal to one\n",
      "Embedding: [-0.08764414 -0.04162508 -0.01143955  0.00578871 -0.01510677  0.07358739\n",
      " -0.00169911 -0.03407443  0.05664667 -0.03833731]...\n",
      "Sentence: This means that during backpropagation, the weights\n",
      "of the network receive sufﬁcient gradient updates, allowing the model to learn\n",
      "effectively\n",
      "Embedding: [-0.01910757 -0.09141982  0.01166184  0.09822508  0.02571104  0.04410549\n",
      " -0.03498108 -0.02913891  0.03545416 -0.02943181]...\n",
      "Sentence: In contrast, activation functions like the sigmoid or tanh have gradients\n",
      "that become very small for large input values, which leads to the vanishing gradient\n",
      "problem as updates diminish over layers.\n",
      "However, it can suffer from the “dying ReLU” problem, where neurons can\n",
      "sometimes become inactive and output zero for any input.\n",
      "Leaky ReLU\n",
      "Another popular activation function to discuss is the Leaky ReLU, similar in concept\n",
      "to the standard ReLU but designed to address its shortcomings\n",
      "Embedding: [-0.07905113 -0.07188278  0.08147443  0.081724    0.01315648  0.05021692\n",
      "  0.02717266  0.01410661  0.06350592  0.02176728]...\n",
      "Sentence: It is similar to ReLU\n",
      "but allows a small, nonzero gradient when the unit is not active to solve the dying\n",
      "ReLU problem\n",
      "Embedding: [-0.07079619 -0.07234944 -0.05044034  0.04361355 -0.00104768  0.01910377\n",
      " -0.01639526  0.0275153   0.04038134 -0.02370394]...\n",
      "Sentence: By allowing a small gradient α when the unit is not active, it ensures\n",
      "that the neurons never die\n",
      "Embedding: [-0.00703454 -0.08815905 -0.01690202  0.02039889 -0.02018017  0.07505286\n",
      "  0.01247086 -0.03717532  0.09427651  0.07046159]...\n",
      "Sentence: The downside is that the value of α needs to be carefully\n",
      "set\n",
      "Embedding: [-0.01216749  0.05261907 -0.10161106 -0.04702673 -0.02889564  0.02960267\n",
      "  0.01837702  0.04098542  0.03452612  0.04379091]...\n",
      "Sentence: If it is too large, it can lead to high variance during training.\n",
      "3.1\n",
      "Components of a Neural Network\n",
      "23\n",
      "To understand concretely why the activation function is needed, we should\n",
      "consider the ﬂow of signal passing through a node.\n",
      "When an input signal is received at a node, it generates an output y using the\n",
      "following formula:\n",
      "y = f (x1w1 + x2w2 + x3w3 + b)\n",
      "(3.2)\n",
      "Here, x1, x2, x3 are the outputs of all the nodes joining this node from the\n",
      "preceding hidden layer (or the input layer); w1, w2, w3 are the weights between\n",
      "these interconnected nodes\n",
      "Embedding: [-0.00603337 -0.09228662  0.047862   -0.00631779  0.03972904  0.03780643\n",
      "  0.05174423 -0.01507022  0.04399465 -0.06451548]...\n",
      "Sentence: The node sums the product of the weights and the\n",
      "input values, add a number, a (bias), and then apply the activation function f to\n",
      "the weighted sum to produce y.\n",
      "Why does a node compute data this way?\n",
      "Recall that the main purpose of a neural network is to act as a function\n",
      "approximator\n",
      "Embedding: [-0.05930699 -0.00337632  0.01420646  0.02186996  0.0285575   0.01622731\n",
      "  0.06132509 -0.04017207  0.07080395  0.0105802 ]...\n",
      "Sentence: If you have ever done a course on linear algebra, you may recall\n",
      "that a multiple linear regression model that approximates any set of data points with\n",
      "a straight line has a form of\n",
      "ypredict = b + w1x1 + w2x2 + w3x3 \n",
      "Embedding: [-0.05299875 -0.05765535 -0.03413855  0.00143596 -0.00294657  0.00594312\n",
      " -0.06562334 -0.04951673  0.00032619  0.02446781]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: + wnxn\n",
      "(3.3)\n",
      "The linear regression equation has the same form as the formula for a node except\n",
      "that, in the case of a neuron, the activation function is applied after the weighted\n",
      "sum is calculated\n",
      "Embedding: [-0.12441225 -0.06137899  0.05015041  0.06775627  0.03169536  0.02467749\n",
      "  0.013976    0.02959024  0.04813088  0.0749449 ]...\n",
      "Sentence: Without the activation function, the neural network could only\n",
      "approximate a function with a straight line, in the same way as a linear regressor\n",
      "does\n",
      "Embedding: [-0.14168383 -0.049797    0.0209979   0.02435609 -0.04452339  0.03669603\n",
      " -0.06154709 -0.00679768  0.02242573 -0.00597982]...\n",
      "Sentence: However, by using a nonlinear activation function, we can approximate any\n",
      "nonlinear target, that is, complex patterns, with less errors\n",
      "Embedding: [-0.09428664 -0.06172058  0.02732791  0.01321656 -0.01832746 -0.03582775\n",
      " -0.00863242 -0.04712144  0.02953128  0.00078456]...\n",
      "Sentence: The activation function\n",
      "also serves another purpose, that is, to activate or deactivate the next neuron\n",
      "Embedding: [-0.06182644 -0.06467707 -0.00151476  0.01068399 -0.01786105  0.06780574\n",
      "  0.05504681 -0.03678383  0.13082111  0.02015098]...\n",
      "Sentence: To turn\n",
      "off the next neuron, we just simply set the output of the activation function to zero.\n",
      "However, if the input to the next neuron is always zero, it would never be activated\n",
      "and become dead to the network.\n",
      "Choosing the activation function for complex network is not an easy task and is\n",
      "a topic of research\n",
      "Embedding: [-0.01788834 -0.01525892  0.02349585  0.02512045 -0.03410673  0.01755326\n",
      " -0.02097787 -0.0294166   0.0558899   0.0069522 ]...\n",
      "Sentence: In the early days, the sigmoid function was the most popular\n",
      "due to its nonlinearity\n",
      "Embedding: [-0.06077651 -0.04110756  0.01394196 -0.05209036 -0.02007389 -0.04290129\n",
      " -0.03461452  0.08891653 -0.02564415  0.06679355]...\n",
      "Sentence: However, researchers found that using the sigmoid activation\n",
      "introduces the vanishing gradient problem for deeper networks where the weights\n",
      "will stop changing after some iterations, hence stopping the network from learning.\n",
      "The rectiﬁed linear unit activation function, ReLU, over time, became the default\n",
      "choice, but this too has problems as it causes dead nodes with some network\n",
      "conﬁgurations.\n",
      "There are many activation functions available in Keras, and it is even possible to\n",
      "create custom activation functions using callable, but in practice, we will only need\n",
      "to use the following popular functions for most cases: ReLU, sigmoid, softmax, and\n",
      "tanh.\n",
      "24\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "In Keras, there are two ways to set the activation of a layer: activations can either\n",
      "be used through an activation layer or through the activation argument in the dense\n",
      "layer itself as in the following example:\n",
      "model = Sequential()\n",
      "model.add(Dense(784, activation=’relu’,input_shape=(784,)))\n",
      "model.add(Dense(784))\n",
      "model.add(activation.ReLU(threshold=0.0))\n",
      "The activation function is available for all forward layers, so we could also deﬁne it\n",
      "directly in the dense layer itself:\n",
      "# without parameters\n",
      "model.add(layers.Dense(64, activation=’relu’))\n",
      "or\n",
      "# with parameters from keras import activations\n",
      "model.add(Dense(784,lambda x:\n",
      "activations.relu(x,threshold=0.1)))\n",
      "Note we have to use a lambda function as the ﬁrst parameter of the ReLU function\n",
      "is a tensor or variable.\n",
      "The decision of which activation function to use is tricky\n",
      "Embedding: [-0.03545549 -0.12490842  0.07149798  0.00020547 -0.02887056  0.03651921\n",
      "  0.00261318  0.00205048  0.00943209 -0.03755205]...\n",
      "Sentence: The nonlinearity of\n",
      "the backpropagation algorithm means it is not obvious to know which function will\n",
      "work best in advance\n",
      "Embedding: [-0.07775322 -0.09311584 -0.0315941  -0.01352235 -0.01799004  0.0084832\n",
      " -0.09613492 -0.03851138 -0.01952812  0.02774833]...\n",
      "Sentence: For most classiﬁcation problems, I would try ReLU ﬁrst, then\n",
      "tanh or softmax for the hidden layer.\n",
      "The consideration for the activation function in the output layer is more scientiﬁc\n",
      "as it depends on the type of result we are expecting for the problem\n",
      "Embedding: [-0.09022734 -0.01379693  0.00484106  0.00980635  0.01416915  0.07963007\n",
      "  0.01120011 -0.03426016 -0.01410085 -0.09250084]...\n",
      "Sentence: For multiple\n",
      "categorical choices, we should use softmax\n",
      "Embedding: [ 0.05968991 -0.09099226 -0.01423425 -0.01783272  0.00959054  0.06799157\n",
      "  0.009273    0.01210448  0.03223531 -0.04212399]...\n",
      "Sentence: This activation function will assign a\n",
      "probability to each output node, and Keras would simply choose the node with the\n",
      "highest probability as the most probable choice\n",
      "Embedding: [-0.01999275 -0.07940619  0.00477808 -0.03567755  0.00849965  0.01435214\n",
      "  0.03798923 -0.0670635  -0.00288321 -0.02510431]...\n",
      "Sentence: In the MNIST example, when the\n",
      "network processes an image of a digit, it will assign a probability of the input image\n",
      "matching the ten output nodes {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}.\n",
      "Of course, being a probability, the sum of output node values will be one\n",
      "Embedding: [-0.03313328 -0.03906005 -0.01830783 -0.05184672  0.05703411 -0.02714381\n",
      "  0.04579638 -0.00734818  0.01140751 -0.00569993]...\n",
      "Sentence: It is\n",
      "also possible to use the sigmoid function in a multi-label classiﬁcation problem, but\n",
      "the outputs of the nodes will not sum to one\n",
      "Embedding: [ 0.01636578 -0.01347676 -0.03701233 -0.06781929  0.01097659  0.03696156\n",
      "  0.05400997 -0.01938224 -0.02556126 -0.05617959]...\n",
      "Sentence: Instead, each output represents the\n",
      "probability of that outcome occurring\n",
      "Embedding: [ 0.01852949  0.00974667 -0.03871727  0.01246372  0.00143886 -0.03147309\n",
      "  0.01493958 -0.01005179  0.12006389 -0.01379914]...\n",
      "Sentence: This is useful in cases where the outcomes\n",
      "are not mutually exclusive\n",
      "Embedding: [-0.04223776  0.05865216 -0.02035422 -0.00358216  0.02661304  0.02450765\n",
      "  0.00367974 -0.04280774  0.15473148 -0.01143517]...\n",
      "Sentence: For example, a patient could have multiple symptoms of\n",
      "the same underlying disease.\n",
      "When we have a binary classiﬁer, that is, if the output only has two mutually\n",
      "exclusive outcomes, then a sigmoid function should be used instead\n",
      "Embedding: [ 0.01235232 -0.03532398  0.018276   -0.056797    0.00506934 -0.02786741\n",
      " -0.00882905  0.02601268  0.01457877 -0.03011709]...\n",
      "Sentence: The sigmoid\n",
      "function, similarly to the softmax used in the case of multi-label problems, returns\n",
      "the probability of the input matching the output\n",
      "Embedding: [-0.03834164 -0.04930738 -0.05386713 -0.07606374  0.05157493  0.03044312\n",
      "  0.06951851  0.06122549  0.01278728 -0.09492875]...\n",
      "Sentence: This means that the output node\n",
      "will not simply be either zero or one but a real number between zero and one.\n",
      "To give a concrete example of how to use a binary classiﬁer, let us again use the\n",
      "MNIST database, but this time, we will only use one output node to check if the\n",
      "handwritten digit is eight\n",
      "Embedding: [-0.02519339  0.01706872 -0.07580837  0.02093071  0.02867748  0.00397774\n",
      " -0.03871905 -0.01374137 -0.04312618 -0.02186808]...\n",
      "Sentence: Of course, we would have to change the target array so\n",
      "that the target arrays yT rain and yT est elements are zero for any digit other than\n",
      "eight and one otherwise\n",
      "Embedding: [ 0.0038155   0.03039386 -0.03532732 -0.04547245  0.00505046  0.01659514\n",
      "  0.05242928 -0.1042008  -0.06921251 -0.07733188]...\n",
      "Sentence: The code now becomes\n",
      "3.1\n",
      "Components of a Neural Network\n",
      "25\n",
      "# load mnist dataset\n",
      "# 60,000 images for xTrain, 10,000 for xTest\n",
      "mnist = tf.keras.datasets.mnist\n",
      "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
      "# convert the 28x28 input matrix to a vector of length 784\n",
      "xTrainFlattened = xTrain.reshape(len(xTrain),784)\n",
      "xTestFlattened = xTest.reshape(len(xTest),784)\n",
      "#set yTrain and yTest to 1 where the digit is 8\n",
      "#and 0 for others\n",
      "yTrain = np.where(yTrain!=8,0,1)\n",
      "yTest = np.where(yTest!=8,0,1)\n",
      "# change the number of output node to 1 and\n",
      "# define the loss function as binary_crossentrophy\n",
      "model = Sequential()\n",
      "model.add(Dense(784, activation=’relu’,\n",
      "input_shape =(784,)))\n",
      "model.add(Dense(784,activation=’relu’))\n",
      "# sigmoid gives the probability of the digit is 8\n",
      "model.add(Dense(1,activation=’sigmoid’))\n",
      "model.compile(optimizer=Adam(),\n",
      "loss=’binary_crossentropy’,\n",
      "metrics=[’accuracy’])\n",
      "model.fit(xTrainFlattened, yTrain, epochs=5)\n",
      "yPredict = model.predict(xTestFlattened)\n",
      "# test the accuracy using the xTest\n",
      "model.evaluate(xTestFlattened,yTest)\n",
      "313/313 [==============================] -\n",
      "2s 5ms/step - loss: 0.0278 - accuracy: 0.9904\n",
      "[0.027823645621538162, 0.9904000163078308]]\n",
      "The network identiﬁes the ﬁgures 8 in the test set with 99% accuracy\n",
      "Embedding: [ 0.06899023 -0.08555366  0.01350482 -0.03835717  0.00911957  0.02933304\n",
      " -0.05616761  0.00024267 -0.11456595 -0.02871436]...\n",
      "Sentence: There are\n",
      "974 ﬁgures 8 in the test dataset, so there should be ten incorrectly classiﬁed images.\n",
      "These ﬁgures are shown in Figure 3-4\n",
      "Embedding: [ 0.04098377  0.00762682  0.02020427 -0.02448498  0.00962271 -0.05635538\n",
      " -0.04123983  0.03215804 -0.06754237 -0.00169876]...\n",
      "Sentence: Perhaps it is more understandable why the\n",
      "ﬁgures 3 would be misclassiﬁed, but the ﬁgure 1 is rather more obvious, and we\n",
      "would expect the network to classify this correctly even when the network is not\n",
      "tuned.\n",
      "3.1.2\n",
      "Neuron Initialization\n",
      "Before we start using the network, we need to initialize the weights and biases of the\n",
      "neurons\n",
      "Embedding: [-0.07583032 -0.09519842  0.05362248 -0.00726474 -0.01500133  0.04576816\n",
      "  0.05272431 -0.05257769 -0.00768031 -0.00657074]...\n",
      "Sentence: In Keras, the default initialization of weights varies depending on the type\n",
      "of layer we are using, although for common layers, such as Dense, convolutional,\n",
      "and RNN, the Glorot Uniform, also known as Xavier Uniform initialization, is used\n",
      "for the weights\n",
      "Embedding: [-0.08298586 -0.07789941  0.00498987 -0.02406749 -0.06684921 -0.01779303\n",
      "  0.02746561 -0.03281816  0.01577632 -0.08887014]...\n",
      "Sentence: This default initializer is designed to keep the scale of the gradients\n",
      "equal in all layers.\n",
      "26\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "Figure 3-4 Images where\n",
      "NN failed to correctly\n",
      "identify the number\n",
      "Biases are normally set to zero except for some RNN layers, such as LSTM\n",
      "where special initialization is required.\n",
      "The choice of these defaults is based on general best practices and empirical\n",
      "evidence suggesting that they work well in a wide range of scenarios\n",
      "Embedding: [-0.04899604 -0.10363946  0.02219487  0.01265913 -0.01510742  0.08242682\n",
      " -0.03981114 -0.0131841  -0.0253246  -0.07119527]...\n",
      "Sentence: However,\n",
      "Keras allows us to customize these initializers by specifying the kernel and bias\n",
      "initializer arguments in the layer constructor as shown in the example below:\n",
      "model = Sequential([\n",
      "Dense(64, input_shape=(20,), activation=’relu’,\n",
      "kernel_initializer=RandomNormal(mean=0.0, stddev=0.05),\n",
      "bias_initializer=Constant(value=0.4)),\n",
      "Dense(1, activation=’sigmoid’,\n",
      "kernel_initializer=RandomNormal(mean=0.0, stddev=0.05),\n",
      "bias_initializer=Constant(value=0.4))])\n",
      "The list of common initialization methods include\n",
      "•\n",
      "Zero Initialization: Setting all weights to zero\n",
      "Embedding: [-0.01359375 -0.07373562  0.03095992 -0.0189724  -0.06033055  0.03315911\n",
      " -0.04572136 -0.00774794 -0.03229009 -0.05489097]...\n",
      "Sentence: This is generally not recom-\n",
      "mended because it leads to the problem of neurons learning the same features.\n",
      "•\n",
      "Random Initialization: Setting weights to random values\n",
      "Embedding: [-0.05847505 -0.123246    0.0340334   0.05218542 -0.12209695  0.00612741\n",
      "  0.08232085 -0.0914767   0.03207322  0.01382255]...\n",
      "Sentence: This is more common,\n",
      "but the scale of randomness needs to be controlled\n",
      "Embedding: [ 0.03492011 -0.06623176 -0.00675944  0.04365568  0.00428292 -0.03468575\n",
      " -0.00099902 -0.07775747  0.09802846  0.03631295]...\n",
      "Sentence: Too high values can lead to\n",
      "exploding gradients, while too low might lead to vanishing gradients.\n",
      "•\n",
      "Xavier/Glorot Initialization: A popular method for initializing weights, espe-\n",
      "cially in networks with sigmoid or tanh activation functions\n",
      "Embedding: [-0.04380085 -0.12625922  0.02711918 -0.00323133 -0.06313706 -0.05253622\n",
      "  0.02230634  0.05160806  0.01601224 -0.04696206]...\n",
      "Sentence: It sets the weights\n",
      "based on the number of inputs and outputs of each neuron, aiming to keep the\n",
      "variance of outputs of each layer approximately equal.\n",
      "•\n",
      "He Initialization: Similar to Xavier, but it’s designed for layers with ReLU\n",
      "activation functions\n",
      "Embedding: [-0.09553517 -0.06429438  0.01422814  0.0004736  -0.0590277   0.02008779\n",
      "  0.03265546 -0.01945337  0.05730367 -0.05501619]...\n",
      "Sentence: It sets the weights considering only the number of inputs,\n",
      "which keeps the variance higher, a necessity for ReLUs.\n",
      "•\n",
      "Orthogonal Initialization: This involves setting the weights of each layer as\n",
      "orthogonal matrices\n",
      "Embedding: [-0.11944225 -0.02952434 -0.00317307  0.01174679 -0.07529793  0.08440286\n",
      " -0.03835352 -0.00365157  0.05622477 -0.06517412]...\n",
      "Sentence: It’s believed to help in maintaining the stability of signals\n",
      "across different layers of deep networks.\n",
      "3.2\n",
      "Network Layers: Building a Hierarchy\n",
      "27\n",
      "The choice of initialization often depends on the type of activation function used\n",
      "in the network\n",
      "Embedding: [-0.09132679 -0.12741014  0.05651921 -0.01118428 -0.01619652  0.02799775\n",
      " -0.06740578 -0.01899983  0.0050352  -0.08644292]...\n",
      "Sentence: For instance, He initialization is preferred with ReLUs, while\n",
      "Xavier is often used with sigmoid or tanh\n",
      "Embedding: [-0.01319035 -0.08330785 -0.00194021 -0.05966366 -0.03910623 -0.03050454\n",
      "  0.02135117  0.0394039  -0.02474329 -0.02081046]...\n",
      "Sentence: Sometimes, it is beneﬁcial to ﬁne-tune\n",
      "the initialization method based on the speciﬁc characteristics of our network and\n",
      "the problem we are solving\n",
      "Embedding: [-0.02056792 -0.02569397 -0.01677887 -0.02906796 -0.07028494 -0.02959561\n",
      " -0.0290328   0.03597144 -0.06680889 -0.00050444]...\n",
      "Sentence: Often, the best way to determine the most effective\n",
      "initialization method is through experimentation and observing how quickly and\n",
      "accurately the network learns.\n",
      "3.2\n",
      "Network Layers: Building a Hierarchy\n",
      "While individual neurons are powerful, in practice it is the structure of the network\n",
      "layers that an ML engineer is more concerned with\n",
      "Embedding: [ 0.02267747 -0.10944005  0.06603777 -0.01270254 -0.04744808 -0.01548702\n",
      " -0.05858477  0.03329825 -0.02417374 -0.03139122]...\n",
      "Sentence: Neural network layers serve\n",
      "as functional blocks, each with a speciﬁc role in processing and transforming data.\n",
      "The network consists of different types of layers, and their arrangement forms the\n",
      "network’s architecture.\n",
      "The topology of a neural network can get complicated, particularly for natural\n",
      "language processing and moving image recognition, but we will discuss them later.\n",
      "In the meantime, the most basic neural network is a feedforward network, which we\n",
      "used in our previous examples, shown in Figure 3-5.\n",
      "A basic neural network has interconnected nodes, represented by circles in\n",
      "Figure 3-5 in three layers: an input layer, a hidden layer, and an output layer\n",
      "Embedding: [-0.02954588 -0.10454448 -0.02111553 -0.03545834  0.04699411  0.04148951\n",
      " -0.04305628 -0.01780987  0.03907539 -0.07540304]...\n",
      "Sentence: Deep\n",
      "neural networks may have several hidden layers interconnected with each other\n",
      "before reaching the output layer\n",
      "Embedding: [-0.07549041 -0.07118812  0.04613824  0.06179293  0.01299813  0.01094437\n",
      " -0.04541985 -0.12100021  0.04988035 -0.14146309]...\n",
      "Sentence: In TensorFlow and Keras, the feedforward layer\n",
      "is referred to as a dense layer\n",
      "Embedding: [-0.01937203 -0.1140928  -0.00031072 -0.00358321  0.02089938  0.02107991\n",
      " -0.04337106 -0.08795726 -0.0018173  -0.08354301]...\n",
      "Sentence: If we refer to the code in Code 3-1, we can see that a\n",
      "dense layer is deﬁned with the number of nodes and an activation function:\n",
      "model.add(Dense(10, activation=’relu’))\n",
      "Figure 3-5 A three-layer feedforward network with three input, ﬁve hidden, and two output nodes\n",
      "28\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "The hidden layers may have millions of nodes capable of mapping any input type\n",
      "to any output type\n",
      "Embedding: [-0.02504708 -0.16000906 -0.01186372  0.0691456   0.01335799  0.04175023\n",
      " -0.01020501 -0.09816926 -0.00914212 -0.03212205]...\n",
      "Sentence: Of course, the more nodes we have, the more data and time are\n",
      "needed to train the network\n",
      "Embedding: [ 0.01391845 -0.03537858 -0.0045527   0.00292664  0.05367934 -0.01318378\n",
      " -0.08549986 -0.10041915 -0.02708538 -0.04651447]...\n",
      "Sentence: A reasonably complicated deep learning network may\n",
      "need millions of data points rather than thousands or hundreds of thousands, so it is\n",
      "normally best practice to keep the network structure as lean as possible.\n",
      "In a feedforward network, information ﬂows from left to right, that is, from the\n",
      "input layer to the hidden layer(s) and then ﬁnally to the output layer\n",
      "Embedding: [-0.02643441 -0.07599115  0.02227511  0.00717253  0.00628815 -0.00835959\n",
      " -0.12396677 -0.06746806  0.01578088 -0.05998529]...\n",
      "Sentence: A number,\n",
      "called weight, represents a connection between two nodes, shown as an arrow in\n",
      "Figure 3-5.\n",
      "This means that each node in the hidden or output layer receives the output\n",
      "weights of the nodes from the preceding layer as input, does some predeﬁned\n",
      "computation, and then passes the result as a number, or weight, to the next hidden\n",
      "or output layer\n",
      "Embedding: [-0.05743276  0.01327154 -0.05663343  0.05071294 -0.01486658  0.02934446\n",
      "  0.06402396 -0.0374064   0.07044459 -0.06832529]...\n",
      "Sentence: This weight is an important number\n",
      "Embedding: [-0.00378127  0.05072831 -0.03419566  0.03996879 -0.03844686  0.0125267\n",
      "  0.08609194  0.07641294 -0.00282626 -0.02023843]...\n",
      "Sentence: An “important” node will have\n",
      "a higher weight, while a node which produces a zero weight all the time is useless\n",
      "and is called a dead node.\n",
      "A feedforward network uses a feedback process to improve its prediction over\n",
      "time\n",
      "Embedding: [-0.01563685 -0.05664123  0.00587216  0.08630167  0.09355252 -0.01988749\n",
      " -0.07746468 -0.02176236  0.0528804   0.01514514]...\n",
      "Sentence: Each time we supply the network with a new input, it predicts the output value\n",
      "using the weights and then compares how close the predicted value is to the actual\n",
      "output value using a loss function\n",
      "Embedding: [-0.0623998   0.02011525 -0.02127777  0.05504488  0.00525837  0.0230412\n",
      " -0.04274988  0.05630375  0.05737842 -0.05420489]...\n",
      "Sentence: The network then adjusts the weights of the nodes\n",
      "in the hidden layer(s) using an algorithm called backpropagation (or backprop for\n",
      "short) to reduce the error\n",
      "Embedding: [-0.08984224  0.06190412  0.03172754  0.10147307  0.01713067  0.01586036\n",
      " -0.01803602 -0.02328991 -0.02419734 -0.0766961 ]...\n",
      "Sentence: This process is repeated until all the inputs are processed\n",
      "and the weights are updated accordingly.\n",
      "It should be clear that three components are very important for a feedforward\n",
      "network: the activation function, the loss functions, and the feedback algorithm.\n",
      "Together they determine how a network gets to learn quickly and correctly.\n",
      "3.3\n",
      "The Optimizer and the Loss Function\n",
      "Other than the activation function, we need to discuss the optimizer and the loss\n",
      "function for a neural network\n",
      "Embedding: [-0.02665309 -0.05862268 -0.00791546 -0.00079667 -0.03279062  0.03482845\n",
      " -0.02608869 -0.09017823  0.05042335 -0.03562294]...\n",
      "Sentence: We may see this in the previous code as\n",
      "model.compile(optimizer=Adam(), loss=’binary_crossentropy’,\n",
      "metrics=[’accuracy’])\n",
      "Both of these components are essential to using a neural network\n",
      "Embedding: [-0.01670553 -0.06987452 -0.00770947  0.00250783  0.00204821  0.02345599\n",
      " -0.00702549 -0.01132567 -0.07892884 -0.07883168]...\n",
      "Sentence: Unfortunately, we\n",
      "will need to have a mathematical background to understand the concepts properly.\n",
      "However, I will illustrate the ideas with analogies as much as possible without\n",
      "resorting to complicated mathematical formulas.\n",
      "The key idea here is that we need to “train” our network to achieve what we want\n",
      "it to do\n",
      "Embedding: [-0.00348208 -0.08483393  0.01411916 -0.04998998 -0.07899421 -0.04755596\n",
      " -0.0543263   0.01724281  0.08810859 -0.02680957]...\n",
      "Sentence: For each predicted output, we need to (1) identify how close we are to the\n",
      "actual output and (2) change the weights of the neurons after each predicted output\n",
      "to (hopefully) inch the network toward the correct solution\n",
      "Embedding: [-0.02811348 -0.05925124  0.00822918  0.00013831 -0.02689334  0.01559509\n",
      " -0.03200222  0.01497964 -0.00321209 -0.02912395]...\n",
      "Sentence: Step 1 is done using the\n",
      "loss function, while it is the job of the optimizer via the backpropagation algorithm\n",
      "in step 2 to improve the accuracy of the network.\n",
      "3.3\n",
      "The Optimizer and the Loss Function\n",
      "29\n",
      "3.3.1\n",
      "The Loss Function\n",
      "The loss function provides the backpropagation algorithm of an estimate of the\n",
      "size of the error in the current state of the model\n",
      "Embedding: [-0.0419082   0.04960978  0.00203813  0.03669734  0.0307146   0.03348072\n",
      " -0.05559835  0.04300631 -0.01578227  0.00379471]...\n",
      "Sentence: It provides the backpropagation\n",
      "optimization algorithm with a single number to minimize\n",
      "Embedding: [-0.09173662 -0.04428709 -0.04781167 -0.03807891  0.02302944  0.06048025\n",
      " -0.01490227 -0.01689322 -0.01802636 -0.04723471]...\n",
      "Sentence: The smaller the error, the\n",
      "better the model is at ﬁtting the training data\n",
      "Embedding: [ 0.0391735   0.05171628  0.0318121   0.0478238   0.08138314 -0.00931881\n",
      " -0.06062155  0.08151554 -0.01630496 -0.08166701]...\n",
      "Sentence: However, for reasons which will be\n",
      "discussed later, it is not necessarily the case that we would want the lowest error\n",
      "during the training process as the model may not perform as well during testing or\n",
      "production because it has overﬁtted the training data.\n",
      "In Keras, there are three types of loss functions\n",
      "Embedding: [-0.00860529  0.04239038  0.05270755 -0.01020807  0.01545769  0.00516043\n",
      " -0.07313783  0.05634207  0.04010912 -0.02427941]...\n",
      "Sentence: Which one we should use\n",
      "depends on the type of problem under consideration\n",
      "Embedding: [-0.04637266  0.04224465 -0.03774551 -0.05040082 -0.03795026 -0.00350503\n",
      "  0.00987434  0.1108786  -0.00308021  0.05158306]...\n",
      "Sentence: For regression, that is,\n",
      "approximating real valued functions, we should use a regression loss\n",
      "Embedding: [-0.0956605   0.03237842 -0.03982984  0.02403456 -0.00740171  0.02281641\n",
      " -0.04720709  0.03244016  0.08465263  0.05310665]...\n",
      "Sentence: With problems\n",
      "where we need to determine the probability of occurrence, then use one of the\n",
      "probabilistic loss functions\n",
      "Embedding: [-0.07644887  0.02052559  0.04193784 -0.03882927  0.03256816  0.01883102\n",
      "  0.10935537  0.0008454   0.11505495  0.03741708]...\n",
      "Sentence: The third type, called hinged losses, is speciﬁcally\n",
      "designed for “maximum-margin” classiﬁcation problems\n",
      "Embedding: [-0.01422075  0.05368684 -0.00579003 -0.0216596  -0.027676   -0.01390222\n",
      "  0.00088889  0.00789373  0.01448658  0.03825817]...\n",
      "Sentence: Underlying any loss\n",
      "function is the concept of proximity measure, which gives a mathematical metric\n",
      "of how close, or equivalently how similar, two objects are to each other.\n",
      "All losses are available in Keras via a class handle and a function handle.\n",
      "The class handles enable us to pass conﬁguration arguments to the constructor as\n",
      "follows.\n",
      "Using a Function Handle\n",
      "When we use a function handle, we typically specify the loss function by its string\n",
      "name when compiling the model:\n",
      "from tensorflow.keras.models import Sequential\n",
      "from tensorflow.keras.layers import Dense\n",
      "# Define a simple model\n",
      "model = Sequential([\n",
      "Dense(64, activation=’relu’, input_shape=(10,)),\n",
      "Dense(1)\n",
      "])\n",
      "# Compile the model using a function handle for the loss\n",
      "model.compile(optimizer=’adam’, loss=’mean_squared_error’)\n",
      "In this case, the mean squared error is the string identiﬁer for the mean squared error\n",
      "loss function.\n",
      "Using a Class Handle\n",
      "When using a class handle, we instantiate a loss class with any required conﬁgura-\n",
      "tion parameters and then pass this instance to the compile method of the model\n",
      "Embedding: [-0.02584106 -0.02645751  0.01757247  0.01548227 -0.07968552  0.04068712\n",
      " -0.01929314  0.04312653  0.06174559 -0.06055059]...\n",
      "Sentence: This\n",
      "approach provides more ﬂexibility, as we can pass additional parameters to the loss\n",
      "function if the loss function supports such parameters\n",
      "Embedding: [-0.13092893  0.03730382 -0.03864042 -0.01706726  0.06579001  0.06216887\n",
      "  0.01710019 -0.0013899   0.03892568 -0.01984587]...\n",
      "Sentence: Here is an example using the\n",
      "MeanSquaredError class:\n",
      "from tensorflow.keras.models import Sequential\n",
      "from tensorflow.keras.layers import Dense\n",
      "from tensorflow.keras.losses import MeanSquaredError\n",
      "30\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "# Define a simple model\n",
      "model = Sequential([\n",
      "Dense(64, activation=’relu’, input_shape=(10,)),\n",
      "Dense(1)])\n",
      "# Instantiate the class with desired configuration\n",
      "mse_loss = MeanSquaredError(reduction=’auto’,\n",
      "name=’mean_squared_error’)\n",
      "# Compile the model using the class handle for the loss\n",
      "model.compile(optimizer=’adam’, loss=mse_loss)\n",
      "3.3.2\n",
      "Loss Function for Regression\n",
      "Regression problems are a set of problems where the model predicts a real value\n",
      "as output\n",
      "Embedding: [-0.06644816 -0.07823832  0.04249249  0.06315567 -0.03313745  0.02715682\n",
      " -0.04963557  0.03382947 -0.03038721 -0.05497962]...\n",
      "Sentence: For example, predicting house prices, company proﬁts, or future stock\n",
      "prices\n",
      "Embedding: [-0.03216759 -0.12013692 -0.02460892  0.04403852  0.02700405 -0.02206898\n",
      " -0.02556298  0.03523951 -0.02113942 -0.02198127]...\n",
      "Sentence: Keras provides both class functions to instantiate objects and set parameters,\n",
      "as well as loss functions that can be called directly\n",
      "Embedding: [-0.10131311  0.00213489 -0.03717548  0.01380707 -0.07895567  0.03054739\n",
      "  0.0063346  -0.04886635 -0.00182022 -0.02284403]...\n",
      "Sentence: In either case, the mean squared\n",
      "error is by far the most popular loss function used to solve regression problems,\n",
      "while cosine similarity is frequently used in natural language processing to measure\n",
      "how similar words are\n",
      "Embedding: [-0.01752826  0.00070846 -0.04340194 -0.02075494 -0.02809582  0.0413476\n",
      " -0.05133818  0.09069948  0.10284998 -0.00232907]...\n",
      "Sentence: We will discuss these two functions below\n",
      "Embedding: [-0.11828478  0.03730549 -0.07257599  0.01088175 -0.0093665   0.03410309\n",
      "  0.06728584  0.01283957  0.01359447 -0.05144065]...\n",
      "Sentence: If you are\n",
      "interested in learning more, here is the complete list of loss functions implemented\n",
      "in Keras: https://keras.io/api/losses/.\n",
      "3.3.3\n",
      "Mean Squared Error\n",
      "The mean squared error (MSE) is frequently used in statistics and machine learning\n",
      "to measure the average of the squares of the errors, essentially quantifying the\n",
      "difference between predicted and actual values\n",
      "Embedding: [-0.05344284 -0.02818557  0.05080076  0.00814763 -0.03496226  0.05965978\n",
      " -0.06563611  0.05470031 -0.02072702  0.00805226]...\n",
      "Sentence: Let’s suppose that we have the\n",
      "actual values for our problem as\n",
      "Y = {10.2, 11.0, 12.5, 1.0, −6.5, 0.0}\n",
      "and the predicted values from our network are\n",
      "Ypredict = {9.9, 12.2, 12.5, 0.0, 1.0, 1.0}\n",
      "then the MSE is given by\n",
      "MSE = 1\n",
      "6[(10.2 −9.9)2 + (11.0 −12.2)2 + (12.5 −12.5)2+\n",
      "(1.0 −0.0)2 + (−6.5 −1.0)2 + (0.0 −1.0)2] = 9.963333\n",
      "(3.4)\n",
      "3.3\n",
      "The Optimizer and the Loss Function\n",
      "31\n",
      "As each term in the MSE formula is squared, the error function is always positive,\n",
      "ensuring that the function focuses on the magnitude of errors\n",
      "Embedding: [ 0.00886883  0.00230801  0.03485093  0.02028888  0.00212481 -0.04684838\n",
      " -0.01771623  0.10861912 -0.03354814 -0.00631886]...\n",
      "Sentence: It becomes zero only\n",
      "when the predicted values match the target values exactly\n",
      "Embedding: [-0.00944888 -0.00304951 -0.0254197   0.05167773  0.05197663 -0.00700668\n",
      "  0.01773618  0.00149168  0.04285182 -0.03652305]...\n",
      "Sentence: Calculating MSE in Keras\n",
      "is straightforward and gives the same result as above.\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "y= [10.2,11,12.5,1,-6.5,0]\n",
      "yPredicted = [9.9,12.2,12.5,0,1,1]\n",
      "mse = tf.keras.losses.MeanSquaredError()\n",
      "print(mse(y,yPredicted).numpy())\n",
      "9.963333\n",
      "This loss function can be speciﬁed in the machine learning function compile as\n",
      "follows:\n",
      "model.compile( loss=tf.keras.losses.MeanSquaredError())\n",
      "3.3.4\n",
      "Cosine Similarity\n",
      "In contrast to regression, which deals with numerical predictions, cosine similarity\n",
      "is used to measure the similarity between two vectors, commonly in applications\n",
      "involving text or sequences\n",
      "Embedding: [-0.02665987 -0.04556161  0.00268911 -0.03606142  0.01098727  0.04593635\n",
      " -0.04566973  0.11932415 -0.01140052 -0.02205346]...\n",
      "Sentence: For example, suppose we want to compare two similar\n",
      "sentences in the popular nursery rhymes “Humpty Dumpty”:\n",
      "“Humpty Dumpty sat on a wall” and “Humpty Dumpty had a great fall”\n",
      "One way to do this is to vectorize each sentence using 0 and 1 to indicate if a word\n",
      "is in the dictionary as shown in Figure 3-6\n",
      "Embedding: [ 0.09317508  0.00687379 -0.01163004 -0.04044794  0.0037338   0.03277642\n",
      "  0.01881619 -0.03935115  0.00789932 -0.00511903]...\n",
      "Sentence: Once vectorized, the cosine of the angle\n",
      "α between the two vectors is a number representing how close (or similar) they are\n",
      "to each other\n",
      "Embedding: [-0.00712849  0.01149342 -0.11795812 -0.09101868 -0.00863633  0.03136105\n",
      " -0.03365193  0.0284137   0.02289686 -0.03388863]...\n",
      "Sentence: The cos() function has values ranging from –1 to 1\n",
      "Embedding: [-0.07175347  0.03781585 -0.0957442   0.02542861 -0.02414004 -0.00750874\n",
      " -0.04640067  0.07244486  0.0312461  -0.00062443]...\n",
      "Sentence: An angle of zero\n",
      "degrees (cos(0) = 1) indicates two vectors pointing in the same direction, signifying\n",
      "maximum similarity\n",
      "Embedding: [-0.04436729 -0.02781437 -0.0919411  -0.07008894 -0.00324415 -0.01827038\n",
      " -0.01816769  0.00298285  0.06737307 -0.06984559]...\n",
      "Sentence: Conversely, cos(180 degrees) equals –1, indicating vectors in\n",
      "opposite directions, signifying maximum dissimilarity, as shown in Figure 3-7c.\n",
      "The advantage of using the cosine similarity metric is that it is very easy and fast\n",
      "to calculate\n",
      "Embedding: [-0.05796666 -0.01969462 -0.04687415 -0.05221532 -0.01440836 -0.01084007\n",
      " -0.04716404  0.07993714  0.05479738 -0.0129668 ]...\n",
      "Sentence: We simply compute the dot product of the two vectors and divide by\n",
      "their lengths as follows:\n",
      "cosα =\n",
      "A.B\n",
      "||A||||B||\n",
      "where ||A|| denotes the length of vector A\n",
      "Embedding: [-0.00320205  0.0332653  -0.07862867 -0.09979287  0.01316747  0.00553397\n",
      " -0.07306533  0.03070128 -0.027322   -0.01925733]...\n",
      "Sentence: For example, the angle between the\n",
      "vector {3, 4, 5} and {−3, 5, 4} is\n",
      "cosα =\n",
      "3.(−3) + 4.5 + 5.4\n",
      "√\n",
      "32 + 42 + 52.\n",
      "\u0002\n",
      "(−3)2 + 52 + 42 = 0.62\n",
      "(3.5)\n",
      "32\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "Figure 3-6 Vectorizing\n",
      "sentences\n",
      "a\n",
      "b\n",
      "c\n",
      "Figure 3-7 Cosine similarity between two vectors\n",
      "Keras has a built-in function to perform the same calculation:\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "y= [3.0,4.0,5.0]\n",
      "yPredicted = [-3.0,5.0,4.0]\n",
      "cosineLoss = tf.keras.losses.CosineSimilarity()\n",
      "print(cosineLoss(y,yPredicted).numpy())\n",
      "-0.6199999\n",
      "We can use this in the compile function as follows:\n",
      "model.compile(optimizer=’Adam’,\n",
      "loss=tf.keras.losses.CosineSimilarity(axis=1))\n",
      "We may notice the parameter axis=1\n",
      "Embedding: [ 0.00569929 -0.04645182 -0.073406   -0.07208227  0.02624008  0.02408822\n",
      " -0.04869467  0.01060953 -0.02536635 -0.03574219]...\n",
      "Sentence: This tells the algorithm to calculate the cosine\n",
      "similarity of the vector to the feature axis\n",
      "Embedding: [-0.0263212   0.00557192 -0.08952884 -0.10996871  0.0277654  -0.00172104\n",
      " -0.07299428  0.02151803 -0.03643067 -0.04371511]...\n",
      "Sentence: We will explore the idea of a feature axis\n",
      "and what it means later on when we discuss the use of a convoluted neural network\n",
      "(CNN) for image processing.\n",
      "3.4\n",
      "Probabilistic Losses\n",
      "33\n",
      "3.4\n",
      "Probabilistic Losses\n",
      "For categorical problems, that is, for problems which require us to identify classes of\n",
      "objects, for example, images of dogs, cats, birds, ﬁsh, etc., we may require the neural\n",
      "network to output the probabilities of the input object belonging to each class\n",
      "Embedding: [-0.00534599 -0.02724883  0.03975946 -0.0116713   0.05164078  0.02637174\n",
      " -0.00313805 -0.02601491  0.05658683  0.00619715]...\n",
      "Sentence: Keras\n",
      "provides many loss functions to do this, but the most popular options are binary,\n",
      "categorical cross-entropy, and sparse categorical cross-entropy classes, which we\n",
      "will discuss below.\n",
      "3.4.1\n",
      "Binary Cross-Entropy\n",
      "Use this entropy function for classiﬁcation problems where the output has only two\n",
      "outcomes, for example, a picture of a dog or cat, the word “happy” or “sad.” For a\n",
      "binary classiﬁcation model, the output is the probability of a sample belonging to\n",
      "one of the two classes, usually represented as 0 or 1\n",
      "Embedding: [ 0.0030253  -0.00383884  0.00799299 -0.02206713 -0.01952777  0.01411307\n",
      " -0.00548225 -0.06457504 -0.00390721 -0.04400887]...\n",
      "Sentence: The binary cross-entropy loss\n",
      "function measures how far the model’s predictions are from the actual labels\n",
      "Embedding: [-0.00297898 -0.02535036 -0.05834542 -0.01849207  0.1116701   0.0692331\n",
      " -0.02006338  0.04428863  0.03088394 -0.05417485]...\n",
      "Sentence: For a\n",
      "single sample, it is deﬁned as\n",
      "L(y) = −y log(p) −(1 −y) log(1 −p)\n",
      "(3.6)\n",
      "For many data points, the loss function is simply the arithmetic average of the\n",
      "total loss for all data points\n",
      "Embedding: [-0.02553717 -0.03349651  0.05099706 -0.00492407  0.08878686 -0.00825539\n",
      "  0.0359639   0.0564241   0.10083498  0.04529257]...\n",
      "Sentence: p is the predicted probability coming from our neural\n",
      "network\n",
      "Embedding: [-0.04490926 -0.06897423  0.03804781  0.03686737  0.03555936  0.05666472\n",
      "  0.07188895  0.03314457  0.1108396   0.02191388]...\n",
      "Sentence: Note that since y can only be 1 or 0, only one part of the equation can be\n",
      "activated\n",
      "Embedding: [-0.01484677 -0.00767206 -0.02346516  0.0563981   0.0388691  -0.00457441\n",
      "  0.01404365 -0.04289715  0.00195424 -0.01416292]...\n",
      "Sentence: When y = 1, L(1) = −log(p)\n",
      "Embedding: [ 0.00146635 -0.03362809  0.08182019  0.01831947  0.10990337 -0.04641775\n",
      "  0.06987506  0.02814396  0.03496007 -0.00892426]...\n",
      "Sentence: If the predicted probability p = 1, the\n",
      "L(1) = 0, so there is no loss\n",
      "Embedding: [-0.0035502  -0.013923    0.05321394  0.06869619  0.0942274   0.01917721\n",
      "  0.01109792  0.03994156  0.0555439   0.01580961]...\n",
      "Sentence: If the probability p is ≈0, −log(p) >> 1, so the\n",
      "loss value is very high\n",
      "Embedding: [ 0.04813753  0.01746583  0.0196223  -0.00329168 -0.00191646 -0.08900848\n",
      "  0.04856503  0.08080421  0.10876493  0.03935347]...\n",
      "Sentence: The same logic works in the case of y = 0 for L(0).\n",
      "If we use Keras to calculate binary cross-entropy for our neural network, it\n",
      "follows the same format as before\n",
      "Embedding: [ 0.00488287 -0.07897464  0.03001304 -0.04281428  0.08446443  0.05484819\n",
      " -0.05356081 -0.06136024  0.0299523  -0.02708964]...\n",
      "Sentence: That is, we need to set the parameter loss in\n",
      "the compile function.\n",
      "lossFunction = BinaryCrossentropy()\n",
      "model.compile(loss=lossFunction,optimizer=’adam’,\n",
      "activation=’sigmoid’,metrics=[’accuracy’])\n",
      "Use the activation function sigmoid for a binary cross-entropy loss function.\n",
      "3.4.2\n",
      "Categorical Cross-Entropy\n",
      "This is the same as the binary cross-entropy loss except that it is used for multi-\n",
      "class outcomes instead of binary\n",
      "Embedding: [ 0.06348246 -0.03092175  0.02350237 -0.02716567 -0.01333851 -0.00778275\n",
      "  0.01907478  0.00650311 -0.05591825 -0.03451494]...\n",
      "Sentence: For example, the output could be a picture of a\n",
      "cat, a dog, a bird, or others\n",
      "Embedding: [ 0.02284553  0.01573714 -0.03243867 -0.0169658   0.00947363 -0.02592195\n",
      " -0.04291521 -0.04412944  0.0793751  -0.01675728]...\n",
      "Sentence: If we use Keras categorical cross-entropy, we will need\n",
      "to vectorize the output ﬁrst so that each output is either 1 or 0\n",
      "Embedding: [ 6.8434179e-02 -5.8059059e-02 -8.0360245e-05 -3.3336155e-02\n",
      " -4.8138238e-03  3.8105603e-02 -3.5257019e-02 -1.1959381e-01\n",
      " -1.0104003e-02 -7.0990086e-02]...\n",
      "Sentence: This is done by\n",
      "using one-hot encoding\n",
      "Embedding: [-0.00627322 -0.03462749 -0.12837036 -0.00132245 -0.05521478  0.00745745\n",
      " -0.01751848 -0.1121159   0.01288401 -0.05065586]...\n",
      "Sentence: Simply put, one-hot encoding assigns a unique one and\n",
      "zero vector for each category as shown in Figure 3-8.\n",
      "34\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "Figure 3-8 One-hot\n",
      "encoding for the three\n",
      "categories: red, yellow, and\n",
      "blue\n",
      "The sof tmax is a suitable activation function for categorical cross-entropy.\n",
      "The softmax function converts the output of the neural network into probability\n",
      "distributions, ensuring that the sum of the probabilities of all output nodes is equal\n",
      "to one.\n",
      "3.4.3\n",
      "Sparse Categorical Cross-Entropy\n",
      "The sparse categorical cross-entropy function is similar to categorical cross-entropy,\n",
      "with the key difference being that it does not require one-hot encoding of output\n",
      "labels\n",
      "Embedding: [ 0.02677674 -0.12024628 -0.0682351   0.00553102  0.03634062  0.06011872\n",
      "  0.00379833 -0.09473189  0.04764605 -0.07681555]...\n",
      "Sentence: Instead, the labels can be directly assigned as integers\n",
      "Embedding: [ 0.01013699  0.05709559 -0.12914203 -0.01345844 -0.03476761  0.10361917\n",
      "  0.09929077 -0.00672684  0.0439091  -0.10681887]...\n",
      "Sentence: For example:\n",
      "red = 1, yellow = 2, blue = 3\n",
      "Embedding: [ 0.01531511 -0.02599582 -0.09395341 -0.01893702 -0.0363162   0.02772332\n",
      "  0.06083708 -0.05950174  0.02058688  0.00055623]...\n",
      "Sentence: The advantage of using sparse cross-entropy is that\n",
      "it saves time and memory as each class is an integer and not a whole vector.\n",
      "3.5\n",
      "Network Optimizer\n",
      "In machine learning, optimization refers to the process of iteratively reﬁning the\n",
      "model parameters to improve its accuracy and reduce error.\n",
      "As mentioned, this is done using an optimizer in the backpropagation process.\n",
      "The main objective of the optimizer is to minimize the value of the loss function after\n",
      "each iteration by changing the weights of the neurons\n",
      "Embedding: [-0.05630949 -0.00825697 -0.00515802 -0.01637627  0.04535171  0.04973478\n",
      " -0.01296921  0.00062983  0.01334096 -0.02312774]...\n",
      "Sentence: It achieves this iteratively\n",
      "using a numerical search algorithm that estimates the next set of weight values\n",
      "based on the loss function\n",
      "Embedding: [-0.10678078  0.05091272 -0.02056259  0.0038256  -0.01112871  0.00194983\n",
      " -0.02429145  0.01840441 -0.01112857 -0.03860484]...\n",
      "Sentence: The new estimated weights should reduce the loss over\n",
      "iterations, but there is no guarantee that it will converge or, if it converges, that it\n",
      "will converge to a global maximum.\n",
      "The algorithm to optimize the weights is normally based on one of the popular\n",
      "algorithms called gradient descent\n",
      "Embedding: [-0.10992789 -0.00920601  0.02466635  0.04702864 -0.02581696 -0.07762878\n",
      " -0.04355873 -0.03022013 -0.04080558 -0.04617934]...\n",
      "Sentence: To understand the intuition behind this algo-\n",
      "rithm, imagine that we are lost on a hill walk and it is now dark\n",
      "Embedding: [-0.04430395 -0.00420403  0.0682697   0.17370719  0.06443293 -0.01701787\n",
      " -0.01521901 -0.01017241  0.09920392 -0.00021478]...\n",
      "Sentence: One strategy to ﬁnd\n",
      "the bottom of the hill is to explore the immediate surrounding and walk a few steps\n",
      "in the direction of the steepest slope, then check for direction again and repeat until\n",
      "we get stuck in some hole or got the bottom of the hill\n",
      "Embedding: [-0.0428809   0.04841811  0.04814444  0.02515292 -0.02321036 -0.08127963\n",
      " -0.13124475  0.07895831  0.03378101 -0.03156248]...\n",
      "Sentence: The strategy requires two\n",
      "parameters: the number of steps before we check for direction (or equivalently, the\n",
      "size of each step if we check after every step) and the direction of descent at each\n",
      "step.\n",
      "Choosing a small step size would slow convergence\n",
      "Embedding: [-0.04020166  0.02395105  0.01078194 -0.04285555 -0.00401365 -0.02996879\n",
      " -0.11713506 -0.02794055 -0.01363838  0.00154367]...\n",
      "Sentence: Conversely, a step size that\n",
      "is too large could mean that we miss the nuances of the ground topology and end\n",
      "up walking randomly up and down the hill\n",
      "Embedding: [ 0.03383966 -0.01187286  0.09076937  0.00288269  0.00939026 -0.04389316\n",
      " -0.14017905  0.1011264   0.00765256  0.00063842]...\n",
      "Sentence: The optimal step size depends on each\n",
      "3.5\n",
      "Network Optimizer\n",
      "35\n",
      "application, but one thing which would help the optimizer, in machine learning and\n",
      "not in real life, is to normalize the data so that a similar step size could be used for\n",
      "many problems\n",
      "Embedding: [-0.03964679  0.03594285  0.06134271 -0.05596118 -0.02382273 -0.10281236\n",
      " -0.12822554  0.00410501 -0.09397642 -0.01060696]...\n",
      "Sentence: We will discuss this point in more detail in later sections.\n",
      "The direction of the steepest gradient for the optimizer aligns with the local\n",
      "gradient of the loss function, which is why we need to choose a loss function for\n",
      "every problem\n",
      "Embedding: [-0.0908265   0.00386774  0.03951798 -0.0422814   0.04596665  0.02837137\n",
      " -0.03680574  0.00956038  0.07090065  0.04972507]...\n",
      "Sentence: Different variants of the gradient descent algorithm may improve\n",
      "the process by adapting the step size depending on the steepness of the gradient.\n",
      "They may also introduce a random walk now and again to avoid getting stuck in a\n",
      "hole, but the basic idea remains the same.\n",
      "There are several optimizers to choose in Keras, but they fall into two categories:\n",
      "basic and adaptive gradient descent algorithms\n",
      "Embedding: [-0.04212831 -0.04182468  0.02516627 -0.03625869 -0.01185788 -0.02513498\n",
      " -0.10540546 -0.06167349 -0.01714339 -0.03191196]...\n",
      "Sentence: We can read the different types on\n",
      "the Internet if we are curious, but in practice, the two most used ones are mini batch\n",
      "gradient descent and Adam.\n",
      "We often use Adam ﬁrst for our training, as it is considered one of the best among\n",
      "the adaptive optimizers\n",
      "Embedding: [-0.06058883 -0.03888203 -0.04410536  0.0122681  -0.01530673  0.01599424\n",
      "  0.00284968  0.00094164 -0.00588109 -0.04500812]...\n",
      "Sentence: However, the mini batch gradient is also worth trying if\n",
      "convergence is slow or if there are memory limitations\n",
      "Embedding: [-0.04537608 -0.08436423 -0.05567103  0.03189781 -0.02334567 -0.00888708\n",
      " -0.08987299 -0.03612017 -0.07882342 -0.07558925]...\n",
      "Sentence: The mini batch term refers\n",
      "to taking the average of the loss function after a batch of input data before updating\n",
      "the weights\n",
      "Embedding: [-0.03561692  0.05708551 -0.02707944  0.08338216 -0.00627551  0.01817184\n",
      " -0.02780667  0.0945762  -0.0001733  -0.025784  ]...\n",
      "Sentence: There is no magic formula for the batch size, but we will discuss some\n",
      "consideration for choosing the value for this parameter later on.\n",
      "An important hyperparameter for an optimizer is the learning rate and its\n",
      "schedule\n",
      "Embedding: [ 0.06704924 -0.00944401 -0.09121981  0.00764297 -0.06957787  0.00373978\n",
      " -0.0736547   0.04224213 -0.1092847   0.00075337]...\n",
      "Sentence: The learning rate is a critical hyperparameter that controls how much the\n",
      "weights in the network are adjusted with respect to the loss gradient\n",
      "Embedding: [-0.01363134 -0.0115362  -0.07126901  0.05019138  0.00892454  0.04189727\n",
      " -0.07480184  0.01752893  0.03067614  0.01780627]...\n",
      "Sentence: A smaller\n",
      "learning rate makes the network learn slower, but it can help the network reach a\n",
      "better or more precise ﬁnal performance\n",
      "Embedding: [ 0.08924727  0.00747927  0.00935756  0.01990961  0.04744227 -0.03906118\n",
      " -0.10235848  0.01576686  0.06338564 -0.02062433]...\n",
      "Sentence: A larger learning rate makes the network\n",
      "learn faster, but it can overshoot the optimal values\n",
      "Embedding: [ 0.05861799 -0.03435438  0.04269547  0.03577224  0.05577629 -0.07115915\n",
      " -0.10868692  0.01789223  0.05123956  0.02064762]...\n",
      "Sentence: Keras also provides a facility to\n",
      "change the active learning rate (or its schedule) via the use of a callback function.\n",
      "To deﬁne the optimizer, use\n",
      "adam = Adam(learning_rate=0.001)\n",
      "The model is then set up to use the optimizer by compiling\n",
      "model.compile(optimizer=adam, loss=’binary_crossentropy’,\n",
      "metrics=[’accuracy’])\n",
      "In Keras, learning rate schedules are mechanisms used to adjust the learning rate\n",
      "during training, allowing for dynamic adaptation based on the model’s performance.\n",
      "This can lead to better performance of the model, as it allows for a more reﬁned\n",
      "tuning of the optimization process\n",
      "Embedding: [-0.01401102 -0.00739539 -0.07267632  0.04559669 -0.02262927 -0.01164643\n",
      " -0.04163574 -0.03168152 -0.00874635 -0.00180275]...\n",
      "Sentence: To illustrate, common types of learning rate\n",
      "schedules include time-based decay, step decay, and exponential decay, each with\n",
      "its own strategy for adjusting the learning rate\n",
      "Embedding: [-0.01688493 -0.05661953 -0.02599115  0.04413031  0.01161325 -0.04865458\n",
      " -0.11495017 -0.00663144  0.11297659  0.03967591]...\n",
      "Sentence: Here are examples of each.\n",
      "Time-Based Decay\n",
      "from tensorflow.keras.models import Sequential\n",
      "from tensorflow.keras.layers import Dense\n",
      "from tensorflow.keras.optimizers import Adam\n",
      "from tensorflow.keras.callbacks import LearningRateScheduler\n",
      "import numpy as np\n",
      "36\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "# Sample model\n",
      "model = Sequential([Dense(64, activation=’relu’,\n",
      "input_shape=(20,)),\n",
      "Dense(1, activation=’sigmoid’)])\n",
      "# Initial learning rate\n",
      "initial_learning_rate = 0.01\n",
      "# Define the scheduler function\n",
      "def scheduler(epoch, lr):\n",
      "decay = 0.1\n",
      "return initial_learning_rate / (1 + decay * epoch)\n",
      "# Compile the model with the initial learning rate\n",
      "model.compile(\n",
      "optimizer=Adam(learning_rate=initial_learnin_rate),\n",
      "loss=’binary_crossentropy’, metrics=[’accuracy’])\n",
      "# Fit the model with the learning rate scheduler\n",
      "model.fit(X_train, y_train, epochs=100,\n",
      "callbacks=[LearningRateScheduler(scheduler)])\n",
      "Step Decay\n",
      "Step decay reduces the learning rate by a factor every few epochs.\n",
      "# Define the scheduler function for step decay\n",
      "def step_decay(epoch):\n",
      "initial_lr = 0.01\n",
      "drop_rate = 0.5\n",
      "epochs_drop = 10.0\n",
      "return initial_lr * np.power(drop_rate,\n",
      "np.floor((1+epoch)/epochs_drop))\n",
      "# Compile and fit as before\n",
      "model.compile(optimizer=Adam(learning_rate=0.01),\n",
      "loss=’binary_crossentropy’,\n",
      "metrics=[’accuracy’])\n",
      "model.fit(X_train, y_train, epochs=100,\n",
      "callbacks=[LearningRateScheduler(step_decay)])\n",
      "Exponential Decay\n",
      "# Define the scheduler function for exponential decay\n",
      "def exponential_decay(epoch):\n",
      "initial_lr = 0.01\n",
      "k = 0.1\n",
      "return initial_lr * np.exp(-k*epoch)\n",
      "# Compile and fit as before\n",
      "model.compile(optimizer=Adam(learning_rate=0.01),\n",
      "loss=’binary_crossentropy’,\n",
      "metrics=[’accuracy’])\n",
      "model.fit(X_train, y_train, epochs=100,\n",
      "callbacks=[LearningRateScheduler(exponential_decay)])\n",
      "3.7\n",
      "TensorBoard\n",
      "37\n",
      "3.6\n",
      "Generalization Errors\n",
      "If a network performs well on the training set but generalizes badly, it is\n",
      "overf itting the data\n",
      "Embedding: [-0.0467113  -0.09590938  0.03390112  0.03412586  0.05323495 -0.07178412\n",
      " -0.11449374 -0.00360329 -0.00670122 -0.05931905]...\n",
      "Sentence: A network might overﬁt if the training set contains accidental\n",
      "regularities in the input data\n",
      "Embedding: [ 0.0108514  -0.0281958   0.08017411  0.04728788  0.0149804   0.0249529\n",
      " -0.02939367 -0.05441291 -0.04638046 -0.08316155]...\n",
      "Sentence: For instance, in our MNIST training dataset, if the\n",
      "handwritten digit was from a single person, then any quirks in the way a digit is\n",
      "written could be taken as gospel truth in our trained network, fooling it to failing to\n",
      "distinguish the handwriting from other people\n",
      "Embedding: [-0.05924249 -0.02544478 -0.01195294 -0.01867035  0.02772682  0.01670159\n",
      " -0.02722468 -0.05792508  0.00229405 -0.04274825]...\n",
      "Sentence: Equally, suppose we have a diverse\n",
      "handwritten dataset from millions of people, a simple network with few neurons\n",
      "will not have the capacity to remember the information in its training data\n",
      "Embedding: [ 0.02005716 -0.08028634 -0.02173142  0.06251819  0.02617738  0.04955759\n",
      " -0.04831206 -0.0125531   0.03398154 -0.06124346]...\n",
      "Sentence: In other\n",
      "words, the number of neurons and possibly the architecture of the network are\n",
      "insufﬁcient to capture the complexity of the data\n",
      "Embedding: [ 0.03102766 -0.06866425 -0.00608931  0.00322317  0.00752156 -0.00808697\n",
      " -0.0520414  -0.02633069  0.0887197   0.02395969]...\n",
      "Sentence: When a network fails to learn this\n",
      "way, it is underf itting the data\n",
      "Embedding: [ 0.03812642 -0.02418146  0.03456619  0.0502227  -0.01066251 -0.03695949\n",
      " -0.01707622 -0.02069007  0.02294808 -0.01431308]...\n",
      "Sentence: An overﬁtting error is also known as variance\n",
      "error\n",
      "Embedding: [-0.00868368  0.0041786   0.02652327  0.03000537 -0.02123458 -0.03978066\n",
      "  0.01469728  0.10159051 -0.00084027  0.03099255]...\n",
      "Sentence: A network with a high overﬁtting error is said to exhibit a high variance.\n",
      "Similarly, an underﬁtting error is known as bias error\n",
      "Embedding: [ 0.01224672 -0.03937701  0.02542159  0.01393001 -0.00015512 -0.01866644\n",
      "  0.03054323  0.05933893  0.01315502 -0.01157768]...\n",
      "Sentence: A high level of underﬁtting\n",
      "means a high level of bias\n",
      "Embedding: [-0.03842952 -0.03357858  0.01591679  0.01040846  0.06831991  0.01598289\n",
      "  0.02594769  0.00727576  0.02333016 -0.02703531]...\n",
      "Sentence: We can deduce from the argument above that over-\n",
      "and underﬁtting errors are related\n",
      "Embedding: [-0.06800557  0.02412865  0.06111417  0.03081898  0.08301616 -0.05716986\n",
      "  0.00622196  0.04964869 -0.02716342 -0.00214893]...\n",
      "Sentence: We reduce the overﬁtting error by reducing the\n",
      "capacity of the network or adding additional training examples\n",
      "Embedding: [-0.00606225 -0.00694624  0.03607596  0.04387072  0.05434192 -0.00994067\n",
      " -0.06293905  0.02475351 -0.05731865 -0.06158745]...\n",
      "Sentence: However, if a model\n",
      "is underﬁtting, adding data does not help\n",
      "Embedding: [ 1.8771592e-05 -3.3503085e-02  9.7118514e-03  7.4947156e-02\n",
      "  5.3872224e-02 -3.3681996e-03 -7.1831577e-02 -1.2286507e-02\n",
      "  5.0560790e-05 -2.0060258e-02]...\n",
      "Sentence: No matter how much we reduce these two\n",
      "types of error, we should understand that for real-world problems, the network can\n",
      "never predict with 100% accuracy, so it is a compromise of accepting a low error\n",
      "rate rather than achieving perfection.\n",
      "A learning curve, illustrated in Figure 3-9, is a graphical representation of the\n",
      "relationship between a model’s performance and a measure of experience, such as\n",
      "the number of training instances or iterations\n",
      "Embedding: [ 0.02588394 -0.00840242  0.01393804  0.07676718  0.0281005  -0.07739363\n",
      " -0.05978324  0.06123415  0.02133721 -0.05419071]...\n",
      "Sentence: It visualizes how effectively the model\n",
      "learns over time and highlights potential issues like overﬁtting or underﬁtting.\n",
      "Keras and other machine learning languages have tools to measure and reduce\n",
      "generalization errors, which we will discuss next\n",
      "Embedding: [-0.02270547 -0.05383307  0.11138148  0.02983007  0.08061846 -0.0210648\n",
      " -0.07378902 -0.02812702 -0.05880351 -0.05286288]...\n",
      "Sentence: It is important to keep in mind\n",
      "that the overall objective of these tools and procedure is to make the best use of the\n",
      "training dataset and reduce the generalization errors.\n",
      "3.7\n",
      "TensorBoard\n",
      "It is imperative that during training, we keep track of how well a model is doing.\n",
      "For very simple model, it may sufﬁce to include debugging statements to show the\n",
      "average loss per epoch\n",
      "Embedding: [ 0.01954219 -0.0596376   0.01604211  0.02028956  0.02186014 -0.00234216\n",
      " -0.05190209  0.04938041 -0.09631442 -0.08535962]...\n",
      "Sentence: A better and more informative way to track the performance\n",
      "of the model is to use TensorBoard.\n",
      "TensorBoard, provided by TensorFlow, Google’s open source machine learning\n",
      "framework, is a visualization toolkit designed for machine learning experimentation.\n",
      "It facilitates the inspection and understanding of machine learning workﬂows.\n",
      "It offers a suite of web applications that help us visualize and understand our\n",
      "TensorFlow runs and graphs\n",
      "Embedding: [ 0.04327861 -0.12240908 -0.06187869 -0.0142753   0.10345966 -0.02793524\n",
      " -0.05169971 -0.0623461  -0.04853425 -0.08938763]...\n",
      "Sentence: TensorBoard is particularly useful in the training and\n",
      "ﬁne-tuning of neural networks.\n",
      "38\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "Figure 3-9 The learning curve\n",
      "Setting up and using TensorBoard is straightforward, typically involving the\n",
      "integration of a few lines of code within the TensorFlow training script to enable\n",
      "logging and visualization\n",
      "Embedding: [ 0.00920211 -0.13776292 -0.07414374 -0.02280216  0.04143591  0.04874426\n",
      " -0.00806205  0.01519889 -0.07191331 -0.07606678]...\n",
      "Sentence: It does not impose a signiﬁcant amount of performance\n",
      "penalties, so it is a practical tool to use in many instances\n",
      "Embedding: [-0.0051311   0.02507098 -0.09260403 -0.0265315   0.01405664 -0.01108486\n",
      " -0.01034513  0.01510587  0.01682091 -0.02726179]...\n",
      "Sentence: I personally prefer to ﬁrst\n",
      "develop and test the model and then integrate TensorBoard for detailed monitoring\n",
      "during actual training runs.\n",
      "Key Features of TensorBoard\n",
      "•\n",
      "Visualization of Metrics: It allows us to track and visualize metrics such as loss\n",
      "and accuracy during the training process\n",
      "Embedding: [ 0.03449279 -0.09595852 -0.06757123 -0.01886868  0.05848265  0.05006723\n",
      " -0.05261986  0.04061325  0.01589561 -0.04510063]...\n",
      "Sentence: We can see these metrics in real time,\n",
      "which helps in understanding how our model is performing and when it begins\n",
      "to overﬁt or underﬁt.\n",
      "•\n",
      "Graph Visualization: TensorBoard provides a way to visualize our model archi-\n",
      "tecture\n",
      "Embedding: [ 0.01730879 -0.13863502 -0.04866681 -0.04188931  0.02426061  0.0067923\n",
      " -0.07923613  0.02091833  0.09687504 -0.06608206]...\n",
      "Sentence: This can help in understanding the TensorFlow graph, observing how\n",
      "tensors ﬂow through the graph, and debugging if necessary.\n",
      "•\n",
      "Viewing Histograms of Weights and Biases: We can see the distribution of\n",
      "weights and biases across different layers in the network over time\n",
      "Embedding: [ 0.00458191 -0.09444424 -0.0066612   0.01054372  0.09201552  0.00975862\n",
      "  0.00816438 -0.08139872 -0.00820511 -0.08046682]...\n",
      "Sentence: This can\n",
      "give insights into how the network is learning.\n",
      "•\n",
      "Projector for Embeddings: TensorBoard includes a tool for visualizing high-\n",
      "dimensional embeddings\n",
      "Embedding: [ 0.06592141 -0.13792454  0.00041827 -0.00752159  0.08964306  0.05509212\n",
      " -0.07477561 -0.01494637  0.02772759 -0.05073171]...\n",
      "Sentence: This feature is particularly useful for tasks like word\n",
      "embeddings in natural language processing.\n",
      "3.7\n",
      "TensorBoard\n",
      "39\n",
      "•\n",
      "Image and Audio Visualization: If we are working with image or audio data,\n",
      "TensorBoard can show actual images or play audio directly within the dashboard,\n",
      "which can be useful for monitoring the outputs of our model.\n",
      "•\n",
      "Hyperparameter Tuning: With the HParams dashboard, we can visualize hyper-\n",
      "parameter tuning experiments with Keras Tuners (or another tuning library).\n",
      "We can record the hyperparameters (like learning rate, number of layers) and\n",
      "metrics (like loss, accuracy) and then compare different runs to see which\n",
      "hyperparameters work best.\n",
      "•\n",
      "Performance Proﬁling: TensorBoard also offers tools to proﬁle the model, help-\n",
      "ing us understand where the bottlenecks in computation are and how efﬁciently\n",
      "our model is running.\n",
      "To use TensorBoard, we typically start by modifying our TensorFlow code to write\n",
      "log ﬁles containing the metrics, embeddings, etc., to a speciﬁed directory\n",
      "Embedding: [ 0.0519332  -0.13607113 -0.07031686 -0.04683375  0.06236735  0.05109243\n",
      " -0.03690164 -0.0205152  -0.01919156 -0.09150846]...\n",
      "Sentence: Then\n",
      "we launch TensorBoard and point it to this log directory and visualize in the web\n",
      "browser.\n",
      "Here are some basic examples of how to use TensorBoard with a TensorFlow/\n",
      "Keras model:\n",
      "Metric Visualization\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
      "from tensorflow.keras.callbacks import TensorBoard\n",
      "import datetime\n",
      "# Prepare dataset (example with MNIST)\n",
      "mnist = tf.keras.datasets.mnist\n",
      "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
      "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
      "# Add a channels dimension\n",
      "x_train = x_train[..., tf.newaxis]\n",
      "x_test = x_test[..., tf.newaxis]\n",
      "# Build the model\n",
      "model = tf.keras.models.Sequential([\n",
      "Conv2D(32, 3, activation=’relu’, input_shape=(28, 28, 1)),\n",
      "Flatten(),\n",
      "Dense(128, activation=’relu’),\n",
      "Dense(10)\n",
      "])\n",
      "# Compile the model\n",
      "model.compile(optimizer=’adam’,\n",
      "loss=tf.keras.losses.\n",
      "SparseCategoricalCrossentropy(from_logits=True),\n",
      "metrics=[’accuracy’])\n",
      "# Set up the TensorBoard callback\n",
      "log_dir = \"logs/fit/\" +\n",
      "40\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
      "tensorboard_callback = TensorBoard(log_dir=log_dir,\n",
      "histogram_freq=1)\n",
      "# Train the model\n",
      "model.fit(x=x_train,\n",
      "y=y_train,\n",
      "epochs=5,\n",
      "validation_data=(x_test, y_test),\n",
      "callbacks=[tensorboard_callback])\n",
      "Graph Visualization\n",
      "The model architecture is automatically logged by TensorBoard\n",
      "Embedding: [ 0.06545392 -0.17798482 -0.02646284 -0.02339497  0.0397393  -0.00269246\n",
      " -0.05768717  0.03891417 -0.04742493 -0.08977222]...\n",
      "Sentence: We can view it in\n",
      "the Graphs tab.\n",
      "Histograms of Weights and Biases\n",
      "The histogram freq=1 parameter in the TensorBoard callback logs the distribution\n",
      "of weights and biases\n",
      "Embedding: [-0.00763741 -0.09678188 -0.09550752  0.00489929  0.01235085  0.03300155\n",
      "  0.02176514  0.01623415 -0.01512123 -0.04173369]...\n",
      "Sentence: These can be viewed in the Histograms tab in TensorBoard.\n",
      "Embedding Visualization\n",
      "For embedding visualization, we need to have an embedding layer in our model and\n",
      "use the TensorBoard callback with an embedding layer speciﬁed.\n",
      "# Assuming ’model’ has an embedding layer\n",
      "tensorboard_callback = TensorBoard(log_dir=log_dir,\n",
      "histogram_freq=1, embeddings_freq=1)\n",
      "To visualize images, we need to modify the TensorBoard callback:\n",
      "file_writer = tf.summary.create_file_writer(log_dir + ’/img’)\n",
      "with file_writer.as_default():\n",
      "tf.summary.image(\"Training data\", x_train, step=0)\n",
      "Performance Proﬁling\n",
      "tensorboard_callback = TensorBoard(log_dir=log_dir,\n",
      "histogram_freq=1, profile_batch=’500,520’)\n",
      "The HParams dashboard, a feature within TensorBoard, offers a specialized\n",
      "interface to visualize and analyze the results of hyperparameter tuning experiments,\n",
      "aiding in the selection of the most effective model conﬁgurations\n",
      "Embedding: [ 0.0757959  -0.08898026 -0.06524073  0.01067307  0.04615035  0.03122156\n",
      "  0.0251072   0.06503733 -0.06984572 -0.08035798]...\n",
      "Sentence: It allows us to\n",
      "interactively compare the performance of different sets of hyperparameters, making\n",
      "it easier to identify the most effective conﬁgurations for our machine learning\n",
      "models.\n",
      "To use the HParams dashboard, we need to log hyperparameters and metrics\n",
      "during our model’s training process\n",
      "Embedding: [-0.02635663 -0.09440523 -0.06712485 -0.00748354  0.00533465 -0.06281727\n",
      " -0.0394781  -0.02397563 -0.01789886 -0.03078046]...\n",
      "Sentence: Essentially, we need to loop through the set of\n",
      "parameters and record the results for each run using TensorBoard as shown below:\n",
      "from tensorboard.plugins.hparams import api as hp\n",
      "3.7\n",
      "TensorBoard\n",
      "41\n",
      "HP_NUM_UNITS = hp.HParam(’num_units’, hp.Discrete([16, 32]))\n",
      "HP_DROPOUT = hp.HParam(’dropout’, hp.RealInterval(0.1, 0.2))\n",
      "HP_OPTIMIZER = hp.HParam(’optimizer’,\n",
      "hp.Discrete([’adam’, ’sgd’]))\n",
      "METRIC_ACCURACY = ’accuracy’\n",
      "with tf.summary.create_file_writer(\n",
      "’logs/hparam_tuning’).as_default():\n",
      "hp.hparams_config(\n",
      "hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
      "metrics=[hp.Metric(METRIC_ACCURACY,\n",
      "display_name=’Accuracy’)],)\n",
      "def train_test_model(hparams, session_num):\n",
      "model = tf.keras.models.Sequential([\n",
      "tf.keras.layers.Dense(hparams[HP_NUM_UNITS],\n",
      "activation=’relu’),\n",
      "tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
      "tf.keras.layers.Dense(10, activation=’softmax’)])\n",
      "model.compile(\n",
      "optimizer=hparams[HP_OPTIMIZER],\n",
      "loss=’sparse_categorical_crossentropy’,\n",
      "metrics=[’accuracy’],)\n",
      "# Run with the hparams\n",
      "model.fit(x_train, y_train, epochs=10) # example values\n",
      "_, accuracy = model.evaluate(x_test, y_test)\n",
      "return accuracy\n",
      "session_num = 0\n",
      "for num_units in HP_NUM_UNITS.domain.values:\n",
      "for dropout_rate in (HP_DROPOUT.domain.min_value,\n",
      "HP_DROPOUT.domain.max_value):\n",
      "for optimizer in HP_OPTIMIZER.domain.values:\n",
      "hparams =\n",
      "HP_NUM_UNITS: num_units,\n",
      "HP_DROPOUT: dropout_rate,\n",
      "HP_OPTIMIZER: optimizer,\n",
      "run_name = \"run-%d\" % session_num\n",
      "print(’--- Starting trial: %s’ % run_name)\n",
      "print(h.name: hparams[h] for h in hparams)\n",
      "accuracy = train_test_model(hparams, session_num)\n",
      "session_num += 1\n",
      "# Log an hparams summary with the metrics.\n",
      "with tf.summary.create_file_writer(’logs/hparam_tuning/’\n",
      "+ run_name).as_default():\n",
      "hp.hparams(hparams) #record the values used\n",
      "tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
      "42\n",
      "3\n",
      "How Machine Learns Using Neural Network\n",
      "Run TensorBoard and navigate to the HParams tab, then use\n",
      "tensorboard --logdir logs/hparam_tuning\n",
      "\n",
      "Embedding: [ 0.03679999 -0.03937965 -0.06868422  0.0140581  -0.04441803 -0.01364443\n",
      "  0.03571524  0.03245442 -0.09488319 -0.11194243]...\n",
      "Sentence: Open the browser and go to http://localhost:6006/\n",
      "Embedding: [ 0.03398121 -0.02321838 -0.03327562 -0.049296    0.03866073 -0.00503563\n",
      " -0.18521203 -0.06446642 -0.04333967 -0.0054102 ]...\n",
      "Sentence: In the HParams dashboard, we\n",
      "can\n",
      "•\n",
      "View tables and visualizations of runs\n",
      "•\n",
      "Filter and sort based on hyperparameters and metrics\n",
      "•\n",
      "Explore parallel coordinates and scatter plot views to analyze relationships\n",
      "between hyperparameters and model performance\n",
      "3.8\n",
      "Using TensorBoard in Colab\n",
      "When using TensorBoard within Google Colab, the procedure remains largely\n",
      "the same as outlined earlier\n",
      "Embedding: [ 0.00317467 -0.1948933  -0.04542083 -0.01785548 -0.02569389  0.01343793\n",
      " -0.09220259 -0.00618513 -0.07169992 -0.09036312]...\n",
      "Sentence: However, it’s important to enable “allow third-party\n",
      "cookies” in the browser settings to avoid encountering a “403 Error.”\n",
      "%tensorboard --logdir logs_directory\n",
      "Use Colab’s ﬁle manager to locate the path of the logs and use that path for the\n",
      "logs_directory variable\n",
      "Embedding: [ 0.0015621  -0.1297385  -0.07067779 -0.01312733  0.07066741 -0.07612671\n",
      "  0.00801184  0.00335127  0.00309837 -0.04315172]...\n",
      "Sentence: The TensorBoard log contains enough of data for other\n",
      "metrics such as confusion matrix to be calculated, but we will have to search add-ins\n",
      "on the Internet.\n",
      "Note that if we wish to view the model graph, then select the Graphs tab.\n",
      "By default, the model is shown inverted with data ﬂowing from bottom to top.\n",
      "The default graph is slightly different to the model produced by Keras’s function\n",
      "plot_model(), but it is perhaps more intuitive than the standard view, but if we\n",
      "need to see the same model as Keras, then select the conceptual graph.\n",
      "Sometimes, we may run into an error with TensorBoard blocking the port 6006\n",
      "because it has been occupied\n",
      "Embedding: [ 0.04079884 -0.13847047 -0.04681476 -0.04201793  0.01796321 -0.02563964\n",
      " -0.06546485  0.04270145  0.00646036 -0.01067226]...\n",
      "Sentence: If this is the case, we will need to kill the existing\n",
      "process on the port\n",
      "Embedding: [-0.04266518 -0.02322355 -0.05944207 -0.11253172  0.03692467 -0.12690173\n",
      " -0.09081272 -0.07204519 -0.02349725  0.05477934]...\n",
      "Sentence: Unless we have a Colab pro subscription which gives access to\n",
      "the terminal app, one way to ﬁnd the correct PID to kill is to create an instance of a\n",
      "terminal using the following commands:\n",
      "!pip install colab-xterm\n",
      "%load_ext colabxterm\n",
      "%xterm\n",
      "Type lsof -i:6006 in the terminal to bring up the PID number and use the\n",
      "displayed PID to kill the process with the command kill PID.\n",
      "4\n",
      "Network Layers\n",
      "In the context of machine learning, and more speciﬁcally in neural networks,\n",
      "“layers” refer to various levels or stages of processing units\n",
      "Embedding: [-0.00419852 -0.09633974 -0.00197232 -0.07884207  0.03558624 -0.01861485\n",
      " -0.03944838  0.04515852  0.04526984  0.03647754]...\n",
      "Sentence: These layers are\n",
      "fundamental in extracting and transforming features from input data, each serving a\n",
      "distinct functional purpose in the learning process\n",
      "Embedding: [-0.0078391   0.02117712  0.0370132   0.0005808   0.05796456  0.05572887\n",
      " -0.03707417 -0.03990983  0.01921608 -0.05179803]...\n",
      "Sentence: Each type of layer is designed to\n",
      "perform a speciﬁc kind of operation on its input data\n",
      "Embedding: [-0.02410622  0.0128451  -0.02993481 -0.02052733 -0.03539314  0.00128619\n",
      " -0.00923245 -0.02784187  0.01065091 -0.02218087]...\n",
      "Sentence: Here are some common types\n",
      "of layers we will encounter in machine learning models.\n",
      "These are the most basic type of layer in neural networks, where each neuron\n",
      "is connected to every neuron in the preceding and subsequent layers\n",
      "Embedding: [-0.01875618 -0.1346122   0.05838083  0.00909073  0.01978973  0.0432211\n",
      " -0.01503655 -0.05765502  0.07440335 -0.03994114]...\n",
      "Sentence: They are\n",
      "typically used for learning nonspatial hierarchies of features.\n",
      "4.1\n",
      "Dense (Fully Connected) Layers\n",
      "A dense layer, characterized by its fully connected nature, can be versatilely used as\n",
      "an input layer, a hidden layer, or an output layer in a neural network, depending on\n",
      "the speciﬁc architecture and requirements of the model\n",
      "Embedding: [ 0.01127505 -0.08126451 -0.00841342  0.03352743  0.00568143  0.03941822\n",
      " -0.02027003 -0.04625661  0.05842732 -0.05512137]...\n",
      "Sentence: We deﬁne the dense layer\n",
      "for the three cases below:\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "# Create a Sequential model\n",
      "model = Sequential()\n",
      "# Adding the input layer\n",
      "# Assume input_dim is the size of the input features\n",
      "model.add(Dense(units=64, activation=’relu’,\n",
      "input_dim=100))\n",
      "© Philip Hua 2024\n",
      "P\n",
      "Embedding: [ 0.02501263 -0.10917255  0.00448993 -0.03494024 -0.02149277  0.07195372\n",
      " -0.03789324 -0.0641144  -0.02419966 -0.09384685]...\n",
      "Sentence: Hua, Neural Networks with TensorFlow and Keras,\n",
      "https://doi.org/10.1007/979-8-8688-1020-6_4\n",
      "43\n",
      "44\n",
      "4\n",
      "Network Layers\n",
      "# Adding a hidden layer\n",
      "model.add(Dense(units=32, activation=’relu’))\n",
      "# Adding the output layer\n",
      "# Assuming it’s for a binary classification problem\n",
      "model.add(Dense(units=1, activation=’sigmoid’))\n",
      "In the example above\n",
      "•\n",
      "Number of Units (Neurons): The units parameter in a dense layer speciﬁes the\n",
      "number of neurons\n",
      "Embedding: [ 0.00936341 -0.13655436 -0.01638239  0.01578989 -0.05926265  0.07814185\n",
      "  0.00396974 -0.0441539  -0.01118156 -0.08166898]...\n",
      "Sentence: The appropriate number of units can vary depending on the\n",
      "complexity of the task and is generally determined through experimentation.\n",
      "•\n",
      "Activation Function: ReLU is commonly used in hidden layers because it\n",
      "helps with the vanishing gradient problem and allows the model to learn\n",
      "complex patterns\n",
      "Embedding: [-0.03726319 -0.08279383 -0.03759764  0.03101859 -0.00570774  0.06688952\n",
      " -0.02729769 -0.02133748  0.10338247 -0.06020118]...\n",
      "Sentence: The sigmoid function in the output layer is typical for binary\n",
      "classiﬁcation.\n",
      "•\n",
      "Input Dimensions: The “input_dim” parameter is crucial for the ﬁrst layer in a\n",
      "sequential model as it speciﬁes the shape of the input data\n",
      "Embedding: [ 0.01529941 -0.06170814  0.01052656 -0.0259207   0.01159597  0.05122474\n",
      " -0.03280737  0.03418214 -0.01967363 -0.07626978]...\n",
      "Sentence: In most deep learning\n",
      "frameworks, like TensorFlow/Keras and PyTorch, we generally do not explicitly\n",
      "specify the batch size dimension when deﬁning the input shape for layers in\n",
      "our model, including the dense (fully connected) layers\n",
      "Embedding: [-0.00165741 -0.08144067 -0.02341419  0.02709889 -0.07598937  0.04711017\n",
      " -0.07639349 -0.01607453 -0.05845813 -0.11543049]...\n",
      "Sentence: The batch dimension\n",
      "is typically assumed to be dynamic, allowing us to process different batch sizes\n",
      "without needing to redeﬁne the model\n",
      "Embedding: [-0.01183167 -0.07366874 -0.0378257   0.09291014 -0.05815766  0.02207236\n",
      " -0.1127461   0.03536227  0.00120291 -0.04766772]...\n",
      "Sentence: When we deﬁne a dense layer in a Keras\n",
      "model, we can use the “input_shape” parameter to specify the shape of the input\n",
      "data, excluding the batch size\n",
      "Embedding: [ 0.00283985 -0.0163931  -0.01975913  0.00364103 -0.04986057  0.05185482\n",
      " -0.02580218 -0.0602772  -0.06133948 -0.08649081]...\n",
      "Sentence: For example:\n",
      "from tensorflow.keras.models import Sequential\n",
      "from tensorflow.keras.layers import Dense\n",
      "model = Sequential()\n",
      "model.add(Dense(64, activation=’relu’,\n",
      "input_shape=(input_dimension,)))\n",
      "# ..\n",
      "Embedding: [ 0.02018324 -0.15958506  0.01071422 -0.00884964 -0.0885744   0.05757435\n",
      " -0.03749829 -0.06150324  0.00623245 -0.11057823]...\n",
      "Sentence: more layers ...\n",
      "However, when we are actually feeding data into the model during training or\n",
      "inference, our data needs to have the appropriate batch dimension\n",
      "Embedding: [-0.00948264 -0.06681174 -0.00541059  0.0471138  -0.01688412  0.0471111\n",
      " -0.07652774  0.00081119  0.02261772 -0.06907575]...\n",
      "Sentence: This means\n",
      "the input data should be shaped with the batch size as the ﬁrst dimension\n",
      "Embedding: [ 0.00393229 -0.01394568 -0.12068434  0.00661047 -0.0744736  -0.00456525\n",
      " -0.0643693   0.05960882 -0.04690725 -0.06976385]...\n",
      "Sentence: In the\n",
      "example above, note that the single input dimension above is now fed with a 2D\n",
      "data array with the ﬁrst dimension being the batch size.\n",
      "import numpy as np\n",
      "from tensorflow.keras.models import Sequential\n",
      "from tensorflow.keras.layers import Dense\n",
      "# Define the model\n",
      "input_dimension = 20\n",
      "# Example input dimension\n",
      "model = Sequential()\n",
      "4.1\n",
      "Dense (Fully Connected) Layers\n",
      "45\n",
      "model.add(Dense(64, activation=’relu’,\n",
      "input_shape=(input_dimension,)))\n",
      "model.add(Dense(10, activation=’softmax’))\n",
      "# Compile the model\n",
      "model.compile(optimizer=’adam’,\n",
      "loss=’categorical_crossentropy’,\n",
      "metrics=[’accuracy’])\n",
      "# Generate dummy data for demonstration\n",
      "batch_size = 32\n",
      "# Example batch size\n",
      "# Create a batch of input data\n",
      "# (32 samples, each with 20 features)\n",
      "input_data = np.random.random((batch_size,\n",
      "input_dimension))\n",
      "# Create corresponding dummy labels\n",
      "# (32 samples, 10 classes for output)\n",
      "labels = np.random.randint(10, size=(batch_size, 1))\n",
      "labels = tf.keras.utils.to_categorical(labels,\n",
      "num_classes=10)\n",
      "# Feed the data to the model\n",
      "model.fit(input_data, labels, epochs=5,\n",
      "batch_size=batch_size)\n",
      "•\n",
      "Output Layer Conﬁguration: The conﬁguration of the output layer depends on\n",
      "the speciﬁc problem (e.g., number of classes in classiﬁcation tasks)\n",
      "Embedding: [ 0.09160189 -0.10948474  0.00742561 -0.00488409 -0.03251392  0.05117745\n",
      " -0.070732   -0.03059324 -0.07174867 -0.13587035]...\n",
      "Sentence: If it is a\n",
      "binary classiﬁcation, the number of units equals one\n",
      "Embedding: [ 0.04064065  0.02476382 -0.06535418  0.00137539 -0.08252831 -0.03553684\n",
      "  0.01187373 -0.0512638  -0.01417349 -0.03236603]...\n",
      "Sentence: For categorical outputs, the\n",
      "number of units will be the number of categories.\n",
      "In particular, for multi-class classiﬁcation output, the activation function will be\n",
      "“softmax.” It turns the output into a probability distribution over the classes,\n",
      "where the output of each neuron corresponds to the probability that the input\n",
      "belongs to the respective class.\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "# Number of output categories\n",
      "num_categories = 10\n",
      "# Create a Sequential model\n",
      "model = Sequential()\n",
      "# Add hidden layers...\n",
      "# Adding the output layer for categorical outputs\n",
      "model.add(Dense(units=num_categories,\n",
      "activation=’softmax’))\n",
      "46\n",
      "4\n",
      "Network Layers\n",
      "Often, we need to add a BatchNormalization layer after the dense layer and\n",
      "before the output layer, so we do not specify all the parameters for the dense\n",
      "layer in a single line.\n",
      "from keras.layers import Dense, BatchNormalization,\n",
      "Activation\n",
      "model.add(Dense(units=64))\n",
      "model.add(BatchNormalization())\n",
      "model.add(Activation(’relu’))\n",
      "4.2\n",
      "Normalization Layers\n",
      "The normalization technique normalizes the inputs of each mini batch to have a\n",
      "mean of zero and a variance of one\n",
      "Embedding: [ 0.03912634 -0.0908123  -0.01999883  0.00086661 -0.02931198  0.06172194\n",
      " -0.06708522 -0.01758289 -0.01914256 -0.09336467]...\n",
      "Sentence: It is often used to stabilize and accelerate the\n",
      "training of deep neural networks\n",
      "Embedding: [-0.09618177 -0.05607522 -0.01549723  0.01612978  0.01406852  0.00235199\n",
      " -0.02080259 -0.00105632  0.0303571  -0.07266223]...\n",
      "Sentence: Keras provides two types of normalization:\n",
      "1\n",
      "Embedding: [-0.00267451 -0.0522014   0.0241609  -0.05649709 -0.02906319 -0.00780505\n",
      " -0.08261999 -0.07418745 -0.09748937 -0.03608603]...\n",
      "Sentence: Batch Normalization: These layers apply a transformation that maintains the\n",
      "mean output close to zero and the output standard deviation close to one.\n",
      "The normalization is used to reduce internal covariate shift\n",
      "Embedding: [-0.0326495  -0.02385159 -0.03472908  0.0023614  -0.01639405  0.05828014\n",
      " -0.04568873 -0.01714559 -0.02209289 -0.00162939]...\n",
      "Sentence: This refers to the\n",
      "change in the distribution of network activations due to the change in network\n",
      "parameters during training which can slow down the training process since layers\n",
      "continuously need to adapt to new distributions\n",
      "Embedding: [-0.04117402 -0.05446865  0.03772885  0.05122964  0.04300244  0.01490566\n",
      "  0.02119637  0.02942276  0.01993385 -0.07089374]...\n",
      "Sentence: This is why Batch Normalization\n",
      "is typically applied after a layer, but before its activation function.\n",
      "2\n",
      "Embedding: [-0.03966328 -0.02140831  0.02417121  0.01955678 -0.0078176   0.02223025\n",
      "  0.02601914 -0.03625334 -0.03624088 -0.02992501]...\n",
      "Sentence: Layer Normalization is another technique used in neural networks, similar\n",
      "in purpose to Batch Normalization but with key differences in its approach\n",
      "and applications\n",
      "Embedding: [-0.05890274 -0.01940977  0.01192687 -0.02495053 -0.03237059  0.01926526\n",
      " -0.02888051 -0.01018174 -0.06817523 -0.08066566]...\n",
      "Sentence: It was introduced in a 2016 paper by Jimmy Lei Ba, Jamie\n",
      "Ryan Kiros, and Geoffrey Hinton titled “Layer Normalization.” Unlike Batch\n",
      "Normalization, which normalizes across the batch dimension, Layer Normal-\n",
      "ization normalizes across the features\n",
      "Embedding: [-0.04201844  0.00238718  0.01234908  0.02971602  0.01976349  0.01848897\n",
      " -0.0241422  -0.0066076  -0.11056086 -0.05269837]...\n",
      "Sentence: In other words, for a given layer, Layer\n",
      "Normalization computes the mean and variance used for normalization from all\n",
      "of the summed inputs to the neurons in that layer.\n",
      "Layer Normalization does not rely on the batch dimension; it works well with\n",
      "different batch sizes and is particularly effective in tasks where the batch size\n",
      "is small or varies\n",
      "Embedding: [-0.01609001 -0.03119282  0.04066622  0.0186896  -0.04142554  0.07979639\n",
      " -0.05586264  0.00292777 -0.04437612 -0.03691383]...\n",
      "Sentence: Layer Normalization can be applied similarly to Batch\n",
      "Normalization, typically after the linear transformation and before the activation\n",
      "function:\n",
      "model.add(Dense(64))\n",
      "model.add(LayerNormalization())\n",
      "model.add(Activation(’relu’))\n",
      "4.3\n",
      "Dropout Layers\n",
      "47\n",
      "4.3\n",
      "Dropout Layers\n",
      "The dropout layers randomly set a fraction of input units to zero at each update\n",
      "during training time, which helps prevent overﬁtting\n",
      "Embedding: [-0.02044089 -0.03927638  0.01115593  0.03397575 -0.04025353  0.03106144\n",
      " -0.03501454 -0.058006   -0.08406133 -0.08873875]...\n",
      "Sentence: The key parameter for a\n",
      "dropout layer is the dropout rate, which speciﬁes the fraction of the input units to be\n",
      "dropped during training\n",
      "Embedding: [-0.01376094 -0.0044231  -0.03044706  0.03853114  0.01932917  0.0785666\n",
      "  0.0086196   0.01223194  0.01592599 -0.12000792]...\n",
      "Sentence: For example, rate = 0.2 means approximately 20% of the\n",
      "input units are set to 0 at each update during the training phase\n",
      "Embedding: [ 0.03729695 -0.04214171 -0.0765258   0.04532152 -0.0288551  -0.0376294\n",
      " -0.10177679 -0.00365496  0.06320865 -0.05723209]...\n",
      "Sentence: The choice of the\n",
      "dropout rate is crucial: a rate that is too high may lead to underﬁtting, while a rate\n",
      "that’s too low might not effectively prevent overﬁtting.\n",
      "It is commonly used in fully connected (dense) layers of a network and is\n",
      "typically applied to the outputs of intermediate layers, but it can be used after any\n",
      "layer except the input layer.\n",
      "While dropout can be used in convolutional layers, it is less common\n",
      "Embedding: [-0.00011716 -0.00599069 -0.0046906  -0.01583771  0.01515632 -0.00829119\n",
      " -0.04736352  0.01789139  0.09598034 -0.11627987]...\n",
      "Sentence: Other\n",
      "regularization techniques, like data augmentation and batch normalization, are often\n",
      "preferred in convolutional neural networks (CNNs).\n",
      "During testing or inference, usually a dropout is not applied\n",
      "Embedding: [-0.04310681  0.00715052  0.07946826  0.00692171 -0.02322481 -0.00484436\n",
      " -0.03959094 -0.03490257 -0.06567621 -0.10532994]...\n",
      "Sentence: The network uses\n",
      "all its units, and the weights are scaled appropriately based on the dropout rate used\n",
      "during training\n",
      "Embedding: [ 0.01040201 -0.00787152 -0.01800176  0.02771751 -0.02647635 -0.0183159\n",
      " -0.02943276  0.01003793  0.05027992 -0.09074768]...\n",
      "Sentence: This scaling is typically handled automatically by frameworks like\n",
      "Keras.\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense, Dropout\n",
      "model = Sequential()\n",
      "model.add(Dense(64, activation=’relu’))\n",
      "model.add(Dropout(0.5))\n",
      "# Applying 50% dropout\n",
      "model.add(Dense(10, activation=’softmax’))\n",
      "4.3.1\n",
      "Flattening Layers\n",
      "If we want to use a custom output layer to classify speciﬁc categories, we will need\n",
      "to add a ﬂatten layer to the end of the hidden layers and a custom output layer\n",
      "Embedding: [ 0.03380009 -0.07117877 -0.08377724  0.0326365  -0.04389019  0.03534145\n",
      " -0.05115048  0.02334203 -0.07217148 -0.10408786]...\n",
      "Sentence: In the\n",
      "MNIST handwritten example, we ﬂatten the input layer explicitly using the reshape\n",
      "method:\n",
      "xTrainFlattened = xTrain.reshape(len(xTrain),784)\n",
      "Using a ﬂatten layer does exactly the same transformation; it simply reshapes a\n",
      "multidimensional vector to a 1D vector as illustrated in Figure 4-1.\n",
      "4.3.2\n",
      "Pooling Layers\n",
      "MaxPooling and Average Pooling are two operations commonly used in the\n",
      "context of convolutional neural networks (CNNs)\n",
      "Embedding: [-0.0764562  -0.04860774  0.04469606 -0.01882643  0.01291204 -0.02713957\n",
      " -0.04196129 -0.01863321 -0.01217154 -0.09231019]...\n",
      "Sentence: They are types of pooling layers\n",
      "that reduce the spatial dimensions (i.e., width and height) of the input feature\n",
      "maps, effectively downsampling the input\n",
      "Embedding: [-0.0385429   0.00613191  0.02982571 -0.01894397  0.02263213  0.03861496\n",
      " -0.01425099  0.02878655  0.02980249 -0.0696647 ]...\n",
      "Sentence: This reduction helps to decrease the\n",
      "48\n",
      "4\n",
      "Network Layers\n",
      "Figure 4-1 Graphical\n",
      "representation of ﬂattening\n",
      "Figure 4-2 Diagram showing MaxPooling2D with pool size=(2,2) and strides=(2,2)\n",
      "Figure 4-3 Diagram showing AveragePooling2D with pool size=(2,2) and strides=(2,2)\n",
      "computational load, control overﬁtting by providing an abstracted form of the\n",
      "representation, and improve the network’s ability to extract dominant features.\n",
      "MaxPooling operates on each feature map independently\n",
      "Embedding: [ 0.08366702  0.04983503  0.08990778 -0.02252018  0.01541251  0.00457873\n",
      " -0.07790259 -0.01079233 -0.05416662 -0.05840757]...\n",
      "Sentence: This process involves\n",
      "sliding a window (of a speciﬁed size and stride) over the input and outputting the\n",
      "4.3\n",
      "Dropout Layers\n",
      "49\n",
      "maximum value within the window at each position\n",
      "Embedding: [-0.01359557  0.02324824 -0.04474763 -0.02548983 -0.03889003  0.0025109\n",
      " -0.02960221  0.01755165 -0.03286578 -0.07985896]...\n",
      "Sentence: This process emphasizes the\n",
      "most pronounced features in each region of the feature map.\n",
      "from keras.layers import MaxPooling2D\n",
      "max_pool = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))\n",
      "Refer to Figure 4-2\n",
      "Embedding: [ 0.08354293 -0.02898544  0.05483582 -0.1223207  -0.03145836 -0.01031643\n",
      " -0.03690923 -0.05509912 -0.06132359 -0.08941951]...\n",
      "Sentence: In this example, pool size=(2, 2) means that the MaxPooling\n",
      "operation is applied over 2 × 2 windows, and strides=(2, 2) means that the window\n",
      "is moved 2 pixels across and 2 pixels down for each operation\n",
      "Embedding: [ 0.01595415  0.00925234 -0.01370137 -0.0310495  -0.03973308 -0.05964651\n",
      "  0.00266642  0.07953518 -0.00854896 -0.08149972]...\n",
      "Sentence: This will effectively\n",
      "reduce the spatial dimensions of the feature map by a factor of 2.\n",
      "Average Pooling also operates on each feature map independently\n",
      "Embedding: [ 0.09170764  0.02278675  0.094313   -0.00543755  0.04520269 -0.01540522\n",
      " -0.02796309 -0.01225083 -0.04158807 -0.04911661]...\n",
      "Sentence: Similar to\n",
      "MaxPooling, it uses a window of a speciﬁed size and stride, but instead of taking\n",
      "the maximum value, it computes the average of the values in the window as shown\n",
      "in Figure 4-3.\n",
      "from keras.layers import AveragePooling2D\n",
      "# Example of an AveragePooling layer in Keras\n",
      "average_pool = AveragePooling2D(pool_size=(2, 2),\n",
      "strides=(2, 2))\n",
      "Here, the term “pool size=(2, 2)” indicates that the Average Pooling is applied over\n",
      "2 × 2 windows, and strides=(2, 2) moves the window 2 pixels over and 2 pixels\n",
      "down\n",
      "Embedding: [ 0.00729898 -0.01987319  0.03075669 -0.04633464 -0.05293209 -0.05579981\n",
      "  0.00619109  0.03029387 -0.02894882 -0.07165382]...\n",
      "Sentence: This reduces the spatial dimensions like MaxPooling, but it averages the\n",
      "values instead of taking the maximum.\n",
      "MaxPooling is more commonly used because it generally performs better,\n",
      "focusing on the most salient features\n",
      "Embedding: [ 0.04160247 -0.01933279  0.05010531 -0.01827095  0.02899869 -0.06382655\n",
      " -0.01958159  0.03898094  0.04345547 -0.03081072]...\n",
      "Sentence: It’s especially effective in scenarios where\n",
      "the background of the input data is relatively uniform or less important.\n",
      "Average Pooling can be more beneﬁcial when we need to preserve background\n",
      "information or when the importance is more uniformly distributed across the feature\n",
      "map.\n",
      "Both types of pooling help to make the representation approximately invariant\n",
      "to small translations, a desirable property in many vision tasks\n",
      "Embedding: [ 0.00101552 -0.00652031  0.01768875 -0.04179858  0.08991949  0.04129414\n",
      "  0.03347889 -0.00273743  0.0699449  -0.08914419]...\n",
      "Sentence: The choice\n",
      "between them often depends on the speciﬁc requirements of the task and empirical\n",
      "performance.\n",
      "4.3.3\n",
      "Convolutional Layers\n",
      "We will almost certainly encounter convolutional layers when dealing with image\n",
      "processing as they are used extensively for upsampling and downsampling images.\n",
      "Convolutional layers are the core building blocks of CNNs\n",
      "Embedding: [-0.04622445 -0.10162026  0.06809613 -0.05256948  0.05180122 -0.04370065\n",
      " -0.08995172 -0.00945067  0.07544027 -0.00424425]...\n",
      "Sentence: They perform a\n",
      "mathematical operation called convolution, which involves sliding a ﬁlter (or kernel)\n",
      "over the input data (like an image)\n",
      "Embedding: [-0.08079239 -0.02332957 -0.01931947 -0.03321692 -0.03594979 -0.08443104\n",
      " -0.00972026 -0.05692533  0.07136698 -0.04165506]...\n",
      "Sentence: As the ﬁlter moves across the input, it performs\n",
      "element-wise multiplication with the part of the input it covers and sums up these\n",
      "products to produce a feature map\n",
      "Embedding: [ 0.02270837  0.01539221  0.00364697 -0.03758371  0.02822959  0.04822595\n",
      "  0.04163152 -0.04753234 -0.04557182 -0.10873315]...\n",
      "Sentence: This process extracts important features from the\n",
      "input, such as edges, textures, or speciﬁc shapes.\n",
      "50\n",
      "4\n",
      "Network Layers\n",
      "Figure 4-4 Convolving a 3 × 3 kernel over a 4 × 4 input using unit strides with no padding\n",
      "[1, p\n",
      "Embedding: [ 0.00139763  0.01721084  0.00688024 -0.06279212  0.00078697 -0.01686896\n",
      " -0.04609548 -0.02866898 -0.02694781 -0.05957388]...\n",
      "Sentence: 68]\n",
      "Refer to Figure 4-4\n",
      "Embedding: [ 0.11180661  0.0739664  -0.07210822 -0.02242006 -0.06656384  0.06133752\n",
      "  0.01807429  0.08400596 -0.00698515 -0.014544  ]...\n",
      "Sentence: In this example, the 3 × 3 kernel is shown in dark blue.\n",
      "With a unit stride, the model takes the values from the input image shown in dark\n",
      "blue and performs mathematical convolution with the kernel\n",
      "Embedding: [-0.07840962 -0.03866876 -0.05361933 -0.02771843  0.01260371 -0.0849538\n",
      " -0.05310208 -0.00847913  0.06597137 -0.0726376 ]...\n",
      "Sentence: At each position, an\n",
      "element-wise multiplication is performed between the values in the kernel and the\n",
      "corresponding values in the image it covers\n",
      "Embedding: [-0.03390113  0.07152094 -0.05987901 -0.05611048  0.02987536 -0.07562531\n",
      "  0.05213409 -0.02262995  0.02586192 -0.05071107]...\n",
      "Sentence: The results of these multiplications\n",
      "are then summed up to get a single number\n",
      "Embedding: [-0.04754718  0.06358145 -0.02767227  0.00878158 -0.06346712 -0.04944811\n",
      "  0.05882987  0.01368447  0.04012053 -0.040448  ]...\n",
      "Sentence: This sum is the output for the current\n",
      "position of the kernel\n",
      "Embedding: [-0.04612517  0.07538086 -0.03908154  0.02750061  0.06717945  0.0022298\n",
      "  0.06142739  0.0224047   0.08047649 -0.00839313]...\n",
      "Sentence: The operation results in an output of size (2,2) shown in\n",
      "green.\n",
      "The weights of the kernels are learned during the training process\n",
      "Embedding: [-0.01322361  0.01865713 -0.04807916  0.00866132  0.00946628 -0.08747501\n",
      "  0.00039214  0.03377665  0.0263137  -0.03153061]...\n",
      "Sentence: The network\n",
      "adjusts these weights to minimize the difference between its predictions and the\n",
      "actual data.\n",
      "Stride refers to the number of units the ﬁlter moves across the input matrix\n",
      "Embedding: [-0.08636371  0.02761144 -0.05993557  0.03373161 -0.0187676  -0.005028\n",
      " -0.03871014 -0.00702711  0.02094181 -0.08480763]...\n",
      "Sentence: With\n",
      "a stride of one, the ﬁlter moves one unit at a time\n",
      "Embedding: [-0.05471044 -0.00360733 -0.06004363 -0.01535269 -0.04008286  0.01480135\n",
      "  0.06096723 -0.05950326  0.03498435 -0.08207417]...\n",
      "Sentence: This results in a detailed feature\n",
      "map, capturing more information\n",
      "Embedding: [ 0.08130334  0.0369693   0.08804774 -0.03774282  0.11492828  0.00757966\n",
      "  0.00519946 -0.00759296 -0.08755518 -0.03922975]...\n",
      "Sentence: With a stride of two, the ﬁlter moves two units\n",
      "each time\n",
      "Embedding: [-0.03695245  0.00246141 -0.0400505  -0.02004342 -0.0494813  -0.01644751\n",
      "  0.0268918  -0.05367405  0.00911817 -0.0984002 ]...\n",
      "Sentence: This leads to a smaller feature map as it skips over more of the input.\n",
      "Strides greater than one are used for downsampling the input.\n",
      "Padding for a convolutional layer is the process of adding extra pixels around\n",
      "the edge of the input\n",
      "Embedding: [-0.00138302 -0.00616208  0.02896395 -0.05735439  0.03747423 -0.01556046\n",
      " -0.03085468 -0.00887771  0.06153553 -0.09401764]...\n",
      "Sentence: The most common types of padding are padding=“valid” (no\n",
      "padding) and padding=“same”.\n",
      "With no padding (valid padding), the size of the feature map is reduced as the\n",
      "ﬁlter cannot move beyond the edge of the input\n",
      "Embedding: [ 0.06536072  0.01299291 -0.01341393 -0.02470981  0.04681437  0.02593392\n",
      "  0.00659133 -0.00203059 -0.03772655 -0.08068963]...\n",
      "Sentence: padding=“same” padding adds\n",
      "zeros around the input so that the output feature map has the same dimensions as\n",
      "the input\n",
      "Embedding: [ 6.2630780e-02 -2.1690061e-02 -7.3706573e-03 -1.4588558e-02\n",
      "  3.7755236e-02  2.2821451e-02 -3.3117134e-02 -5.5532309e-05\n",
      " -1.4834943e-02 -9.0339363e-02]...\n",
      "Sentence: Refer to Figure 4-5\n",
      "Embedding: [ 0.07207303  0.03067557 -0.01509527  0.02796222  0.03151642  0.01120511\n",
      "  0.06658552  0.07785162  0.04591304  0.02561781]...\n",
      "Sentence: In this example, we introduce padding to enlarge the\n",
      "size of the 5 × 5 input in blue to an output size of 6 × 6 shown in green.\n",
      "Declaring a convolutional layer in Keras is straightforward\n",
      "Embedding: [-0.03844277 -0.01533436  0.04766734 -0.07498157  0.0006447   0.00569005\n",
      " -0.0204623  -0.06256754 -0.04310388 -0.06658044]...\n",
      "Sentence: The convolutional\n",
      "layer we will most commonly encounter is the Conv2D layer, which is typically\n",
      "used for processing images.\n",
      "from keras.layers import Conv2D\n",
      "conv_layer = Conv2D(filters, kernel_size, strides=(1, 1),\n",
      "padding=’valid’, activation=’relu’, input_shape)\n",
      "Filters The number of ﬁlters (kernels) in the convolutional layer\n",
      "Embedding: [-0.00281752 -0.04998727  0.05517602 -0.05319199  0.01184493 -0.05800878\n",
      " -0.03155953 -0.04674561  0.0256444  -0.1143594 ]...\n",
      "Sentence: Each ﬁlter\n",
      "extracts different features from the input\n",
      "Embedding: [ 0.03118235  0.06320848  0.04494557 -0.01018181  0.07373423  0.05766833\n",
      "  0.07268704 -0.07609294 -0.02475045 -0.12671892]...\n",
      "Sentence: In our previous example, we use a single\n",
      "4.3\n",
      "Dropout Layers\n",
      "51\n",
      "Figure 4-5 Convolving a 4 × 4 kernel over a 5 × 5 input padded with a 2 × 2 border of zeros\n",
      "using unit strides [1, p\n",
      "Embedding: [-0.00637191 -0.00831364  0.02489076 -0.05087999 -0.01754978 -0.0555688\n",
      " -0.0330082  -0.03664278 -0.02437011 -0.10541525]...\n",
      "Sentence: 14]\n",
      "ﬁlter, but there is no reason for that\n",
      "Embedding: [-0.01914621  0.04182757 -0.0421252  -0.04254877  0.00126957 -0.01686608\n",
      "  0.08825131  0.06732951  0.08155289 -0.07608379]...\n",
      "Sentence: Multiple ﬁlters are often use in many cases on\n",
      "the image.\n",
      "Kernel Size The size of the ﬁlter\n",
      "Embedding: [ 0.04855312  0.04248596  0.00195608 -0.03423292  0.09572368 -0.11399744\n",
      "  0.01959971  0.0436979   0.04892937 -0.07756925]...\n",
      "Sentence: Common choices include (3, 3) or (5, 5)\n",
      "Embedding: [ 0.04075299 -0.03664137 -0.02426128 -0.05892896  0.01228616  0.03711066\n",
      " -0.04893717 -0.06619646  0.03318368  0.07931246]...\n",
      "Sentence: This\n",
      "parameter can be an integer in which case a square kernel is implied or a tuple of\n",
      "two integers to explicitly specify the x and y ﬁlter dimension.\n",
      "4.3.4\n",
      "CNN As an Input Layer\n",
      "When used as an input layer in a neural network, the ﬁrst convolutional layer\n",
      "typically processes the raw input data.\n",
      "This layer must be conﬁgured with the shape of the input data (e.g., image\n",
      "dimensions and color channels), for example, an input shape of (28, 28, 1) for\n",
      "grayscale images of size 28 × 28 pixels or (224, 224, 3) for color images of size\n",
      "224 × 224 pixels with three color channels (RGB)\n",
      "Embedding: [ 0.03119688 -0.04966741  0.03166111 -0.02610081  0.00118732  0.01649824\n",
      "  0.0342356  -0.02527935 -0.00750444 -0.15047278]...\n",
      "Sentence: Note that the arrangement of\n",
      "dimensions for an RGB image can be speciﬁed in Keras using channel_ﬁrst or\n",
      "channel_last format so that a (224, 224, 3) image is still valid as a (3, 224, 224)\n",
      "tensor if the parameter data_format= “channel_ﬁrst” is speciﬁed\n",
      "Embedding: [ 0.09248945 -0.10817838  0.00215984 -0.08664608 -0.01158362  0.05228219\n",
      " -0.02701675 -0.03031266 -0.06414235 -0.0668999 ]...\n",
      "Sentence: If a grayscale\n",
      "image is used, then the number of channels is one instead of three\n",
      "Embedding: [ 0.10324446 -0.05173187  0.01278013 -0.10275555 -0.01760081 -0.0415662\n",
      "  0.05627854 -0.05550768  0.06438231 -0.01870065]...\n",
      "Sentence: An example\n",
      "of using the CNN as the ﬁrst layer with the channel_ﬁrst option is shown below:\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Conv2D\n",
      "model = Sequential()\n",
      "model.add(Conv2D(32, kernel_size=(3, 3), activation=’relu’,\n",
      "input_shape=(1, 28, 28), data_format=’channels_first’))\n",
      "The pixels in an RGB image is usually normalized to tensor with a range of [0,1]\n",
      "or [–1,1] before feeding into a CNN input layer\n",
      "Embedding: [-0.00698109 -0.08255281  0.03267105 -0.02818832 -0.02299038  0.03641687\n",
      " -0.00011273 -0.02611868 -0.04971932 -0.1102514 ]...\n",
      "Sentence: If the original pixel values are in\n",
      "52\n",
      "4\n",
      "Network Layers\n",
      "the range of [0,255], one common approach is to scale these values down to a range\n",
      "between 0 and 1 by dividing all pixel values by 255, for example:\n",
      "normalized image = image\n",
      "255.0\n",
      "Another common technique involves subtracting the mean and dividing by the stan-\n",
      "dard deviation of the pixel values, either globally or per channel\n",
      "Embedding: [ 0.10816138  0.01477439  0.03598324 -0.06585731 -0.03628909 -0.00886006\n",
      " -0.01745498 -0.00988399 -0.0577528  -0.05314433]...\n",
      "Sentence: This standardizes\n",
      "the pixel values to have a mean of zero and a standard deviation of one by subtracting\n",
      "the mean and dividing by the standard deviation:\n",
      "normalized image = (image −mean)\n",
      "σ\n",
      "The mean and standard deviation can be computed over the entire dataset.\n",
      "If we are using a pretrained model, it is important to normalize the images in\n",
      "the same way the model was originally trained\n",
      "Embedding: [ 2.9021464e-02  3.4846269e-02  1.4506078e-02 -7.8910086e-03\n",
      " -3.0506531e-02  2.4806133e-05 -4.5298867e-02  2.1332201e-02\n",
      " -1.7167553e-02  5.0967284e-03]...\n",
      "Sentence: For example, models trained on\n",
      "the ImageNet dataset often use speciﬁc mean and standard deviation values for\n",
      "normalization\n",
      "Embedding: [ 0.03743293 -0.07105615 -0.01673467 -0.008276    0.0383762  -0.00983532\n",
      " -0.07617852  0.01084362  0.00876035 -0.00720208]...\n",
      "Sentence: If unnormalized images are fed into a pretrained model, bizarre\n",
      "results can be seen with color shifts or patches of wrong colors appearing in the\n",
      "output.\n",
      "Normalizing the input values helps accelerate training and improve performance\n",
      "by stabilizing the distribution of values within the network.\n",
      "4.3.5\n",
      "Multiple CNN Layers\n",
      "Although we have shown a single CNN layer for illustration, in practice a series of\n",
      "CNN layers of different kernel sizes, strides, padding, etc., are used to upsample\n",
      "and downsample an image\n",
      "Embedding: [-0.02656934 -0.02832952  0.10326129  0.01105607  0.01919653 -0.00371357\n",
      " -0.07869101 -0.08849952  0.04553074 -0.0794443 ]...\n",
      "Sentence: Instead of using the image at its original size, the\n",
      "image is ﬁrst “upsampled” via the use of nearest neighbor, bilinear interpolation,\n",
      "or transposed convolution to increase the effective resolution of the image\n",
      "Embedding: [-0.06814219  0.05278412  0.05006277 -0.07633599 -0.01111466 -0.07610749\n",
      " -0.04881749  0.02218476 -0.02501374 -0.00016874]...\n",
      "Sentence: Toward\n",
      "the end of the CNN layer chain, the upsampled image is then downsampled to the\n",
      "output size.\n",
      "The initial layers of a CNN typically learn to recognize simple patterns, like\n",
      "edges and basic textures\n",
      "Embedding: [-0.09138066 -0.00883858  0.08073685 -0.03889831 -0.02485764 -0.01040791\n",
      " -0.07068367 -0.04626864 -0.0003697  -0.05542956]...\n",
      "Sentence: As we progress deeper into the network, later layers learn\n",
      "to recognize more complex features, like shapes or speciﬁc objects, by combining\n",
      "the simpler features extracted in earlier layers\n",
      "Embedding: [ 0.03438164 -0.03044421  0.09261784  0.06240013  0.09410589 -0.01701116\n",
      " -0.06404062 -0.06667595  0.03302214 -0.06592357]...\n",
      "Sentence: This is why when we select a layer to\n",
      "use in a pretrained network, such as VGG-16, as shown in Figure 4-6, we can choose\n",
      "to use a layer in an earlier layer such as “conv2_1” or a deeper block to extract more\n",
      "abstract feature such as “conv4_3.” One common problem with using CNN layers is\n",
      "the “checkerboard” issue, often referred to as “checkerboard artifacts, particularly in\n",
      "tasks involving image generation like autoencoders, generative adversarial networks\n",
      "(GANs), and super-resolution\n",
      "Embedding: [-0.07485826  0.01416676  0.1054144   0.03193589  0.10987688 -0.05756847\n",
      " -0.04738788 -0.07096224  0.04297477 -0.11061492]...\n",
      "Sentence: These artifacts manifest as a checkerboard pattern\n",
      "in the generated images as shown in Figure 4-7\n",
      "Embedding: [-0.05769526  0.06179119  0.0097504  -0.01938106  0.05132142 -0.11167365\n",
      "  0.03528022 -0.04288257  0.00474858 -0.0411089 ]...\n",
      "Sentence: The issue primarily arises due\n",
      "4.3\n",
      "Dropout Layers\n",
      "53\n",
      "Figure 4-6 VGG-16 network block diagram [2, p\n",
      "Embedding: [-0.03248218  0.03649766  0.06074118  0.00851021  0.04124919 -0.01251718\n",
      " -0.07216395 -0.02512989 -0.00540166 -0.0463603 ]...\n",
      "Sentence: 3]\n",
      "Figure 4-7 Examples of checkerboard artifacts from a CNN layer [3]\n",
      "to the use of strided convolutions or transposed convolutions (sometimes called\n",
      "deconvolutions) for upsampling.\n",
      "The checkerboard problem is caused when using strided or transposed convolu-\n",
      "tions for upsampling; the overlap in the convolution operation can be uneven\n",
      "Embedding: [-0.1090086  -0.07814611  0.00710074 -0.04896613 -0.0196084  -0.11515383\n",
      "  0.02330787 -0.03509004  0.00366504 -0.09512262]...\n",
      "Sentence: This\n",
      "uneven overlap can lead to certain pixels being updated more frequently than others,\n",
      "creating a visible grid-like pattern in the output.\n",
      "54\n",
      "4\n",
      "Network Layers\n",
      "The solution to this is to use a different non-overlapping stride sizes, change the\n",
      "kernel size, or alternative upsampling techniques\n",
      "Embedding: [-0.0375323   0.01977032  0.01898003 -0.04459331 -0.02418432 -0.10907392\n",
      " -0.05980082 -0.05360346  0.00215892 -0.08805811]...\n",
      "Sentence: Often, we will ﬁnd the researcher\n",
      "adding a convolutional layer to smear out the checkerboard effect with bilinear\n",
      "interpolation.\n",
      "The GAN project included in this book also suffers from this problem, and the\n",
      "solution was to generate a more diverse set of data, including augmented cartoon\n",
      "images and longer training time.\n",
      "4.3.6\n",
      "Embedding Layers\n",
      "An embedding layer is a specialized layer in neural networks, used primarily in the\n",
      "ﬁeld of natural language processing (NLP), but also applicable in other areas where\n",
      "data can be converted into discrete tokens\n",
      "Embedding: [-0.09397354 -0.09146705  0.04393949 -0.04178997  0.04473018  0.00416453\n",
      " -0.02309213 -0.08488346  0.03658243 -0.1275976 ]...\n",
      "Sentence: For example, the BachBot application in\n",
      "this book uses an embedding layer.\n",
      "The main function of an embedding layer is to convert these tokens (like words\n",
      "in text) into dense vectors of ﬁxed size, which are more meaningful and suitable\n",
      "for performing various machine learning tasks, although in the case of BachBot,\n",
      "embedding the input did not produce a signiﬁcant improvement in the results.\n",
      "In text processing, words or phrases are typically represented as discrete tokens\n",
      "or integers\n",
      "Embedding: [-0.0259943  -0.04619871 -0.00500221  0.0140461   0.01007241  0.06309114\n",
      " -0.03362223  0.00156481  0.06139944 -0.04281688]...\n",
      "Sentence: Each unique word in our vocabulary is assigned a unique integer ID.\n",
      "The embedding layer transforms these integer tokens into dense vectors of a\n",
      "speciﬁed size\n",
      "Embedding: [ 0.01315355 -0.06036102 -0.00963737 -0.02412383  0.0078691   0.08043256\n",
      "  0.05057649 -0.04313723  0.05800331 -0.05303985]...\n",
      "Sentence: This size is a hyperparameter (that is chosen by us) and represents\n",
      "the dimensions of the embedding space.\n",
      "Unlike one-hot encoded vectors which are high-dimensional and sparse, embed-\n",
      "ding vectors are low-dimensional and dense, containing real-valued numbers.\n",
      "The vectors obtained from an embedding layer capture more information about\n",
      "words, including semantic meaning and contextual relationships\n",
      "Embedding: [ 0.01193266 -0.07401685 -0.02920079 -0.0034749   0.0043817   0.03673656\n",
      "  0.01816678 -0.01808256  0.09253301 -0.05506451]...\n",
      "Sentence: During training,\n",
      "these vectors are learned and adjusted to reduce the model’s prediction error, making\n",
      "the embeddings contextual to the speciﬁc task.\n",
      "Often, pretrained word embeddings, such as Word2Vec and Glove, are used in\n",
      "the embedding layer\n",
      "Embedding: [-0.01370657 -0.05528319  0.03630686  0.05578209  0.07344751  0.08913878\n",
      " -0.0097792   0.01390954  0.04993343 -0.01606576]...\n",
      "Sentence: These embeddings are trained on large datasets and capture a\n",
      "vast amount of semantic information.\n",
      "Here is a simple example of how to use an embedding layer in Keras:\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Embedding\n",
      "model = Sequential()\n",
      "model.add(Embedding(input_dim=vocab_size,\n",
      "output_dim=embedding_dim, input_length=max_length))\n",
      "4.3\n",
      "Dropout Layers\n",
      "55\n",
      "4.3.7\n",
      "Residual Layers\n",
      "The key idea behind residual layers is the introduction of skip connections, also\n",
      "called shortcut connections or residual connections\n",
      "Embedding: [ 0.02500885 -0.07490526  0.01016858 -0.00849649  0.02828738  0.09256233\n",
      " -0.07110199 -0.02163136  0.01362075 -0.08545385]...\n",
      "Sentence: These connections allow the\n",
      "input to a layer or a set of layers to be added to its output\n",
      "Embedding: [-0.04795503 -0.02230368 -0.09853035  0.00888215  0.00308149  0.09421036\n",
      " -0.0232787  -0.04316489  0.06025244 -0.07124774]...\n",
      "Sentence: This is typically done by\n",
      "adding the output of a convolutional block to its input so that the output of the block\n",
      "is the sum of the two\n",
      "Embedding: [-0.07699265 -0.00678655 -0.04258494  0.00779967 -0.04988988  0.00599123\n",
      " -0.0395383  -0.06696803  0.02782151 -0.06946118]...\n",
      "Sentence: For instance, in a basic residual block, if the input is x and\n",
      "the output of the convolutional layers is F(x), the ﬁnal output of the block will be\n",
      "F(x) + x.\n",
      "These skip connections help in easing the ﬂow of gradients during backpropaga-\n",
      "tion because they provide an alternative pathway for the gradient\n",
      "Embedding: [-0.11759302 -0.02261457 -0.01183592  0.05801262  0.00064486  0.07426472\n",
      " -0.01735875 -0.06847891  0.07312794 -0.07079721]...\n",
      "Sentence: This architecture\n",
      "alleviates the vanishing gradient problem and allows for training much deeper\n",
      "networks.\n",
      "The skip connections often perform identity mapping, where the input is passed\n",
      "through unchanged to the output\n",
      "Embedding: [-0.0688996  -0.04786621  0.01276048  0.02201159  0.00344131  0.03876566\n",
      " -0.02458793 -0.12071554  0.07283757 -0.11849683]...\n",
      "Sentence: When the input and output dimensions differ, a\n",
      "linear projection might be applied to match the dimensions.\n",
      "from keras.layers import Input, Conv2D,\n",
      "BatchNormalization, Add\n",
      "from keras.models import Model\n",
      "# Input tensor\n",
      "input_tensor = Input(shape=(256, 256, 3))\n",
      "# First convolutional layer\n",
      "conv1 = Conv2D(64, (3, 3), activation=’relu’,\n",
      "padding=’same’)(input_tensor)\n",
      "conv1 = BatchNormalization()(conv1)\n",
      "# Second convolutional layer\n",
      "conv2 = Conv2D(64, (3, 3), activation=’relu’,\n",
      "padding=’same’)(conv1)\n",
      "conv2 = BatchNormalization()(conv2)\n",
      "# Skip Connection (identity mapping)\n",
      "skip_connection = Add()([conv2, input_tensor])\n",
      "# Creating the model\n",
      "model = Model(inputs=input_tensor,\n",
      "outputs=skip_connection)\n",
      "4.3.8\n",
      "Recurrent Layers\n",
      "An RNN layer is designed to deal with sequential and temporal problems, such\n",
      "as language translation, natural language processing (NLP), music generation, and\n",
      "image captioning.\n",
      "Let’s take an idiom, such as “Easier said than done,” which is taken to mean\n",
      "not as easy as it appears to be\n",
      "Embedding: [-0.02296527 -0.11981492  0.03652297 -0.04052023 -0.02273052  0.05398762\n",
      " -0.05850902 -0.03376424 -0.00643322 -0.16838866]...\n",
      "Sentence: In order for the idiom to make sense, it needs to be\n",
      "56\n",
      "4\n",
      "Network Layers\n",
      "expressed in that speciﬁc order\n",
      "Embedding: [ 0.04842958 -0.00354434  0.02915124 -0.03076403 -0.03395855  0.06990927\n",
      " -0.00695458 -0.01598297  0.02742018 -0.0091764 ]...\n",
      "Sentence: As a result, recurrent networks need to account for\n",
      "the position of each word in the idiom and use that information to predict the next\n",
      "word in the sequence.\n",
      "A recurrent layer is a sweeping term referring to a group of specialized layers in\n",
      "Keras\n",
      "Embedding: [-0.075803   -0.08900042  0.05587832 -0.00664176 -0.00079106  0.10690173\n",
      "  0.03094074 -0.0083382   0.07003662 -0.07999322]...\n",
      "Sentence: There are too many variants to describe in detail here, so it is best to refer\n",
      "to the Keras manual for more speciﬁc details, but here is a brief description of what\n",
      "each type is used for:\n",
      "1\n",
      "Embedding: [-0.06109346 -0.04223095  0.01958954 -0.06544859 -0.01590337  0.06422445\n",
      " -0.0063044  -0.02768934 -0.00231354 -0.08103706]...\n",
      "Sentence: LSTM Layer: Ideal for capturing long-term dependencies in sequential data.\n",
      "Commonly used in time series forecasting, natural language processing, and\n",
      "sequence prediction tasks\n",
      "Embedding: [-0.07905851 -0.08690191  0.07984618  0.04914006  0.06690994  0.13478678\n",
      " -0.04815491  0.00431096  0.00249336 -0.06131322]...\n",
      "Sentence: The BachBot project implementation in this book uses\n",
      "LSTM layers to capture music sequences.\n",
      "2\n",
      "Embedding: [-0.05756173 -0.06411344 -0.00470526 -0.04239593  0.01844252  0.17819412\n",
      " -0.09854677 -0.03358574 -0.06009548 -0.11592148]...\n",
      "Sentence: GRU Layer: Similar to LSTM, but with a simpler architecture\n",
      "Embedding: [-0.05932164 -0.0948934  -0.00341678 -0.03868926  0.01983229  0.07101998\n",
      " -0.0056593   0.00045358 -0.07905113 -0.11603407]...\n",
      "Sentence: Used for tasks\n",
      "like text generation, speech recognition, and time series analysis\n",
      "Embedding: [-0.08547612 -0.01485357 -0.05240491 -0.02202217 -0.04772134 -0.00629718\n",
      " -0.00680675  0.00402774  0.06324391 -0.05864432]...\n",
      "Sentence: Requires fewer\n",
      "parameters than LSTM, making it more efﬁcient while still capturing long-term\n",
      "dependencies effectively.\n",
      "3\n",
      "Embedding: [-0.02460828 -0.06900277  0.03436903  0.01918603  0.11097383  0.07302924\n",
      " -0.0758516   0.04181587 -0.04147972 -0.02793245]...\n",
      "Sentence: SimpleRNN Layer: The most basic form of RNN, suitable for sequences where\n",
      "short-term context is sufﬁcient\n",
      "Embedding: [-0.10695963 -0.08037748  0.05819465 -0.01920808 -0.01411661  0.12899056\n",
      "  0.01060567 -0.02708185  0.01365584 -0.10865375]...\n",
      "Sentence: Useful in simpler sequence tasks.\n",
      "4\n",
      "Embedding: [-0.11424869  0.04436699  0.0093914  -0.04348117  0.01860285  0.04654196\n",
      "  0.05924219  0.00851303  0.00245869 -0.01241621]...\n",
      "Sentence: TimeDistributed Layer: Applies a speciﬁed layer to each time step of a sequence\n",
      "independently\n",
      "Embedding: [-0.13767214  0.04977665  0.0553806   0.00426569  0.02525665  0.06261317\n",
      "  0.01127077 -0.03920503  0.03373719 -0.10075846]...\n",
      "Sentence: Commonly used with CNN layers in sequence-to-sequence tasks,\n",
      "like video processing or time series classiﬁcation.\n",
      "5\n",
      "Embedding: [-0.18112071 -0.06635244  0.01643247 -0.02293838 -0.00639068  0.07012514\n",
      " -0.03319904 -0.04429179  0.05575599 -0.09075309]...\n",
      "Sentence: Bidirectional Layer: Wraps around another RNN layer (like LSTM or GRU) to\n",
      "process the sequence in both forward and backward directions\n",
      "Embedding: [-0.14282481 -0.10470066  0.0473207  -0.02439654 -0.05118483  0.0755282\n",
      " -0.0636976  -0.05695786  0.02189405 -0.08965021]...\n",
      "Sentence: Widely used in\n",
      "NLP tasks like sentiment analysis and machine translation.\n",
      "6\n",
      "Embedding: [-0.04926945 -0.00785681 -0.01426265  0.01965866  0.03796782  0.05279549\n",
      "  0.03794871  0.06265196  0.02864574  0.02523813]...\n",
      "Sentence: ConvLSTM1D, ConvLSTM2D, ConvLSTM3D: Used for a sequence of images\n",
      "or videos.\n",
      "A distinguishing characteristic of recurrent networks is that they share parame-\n",
      "ters across each layer of the network\n",
      "Embedding: [-0.1281879  -0.09050345 -0.01194306 -0.05068809  0.03572669  0.01275603\n",
      "  0.00217589  0.02598068  0.10994159 -0.07660893]...\n",
      "Sentence: While feedforward networks have different\n",
      "weights across each node, recurrent neural networks share the same weight param-\n",
      "eter within each layer of the network\n",
      "Embedding: [-0.05853561 -0.12911768  0.03533464  0.00139361  0.05158158  0.03743757\n",
      " -0.05736595 -0.06784705  0.05117371 -0.0916343 ]...\n",
      "Sentence: These weights are still adjusted in through\n",
      "the processes of backpropagation through time and gradient descent to facilitate\n",
      "learning.\n",
      "The backpropagation through time (BPTT) algorithm is slightly different from\n",
      "traditional backpropagation as it is speciﬁc to sequence data\n",
      "Embedding: [-9.1654100e-02  2.7210794e-02 -2.3731731e-03  4.1316822e-02\n",
      " -3.6717735e-02  2.9259110e-03 -6.5895304e-02 -1.5916087e-02\n",
      "  3.6743615e-05 -8.3650842e-02]...\n",
      "Sentence: The principles of\n",
      "BPTT are the same as traditional backpropagation, where the model trains itself\n",
      "by calculating errors from its output layer to its input layer\n",
      "Embedding: [-0.11887037 -0.00126481  0.00277567  0.04417617 -0.02365375  0.03346749\n",
      " -0.07631034  0.0419171  -0.02030872 -0.04943277]...\n",
      "Sentence: BPTT differs from\n",
      "the traditional approach in that BPTT sums errors at each time step, whereas\n",
      "feedforward networks do not need to sum errors as they do not share parameters\n",
      "across each layer.\n",
      "Through this process, RNNs tend to run into two problems, known as exploding\n",
      "gradients and vanishing gradients\n",
      "Embedding: [-0.15036644 -0.06403341  0.02367907  0.06913275  0.00792747  0.02036797\n",
      " -0.08699547 -0.02328361  0.04066893 -0.09236511]...\n",
      "Sentence: These issues are deﬁned by the size of the\n",
      "gradient, which is the slope of the loss function along the error curve\n",
      "Embedding: [-0.02784161  0.01092028  0.05310418  0.01323586  0.04477707  0.00400989\n",
      " -0.09130698  0.07660335  0.01528042  0.00309774]...\n",
      "Sentence: When the\n",
      "gradient is too small, it continues to become smaller, updating the weight parameters\n",
      "until they become insigniﬁcant—that is, zero\n",
      "Embedding: [-0.02288148 -0.02892904 -0.00051982  0.07232035 -0.03759559 -0.00463931\n",
      " -0.05751515  0.01973602  0.01765478 -0.0122933 ]...\n",
      "Sentence: When that occurs, the algorithm is no\n",
      "4.3\n",
      "Dropout Layers\n",
      "57\n",
      "longer learning\n",
      "Embedding: [ 0.01225623 -0.03286164  0.03995767  0.01979329  0.06554978 -0.05105788\n",
      " -0.08658499 -0.09724916 -0.03965119 -0.05133523]...\n",
      "Sentence: Exploding gradients occur when the gradient is too large, creating\n",
      "an unstable model\n",
      "Embedding: [-0.01931214 -0.12318986  0.05596263  0.04549303 -0.00913579 -0.03969884\n",
      " -0.09370752  0.04606473  0.01633285 -0.040213  ]...\n",
      "Sentence: In this case, the model weights will grow too large, and they\n",
      "will eventually be represented as NaN\n",
      "Embedding: [-0.09084906 -0.09349481 -0.01540358 -0.0112885   0.0365881  -0.08769663\n",
      " -0.08265999 -0.00140361  0.05029206 -0.0155299 ]...\n",
      "Sentence: One solution to these issues is to reduce\n",
      "the number of hidden layers within the neural network, eliminating some of the\n",
      "complexity of the RNN model.\n",
      "We will look at an example of an LSTM layer:\n",
      "from keras.models import Sequential\n",
      "from keras.layers import LSTM\n",
      "# Define the model\n",
      "model = Sequential()\n",
      "# Add an LSTM layer\n",
      "# ’units’ refers to the number of neurons\n",
      "# in the LSTM layer\n",
      "# ’input_shape’ should match the shape of our\n",
      "# training data\n",
      "model.add(LSTM(units=50, activation=’tanh’,\n",
      "recurrent_activation=’sigmoid’,\n",
      "input_shape=(time steps, features)))\n",
      "# model.add(Dense(1))\n",
      "# Example for a regression problem\n",
      "It is important to understand what the parameters mean as they can be rather\n",
      "confusing with RNN\n",
      "Embedding: [-0.07068386 -0.11419282  0.08662751  0.04578392  0.00881499  0.07737024\n",
      " -0.07603313 -0.02815597  0.00139153 -0.13137163]...\n",
      "Sentence: Refer to Figure 4-8\n",
      "Embedding: [ 0.06315846  0.0616377  -0.02308442  0.03266355  0.00102338  0.01981721\n",
      "  0.03766228  0.14716104  0.0504738  -0.01115633]...\n",
      "Sentence: The subscript t1, t, t +1 refers to the time\n",
      "step\n",
      "Embedding: [-0.11007305  0.0195573   0.05957975 -0.00580472  0.02160048 -0.02406738\n",
      " -0.02553578  0.07576894  0.04726472 -0.00417011]...\n",
      "Sentence: The Xt−1, Xt, Xt+1 are the input tensors at each time step; yt−1, yt, yt+1 are\n",
      "the outputs\n",
      "Embedding: [-0.06395332 -0.02405532 -0.01631459 -0.04817104  0.04120344  0.02117944\n",
      "  0.00576071 -0.01218164 -0.01820029 -0.09459241]...\n",
      "Sentence: The ht−1, ht, ht+1 are the outputs of the hidden states which are used\n",
      "in conjunction with the inputs Xs to get Ys\n",
      "Embedding: [-0.10086836  0.04029939 -0.05389066  0.00692026  0.06078233  0.04240021\n",
      "  0.04153734 -0.02184766  0.03086342 -0.02996369]...\n",
      "Sentence: The W is the common weight tensor of\n",
      "the hidden states.\n",
      "Each hidden state hi has a number of units of hidden cells, four in this case, and\n",
      "this is the hyperparameter units needed for deﬁning the LSTM layer.\n",
      "Figure 4-8 An RNN-LSTM network\n",
      "58\n",
      "4\n",
      "Network Layers\n",
      "Figure 4-9 The block diagram of an LSTM cell\n",
      "There are two activation functions speciﬁed in the example, activation=’tanh’ and\n",
      "recurrent_activation=’sigmoid’\n",
      "Embedding: [-0.04838534 -0.0449655  -0.02212729  0.08456578  0.03804351  0.1213737\n",
      "  0.02549563 -0.00810554 -0.00780029 -0.07323976]...\n",
      "Sentence: Unfortunately (because it is complex) to understand\n",
      "these terms, we need to examine the conﬁguration of an LSTM unit.\n",
      "Refer to Figure 4-9\n",
      "Embedding: [ 0.0011164  -0.10664751 -0.03097698 -0.0014694   0.01304383  0.07158431\n",
      " -0.02625938  0.07063162 -0.01742522 -0.0214737 ]...\n",
      "Sentence: The hidden state ht is referred to as the actual output of the\n",
      "LSTM cell for each time step\n",
      "Embedding: [-0.08380555  0.00513532 -0.05559506  0.04857623  0.03637641  0.08501193\n",
      " -0.0370752   0.03136391  0.04917634 -0.04320809]...\n",
      "Sentence: It is derived from the cell state but is not the same as\n",
      "the cell state\n",
      "Embedding: [-0.04786279  0.03984828 -0.07065555 -0.00171835 -0.01242096  0.0360668\n",
      " -0.02505218 -0.01293748  0.07408819  0.08673027]...\n",
      "Sentence: The hidden state is calculated using the cell state and the output of the\n",
      "output gate\n",
      "Embedding: [-0.09982096  0.05294009 -0.09110896  0.06295022 -0.01131233  0.03677254\n",
      " -0.00373586 -0.02406456  0.0766627   0.02852362]...\n",
      "Sentence: It’s typically passed to subsequent layers in the network or used as the\n",
      "ﬁnal output in sequence processing tasks.\n",
      "The cell state ct is the internal memory of the LSTM cell\n",
      "Embedding: [-0.02776246 -0.02864473 -0.06892618 -0.01711284 -0.02964223  0.06608521\n",
      "  0.00828176  0.02668102  0.06743252  0.011173  ]...\n",
      "Sentence: It carries information\n",
      "across time steps and is updated at each time step based on the previous cell state,\n",
      "the current input, and the outputs of the forget and input gates\n",
      "Embedding: [-0.03488503  0.02543269 -0.06717646 -0.0113369  -0.00840859  0.05112921\n",
      "  0.02231061 -0.01940504  0.09875466 -0.03974884]...\n",
      "Sentence: The cell state is used\n",
      "as an internal mechanism that allows the LSTM to maintain a memory over time, so\n",
      "we do not refer to it as an output of the LSTM cell.\n",
      "At each time step, the LSTM cell takes the previous cell state ct−1 and the\n",
      "previous hidden state ht−1, along with the current input xt, to calculate the new\n",
      "cell state ct and the new hidden state ht\n",
      "Embedding: [-0.03204772  0.01346654 -0.03366784  0.01917948  0.03942856  0.09406532\n",
      " -0.00800212  0.02094996  0.04008473  0.00935335]...\n",
      "Sentence: The new hidden state ht is then propagated\n",
      "forward in two directions: horizontally to the next time step t + 1 in the sequence\n",
      "and vertically to the next layer if the LSTM is part of a stacked LSTM architecture.\n",
      "Notice that there are two activation functions for an LSTM cell, and these are the\n",
      "parameters required when setting up an LSTM layer in Keras.\n",
      "4.3.9\n",
      "Activation Function\n",
      "This parameter refers to the activation function used for the LSTM cell’s output\n",
      "Embedding: [-0.07761131 -0.03442479  0.02873176  0.00572448  0.04129762  0.12209966\n",
      " -0.05584934 -0.00284004 -0.00660491 -0.04177579]...\n",
      "Sentence: The\n",
      "activation function is applied to the cell state before it is outputted\n",
      "Embedding: [-0.06776436 -0.0044502  -0.03307184  0.0092791  -0.04620973  0.06575324\n",
      "  0.0746288   0.01983232  0.09620924  0.02590887]...\n",
      "Sentence: This is akin to\n",
      "the activation function in a traditional feedforward neural network layer\n",
      "Embedding: [-0.06273904 -0.06146308 -0.01741443  0.00502927  0.00784509  0.01851385\n",
      " -0.00542849 -0.04418961  0.08453107 -0.03969316]...\n",
      "Sentence: Common\n",
      "4.3\n",
      "Dropout Layers\n",
      "59\n",
      "choices for the activation function are nonlinear functions, like tanh or ReLU\n",
      "Embedding: [-0.07783965 -0.08076272  0.04005443 -0.01000057 -0.0297164   0.08064648\n",
      "  0.04517752  0.01331682  0.00268459 -0.02611252]...\n",
      "Sentence: tanh\n",
      "is the most common choice in LSTMs, as it outputs values in a range between –1\n",
      "and 1, which is useful for normalizing the output of the LSTM.\n",
      "4.3.10 Recurrent Activation\n",
      "The recurrent_activation argument applies to the input, forget, and output gates.\n",
      "The recurrent activation function is used to calculate the state of these gates and\n",
      "thus regulates the ﬂow of information through the cell.\n",
      "The common choice for the recurrent activation function is the sigmoid function.\n",
      "The sigmoid function outputs values between zero and one, making it suitable for\n",
      "gating purposes (like deciding how much of the previous state to keep or how much\n",
      "of the new state to write).\n",
      "The parameters b, V, W are respectively biases, input weights, and recurrent\n",
      "weights\n",
      "Embedding: [ 0.00914312 -0.08362402 -0.0074985  -0.02538481  0.0147692   0.09227668\n",
      "  0.0688662   0.03009807  0.04072518 -0.00519794]...\n",
      "Sentence: In the LSTM architecture, the forget gate uses the output of the previous\n",
      "hidden state cell to control the cell state Ct to remove irrelevant information\n",
      "Embedding: [-0.02321773 -0.01144965 -0.04327973  0.0976964  -0.0004829   0.08456855\n",
      "  0.0013012  -0.02869667  0.05255353 -0.05382989]...\n",
      "Sentence: On the\n",
      "other hand, the input gate and input unit add new information to Ct from the current\n",
      "input.\n",
      "4.3.11 Other Layers\n",
      "There are other types of specialized layers which are out of scope for this book\n",
      "Embedding: [-0.05898993 -0.07300521 -0.0387361  -0.02041655 -0.03756488  0.03039706\n",
      " -0.03132636  0.00897857  0.04186057 -0.02221808]...\n",
      "Sentence: In\n",
      "particular, the attention layer is used extensively for large language models (LLMs).\n",
      "These layers allow the model to focus on speciﬁc parts of the input sequentially,\n",
      "rather than using the entire input at once\n",
      "Embedding: [ 0.04912663 -0.08704985  0.0148427   0.00190721  0.04721656  0.09059965\n",
      "  0.01026437  0.01062339  0.14184536 -0.04112178]...\n",
      "Sentence: They are a key component in transformer\n",
      "models, which are used in various NLP tasks.\n",
      "5\n",
      "The Training Process\n",
      "As much as we would like to throw the data into a machine learning model and\n",
      "get instant insights into the data, this is not the way it will work\n",
      "Embedding: [-0.08246502  0.00633722  0.00491482  0.03088749  0.04370959  0.02450482\n",
      " -0.0015843  -0.00613062  0.01113436 -0.00832631]...\n",
      "Sentence: In most cases, the\n",
      "data have to be scrubbed, transformed into model-readable format, and augmented.\n",
      "In addition, we also need to select and design an appropriate machine learning\n",
      "algorithm for the task.\n",
      "Data preprocessing is a relatively standard procedure in most cases\n",
      "Embedding: [ 0.00596861  0.02228038 -0.02446932  0.02298233 -0.03468156 -0.04389143\n",
      " -0.07897133 -0.10066225 -0.08346162  0.0675927 ]...\n",
      "Sentence: Selecting the\n",
      "right algorithm can be overwhelming, particularly when the model neural network\n",
      "names are highly complex\n",
      "Embedding: [-0.08695904 -0.09729712  0.04703232 -0.01284325  0.02400765 -0.04901462\n",
      " -0.08027806 -0.02409099  0.01467817 -0.11013716]...\n",
      "Sentence: For example, we will show examples of convoluted,\n",
      "recurrent, long short-term memory, and generative adversarial neural networks in\n",
      "this book\n",
      "Embedding: [-0.07288165 -0.0666125   0.06827082  0.05181254  0.01189778  0.05528704\n",
      " -0.03933554 -0.04484894 -0.05264032 -0.04448779]...\n",
      "Sentence: The naming convention, although confusing at ﬁrst, will be helpful as a\n",
      "memory aid once we have understood the intended functionalities as the name often\n",
      "refers to the topology of the network itself\n",
      "Embedding: [-0.00914649 -0.09705845 -0.06555099  0.000359   -0.06526104 -0.00317132\n",
      "  0.00338844  0.03927493  0.08245678 -0.06989808]...\n",
      "Sentence: Refer to Figure 5-1\n",
      "Embedding: [ 0.01619411  0.01128082  0.01074403  0.03745903  0.05450648 -0.00502712\n",
      "  0.0646028   0.07249446  0.04165175  0.0254449 ]...\n",
      "Sentence: The diagram shows a\n",
      "typical end-to-end machine learning process\n",
      "Embedding: [-0.00049396 -0.04401262 -0.00340486 -0.01395914  0.05020487 -0.02421256\n",
      " -0.07034341  0.02798493 -0.06400485 -0.0123484 ]...\n",
      "Sentence: The data loading and productionizing\n",
      "of the model stages are the same as for other IT projects, although we will discuss\n",
      "some data types in Python which would make the data loading easier for machine\n",
      "learning\n",
      "Embedding: [-0.06254824 -0.00114922  0.00736527  0.0380946  -0.00926183 -0.11870231\n",
      " -0.13439573  0.02985271 -0.06140218 -0.00554989]...\n",
      "Sentence: The middle three stages are speciﬁc to machine learning, which we will\n",
      "discuss in detail below.\n",
      "5.1\n",
      "Data Loading\n",
      "In a commercial environment, it is most likely that the data for the project would\n",
      "be stored in a relational database and would require coding using SQL for retrieval.\n",
      "For learning and smaller datasets stored in a CSV ﬁle or online via a URL, we can\n",
      "use NumPy or Pandas to read the data in directly.\n",
      "© Philip Hua 2024\n",
      "P\n",
      "Embedding: [-0.02042934 -0.04064275 -0.05339137  0.01991359 -0.00619219 -0.05495523\n",
      " -0.07458822  0.02893446 -0.0413106   0.02730018]...\n",
      "Sentence: Hua, Neural Networks with TensorFlow and Keras,\n",
      "https://doi.org/10.1007/979-8-8688-1020-6_5\n",
      "63\n",
      "64\n",
      "5\n",
      "The Training Process\n",
      "Figure 5-1 End-to-end machine learning process\n",
      "For this demonstration, the COVID-19 database from Kaggle will be used\n",
      "Embedding: [-0.07705093 -0.09446912 -0.01651111  0.00417507  0.03177514  0.02944254\n",
      " -0.08645752  0.00886299 -0.11687708 -0.02522972]...\n",
      "Sentence: The\n",
      "COVID-19 database can be downloaded from Kaggle using the URL to the current\n",
      "local directory:\n",
      "https://www.kaggle.com/datasets/meirnizri/covid19-dataset\n",
      "The dataset is approximately 5MB in size, in CSV format, making it manageable\n",
      "for processing\n",
      "Embedding: [-0.05883199 -0.04411117 -0.11439695 -0.01791378  0.02706904  0.01375929\n",
      " -0.05512658  0.09012815 -0.03169355  0.08685192]...\n",
      "Sentence: We will be using this dataset as a project later on, so we would just\n",
      "be loading it for now.\n",
      "Using Pandas to load data into a pandas.DataFrame is probably the most ﬂexible\n",
      "way, allowing us to summarize the data immediately\n",
      "Embedding: [ 0.03756383 -0.00627393 -0.065548   -0.02088511 -0.02061835  0.02499727\n",
      " -0.04518258  0.01462108 -0.09222644 -0.0090662 ]...\n",
      "Sentence: If using Google Colab, upload\n",
      "the ﬁle by dragging it into a Colab directory\n",
      "Embedding: [-0.0914675  -0.12162246 -0.03070936  0.00645238  0.08451265  0.00692352\n",
      " -0.07084464  0.04025388  0.0028337  -0.01606942]...\n",
      "Sentence: As an example, use the procedure\n",
      "below to upload the ﬁle /content/sample_data/Covid Data.csv to Colab.\n",
      "The ﬁrst line in the ﬁle contains the column headings, so we assign\n",
      "data.columns = iloc[0]; otherwise, we would have to assign the column\n",
      "names explicitly as\n",
      "pandas.DataFrame(data,columns=[’USMER’,’MEDICAL_UNIT’,...]\n",
      "import pandas\n",
      "filename = \"/content/sample_data/Covid Data.csv\"\n",
      "data = pandas.read_csv(filename)\n",
      "pandas.columns = data.iloc[0] # use the first row as names\n",
      "data = data[1:]\n",
      "print(data.shape)\n",
      "print(data.head(5))\n",
      "(1048574, 21)\n",
      "USMER\n",
      "MEDICAL_UNIT\n",
      "SEX\n",
      "PATIENT_TYPE\n",
      "DATE_DIED ...\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "03/06/2020\n",
      "...\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "09/06/2020\n",
      "...\n",
      "3\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "12/06/2020\n",
      "...\n",
      "4\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "21/06/2020\n",
      "...\n",
      "5\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "9999-99-99\n",
      "...\n",
      "AGE\n",
      "PREGNANT\n",
      "DIABETES\n",
      "...\n",
      "ASTHMA\n",
      "INMSUPR\n",
      "5.1\n",
      "Data Loading\n",
      "65\n",
      "1\n",
      "72\n",
      "97\n",
      "2\n",
      "...\n",
      "2\n",
      "2 ...\n",
      "2\n",
      "55\n",
      "97\n",
      "1\n",
      "...\n",
      "2\n",
      "2 ...\n",
      "3\n",
      "53\n",
      "2\n",
      "2\n",
      "...\n",
      "2\n",
      "2 ...\n",
      "4\n",
      "68\n",
      "97\n",
      "1\n",
      "...\n",
      "2\n",
      "2 ...\n",
      "5\n",
      "40\n",
      "2\n",
      "2\n",
      "...\n",
      "2\n",
      "2 ...\n",
      "CARDIOVASCULAR\n",
      "OBESITY\n",
      "RENAL_CHRONIC\n",
      "TOBACCO ...\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "...\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "...\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "...\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "...\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "...\n",
      "[5 rows x 21 columns]\n",
      "data.describe()\n",
      "USMER\n",
      "MEDICAL_UNIT\n",
      "SEX\n",
      "PATIENT_TYPE ...\n",
      "count\n",
      "77064.000000\n",
      "77064.000000\n",
      "77064.000000 ...\n",
      "mean\n",
      "1.486271\n",
      "3.740956\n",
      "1.567243 ...\n",
      "std\n",
      "0.499815\n",
      "0.456079\n",
      "0.495461 ...\n",
      "min\n",
      "1.000000\n",
      "1.000000\n",
      "1.000000 ...\n",
      "25%\n",
      "1.000000\n",
      "3.000000\n",
      "1.000000 ...\n",
      "50%\n",
      "1.000000\n",
      "4.000000\n",
      "2.000000 ...\n",
      "75%\n",
      "2.000000\n",
      "4.000000\n",
      "2.000000 ...\n",
      "max\n",
      "2.000000\n",
      "4.000000\n",
      "2.000000 ...\n",
      "Pandas has several useful functions to give a high-level view of the data.\n",
      "data.describe() gives the overall statistics for the data\n",
      "Embedding: [-0.04379454  0.00524288 -0.09146006 -0.00253318  0.0148601  -0.02651334\n",
      " -0.04975683  0.07974361 -0.050832    0.03713855]...\n",
      "Sentence: It is not particularly\n",
      "useful in this case since the data is mostly categorical but would prove beneﬁcial\n",
      "for other numerical datasets\n",
      "Embedding: [-0.01509151  0.03126408 -0.03121835 -0.02960152  0.02884821  0.04639808\n",
      " -0.08003588 -0.04571149 -0.0449584  -0.05181122]...\n",
      "Sentence: data.info() tells us if the columns have null values.\n",
      "<class ’pandas.core.frame.DataFrame’>\n",
      "RangeIndex: 77064 entries, 1 to 77064\n",
      "Data columns (total 21 columns):\n",
      "#\n",
      "Column\n",
      "Non-Null Count\n",
      "Dtype\n",
      "---\n",
      "------\n",
      "--------------\n",
      "-----\n",
      "0\n",
      "USMER\n",
      "77064 non-null\n",
      "int64\n",
      "1\n",
      "MEDICAL_UNIT\n",
      "77064 non-null\n",
      "int64\n",
      "2\n",
      "SEX\n",
      "77064 non-null\n",
      "int64\n",
      "3\n",
      "PATIENT_TYPE\n",
      "77064 non-null\n",
      "int64\n",
      "4\n",
      "DATE_DIED\n",
      "77064 non-null\n",
      "object\n",
      "5\n",
      "INTUBED\n",
      "77064 non-null\n",
      "int64\n",
      "6\n",
      "PNEUMONIA\n",
      "77064 non-null\n",
      "int64\n",
      "7\n",
      "AGE\n",
      "77064 non-null\n",
      "int64\n",
      "8\n",
      "PREGNANT\n",
      "77064 non-null\n",
      "int64\n",
      "9\n",
      "DIABETES\n",
      "77064 non-null\n",
      "int64\n",
      "10\n",
      "COPD\n",
      "77064 non-null\n",
      "int64\n",
      "11\n",
      "ASTHMA\n",
      "77064 non-null\n",
      "int64\n",
      "12\n",
      "INMSUPR\n",
      "77064 non-null\n",
      "int64\n",
      "13\n",
      "HIPERTENSION\n",
      "77064 non-null\n",
      "int64\n",
      "14\n",
      "OTHER_DISEASE\n",
      "77064 non-null\n",
      "int64\n",
      "15\n",
      "CARDIOVASCULAR\n",
      "77064 non-null\n",
      "int64\n",
      "16\n",
      "OBESITY\n",
      "77063 non-null\n",
      "float64\n",
      "17\n",
      "RENAL_CHRONIC\n",
      "77063 non-null\n",
      "float64\n",
      "66\n",
      "5\n",
      "The Training Process\n",
      "18\n",
      "TOBACCO\n",
      "77063 non-null\n",
      "float64\n",
      "19\n",
      "CLASIFFICATION_FINAL\n",
      "77063 non-null\n",
      "float64\n",
      "20\n",
      "ICU\n",
      "77063 non-null\n",
      "float64\n",
      "dtypes: float64(5), int64(15), object(1)\n",
      "memory usage: 12.3+ MB\n",
      "None\n",
      "We can see from the summary that columns 16 to 20 have missing data\n",
      "Embedding: [ 0.05540785  0.03416367 -0.09240147  0.00479664  0.06027825 -0.02335028\n",
      " -0.01350221  0.05055434 -0.08189186 -0.01603698]...\n",
      "Sentence: A\n",
      "more accurate way to count the total number of missing data is by using\n",
      "data.isnull().sum().sum()\n",
      "Embedding: [ 0.07124911 -0.00829267  0.04700422  0.1135219  -0.05188566  0.05061267\n",
      " -0.00481091  0.01449904  0.05180959 -0.00295143]...\n",
      "Sentence: This returns ﬁve missing data points as expected.\n",
      "Once we know there are null values, we can use\n",
      "nullValues = data[data[’OBESITY’].isnull()]\n",
      "to return the rows with missing values for a particular column\n",
      "Embedding: [ 0.07749529  0.04787655  0.00453014  0.08473449  0.03284413  0.04435658\n",
      "  0.01281886 -0.0395854   0.0023221  -0.04909579]...\n",
      "Sentence: The isnull()\n",
      "function works for NaN data as well, so there is no need to use isna() separately.\n",
      "It is possible to use a pandas DataFrame anywhere a NumPy array is used if we\n",
      "have a data type of real or integer\n",
      "Embedding: [ 0.04159697 -0.03107539 -0.0782795  -0.07451139  0.04037255 -0.03629505\n",
      "  0.0027883  -0.07200851 -0.00829896  0.08024456]...\n",
      "Sentence: This works because the pandas.DataFrame class\n",
      "supports the __array__ protocol, and TensorFlow’s tf.convert_to_tensor\n",
      "function accepts objects that support the protocol\n",
      "Embedding: [ 0.04658067 -0.04359676 -0.08307448 -0.06049607  0.05259576 -0.06845205\n",
      " -0.00611274 -0.10222144 -0.03743539 -0.0131532 ]...\n",
      "Sentence: Alternatively, we can convert the\n",
      "dataframe directly to NumPy array or tensor using the following commands:\n",
      "numpy.array(data)\n",
      "or\n",
      "tf.convert_to_tensor(data)\n",
      "In many cases, we need to transform or rescale the input data before using the model.\n",
      "This is normally done by adding column(s) to the original dataset using\n",
      "DataFrame.insert(loc=location, column=\"column name\")\n",
      "and applying the necessary logic to create the new data\n",
      "Embedding: [ 0.10538193 -0.1034809  -0.04821284 -0.01855128  0.0568357  -0.01888556\n",
      " -0.04229199 -0.02477339 -0.05081405  0.0340215 ]...\n",
      "Sentence: For example, in the COVID-\n",
      "19 dataset, we may want to create a column to specify if the patient has existing\n",
      "medical conditions as\n",
      "data.insert(column=\"PreExisting Condition\")\n",
      "Loading the data via a URL is also straightforward using Pandas, and the code is\n",
      "the same except that instead of passing the path of the local ﬁle, we would pass the\n",
      "URL to the read_csv() method\n",
      "Embedding: [-0.00826821  0.04724608 -0.08024191  0.00361727 -0.0539233  -0.029152\n",
      " -0.05381912  0.08375052 -0.02915742  0.0123678 ]...\n",
      "Sentence: As before though, if we use Colab, then the ﬁle\n",
      "needs to be uploaded onto Google Drive before it can be read.\n",
      "5.1.1\n",
      "Loading Images\n",
      "In image classiﬁcation tasks, it’s common to train models using hundreds of\n",
      "thousands of images with convolutional neural networks\n",
      "Embedding: [-0.09299497 -0.13859312  0.06395597  0.02182863  0.02835682 -0.024925\n",
      " -0.07346889  0.01602513  0.00313187 -0.05152013]...\n",
      "Sentence: Fortunately, Keras offers\n",
      "several utilities to streamline the process of image loading and preprocessing\n",
      "Embedding: [-0.05719652 -0.0155096   0.04814507 -0.05157336  0.05872779 -0.07459116\n",
      " -0.08883104 -0.05552958 -0.08526352 -0.0265858 ]...\n",
      "Sentence: If the\n",
      "directory structure is\n",
      "main_directory\n",
      "\\ class a\n",
      "5.2\n",
      "Data Processing\n",
      "67\n",
      "image 1.jpg\n",
      "image 2.jpg\n",
      "\\ class b\n",
      "image 3.jpg\n",
      "image 4.jpg\n",
      "...\n",
      "then calling tf.keras.utils.image_dataset_from_directory() will gener-\n",
      "ate a dataset from the ﬁles in the subdirectories and assign automatic labels to\n",
      "each group of images, so it will return tuples in the form of images,labels\n",
      "Embedding: [ 0.00075659 -0.03480859 -0.01494657 -0.04626157  0.03310806 -0.02570522\n",
      " -0.00167443  0.02112629 -0.04752183 -0.07737021]...\n",
      "Sentence: The\n",
      "complete list of parameters is explained under:\n",
      "https://keras.io/api/data_loading/image/\n",
      "Most parameters are self-explanatory; however, the following ones require further\n",
      "explanation:\n",
      "•\n",
      "Labels: There are three options\n",
      "Embedding: [-0.03118895 -0.02007408 -0.05830497 -0.02138218 -0.01767056  0.04069359\n",
      " -0.00051499  0.00727166 -0.06457158 -0.08333284]...\n",
      "Sentence: “inferred” labels are generated from the direc-\n",
      "tory structure, for example, class a, class b, in conjunction with the param-\n",
      "eter label mode\n",
      "Embedding: [-0.1334318  -0.06314979 -0.09067419 -0.01196063  0.07668053  0.07176214\n",
      "  0.01669822  0.00477856  0.04049416 -0.04629422]...\n",
      "Sentence: If the label mode is int, the labels will be encoded as\n",
      "integers to be used with sparse_categorical_crossentropy loss func-\n",
      "tion\n",
      "Embedding: [ 0.0452308  -0.00071489 -0.06951448 -0.01294973 -0.01439025  0.06039694\n",
      "  0.05574121 -0.03330462 -0.06266934 -0.10767958]...\n",
      "Sentence: “categorical” label mode means the labels will be one-hot encoded for\n",
      "categorical_crossentropy loss\n",
      "Embedding: [ 0.05272765 -0.04696505 -0.03775934  0.04465252  0.00071736  0.05150209\n",
      "  0.01249824 -0.03405329 -0.01248797 -0.0775127 ]...\n",
      "Sentence: When there are only two classes, “binary”\n",
      "should be used with binary_entropy loss function.\n",
      "•\n",
      "Batch size: A machine learning algorithm normally processes images in batches\n",
      "and updates the neuron weights after each batch size instead of a single image.\n",
      "•\n",
      "Validation Split: If this is set to 1, then the subset parameter will need to be\n",
      "speciﬁed as below.\n",
      "•\n",
      "Subset: One of “training,” “validation,” or “both.” When subset=“both”, it returns\n",
      "a tuple of training and validation datasets.\n",
      "The Keras utility also allows the loading of individual images using\n",
      "tf.keras.utils.load_img()\n",
      "Embedding: [ 0.01949497  0.0359524  -0.00506653 -0.03715109  0.01298664 -0.02166888\n",
      "  0.00655119 -0.03231504 -0.05292693 -0.06704296]...\n",
      "Sentence: The point to note is that the utility returns a\n",
      "PIL image instance, and this needs to be converted to a NumPy array using\n",
      "tf.keras.utils.img_to_array as data for the input layer\n",
      "Embedding: [ 0.0019521  -0.0189333  -0.00900313 -0.03842868 -0.00614871 -0.00893919\n",
      "  0.00207214 -0.01767549  0.00960922 -0.02850023]...\n",
      "Sentence: This process is\n",
      "typically sufﬁcient in most cases\n",
      "Embedding: [-0.03643383 -0.01249316 -0.03806258 -0.03555962  0.02084951 -0.08675092\n",
      " -0.04111805 -0.00138633  0.04135018  0.05417332]...\n",
      "Sentence: However, when working with pretrained networks,\n",
      "additional preprocessing may be required to ensure the images are in the correct\n",
      "format\n",
      "Embedding: [-0.00470442 -0.00667736  0.03855419 -0.02595744  0.04257197 -0.01966325\n",
      " -0.1057018  -0.07960745 -0.02126011 -0.04476098]...\n",
      "Sentence: Since there is no standardization for this step, it is essential to consult the\n",
      "speciﬁc instructions for the input layer of each pretrained network.\n",
      "5.2\n",
      "Data Processing\n",
      "After loading the data, it is necessary to prepare the data in a format that could be\n",
      "fed into the neural network\n",
      "Embedding: [-0.03165238 -0.03126939  0.02722879  0.02531826 -0.0432329   0.04907358\n",
      " -0.1120854  -0.03234901 -0.08482312 -0.05965379]...\n",
      "Sentence: The main objective for the data preparation is to clean\n",
      "the data as much as possible so that they can be passed as features into the model\n",
      "Embedding: [ 0.00175314  0.03379067  0.03678495  0.00709049  0.00137242 -0.04223245\n",
      " -0.05559432 -0.07639871 -0.07131945  0.03315569]...\n",
      "Sentence: In\n",
      "some cases, particularly when we do not have enough data for the machine to train,\n",
      "68\n",
      "5\n",
      "The Training Process\n",
      "some data augmentation is also necessary to improve the model’s accuracy\n",
      "Embedding: [-0.00728601 -0.03920897  0.02460469  0.02118088 -0.03355357 -0.00634589\n",
      " -0.06541752 -0.00542471 -0.05869893 -0.04294575]...\n",
      "Sentence: There\n",
      "are many issues with data, but the common ones are dealt with below.\n",
      "5.2.1\n",
      "Splitting the Dataset: Training, Development, Test\n",
      "Machine learning is an iterative process\n",
      "Embedding: [-0.04514363 -0.04172954  0.07544816 -0.00894747  0.04309344 -0.09566163\n",
      " -0.07596329 -0.04054091 -0.13196701  0.0354277 ]...\n",
      "Sentence: Choosing the right model with the right set\n",
      "of parameters at the outset is impossible, so practically we have to try out different\n",
      "models and parameters and reﬁne them until our goals are achieved\n",
      "Embedding: [-0.02569342 -0.05073586 -0.03281249  0.0175456  -0.0200357   0.03506302\n",
      " -0.07371847  0.02548834  0.02759438 -0.0132361 ]...\n",
      "Sentence: When we\n",
      "approach machine learning this way, it is standard practice to split the dataset into\n",
      "separate training, development, and test datasets as shown in Figure 5-2.\n",
      "The idea is that we use the training dataset to experiment with different models\n",
      "and try out different parameters\n",
      "Embedding: [-0.02886031 -0.02202612  0.03249733  0.03933403  0.0668041  -0.00344511\n",
      " -0.06144298 -0.07603025 -0.03807868 -0.05008116]...\n",
      "Sentence: The development dataset, also called the holdout or\n",
      "cross-validation dataset, is then used to compare the generalization performance of\n",
      "different models on unseen data\n",
      "Embedding: [-0.02975317 -0.04346871 -0.05672038  0.02196698  0.06552187 -0.01182012\n",
      " -0.04654147  0.00559705  0.01431479 -0.04217869]...\n",
      "Sentence: We do not use the training dataset for this purpose\n",
      "to avoid the risk of shortlisting the best overﬁtted models as discussed in the previous\n",
      "section\n",
      "Embedding: [-0.0260267  -0.03419739  0.00990015  0.0516967   0.1022879   0.04959828\n",
      " -0.073109   -0.02533667 -0.05422949 -0.06820466]...\n",
      "Sentence: The development dataset is also used for ﬁne-tuning hyperparameters\n",
      "of the models, such as the step size or the optimization algorithm\n",
      "Embedding: [-0.00735621  0.0002982  -0.07478931 -0.00178447 -0.02274838 -0.02545266\n",
      " -0.09659567  0.03249179 -0.03805114 -0.00279718]...\n",
      "Sentence: We do not\n",
      "use the training data to select model parameters as this will lead to suboptimal\n",
      "hyperparameters, giving bias toward models that will overﬁt.\n",
      "The best model selected from the development set is then evaluated using the\n",
      "test data\n",
      "Embedding: [-0.00285742 -0.03036504 -0.01374756  0.03684844  0.03966795  0.03083527\n",
      " -0.05708037  0.02528663 -0.03564892 -0.01582795]...\n",
      "Sentence: If we have a smallish dataset, say less than 10,000 data points, then\n",
      "the split between the three training/dev/test datasets is normally in the ratio of\n",
      "60%:20%:20%\n",
      "Embedding: [ 0.03628782 -0.08007113 -0.03661757 -0.03254029  0.0701766  -0.06550726\n",
      " -0.08307949 -0.01570454 -0.01733696 -0.0184889 ]...\n",
      "Sentence: Commercial projects with 1,000,000+ samples use much more data\n",
      "to train and less to tune and validate, so the ratio could even be in the order of\n",
      "99%:0.5%:0.5% or even less for the development and test data.\n",
      "To build a well-performing model, it is essential to train and test the data which\n",
      "came from the same distribution\n",
      "Embedding: [ 0.04526636 -0.07413199 -0.06565799 -0.01230574  0.02165538 -0.06990251\n",
      " -0.10371006  0.04490997  0.04688958  0.04253615]...\n",
      "Sentence: This means, for instance, that we should be looking\n",
      "broadly at the same type and quality of data: clear pictures of cats taken in similar\n",
      "surrounding for the datasets\n",
      "Embedding: [ 0.05043091 -0.00957263  0.01247944  0.02350494  0.0423882  -0.08354645\n",
      "  0.00102205 -0.039615    0.03887876 -0.02570699]...\n",
      "Sentence: What we want to avoid in this example is to have the\n",
      "model trained on domestic cats and evaluated on blurry pictures of lynxes\n",
      "Embedding: [ 0.01778319 -0.04345478  0.04682054  0.02054637 -0.00292284 -0.04270543\n",
      " -0.01939492 -0.02848354 -0.04934542  0.04121673]...\n",
      "Sentence: In some\n",
      "cases, it may not be possible to have a big dataset for the model to train on\n",
      "Embedding: [ 0.01055832 -0.0466113  -0.02731814  0.03143123  0.05840152  0.01728992\n",
      " -0.1348207  -0.0263548  -0.05932392  0.01266954]...\n",
      "Sentence: For\n",
      "these cases, there are tricks that we could use to augment the data, which will be\n",
      "discussed in Section 5.2.6.\n",
      "5.2.2\n",
      "Categorical Data\n",
      "When data is represented as a list of categories or ﬁnite objects, for example,\n",
      "{apples, oranges, strawberries, bananas, grapes}, some algorithms, such as decision\n",
      "trees, can deal with the text directly, and there is no need for any data encoding.\n",
      "For many other algorithms, the data needs to be converted into a list of numerical\n",
      "IDs\n",
      "Embedding: [ 0.01602986  0.02706936  0.01368038  0.03592196  0.00436754  0.04180222\n",
      " -0.04273553 -0.08322746 -0.04284663 -0.01920763]...\n",
      "Sentence: It may be sufﬁcient to assign a numeric ID to each item, for example,\n",
      "{apples=1,oranges=2,...}\n",
      "Embedding: [ 0.0132799   0.02525136 -0.04156063  0.07287777  0.02141173  0.08029957\n",
      "  0.06996537 -0.04855     0.04338856 -0.04904646]...\n",
      "Sentence: However, integer encoding may lead the algorithm to\n",
      "imbue a spurious relationship between different categories because of numerical\n",
      "5.2\n",
      "Data Processing\n",
      "69\n",
      "Figure 5-2 Splitting the data into training, development, and test datasets\n",
      "ordering\n",
      "Embedding: [ 0.06727456 -0.00106844  0.02153414 -0.02903803  0.00104498 -0.04549587\n",
      " -0.10155053 -0.06405507 -0.01346814 -0.05187668]...\n",
      "Sentence: Assuming natural ordering between the numerical categories may result\n",
      "in poor performance and/or unexpected results.\n",
      "One-hot encoding is a binary encoding scheme where each item in the list of\n",
      "categories is assigned a value of one if true and zero if not\n",
      "Embedding: [ 0.03834356 -0.0390907  -0.03719171  0.02329427 -0.01912785 -0.00010855\n",
      " -0.06882669 -0.0846818   0.03084169 -0.00260025]...\n",
      "Sentence: The unique list of\n",
      "categories stored in the rows is translated as columns in Pandas and assigns a\n",
      "corresponding one and zero using the method get_dummies() as in the following\n",
      "example:\n",
      "import pandas\n",
      "data = pandas.DataFrame(list([’apples’,’oranges’,\n",
      "’strawberries’,’bananas’,’grapes’]), columns = [’fruits’])\n",
      "converted = pandas.get_dummies(data.fruits, prefix=’onehot’)\n",
      "print(data)\n",
      "print(converted)\n",
      "fruits\n",
      "0\n",
      "apples\n",
      "1\n",
      "oranges\n",
      "2\n",
      "strawberries\n",
      "3\n",
      "bananas\n",
      "4\n",
      "grapes\n",
      "onehot_ onehot_\n",
      "onehot_ onehot_\n",
      "onehot_\n",
      "apples\n",
      "bananas\n",
      "grapes\n",
      "oranges\n",
      "strawberries\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "The term “dummy” refers to the use of a statistical dummy variable in regression\n",
      "analysis\n",
      "Embedding: [-0.0194393  -0.02099375 -0.07272929  0.02158049  0.01910255  0.02959106\n",
      "  0.02103239 -0.02884201  0.00773188 -0.02399881]...\n",
      "Sentence: In statistics, a dummy variable acts like a switch in a regression equation,\n",
      "turning the parameter on and off by setting one or zero without the need to write\n",
      "multiple equations with different variables.\n",
      "70\n",
      "5\n",
      "The Training Process\n",
      "5.2.3\n",
      "Preprocessing Images\n",
      "Training a neural network to classify images normally means loading a custom\n",
      "dataset with image ﬁles in one of JPEG, BMP, or PNG format\n",
      "Embedding: [-0.02842417 -0.03377635 -0.03691758  0.06893171  0.04355659  0.0728628\n",
      "  0.0247227  -0.03131506 -0.04812808 -0.00477172]...\n",
      "Sentence: The pixels then\n",
      "have to be converted into a NumPy array or tensor of type ﬂoat and resized to match\n",
      "the size of the input layer of the neural network\n",
      "Embedding: [ 0.01276209 -0.03545114  0.0220766  -0.06893742  0.00816364 -0.00821332\n",
      " -0.00300413 -0.06154705 -0.11133801 -0.10124058]...\n",
      "Sentence: Although not strictly necessary, the\n",
      "pixel values are normally rescaled to the range 0 to 1 or −1 to 1, which may speed\n",
      "up the training process\n",
      "Embedding: [ 0.00010803 -0.04745707  0.00146467 -0.03959646 -0.00605586 -0.02148071\n",
      " -0.028338   -0.06078795 -0.0424401  -0.06592606]...\n",
      "Sentence: As an example, we will use the VGG-16 pretrained network\n",
      "in Keras to classify pictures of cats and dogs.\n",
      "A number of pretrained networks are available in Keras as applications in\n",
      "two parts: model architecture and weights\n",
      "Embedding: [-0.03260703 -0.02702413  0.02000475  0.00045425  0.00257442  0.03902553\n",
      " -0.08031093 -0.03655151 -0.0178903  -0.06871677]...\n",
      "Sentence: The model architectures are already\n",
      "downloaded when we installed Keras; the weights are stored in large ﬁles which\n",
      "need to be downloaded when we instantiate a model\n",
      "Embedding: [-0.03185333 -0.05943673 -0.02632316 -0.00816378  0.00220501 -0.02526197\n",
      " -0.0823729  -0.00700818  0.01509454 -0.03612445]...\n",
      "Sentence: The reader can read up on the\n",
      "different models in Keras on the ofﬁcial website:\n",
      "https://keras.io/api/applications/\n",
      "As we will be using the VGG-16 network, let’s discuss some of its properties\n",
      "which we need to know so that we can use it correctly.\n",
      "The VGG-16 network is a convoluted neural network (CNN) which is designed\n",
      "for image recognition\n",
      "Embedding: [-0.04566726 -0.03330623  0.00728121 -0.06587423  0.04261326  0.02900264\n",
      " -0.05385143  0.0106358  -0.02737962 -0.0811983 ]...\n",
      "Sentence: It is used for object detection and image classiﬁcation able\n",
      "to classify 1000 different classes of objects with 92% accuracy.\n",
      "The list of classes can be found at\n",
      "https://image-net.org/challenges/LSVRC/2014/browse-synsets\n",
      "which includes classes of animals, such as cats, dogs, whales, etc.\n",
      "The network was trained on color images of size 224 by 224 pixels with three\n",
      "color channels, so we need to convert our input images to this size\n",
      "Embedding: [-0.02098218 -0.05047675 -0.02928443 -0.01660134  0.05688344  0.01253443\n",
      "  0.04024789  0.00352368  0.02286129 -0.0319402 ]...\n",
      "Sentence: In addition to\n",
      "adjusting the image size, we also need to use the\n",
      "keras.applications.preprocess_input()\n",
      "method to convert the RGB colors for the input data to BGR, which is the color\n",
      "format used by VGG-16.\n",
      "We do not need to do anything to the hidden layers other than to use the pretrained\n",
      "weights and tell the network to predict our image as one of the 1000 different classes.\n",
      "In Code 5-1 below, the parameter include_top=True means we are using the\n",
      "complete network\n",
      "Embedding: [-0.0383223   0.03635822  0.0343923   0.02771972  0.05661543  0.03720429\n",
      " -0.02149027 -0.01796911 -0.09604968 -0.07984892]...\n",
      "Sentence: It is possible just to use the pretrained network hidden layers and\n",
      "specify custom-sized input and output layers by setting this parameter to false\n",
      "Embedding: [-0.02707835  0.00988854 -0.00119802  0.09204339 -0.02283988  0.08998767\n",
      " -0.07734215 -0.06586427 -0.07139549 -0.09237389]...\n",
      "Sentence: The\n",
      "pretrained network then can be repurposed and further trained on our own set of\n",
      "data.\n",
      "Using a pretrained network this way is called transfer learning\n",
      "Embedding: [-0.01235468 -0.06665698 -0.00751059  0.08498869  0.00167538  0.0359988\n",
      " -0.01185128 -0.04829381  0.00719605 -0.05819643]...\n",
      "Sentence: It allows the\n",
      "model trained on one task to be repurposed for a related task with much quicker\n",
      "retraining\n",
      "Embedding: [-0.08119134 -0.02632244 -0.00244991  0.04496331  0.08947369  0.0748586\n",
      " -0.01035086 -0.02454241  0.06440675 -0.02869857]...\n",
      "Sentence: The variable predictionLabels is a list containing triplets in the\n",
      "format below\n",
      "Embedding: [-0.0342821  -0.02690706 -0.10449305 -0.00165972  0.00757587  0.08637238\n",
      "  0.02192155 -0.00594544 -0.05314886 -0.03412786]...\n",
      "Sentence: The ﬁrst item is the label code, the second is the label text, and the\n",
      "number is the prediction probability.\n",
      "<class ’list’> [(’n02123045’, ’tabby’, 0.560446)|\n",
      "5.2\n",
      "Data Processing\n",
      "71\n",
      "Code 5-1 Using the VGG-16 pretrained network to classify cats and dogs\n",
      "The network returns the list sorted by probability from high to low, so the\n",
      "ﬁrst item in the list is the highest probability\n",
      "Embedding: [-0.02714024  0.03089237 -0.01780252 -0.04062916 -0.00527968  0.00166966\n",
      "  0.08671221  0.05040345 -0.04035491 -0.01693507]...\n",
      "Sentence: This is why we can use\n",
      "predictionLabels[0][0][1] to get the label name for the most likely class\n",
      "of animal.\n",
      "72\n",
      "5\n",
      "The Training Process\n",
      "It is quite remarkable that we are able to use a sophisticated network to predict\n",
      "pictures of cats and dogs using a single line of code\n",
      "Embedding: [-0.03945224 -0.02746907  0.02000476  0.0262579   0.04077762 -0.00695915\n",
      "  0.03434208 -0.00757223 -0.0268156  -0.05361351]...\n",
      "Sentence: Upon reviewing the model’s\n",
      "results, it becomes evident that while effective, the model is not 100% perfect\n",
      "Embedding: [ 0.0165184  -0.00902972  0.02691334  0.07861345  0.03019575 -0.07042864\n",
      " -0.0702297   0.07357809 -0.06253387  0.00799759]...\n",
      "Sentence: Some\n",
      "misclassiﬁed pictures are clearly wrong to the viewer but perhaps forgivable if we\n",
      "view at the process for what it is—the detection of similar patterns in new pictures\n",
      "using weights which have been trained on a group of images.\n",
      "5.2.4\n",
      "Normalization and Standardization\n",
      "It is often the case that the input variables have different scales\n",
      "Embedding: [-0.01746023 -0.02488785  0.02121395 -0.01326186  0.02663825 -0.04511841\n",
      " -0.02638727 -0.07118218  0.01599517 -0.05576235]...\n",
      "Sentence: For example, a\n",
      "company’s proﬁt in dollars could be in billions, while its proﬁt margin is expressed\n",
      "in percentage\n",
      "Embedding: [ 0.05557911 -0.03176027 -0.1320841   0.00961686 -0.0179956  -0.05174031\n",
      "  0.00024229  0.06039622  0.09773951  0.03132233]...\n",
      "Sentence: Input variables may also have different units, such as cm, km, or\n",
      "miles.\n",
      "When we model a problem with input of different scales, the weights for the\n",
      "model may also be large\n",
      "Embedding: [ 0.05380245 -0.05592095 -0.03496606  0.02180121 -0.03344114  0.0053762\n",
      " -0.07436721  0.03289765  0.06148656 -0.05415782]...\n",
      "Sentence: After all, we are trying to approximate a function that ﬁt\n",
      "the data points\n",
      "Embedding: [-0.02996414  0.03504026  0.01383887 -0.04695918 -0.01945366 -0.07080203\n",
      "  0.0140532   0.03195867 -0.00159342  0.01401869]...\n",
      "Sentence: The optimizer used in the backpropagation algorithm also works\n",
      "better when the scales are uniformed across the different variables\n",
      "Embedding: [ 0.00040902 -0.03690377 -0.03832051  0.01285584  0.02106221  0.0187112\n",
      " -0.03378927 -0.03128356  0.00018391 -0.02414006]...\n",
      "Sentence: The goal of\n",
      "normalization is to change the values of numeric columns in the dataset to use\n",
      "5.2\n",
      "Data Processing\n",
      "73\n",
      "a common scale, without distorting differences in the ranges of values without\n",
      "losing information\n",
      "Embedding: [ 0.05718524  0.02599091 -0.00494302 -0.06544994  0.00178439 -0.02174358\n",
      " -0.10870703 -0.04782343 -0.12418323  0.00228296]...\n",
      "Sentence: Normalization and standardization are crucial steps in data\n",
      "preprocessing, ensuring that each input feature contributes equally to the analysis.\n",
      "Transformation can be done manually by using\n",
      "sklearn.preprocessing\n",
      "transformation or standardization methods on the input column(s), or we can use\n",
      "a Normalize layer in Keras to perform rescaling for us\n",
      "Embedding: [ 0.03041786  0.00372913 -0.03136332 -0.06336643 -0.03054511 -0.00682892\n",
      " -0.11782108 -0.05762945 -0.10619655  0.00994245]...\n",
      "Sentence: If we transform data, it is\n",
      "important that the parameters are calculated for the training set and then used for\n",
      "the development and test datasets.\n",
      "There are several transformation methods in sklearn, but two useful methods are\n",
      "fit_transform() and transform() for the MinMaxScaler and StandardScaler\n",
      "classes\n",
      "Embedding: [-0.05409556  0.04146415 -0.05734272 -0.06535575  0.02026727 -0.02211569\n",
      " -0.06894357 -0.00501949 -0.05845241 -0.02202911]...\n",
      "Sentence: StandardScaler normalizes data to a mean of 0 and a standard deviation\n",
      "of 1, making it suitable for algorithms that assume data is centered around zero.\n",
      "MinMaxScaler, on the other hand, scales data to a speciﬁed range, often [0, 1],\n",
      "which is useful in neural network applications.\n",
      "The StandardScaler fit_transform() uses the following formula:\n",
      "xtransform = x −μ\n",
      "σ\n",
      "(5.1)\n",
      "where μ is the average value of the dataset and σ is the standard deviation, whereas\n",
      "the MinMaxScaler will use\n",
      "xtransform =\n",
      "x −xx min\n",
      "xmax −xmin\n",
      "(5.2)\n",
      "For example, we can see below that the transformed data using the standard scaler\n",
      "has mean zero and a unit standard deviation regardless of the original data, whereas\n",
      "the MinMaxScaler will scale differently and is more values dependent\n",
      "Embedding: [-0.0206645  -0.00837826 -0.01746556 -0.02672611 -0.01445741 -0.02776523\n",
      " -0.12965645  0.11657086  0.03366712 -0.04553796]...\n",
      "Sentence: However,\n",
      "the MinMaxScaler is useful for image processing when we want to compress the\n",
      "[0,255] color range down to [0,1].\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "import numpy as np\n",
      "trainingData = np.array([1.0,2.0,3.0,4.0,5.0,6.0])\n",
      "scaler = StandardScaler()\n",
      "transformedData = scaler.fit_transform(trainingData.\n",
      "reshape(-1,1))\n",
      "print(transformedData.mean())\n",
      "print(transformedData.std())\n",
      "mmScaler = MinMaxScaler()\n",
      "mmTransformed = mmScaler.fit_transform(trainingData.\n",
      "reshape(-1,1))\n",
      "print(mmTransformed)\n",
      "print(mmTransformed.std())\n",
      "74\n",
      "5\n",
      "The Training Process\n",
      "-3.700743415417188e-17\n",
      "1.0\n",
      "[[0\n",
      "Embedding: [-0.00744611  0.02350845  0.00567704 -0.03133984  0.00098546 -0.06876375\n",
      " -0.02700507  0.03448668 -0.060283   -0.02128563]...\n",
      "Sentence: ]\n",
      "[0.2]\n",
      "[0.4]\n",
      "[0.6]\n",
      "[0.8]\n",
      "[1\n",
      "Embedding: [ 0.04733217  0.04762184 -0.01324099 -0.01341581 -0.02204187 -0.07357959\n",
      "  0.09383363  0.07823414  0.0201026  -0.03581884]...\n",
      "Sentence: ]]\n",
      "0.34156502553198664\n",
      "For convenience, Keras allows the scaler to work with Pandas DataFrame directly,\n",
      "so it is easier to perform transformation on the data columns directly.\n",
      "scaler = StandardScaler()\n",
      "dfScaled = pandas.DataFrame(scaler.\n",
      "fit_transform(data[[’AGE’]]))\n",
      "5.2.5\n",
      "Missing Data\n",
      "Handling missing data is a common preprocessing challenge\n",
      "Embedding: [ 0.02027191  0.00386073  0.0179716  -0.02660624  0.02841456 -0.01615237\n",
      " -0.0872715  -0.0229616  -0.08195996 -0.02858655]...\n",
      "Sentence: Strategies include\n",
      "removing rows or columns with missing values or imputing these values based\n",
      "on the rest of the dataset\n",
      "Embedding: [ 0.00214309  0.08833566  0.01750107  0.00159059  0.05101936 -0.01216172\n",
      " -0.01725276 -0.09100852 -0.03321527 -0.02773388]...\n",
      "Sentence: Missing data in columns or rows can be dealt with by\n",
      "removing the relevant row(s) or column(s) if they are not signiﬁcant to the whole\n",
      "dataset, or we can look to use an algorithm in Keras/Pandas to impute missing\n",
      "values.\n",
      "In the ﬁrst instance, we can use a dropna() method in Pandas to delete any row\n",
      "or column in a DataFrame which has missing values\n",
      "Embedding: [-0.00162997  0.04830619  0.00249606 -0.00516935  0.07517578 -0.0563091\n",
      " -0.02649887 -0.07964165  0.00826929  0.0037839 ]...\n",
      "Sentence: For example:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "missingData = ’col1’:[1, 2,3],’col2’:[3, np.NaN,5],\n",
      "’col3’:[6,7,np.NaN]\n",
      "df = pd.DataFrame(data=missingData)\n",
      "print(df)\n",
      "noMissingRow= df.dropna(axis=0)\n",
      "print(’No missing row’,noMissingRow)\n",
      "noMissingCol= df.dropna(axis=1)\n",
      "print(’No missing col’,noMissingCol)\n",
      "col1\n",
      "col2\n",
      "col3\n",
      "0\n",
      "1\n",
      "3.0\n",
      "6.0\n",
      "1\n",
      "2\n",
      "NaN\n",
      "7.0\n",
      "2\n",
      "3\n",
      "5.0\n",
      "Na\n",
      "N\n",
      "No missing row col1\n",
      "col2\n",
      "col3\n",
      "0\n",
      "1\n",
      "3.0\n",
      "6.0\n",
      "No missing col col1\n",
      "5.2\n",
      "Data Processing\n",
      "75\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "Pandas also has a method fillna() to ﬁll in missing data\n",
      "Embedding: [-0.02584859 -0.07301363 -0.00116308  0.00054727  0.06370666 -0.06542648\n",
      " -0.02621363 -0.08448126 -0.03919915  0.03566159]...\n",
      "Sentence: Backﬁlling can be done\n",
      "for the dataframe or by rows and columns\n",
      "Embedding: [ 0.00486063 -0.02041759 -0.09211393 -0.03792012  0.04095627  0.04882044\n",
      " -0.04296737 -0.06953356 -0.08092206  0.03335153]...\n",
      "Sentence: The syntax for this method has several\n",
      "useful options, including ﬁlling missing data using data from the ﬁrst available data\n",
      "before or after the missing column or row.\n",
      "dataframe.fillna(value, method, axis, inplace, limit,\n",
      "downcast)\n",
      "This returns a new dataframe if the inplace parameter is false and None if it is true.\n",
      "Some examples of fillna() are shown below:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "df1 = pd.DataFrame(’Column1’: [1.0,2.0,None],\n",
      "’Column2’: [3.0,None,5.0],\n",
      "’Column3’: [None,6.0,7.0])\n",
      "df1.fillna(0)\n",
      "df1.fillna(value=’Column1’: 0.1,’Column2’: 0.2)\n",
      "#original dataframe\n",
      "print(df1,’original dataframe’)\n",
      "# forward fill using available number in the previous row\n",
      "dff = df1.fillna(method=’ffill’,axis=’rows’)\n",
      "print(dff,’forward fill’)\n",
      "# backward fill using available number in the row after\n",
      "dfb= df1.fillna(method=’bfill’,axis=’rows’)\n",
      "print(dfb,’backward fill’)\n",
      "Column1\n",
      "Column2\n",
      "Column3\n",
      "0\n",
      "1.0\n",
      "3.0\n",
      "NaN\n",
      "1\n",
      "2.0\n",
      "NaN\n",
      "6.0\n",
      "2\n",
      "NaN\n",
      "5.0\n",
      "7.0 original dataframe\n",
      "Column1\n",
      "Column2\n",
      "Column3\n",
      "0\n",
      "1.0\n",
      "3.0\n",
      "NaN\n",
      "1\n",
      "2.0\n",
      "3.0\n",
      "6.0\n",
      "2\n",
      "2.0\n",
      "5.0\n",
      "7.0 forward fill\n",
      "Column1\n",
      "Column2\n",
      "Column3\n",
      "0\n",
      "1.0\n",
      "3.0\n",
      "6.0\n",
      "1\n",
      "2.0\n",
      "5.0\n",
      "6.0\n",
      "2\n",
      "NaN\n",
      "5.0\n",
      "7.0 backward fill\n",
      "Using dropna() simpliﬁes the dataset but can lead to loss of valuable information.\n",
      "ﬁllna(), while preserving data, requires careful choice of imputation strategy to\n",
      "avoid introducing bias.\n",
      "As well as Pandas, the scikit-learn library offers a convenient way to impute\n",
      "values by calling the SimpleImpute class\n",
      "Embedding: [-0.03797733 -0.0512904  -0.00683331 -0.03676972  0.01179294 -0.05995947\n",
      " -0.03782577 -0.06378229 -0.046945    0.05500249]...\n",
      "Sentence: One of the most common interpolation\n",
      "techniques is mean imputation where we simply replace the missing values in each\n",
      "column with the column’s mean or median value\n",
      "Embedding: [-0.05949528  0.04280948  0.03404203 -0.00789478 -0.04188268 -0.0126087\n",
      " -0.0855808   0.04427114 -0.02254691 -0.02097992]...\n",
      "Sentence: The scikit-learn SimpleImputer\n",
      "76\n",
      "5\n",
      "The Training Process\n",
      "method is more ﬂexible as it offers more backﬁll option and can work on nparray\n",
      "data type as well as a dataframe.\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.impute import SimpleImputer\n",
      "missingData = ’col1’:[1, 2,3,3,3,3],’col2’:[3,\n",
      "np.NaN,5,4,4,4],\n",
      "’col3’:[6,7,np.NaN,8,8,8]\n",
      "df = pd.DataFrame(data=missingData)\n",
      "print(df)\n",
      "sim = SimpleImputer(missing_values=np.nan, strategy=’mean’)\n",
      "simMedian = SimpleImputer(missing_values=np.nan,\n",
      "strategy=’median’)\n",
      "imputedData = sim.fit_transform(df.values)\n",
      "imputedMedian = simMedian.fit_transform(df.values)\n",
      "print(’imputed mean’)\n",
      "print(imputedData)\n",
      "print(’imputed median’)\n",
      "print(imputedMedian)\n",
      "col1\n",
      "col2\n",
      "col3\n",
      "0\n",
      "1\n",
      "3.0\n",
      "6.0\n",
      "1\n",
      "2\n",
      "NaN\n",
      "7.0\n",
      "2\n",
      "3\n",
      "5.0\n",
      "NaN\n",
      "3\n",
      "3\n",
      "4.0\n",
      "8.0\n",
      "4\n",
      "3\n",
      "4.0\n",
      "8.0\n",
      "5\n",
      "3\n",
      "4.0\n",
      "8.0\n",
      "imputed mean\n",
      "[[1.\n",
      "3.\n",
      "6\n",
      "Embedding: [-0.01534211 -0.04153248  0.01026108 -0.04421006  0.09060149 -0.06108979\n",
      " -0.05495128  0.03128807 -0.08910839  0.05286793]...\n",
      "Sentence: ]\n",
      "[2.\n",
      "4.\n",
      "7\n",
      "Embedding: [ 0.02305731  0.07633905  0.08957225  0.01927808  0.02441941 -0.06037226\n",
      "  0.08013037  0.03088744 -0.07163949 -0.04461566]...\n",
      "Sentence: ]\n",
      "[3.\n",
      "5.\n",
      "7.4]\n",
      "[3.\n",
      "4.\n",
      "8\n",
      "Embedding: [ 0.00119662  0.0978642   0.0437547  -0.01877676  0.01882352 -0.04566098\n",
      "  0.1029103   0.04270859 -0.02341896 -0.05187222]...\n",
      "Sentence: ]\n",
      "[3.\n",
      "4.\n",
      "8\n",
      "Embedding: [-0.01489811  0.07851089  0.06071137 -0.01328243  0.03146631 -0.06032762\n",
      "  0.07745083  0.05322732 -0.02753527 -0.07063552]...\n",
      "Sentence: ]\n",
      "[3.\n",
      "4.\n",
      "8\n",
      "Embedding: [-0.01489811  0.07851089  0.06071137 -0.01328243  0.03146631 -0.06032762\n",
      "  0.07745083  0.05322732 -0.02753527 -0.07063552]...\n",
      "Sentence: ]]\n",
      "imputed median\n",
      "[[1\n",
      "Embedding: [-0.01669103  0.07880554  0.03175691 -0.0361512   0.04186831 -0.05199892\n",
      "  0.11251134  0.10629413 -0.03628119 -0.02206645]...\n",
      "Sentence: 3\n",
      "Embedding: [-0.02898993 -0.03105902 -0.09450372  0.02229462 -0.01062468 -0.03119772\n",
      "  0.09344781  0.01900541  0.00498642 -0.0639631 ]...\n",
      "Sentence: 6.]\n",
      "[2\n",
      "Embedding: [ 0.03439735  0.02752065  0.00696239  0.00465979 -0.01130041  0.00027074\n",
      "  0.12210109  0.04094138 -0.01742973 -0.03218877]...\n",
      "Sentence: 4\n",
      "Embedding: [ 0.04689893  0.00025665 -0.08567224  0.00702512 -0.06945483  0.00230715\n",
      "  0.06537846  0.00988497  0.00209017 -0.04645903]...\n",
      "Sentence: 7.]\n",
      "[3\n",
      "Embedding: [ 0.00813974  0.03107622  0.02867124  0.0261488   0.00142923 -0.01845886\n",
      "  0.15423559  0.02024431 -0.03176241 -0.03393717]...\n",
      "Sentence: 5\n",
      "Embedding: [-0.04131202 -0.00670328 -0.03135115  0.03367243  0.0030057  -0.00118033\n",
      "  0.08267043  0.01653073 -0.01819729  0.00195147]...\n",
      "Sentence: 8.]\n",
      "[3\n",
      "Embedding: [ 0.00431045  0.05166319  0.01421341  0.01276846 -0.01363475 -0.01577182\n",
      "  0.11978367  0.0527888  -0.00123291 -0.04855156]...\n",
      "Sentence: 4\n",
      "Embedding: [ 0.04689893  0.00025665 -0.08567224  0.00702512 -0.06945483  0.00230715\n",
      "  0.06537846  0.00988497  0.00209017 -0.04645903]...\n",
      "Sentence: 8.]\n",
      "[3\n",
      "Embedding: [ 0.00431045  0.05166319  0.01421341  0.01276846 -0.01363475 -0.01577182\n",
      "  0.11978367  0.0527888  -0.00123291 -0.04855156]...\n",
      "Sentence: 4\n",
      "Embedding: [ 0.04689893  0.00025665 -0.08567224  0.00702512 -0.06945483  0.00230715\n",
      "  0.06537846  0.00988497  0.00209017 -0.04645903]...\n",
      "Sentence: 8.]\n",
      "[3\n",
      "Embedding: [ 0.00431045  0.05166319  0.01421341  0.01276846 -0.01363475 -0.01577182\n",
      "  0.11978367  0.0527888  -0.00123291 -0.04855156]...\n",
      "Sentence: 4\n",
      "Embedding: [ 0.04689893  0.00025665 -0.08567224  0.00702512 -0.06945483  0.00230715\n",
      "  0.06537846  0.00988497  0.00209017 -0.04645903]...\n",
      "Sentence: 8.]]\n",
      "5.2.6\n",
      "Data Augmentation\n",
      "Data augmentation is a powerful technique to enhance the size and quality of\n",
      "training datasets by introducing variations\n",
      "Embedding: [-0.00469466 -0.08295341  0.08520154  0.00999977 -0.05257278 -0.01996133\n",
      " -0.033827   -0.04439158 -0.12823547 -0.07288675]...\n",
      "Sentence: This is especially important in ﬁelds\n",
      "like image processing, audio analysis, and natural language processing.\n",
      "It is useful to create more input data with transformed data using augmentation.\n",
      "By applying augmentation, we can increase the model’s capacity to generalize and\n",
      "5.2\n",
      "Data Processing\n",
      "77\n",
      "make better predictions\n",
      "Embedding: [ 0.00894163 -0.08207414  0.02945048 -0.00196482  0.00676681  0.00736723\n",
      " -0.07888488 -0.05917774 -0.02389321 -0.04914498]...\n",
      "Sentence: Data augmentation can be used for many applications,\n",
      "including text, audio, and images\n",
      "Embedding: [-0.0351775  -0.07371009  0.02572211 -0.03473094 -0.01807431  0.01664056\n",
      " -0.02491241 -0.01692828 -0.03955536 -0.04515076]...\n",
      "Sentence: For images, we can perform geometric trans-\n",
      "formation such as scaling, rotating, ﬂipping, cropping, kernel ﬁltering (sharpening\n",
      "or blurring), or mixing images.\n",
      "For audio, we can shift tone, balance, or speed or inject noise into an audio\n",
      "transcript to simulate dropout\n",
      "Embedding: [-0.04683904 -0.08719391 -0.01153842 -0.06353878 -0.00209408 -0.03867894\n",
      " -0.00496029 -0.07835563  0.03342529 -0.08603509]...\n",
      "Sentence: We can even use an advanced library, such as Dolby\n",
      "noise reduction, to remove background noises.\n",
      "For natural language processing, it is more difﬁcult to augment data due to the\n",
      "grammatical structure of the text\n",
      "Embedding: [ 0.02945451 -0.05126821  0.07909841 -0.02824514  0.02778995  0.00269919\n",
      "  0.01756392 -0.14083594  0.02383759 -0.07792407]...\n",
      "Sentence: Augmentation can be performed at character,\n",
      "word, or sentence level.\n",
      "Some common techniques are used to create synthetic sentences, such as back\n",
      "translation, that is, we translate an English sentence into a foreign language and\n",
      "then back-translate the foreign sentence into English again to hopefully generate\n",
      "a different sentence from the original one\n",
      "Embedding: [-0.04861424 -0.04022833  0.03201362  0.04280325 -0.08104887  0.02349812\n",
      " -0.00082478 -0.01784938  0.00371283 -0.01565056]...\n",
      "Sentence: One commonly used and effective\n",
      "technique is synonym replacement via word embedding\n",
      "Embedding: [-0.00483474 -0.03362824 -0.00928413 -0.0231202  -0.02468268  0.00079399\n",
      " -0.02211164  0.04367169 -0.01467635 -0.00735233]...\n",
      "Sentence: The N-word embedding\n",
      "algorithm, for example, replaces N non-stopwords by pretrained synonyms.\n",
      "Several libraries are available to use for this purpose, but they are divided into\n",
      "two categories: for non-contextual word embedding, models such as Glove and\n",
      "Word2Vec\n",
      "Embedding: [-0.03298268 -0.1024946  -0.00324089  0.00058657  0.01812581  0.02999451\n",
      " -0.0255357  -0.01103861  0.0084391  -0.0087988 ]...\n",
      "Sentence: The more advanced models, which use so-called transformer layers\n",
      "for learning contextual information, are BERT and RoBERTa from Google.\n",
      "Implementing data augmentation in Keras is straightforward; we can either\n",
      "use the TensorFlow library to perform the necessary transformation, such\n",
      "as image rotation or word embedding, and use them as extra input data, or\n",
      "we can use Keras preprocessing layers for data augmentation, for example,\n",
      "tf.keras.layers.RandomCrop or tf.keras.layers.RandomRotation, and\n",
      "make the processing layers part of our model\n",
      "Embedding: [-0.08166506 -0.08777907  0.05484507 -0.01096427 -0.00053724  0.0156766\n",
      " -0.0255366  -0.01101373 -0.03629303 -0.01762814]...\n",
      "Sentence: Note that the data augmentation\n",
      "should only be active during training and not in production as we wish to supplement\n",
      "the input data to train the model to improve its score and not to create fake live data.\n",
      "We will now look at some code snippets to augment images, sound, and sen-\n",
      "tences\n",
      "Embedding: [-0.06976134 -0.12337461  0.03899686  0.00806686 -0.00744916  0.0005589\n",
      " -0.03263072 -0.0810677  -0.11196665 -0.03198571]...\n",
      "Sentence: In Keras, data augmentation can be easily implemented using preprocessing\n",
      "layers\n",
      "Embedding: [-7.7828251e-02 -5.0654300e-02  7.4153215e-02 -1.7694835e-02\n",
      " -6.2198222e-02  6.5366869e-05 -7.2101668e-02 -9.0876773e-02\n",
      " -1.5352769e-01 -3.7750110e-02]...\n",
      "Sentence: Below is an example of how to resize and rotate images using these layers.\n",
      "Example 1: The example below uses the Keras preprocessing layer to resize\n",
      "and randomly rotate images of roses for the input layer before sending them to\n",
      "the next layer in the network\n",
      "Embedding: [-0.02033507 -0.01836132  0.03079712 -0.03955837 -0.00259362  0.03037393\n",
      " -0.01283503 -0.00306358 -0.03536873 -0.02697496]...\n",
      "Sentence: With this option, preprocessing will happen on the\n",
      "device, synchronously with the rest of the model execution, so that it will maximize\n",
      "GPU acceleration\n",
      "Embedding: [-0.03003123 -0.03156306 -0.02591241 -0.01147991  0.00602714 -0.08048963\n",
      " -0.07511451 -0.05746981 -0.03692347 -0.00555343]...\n",
      "Sentence: If we are training on a GPU, this is the best option for the\n",
      "normalization, image preprocessing, and data augmentation layers\n",
      "Embedding: [-0.03275187 -0.05180033 -0.00299484 -0.03034888  0.0071598  -0.03962092\n",
      " -0.06950943 -0.05080884 -0.10852707 -0.05263168]...\n",
      "Sentence: The second\n",
      "option is to loop through each image and save them as new images as shown by\n",
      "the augment() function\n",
      "Embedding: [ 0.01141265 -0.04733772  0.00243765  0.06195036  0.07761697 -0.00989622\n",
      " -0.04668533 -0.01794087 -0.00538726  0.01995726]...\n",
      "Sentence: An example of the output from the augment() function\n",
      "applied to a rose image is shown in Figure 5-3.\n",
      "import tensorflow as tf\n",
      "import pathlib\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.image as mpimg\n",
      "from PIL import Image\n",
      "from keras import layers\n",
      "78\n",
      "5\n",
      "The Training Process\n",
      "import numpy as np\n",
      "def augment(oldImage):\n",
      "image = oldImage.copy()\n",
      "image = tf.image.random_crop(image, size=[128, 128, 3])\n",
      "image = tf.image.random_flip_left_right(image)\n",
      "return image\n",
      "image = Image.open(\"/content/drive/MyDrive/Data/rose.jpg\")\n",
      "tensor = np.array(image)\n",
      "sizeScaleRotate = tf.keras.Sequential([\n",
      "layers.Resizing(128, 128),\n",
      "layers.Rescaling(1./255),\n",
      "layers.RandomRotation(np.pi)\n",
      "])\n",
      "imageAfter = sizeScaleRotate(tensor)\n",
      "fig = plt.figure(figsize=(10, 7))\n",
      "plt.subplot(1,3,1)\n",
      "plt.imshow(image)\n",
      "plt.subplot(1,3,2)\n",
      "plt.imshow(imageAfter)\n",
      "model = tf.keras.Sequential([\n",
      "# Add the preprocessing layers\n",
      "sizeScaleRotate,\n",
      "# the rest of the model\n",
      "layers.Dense(32, activation=’relu’)\n",
      "])\n",
      "# augment data separately\n",
      "imageAfter2 = augment(tensor)\n",
      "plt.subplot(1,3,3)\n",
      "plt.imshow(imageAfter2)\n",
      "Figure 5-3 Original image (left), resize and rotate (middle), crop and ﬂip left-right (right)\n",
      "5.3\n",
      "Tuning Our Network\n",
      "79\n",
      "5.3\n",
      "Tuning Our Network\n",
      "The machine learning process is highly iterative\n",
      "Embedding: [-0.07783318 -0.06361396  0.06557211  0.01196295  0.08213453 -0.03762544\n",
      " -0.02315358 -0.01179156 -0.02398803 -0.07069939]...\n",
      "Sentence: Given that it is relatively easy\n",
      "to code up a simple neural network in Python, it is often the case that we would\n",
      "code up, evaluate, and recode until our objectives are met\n",
      "Embedding: [-0.09391561 -0.0654128  -0.03580265  0.03510028 -0.01424874 -0.04648494\n",
      " -0.07208511 -0.01813366 -0.0242826  -0.0218632 ]...\n",
      "Sentence: An important part of this\n",
      "iterative process is the ability to evaluate the current model and the knowledge to\n",
      "improve it if needed.\n",
      "There are several parameters to choose when we are designing a model, namely,\n",
      "the number of units, layers, choice of loss functions, optimization procedure,\n",
      "number of epochs, the activation function, and the learning rate of the model.\n",
      "There are two types of parameters in machine learning: model and algorithm\n",
      "hyperparameters.\n",
      "•\n",
      "Model Hyperparameters: These are parameters for our model, such as the number\n",
      "of nodes and layers.\n",
      "•\n",
      "Algorithm Hyperparameters: These are usually the parameters for the backprop-\n",
      "agation algorithm, such as the learning rate.\n",
      "Specialized networks will include additional parameters to select, but the parameters\n",
      "mentioned are the basic parameters in most deep neural network (DNN) models.\n",
      "A common discussion on the network performance is the trade-off between the\n",
      "level of bias and variance\n",
      "Embedding: [-0.00123267 -0.06992075  0.02202987 -0.01318101 -0.0510703   0.03960229\n",
      " -0.03638033  0.03130767  0.00051293 -0.08305464]...\n",
      "Sentence: This is just a technical term for the degree of overﬁtting\n",
      "(high variance) versus underﬁtting (high bias)\n",
      "Embedding: [ 0.02364749 -0.07062878 -0.0323767   0.01216654  0.04685441 -0.01972929\n",
      " -0.03445056  0.08640105  0.06670562  0.00576724]...\n",
      "Sentence: As mentioned before, a high variance\n",
      "network will have a low error rate with the training dataset but a high error rate with\n",
      "the validation dataset because it does not generalize well\n",
      "Embedding: [ 0.03163284 -0.06247276  0.07959037 -0.00071295 -0.00736729  0.01539225\n",
      " -0.03055253  0.00621092  0.01127483 -0.1097757 ]...\n",
      "Sentence: Underﬁtting or high bias\n",
      "means the network is not sufﬁciently complex to deal with the problem.\n",
      "A network with high bias and variance will have a large error both in the training\n",
      "and validation datasets\n",
      "Embedding: [ 0.00072054 -0.02016663  0.02231793  0.02317375  0.0739707  -0.01489799\n",
      " -0.02956774 -0.00992998 -0.00901545 -0.03677626]...\n",
      "Sentence: Of course, we want a low bias, low variance network if\n",
      "possible, but, usually, reducing the error for one means increasing the error for the\n",
      "other, hence the commonly known “bias-variance trade-off” in machine learning.\n",
      "It is a fallacy to assume that a highly complex network will have high variance\n",
      "(i.e., prone to overﬁtting)\n",
      "Embedding: [ 0.03858572  0.00351606  0.07126663  0.02991975  0.01405927 -0.01957733\n",
      " -0.05326924  0.01196701  0.01571995 -0.02790901]...\n",
      "Sentence: A large language model, such as GPT-4, can have billions\n",
      "of parameters but generalize exceptionally well when compared to lesser models.\n",
      "We only need to compare the answers from GPT-4 to a lesser model to know that\n",
      "this is true.\n",
      "The basic recipes for dealing with the bias-variance problem are as follows:\n",
      "•\n",
      "Get as much data as possible.\n",
      "•\n",
      "If we have a high bias problem (underﬁt), then use a bigger network, train longer,\n",
      "or change the architecture.\n",
      "•\n",
      "The high variance problem is usually a more common and difﬁcult one to solve.\n",
      "For high variance error (overﬁtting with the validation dataset), then consider\n",
      "using regularization in our network, get more data, or change the architecture.\n",
      "We will use regularization in many of our examples later on in the book and\n",
      "80\n",
      "5\n",
      "The Training Process\n",
      "will discuss them later, but if you come across terms like ridge regression, lasso,\n",
      "dropout, batch norm, or teacher forcing, then do not be overly concerned with\n",
      "knowing the exact details, they are just techniques to reduce high variance error\n",
      "and are relatively easy to implement in Keras.\n",
      "Fortunately, Keras provides a tuner library to help pick the optimal set of parameters\n",
      "for our model\n",
      "Embedding: [-0.00837556 -0.02520272  0.03561263 -0.05221552  0.00204516  0.07968116\n",
      " -0.01747435  0.05657894 -0.05911561 -0.02192577]...\n",
      "Sentence: The Keras Tuner class has four tuners available: Random Search,\n",
      "Hyperband, BayesianOptimization, and Sklearn\n",
      "Embedding: [-0.0155924  -0.08857427 -0.07828625 -0.07795428 -0.02516764  0.03752069\n",
      " -0.02781053 -0.09729543 -0.06293112 -0.05297548]...\n",
      "Sentence: The Sklearn tuner is used for\n",
      "Sklearn only; if we only use Keras machine learning models, then select one of\n",
      "the other three tuner classes: Random Search, Hyperband, BayesianOptimization.\n",
      "The tuner class can tune many parameters at the same time, including the\n",
      "selection for the number of nodes and layers\n",
      "Embedding: [-0.02405076 -0.07461885 -0.07888091 -0.04086027  0.05459388  0.02675517\n",
      " -0.01246286 -0.11813799 -0.05475298 -0.06041121]...\n",
      "Sentence: In addition, model parameters, such as\n",
      "the learning rate, can also be tuned\n",
      "Embedding: [-0.0160831  -0.04401434 -0.09745492  0.01192853 -0.01835562  0.00047369\n",
      " -0.05375159 -0.00635282  0.02678891 -0.00157083]...\n",
      "Sentence: We build our model and tell the tuner to tune the\n",
      "deﬁned parameters\n",
      "Embedding: [-0.07343309 -0.02474365 -0.08403578 -0.02398495 -0.03734054  0.01308773\n",
      " -0.03817844 -0.01300765 -0.05072923 -0.01823508]...\n",
      "Sentence: It will return the “best” model(s) to use along with a summary\n",
      "of the results.\n",
      "The tuner serves an efﬁcient way to select the hyperparameters\n",
      "Embedding: [-0.02112468 -0.04975649 -0.05937431  0.00138595  0.02647303  0.05236811\n",
      " -0.05878093  0.00978887 -0.04054986 -0.04834201]...\n",
      "Sentence: The main\n",
      "disadvantage in using a tuner is the long runtime, but it is quicker than trying to do\n",
      "it manually! Out of the three methods, Hyperband is the most efﬁcient in resource\n",
      "allocation, and in practice, we should use either the Hyperband or the Bayesian\n",
      "algorithm.\n",
      "We can see how the tuner works by using it on our Modiﬁed National Institute\n",
      "of Standards and Technology (UNIST) project\n",
      "Embedding: [ 0.00271613  0.02519094 -0.13771419 -0.04897219 -0.00570625  0.02138072\n",
      " -0.03589455 -0.0013436  -0.05082487 -0.03197174]...\n",
      "Sentence: For convenience, the original code\n",
      "is repeated here followed by the new code tuned by Keras.\n",
      "from keras import activations\n",
      "import numpy as np\n",
      "import keras\n",
      "import tensorflow as tf\n",
      "import matplotlib.pyplot as plt\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "from keras import activations\n",
      "from keras.optimizers import Adam\n",
      "from google.colab import files\n",
      "# load mnist dataset\n",
      "# 60,000 images for xTrain, 10,000 for xTest\n",
      "mnist = tf.keras.datasets.mnist\n",
      "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
      "#convert the 28x28 input matrix to a vector of length 784\n",
      "xTrainFlattened = xTrain.reshape(len(xTrain),784)\n",
      "xTestFlattened = xTest.reshape(len(xTest),784)\n",
      "#set yTrain and yTest to 1 where the digit is 8 and\n",
      "#0 for others\n",
      "yTrain8 = np.where(yTrain!=8,0,1)\n",
      "yTest8 = np.where(yTest!=8,0,1)\n",
      "print(\"Count of yTrain = 8\",(yTrain8 == 1).sum(),\n",
      "\" out of \",len(yTrain))\n",
      "5.3\n",
      "Tuning Our Network\n",
      "81\n",
      "print(\"Count of yTest = 8\",np.sum(yTest8 == 1),\n",
      "\" out of \",len(yTest))\n",
      "#create the neural network as before\n",
      "model = Sequential()\n",
      "model.add(Dense(784, activation=’relu’,\n",
      "input_shape = (784,)))\n",
      "model.add(Dense(784,activation=’relu’))\n",
      "# the sigmoid activation will show\n",
      "#the probability of each digit\n",
      "model.add(Dense(1,activation=’sigmoid’))\n",
      "model.compile(optimizer=Adam(),\n",
      "loss=’binary_crossentropy’,\n",
      "metrics=[’accuracy’]) # show the accuracy of prediction\n",
      "model.fit(xTrainFlattened, yTrain8, epochs=5)\n",
      "yPredict = model.predict(xTestFlattened)\n",
      "# test the accuracy using the xTest\n",
      "model.evaluate(xTestFlattened,yTest8)\n",
      "We will tune the code above using the Keras tuner\n",
      "Embedding: [ 0.02645949 -0.09801948  0.03036254 -0.04710484  0.00950584  0.01289096\n",
      "  0.01608701 -0.0011743  -0.11844634 -0.07704878]...\n",
      "Sentence: Before we can use it, we may\n",
      "need to install the tuner package using the following command on Colab or our local\n",
      "terminal if we run the code locally on our PC:\n",
      "!pip install keras-tuner\n",
      "Once the library is installed, we can deﬁne a hypermodel by two methods.\n",
      "Either\n",
      "•\n",
      "Creating a model builder function and passing a hyperparameter instance as a\n",
      "parameter to that function\n",
      "Embedding: [ 0.02114524 -0.12230511 -0.03169102 -0.01686721 -0.06871588  0.02006368\n",
      " -0.09936879 -0.04325635 -0.14492369 -0.03719546]...\n",
      "Sentence: The model builder function returns a compiled model\n",
      "and uses hyperparameters we deﬁne inline to tune the model\n",
      "Embedding: [-0.05268557 -0.01255805 -0.01848652  0.07651874 -0.03955799 -0.00051925\n",
      " -0.10231238 -0.01514445 -0.06445008 -0.01920068]...\n",
      "Sentence: Once we have\n",
      "deﬁned the search space, we can select a tuner class, such as Hyperband or\n",
      "BayesianOptimization, to start the search.\n",
      "•\n",
      "Subclassing the HyperModel class of the Keras Tuner API.\n",
      "In addition to these two methods, we can also use the two predeﬁned HyperModel\n",
      "classes, HyperXception and HyperResNet, but since these are mainly used for\n",
      "computer vision applications only, we will not be addressing them here.\n",
      "As an example of how to create a model builder function, we will use the tuner\n",
      "to choose the number of units, the activation function, and the learning rate in our\n",
      "UNIST application.\n",
      "from keras import activations\n",
      "import numpy as np\n",
      "import keras\n",
      "import tensorflow as tf\n",
      "import matplotlib.pyplot as plt\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "from keras.layers import Dropout\n",
      "from keras import activations\n",
      "82\n",
      "5\n",
      "The Training Process\n",
      "from keras.optimizers import Adam\n",
      "from google.colab import files\n",
      "#import the tuner\n",
      "import keras_tuner\n",
      "# load mnist dataset\n",
      "# 60,000 images for xTrain, 10,000 for xTest\n",
      "mnist = tf.keras.datasets.mnist\n",
      "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
      "xTrainFlattened = xTrain.reshape(len(xTrain),784)\n",
      "xTestFlattened = xTest.reshape(len(xTest),784)\n",
      "#set yTrain and yTest to 1 where the digit is 8 and\n",
      "#0 for others\n",
      "yTrain8 = np.where(yTrain!=8,0,1)\n",
      "yTest8 = np.where(yTest!=8,0,1)\n",
      "print(\"Count of yTrain = 8\",(yTrain8 == 1).sum(),\n",
      "\" out of \",len(yTrain))\n",
      "print(\"Count of yTest = 8\",np.sum(yTest8 == 1),\n",
      "\" out of \",len(yTest))\n",
      "#create the neural network as before\n",
      "def buildModel(hp):\n",
      "model = Sequential()\n",
      "model.add(Dense(784, activation=’relu’,\n",
      "input_shape = (784,)))\n",
      "#define the search space\n",
      "for i in range(hp.Int(\"num_layers\", 1, 5)):\n",
      "model.add(\n",
      "Dense(\n",
      "# Tune number of units separately.\n",
      "units=hp.Int(f\"layerUniti\", min_value=2^4,\n",
      "max_value=2^10, step=2^3),\n",
      "activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),))\n",
      "if hp.Boolean(\"dropout\"): model.add(Dropout(rate=0.25))\n",
      "# choice of learning rates\n",
      "learningRate = hp.Choice(\"lr\", values=[1e-2, 1e-3, 1e-4])\n",
      "model.add(Dense(1,activation=’sigmoid’))\n",
      "model.compile(optimizer=Adam(learning_rate=learningRate),\n",
      "loss=’binary_crossentropy’, metrics=[’accuracy’])\n",
      "return model\n",
      "buildModel(keras_tuner.HyperParameters())\n",
      "tuner = keras_tuner.Hyperband(buildModel,\n",
      "objective=’val_accuracy’,\n",
      "max_epochs=10,\n",
      "factor=3)\n",
      "tuner.search_space_summary()\n",
      "tuner.search(xTrainFlattened, yTrain8, epochs=5,\n",
      "validation_data=(xTestFlattened, yTest8))\n",
      "tuner.results_summary()\n",
      "5.3\n",
      "Tuning Our Network\n",
      "83\n",
      "Best val_accuracy So Far: 0.9947999715805054\n",
      "Total elapsed time: 00h 30m 38s\n",
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 10 best trials\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "layerUnit0: 8\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.001\n",
      "layerUnit1: 7\n",
      "layerUnit2: 6\n",
      "layerUnit3: 7\n",
      "layerUnit4: 7\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0012\n",
      "Score: 0.9947999715805054\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "layerUnit0: 7\n",
      "activation: relu\n",
      "dropout: False\n",
      "lr: 0.0001\n",
      "layerUnit1: 6\n",
      "layerUnit2: 8\n",
      "layerUnit3: 6\n",
      "layerUnit4: 8\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 0015\n",
      "Score: 0.992900013923645\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 5\n",
      "layerUnit0: 8\n",
      "activation: relu\n",
      "dropout: True\n",
      "lr: 0.0001\n",
      "layerUnit1: 6\n",
      "layerUnit2: 6\n",
      "layerUnit3: 8\n",
      "layerUnit4: 6\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 4\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "84\n",
      "5\n",
      "The Training Process\n",
      "The optimizer took about 30 mins to complete all the epochs and completed its\n",
      "search for the “best” hyperparameters\n",
      "Embedding: [-0.09100494 -0.09329256 -0.02910484 -0.03187597 -0.02075374  0.00281517\n",
      " -0.08192373 -0.01886979 -0.09525371 -0.02552095]...\n",
      "Sentence: I have included the ﬁrst few best trials in the\n",
      "output above\n",
      "Embedding: [ 0.01122631  0.03446808 -0.03539093 -0.06021653  0.03462983 -0.01580091\n",
      "  0.0185833   0.04748994 -0.07382246  0.00574369]...\n",
      "Sentence: We can either recreate our model using these parameters manually or\n",
      "retrieve it from the optimizer and save it down.\n",
      "5.4\n",
      "Customizations\n",
      "In this section, we delve into the various ways Keras enables the customization of\n",
      "neural network architectures, focusing on the distinct approaches and the ﬂexibility\n",
      "each offers for building tailored deep learning models.\n",
      "In Keras, there are essentially three ways to use APIs to deﬁne a neural network:\n",
      "sequential, functional, and model subclassing\n",
      "Embedding: [-0.09945517 -0.05339285  0.04571528  0.00457288 -0.05551339  0.04396103\n",
      " -0.10296332 -0.02046099 -0.08096903 -0.08012083]...\n",
      "Sentence: The sequential API is the easiest\n",
      "to implement, but it is the most restrictive with each layer only connecting to the\n",
      "subsequent layer in a linear fashion.\n",
      "The functional API provides greater ﬂexibility, allowing branches of layers,\n",
      "multiple inputs and outputs\n",
      "Embedding: [-0.06786909 -0.05546821 -0.04163307  0.00814912 -0.04518249  0.0840436\n",
      " -0.10460274  0.00381343  0.06486005 -0.06751273]...\n",
      "Sentence: A model such as ResNet or Inception is easily\n",
      "implemented using this method\n",
      "Embedding: [-0.07595386 -0.05958048 -0.03784017 -0.03444664  0.04080565 -0.01087305\n",
      "  0.00130772 -0.00719501  0.01959527 -0.02483617]...\n",
      "Sentence: In most cases, using the functional API is all we\n",
      "need to implement very sophisticated networks.\n",
      "Lastly, model subclassing provides complete control over the training procedure:\n",
      "from customizing transfer function, custom layers, and models to monitoring and\n",
      "stopping the training process early using callbacks\n",
      "Embedding: [-0.10997579 -0.02847223  0.02749119  0.05392743  0.01495391 -0.00064889\n",
      " -0.07146499  0.04005471 -0.02398061 -0.05967261]...\n",
      "Sentence: Such ﬂexibility comes with\n",
      "increasing complexity in coding and the removal of some useful utilities, such as\n",
      "printsummary(), etc.\n",
      "5.5\n",
      "Functional API\n",
      "The main idea of the functional API is a way to build graphs of layers\n",
      "Embedding: [-0.0599984   0.01637451 -0.08911306  0.05672258  0.0425636  -0.01355618\n",
      " -0.05582646  0.0071888   0.01443113 -0.00819496]...\n",
      "Sentence: Instead of\n",
      "the sequential model where each layer follows the previous one in a linear fashion,\n",
      "the functional API can handle models with nonlinear topology, shared layers, and\n",
      "multiple inputs or outputs\n",
      "Embedding: [-0.09973954 -0.08855032 -0.00406259  0.05074971 -0.05160445  0.07476494\n",
      " -0.13337487  0.0102664   0.06463606 -0.06413256]...\n",
      "Sentence: In the functional API, models are created by specifying\n",
      "their inputs and outputs in a graph of layers\n",
      "Embedding: [-0.05448626 -0.03798107 -0.03977714  0.07629433 -0.00639762  0.0340518\n",
      " -0.07538116  0.03811018  0.06965444 -0.04320114]...\n",
      "Sentence: That means that a single graph of layers\n",
      "can be used to generate multiple models\n",
      "Embedding: [-0.04698794 -0.07788675 -0.00097631  0.0612322   0.07714155  0.02436185\n",
      " -0.10143048 -0.00311126  0.03893108 -0.03608622]...\n",
      "Sentence: This ﬂexibility is essential when we wish\n",
      "to implement the more advanced models, such as RNN, GAN, or CNN, in later\n",
      "chapters.\n",
      "5.6\n",
      "Custom Models\n",
      "85\n",
      "The key idea of the functional API is the use of one layer as a parameter input\n",
      "to another layer, so we can easily use one layer as input to several other layers and\n",
      "allow for branching in a network\n",
      "Embedding: [-0.12180242 -0.05063099 -0.01891086  0.06480736  0.00126692  0.05223435\n",
      " -0.08057123  0.01428601  0.01509861 -0.09646589]...\n",
      "Sentence: To have several input layers into one layer, Keras\n",
      "provides a concatenate layer which merges the input layers into a single list to\n",
      "feed into the next layer.\n",
      "Once the model is deﬁned using the functional API, training, evaluation, and\n",
      "inference work exactly in the same way for models built using the functional API as\n",
      "for sequential models.\n",
      "We will explain the use of the functional API by providing examples of how to\n",
      "create customized layers, models, and loss functions in the next few sections.\n",
      "5.6\n",
      "Custom Models\n",
      "Custom models are created simply by feeding a layer with a preceding layer as an\n",
      "input\n",
      "Embedding: [-0.06719512 -0.06003181  0.04718532  0.01150988 -0.02788891  0.07731432\n",
      " -0.0915422   0.03612341  0.03362146 -0.05454963]...\n",
      "Sentence: For example, let us deﬁne two inputs with two output models with a dense\n",
      "layer in between using the functional API\n",
      "Embedding: [-0.06982715 -0.08461101 -0.04461293  0.0393585  -0.01218654  0.04626067\n",
      " -0.0887725  -0.01823951  0.0343708  -0.10746539]...\n",
      "Sentence: The code would be as follows:\n",
      "import tensorflow as tf\n",
      "import keras\n",
      "from keras.layers import *\n",
      "from keras.models import Sequential, Model\n",
      "from keras.optimizers import Adam, RMSprop\n",
      "import numpy as np\n",
      "from keras.utils import plot_model\n",
      "input1 = Input(shape=(32,),name=\"input1\")\n",
      "input2 = Input(shape=(128,),name=\"input2\")\n",
      "x1 = Dense(2, name = \"dense1\")(input1)\n",
      "x = Dense(1,name = \"dense2\")(input2)\n",
      "x2 = Dense(1,name = \"dense2_2\")(x)\n",
      "concatted = Concatenate(name=\"concatted\")([x1, x2])\n",
      "model = Model(inputs=[input1, input2], outputs=concatted)\n",
      "plot_model(model, show_shapes=True,\n",
      "show_layer_names=True, to_file=’modelconcat.png’)\n",
      "The plot_model function gives the following diagram which is a mapping of what\n",
      "we have just coded.\n",
      "86\n",
      "5\n",
      "The Training Process\n",
      "The functional API offers remarkable ﬂexibility due to its ability to use a layer\n",
      "as an input to another layer\n",
      "Embedding: [ 0.02756473 -0.15176946  0.01879617 -0.04655771  0.02662474  0.0132995\n",
      "  0.0167692   0.01511244 -0.04479129 -0.06383923]...\n",
      "Sentence: This feature allows us to create complex branching in\n",
      "the hidden layers and provides the ﬂexibility to process various types of input data,\n",
      "such as numeric, categorical, and images, through different paths, merging them at\n",
      "the ﬁnal layer\n",
      "Embedding: [-0.01070649 -0.03370312 -0.01735057  0.04210687  0.06467555  0.02965886\n",
      " -0.05575489 -0.03628932  0.0607919  -0.07154494]...\n",
      "Sentence: While we have omitted the activation function on the dense layer for\n",
      "clarity, it functions identically to a sequential network.\n",
      "In later chapters, we will extensively use the functional API to introduce different\n",
      "network topologies\n",
      "Embedding: [-0.05867852 -0.10674756  0.01917813  0.02920183 -0.03724444  0.05149363\n",
      "  0.00504511 -0.02114267  0.04072764 -0.07558912]...\n",
      "Sentence: Regardless of how intricate the layers may seem, they are\n",
      "constructed in the same manner as described here.\n",
      "Moreover, the functional API empowers us to override Keras’s model base class,\n",
      "enabling the creation of customized models\n",
      "Embedding: [-0.07932717 -0.02512385  0.02879092 -0.01861346 -0.03846733 -0.0345284\n",
      " -0.10233967 -0.00945332  0.00701006 -0.01320691]...\n",
      "Sentence: A customized model groups layers with\n",
      "a set of input nodes, hidden layers, and output\n",
      "Embedding: [-0.07680075 -0.02832993 -0.00513019  0.07189586  0.08736537  0.0927472\n",
      " -0.05611335 -0.07675955 -0.00477586 -0.05244332]...\n",
      "Sentence: This approach proves beneﬁcial when\n",
      "the same group of layers needs to be repeated numerous times in a complex network.\n",
      "By deﬁning a customized model, we can reuse the code without duplicating the layer\n",
      "structure.\n",
      "For instance, let’s consider the construction of a Siamese network using the\n",
      "functional API\n",
      "Embedding: [-0.08030058 -0.05063274  0.01953954  0.06291939 -0.01444729  0.05464044\n",
      " -0.05802143 -0.09589496  0.07040782 -0.09582303]...\n",
      "Sentence: A Siamese network comprises two identical subnetworks feeding\n",
      "into a comparator layer at the output\n",
      "Embedding: [ 0.01265972 -0.06123443  0.04477002 -0.00650032 -0.00265192  0.02009742\n",
      " -0.04977571 -0.06369966  0.02283962 -0.11095287]...\n",
      "Sentence: These subnetworks share the same architecture\n",
      "and parameters and are essentially mirror images of each other\n",
      "Embedding: [-0.06261127 -0.07299284 -0.02413576 -0.04853041  0.03683227 -0.09050282\n",
      " -0.08341786 -0.07019594 -0.01294134 -0.11927371]...\n",
      "Sentence: If the weights\n",
      "of one subnetwork are updated, the weights of the other subnetwork are updated\n",
      "accordingly.\n",
      "The Siamese network topology is often utilized to compute the degree of\n",
      "similarity between two items, such as images, words, or sounds\n",
      "Embedding: [-0.00028184 -0.1270255  -0.03176365 -0.01016605  0.00532655  0.01918967\n",
      " -0.04487067 -0.0709056   0.0726774  -0.09244017]...\n",
      "Sentence: In this example,\n",
      "we will create a network to compare two images\n",
      "Embedding: [-0.00919239 -0.02649861 -0.024778   -0.02811584  0.02077702 -0.05824277\n",
      " -0.04223331  0.01024329  0.03162217 -0.08097558]...\n",
      "Sentence: This involves constructing two\n",
      "identical CNN subnetworks (referred to as Siamese sisters)\n",
      "Embedding: [-0.07586013 -0.11449453  0.01352088 -0.01982803 -0.02062528 -0.05417952\n",
      " -0.09718037 -0.08835286  0.03029777 -0.10835964]...\n",
      "Sentence: Each network outputs\n",
      "a vector, which is then fed into a ﬁnal comparative layer to assess the degree of\n",
      "dissimilarity.\n",
      "5.6\n",
      "Custom Models\n",
      "87\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.layers import Input, Conv2D,\n",
      "MaxPooling2D, Flatten, Dense, Lambda\n",
      "from tensorflow.keras.models import Model\n",
      "import tensorflow.keras.backend as K\n",
      "def initialize_base_network():\n",
      "#Define the base network (shared layers)\n",
      "input = Input(shape=(input_shape,),\n",
      "name=\"base_input\")\n",
      "x = Conv2D(64, (3, 3), activation=’relu’)(input)\n",
      "x = MaxPooling2D((2, 2))(x)\n",
      "x = Conv2D(128, (3, 3), activation=’relu’)(x)\n",
      "x = MaxPooling2D((2, 2))(x)\n",
      "x = Flatten()(x)\n",
      "x = Dense(128, activation=’relu’)(x)\n",
      "return Model(inputs=input, outputs=x)\n",
      "def euclidean_distance(vectors):\n",
      "#Define the Euclidean distance function\n",
      "x, y = vectors\n",
      "sum_square = K.sum(K.square(x - y), axis=1,\n",
      "keepdims=True)\n",
      "return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
      "input_shape = (105, 105, 1)\n",
      "# Example input shape\n",
      "# Create the base network\n",
      "base_network = initialize_base_network()\n",
      "# Create the left input and point to\n",
      "#the base network\n",
      "input_a = Input(shape=input_shape, name=\"left_input\")\n",
      "processed_a = base_network(input_a)\n",
      "# Create the right input and point to\n",
      "#the same base network\n",
      "input_b = Input(shape=input_shape, name=\"right_input\")\n",
      "processed_b = base_network(input_b)\n",
      "# Calculate the distance between the\n",
      "# two encoded inputs\n",
      "distance = Lambda(euclidean_distance,\n",
      "output_shape=(1,),\n",
      "name=\"distance\")([processed_a, processed_b])\n",
      "# Create the Siamese network model\n",
      "model = Model(inputs=[input_a, input_b],\n",
      "outputs=distance)\n",
      "# Define the optimizer and compile the model\n",
      "model.compile(loss=\"contrastive_loss\",\n",
      "optimizer=\"adam\")\n",
      "88\n",
      "5\n",
      "The Training Process\n",
      "# Now the model is ready to be trained with\n",
      "# pairs of inputs and a label indicating\n",
      "# their similarity\n",
      "5.7\n",
      "Model Selection\n",
      "Model selection seems daunting as there are so many alternatives to choose from,\n",
      "but in practice, it is often the case that real-world requirements and constraints would\n",
      "help to guide us to the most appropriate model\n",
      "Embedding: [ 0.05873405 -0.11617688  0.02145794 -0.06469528  0.01092038  0.00713438\n",
      " -0.06014711  0.00393867 -0.00237784 -0.07260139]...\n",
      "Sentence: As surprising as it may seem, it is\n",
      "often ﬁne-tuning and experimentation that often take a long time to master and get\n",
      "right.\n",
      "The considerations for model selection in this section are mainly based on learn-\n",
      "ing and research-based requirements\n",
      "Embedding: [ 0.03332052 -0.07943582  0.06333154  0.0696243   0.0666489  -0.03498121\n",
      " -0.12723452  0.01404123  0.02908473  0.00424277]...\n",
      "Sentence: Commercial projects often require complex\n",
      "and larger models, which are beyond the scope of this book\n",
      "Embedding: [ 0.03411112 -0.05598114  0.0244674   0.00149233  0.0236464  -0.06156681\n",
      " -0.14383686  0.09053984  0.06677233  0.02367922]...\n",
      "Sentence: As an anecdote sidenote\n",
      "on model selection in a commercial environment, several software companies allow\n",
      "the user to run the data against hundreds of different models and parameters and\n",
      "choose the model with the best results\n",
      "Embedding: [-0.02146344 -0.04237469  0.01709961  0.06253011  0.06327002 -0.02338385\n",
      " -0.09315687  0.07260431  0.02942273 -0.00831674]...\n",
      "Sentence: While this is a valid approach, it would not\n",
      "work well with less time and resources.\n",
      "For many tasks, especially in computer vision and natural language processing,\n",
      "pretrained models are available\n",
      "Embedding: [-0.00151048 -0.02520466  0.00204885  0.00773292  0.02465865  0.07555609\n",
      " -0.03303336 -0.01771848  0.00022994 -0.04235666]...\n",
      "Sentence: These can be a good starting point and can be\n",
      "ﬁne-tuned on your speciﬁc dataset\n",
      "Embedding: [ 0.00022171 -0.07264359 -0.04446386 -0.02901179 -0.04876361  0.02609303\n",
      " -0.03130139 -0.03540401 -0.11818123 -0.06309891]...\n",
      "Sentence: At the very least, examining these pretrained\n",
      "models would give us a good idea of what a simpliﬁed architecture should be for our\n",
      "problem\n",
      "Embedding: [-0.03951193 -0.0339461  -0.00435413 -0.03032638 -0.01961019  0.05135991\n",
      " -0.13390996 -0.00805852 -0.04042652 -0.04566855]...\n",
      "Sentence: For instance, if the pretrained model uses predominantly CNN or ResNet\n",
      "layers with good result, then a similar type of layers should be used for our project.\n",
      "Speed requirement is an important factor to consider\n",
      "Embedding: [-0.01288047 -0.03989059  0.06861119 -0.00611958  0.00775151  0.07332425\n",
      " -0.08522054  0.00113678  0.01577545 -0.08309966]...\n",
      "Sentence: For applications requiring\n",
      "real-time responses, like mobile or web applications, lightweight models are\n",
      "preferable, but for tasks where accuracy is paramount and response time is less\n",
      "critical, like medical image analysis, more complex models can be used to get better\n",
      "results.\n",
      "The complexity of the model is a double-edged sword\n",
      "Embedding: [-0.02431999 -0.00608111  0.00550579  0.02616875  0.07429252 -0.1078788\n",
      " -0.07525387  0.08580126  0.09128474 -0.00356201]...\n",
      "Sentence: More complex models\n",
      "have greater power and ﬂexibility but are prone to overﬁtting, especially when\n",
      "the data size is limited\n",
      "Embedding: [ 0.01374542 -0.03468914 -0.00280237  0.08296707  0.08144353 -0.10037345\n",
      " -0.17250626  0.06346322  0.04287942  0.03798804]...\n",
      "Sentence: Techniques such as dropout, regularization, and data\n",
      "augmentation are employed to combat overﬁtting\n",
      "Embedding: [-0.04809143  0.01907831  0.06343719 -0.0032462   0.00101697 -0.01748955\n",
      " -0.00917087 -0.05677565 -0.09606548 -0.05625675]...\n",
      "Sentence: Conversely, too simple a model\n",
      "might not capture the complexity of the data, resulting in underﬁtting and poor\n",
      "overall performance.\n",
      "At the core of model selection is the speciﬁcity of the task\n",
      "Embedding: [ 0.03278305 -0.03226699  0.03532192  0.07604078  0.12899503 -0.06286336\n",
      " -0.1251741   0.0723666   0.00808346  0.0349898 ]...\n",
      "Sentence: For instance, deep\n",
      "convolutional neural networks (CNNs) are often the go-to choice for image or\n",
      "speech recognition tasks, leveraging their ability to capture spatial hierarchies.\n",
      "On the other hand, sequence modeling tasks, like language translation or time-\n",
      "series prediction, beneﬁt from the temporal dynamics captured by recurrent neural\n",
      "networks (RNNs), long short-term memory networks (LSTMs), or gated recurrent\n",
      "units (GRUs)\n",
      "Embedding: [-0.09609354 -0.10995638  0.02693922 -0.03464173  0.01954785  0.0792793\n",
      " -0.05300086 -0.00999912  0.11407349 -0.08546056]...\n",
      "Sentence: In regression tasks where the goal is to predict numerical values,\n",
      "simpler DNN architectures might sufﬁce, though complex data might still require\n",
      "5.9\n",
      "Neural Networks Applications\n",
      "89\n",
      "the sophistication of CNNs or RNNs\n",
      "Embedding: [-0.09046531 -0.0761649   0.07571328 -0.03341619 -0.00363645  0.01359206\n",
      " -0.03961082 -0.00600688  0.02051014 -0.07931636]...\n",
      "Sentence: Additionally, for generative tasks like image\n",
      "generation or style transfer, models like generative adversarial networks (GANs) or\n",
      "variational autoencoders (VAEs) are typically used.\n",
      "The characteristics of the data also play a pivotal role in model selection\n",
      "Embedding: [-0.05777269 -0.04418099  0.07989217  0.04499005  0.03462667  0.04793864\n",
      " -0.05490344 -0.02623428  0.08111767 -0.02481823]...\n",
      "Sentence: Large\n",
      "datasets can often support deeper and more complex networks, but this comes with\n",
      "increased computational demands\n",
      "Embedding: [ 1.4992015e-02 -6.8211116e-02  2.6477493e-02  5.9907576e-05\n",
      "  7.0449442e-02 -8.5574426e-02 -1.3781533e-01  2.3296673e-03\n",
      "  2.3732651e-02 -6.1537735e-03]...\n",
      "Sentence: High-dimensional data, such as high-resolution\n",
      "images, may necessitate more sophisticated models to effectively capture underlying\n",
      "patterns\n",
      "Embedding: [-0.00680934 -0.06970077  0.07161338 -0.03881099  0.0696874  -0.02456914\n",
      " -0.07882267 -0.05334914  0.06593226 -0.02267396]...\n",
      "Sentence: The quality and diversity of the training data are equally important; noisy,\n",
      "imbalanced, or unrepresentative datasets can lead to poor model performance,\n",
      "making data preprocessing and augmentation crucial.\n",
      "In summary, while the selection of an appropriate model can be a complex task,\n",
      "understanding the speciﬁc requirements and constraints of our project is crucial in\n",
      "guiding you toward the most effective and efﬁcient model choice.\n",
      "5.8\n",
      "Model Depth and Complexity\n",
      "Each layer in a DNN extracts a level of abstraction of the data\n",
      "Embedding: [-0.0279726  -0.09096672  0.07854962 -0.01398973  0.01141629  0.00183027\n",
      " -0.07581865 -0.00837203 -0.03449005 -0.05269248]...\n",
      "Sentence: In general, more\n",
      "layers allow the network to learn more complex patterns\n",
      "Embedding: [-0.00987412 -0.06405596  0.06262544 -0.01038754  0.05843029  0.01095735\n",
      " -0.07927238 -0.0362799   0.07493132 -0.03335008]...\n",
      "Sentence: For instance, in a CNN\n",
      "that is used for image recognition, initial layers might detect edges, while deeper\n",
      "layers could identify more complex structures, like shapes or speciﬁc objects.\n",
      "The complexity and volume of your data are key indicators when choosing the\n",
      "model depth and complexity\n",
      "Embedding: [ 0.0190037  -0.06550865  0.04054246 -0.03961151  0.04853314 -0.09939835\n",
      " -0.09507211  0.01303317  0.09678688 -0.01250594]...\n",
      "Sentence: Simple patterns and smaller datasets often require\n",
      "fewer layers, as a deep network might overﬁt, learning noise rather than useful\n",
      "patterns\n",
      "Embedding: [-0.01759944 -0.05918415  0.13039362  0.01611967  0.03974751 -0.02259301\n",
      " -0.08011889 -0.06066476  0.0068216  -0.06864537]...\n",
      "Sentence: Conversely, complex data such as high-resolution images or intricate\n",
      "language structures might beneﬁt from deeper architectures.\n",
      "Although we have not discussed the transformer layer in this book due to its\n",
      "complexity, using transformer layers in a neural network architecture is particularly\n",
      "advantageous for certain types of problems, especially those involving sequential\n",
      "data or requiring the understanding of long-range dependencies\n",
      "Embedding: [-0.11102209 -0.03174244  0.06802367 -0.05039832 -0.01843882  0.02857707\n",
      " -0.07616629  0.02860534  0.04674582 -0.09963518]...\n",
      "Sentence: The transformer\n",
      "model, introduced in the seminal paper “Attention Is All You Need” by Vaswani\n",
      "et al., has revolutionized the ﬁeld of natural language processing (NLP) and is\n",
      "increasingly being adapted for other applications, such as computer vision.\n",
      "In conclusion, the depth and complexity of a neural network model should be\n",
      "carefully tailored to the speciﬁc characteristics of our data and the nature of the task\n",
      "at hand, balancing the ability to learn intricate patterns with the risk of overﬁtting,\n",
      "to achieve optimal performance.\n",
      "5.9\n",
      "Neural Networks Applications\n",
      "We will now present some applications which were state-of-the-art models a few\n",
      "years ago\n",
      "Embedding: [-0.06936367 -0.10379629  0.06823848 -0.04175405  0.02535404  0.03795895\n",
      " -0.03926493  0.05423923  0.04798103 -0.03585733]...\n",
      "Sentence: The main purpose of presenting my own implementation of these research\n",
      "projects is to illustrate two important points:\n",
      "90\n",
      "5\n",
      "The Training Process\n",
      "•\n",
      "The reader should, hopefully, be able to follow and understand the code now.\n",
      "•\n",
      "Gain insights into the subtle but crucial considerations researchers must account\n",
      "for when designing innovative models.\n",
      "These applications, demand signiﬁcant computing resources\n",
      "Embedding: [-0.09595063  0.01831486 -0.03604247 -0.03335664 -0.02337384 -0.04764523\n",
      " -0.00389156  0.09444478 -0.03666417 -0.0147913 ]...\n",
      "Sentence: All of them take days,\n",
      "if not several weeks, to run on a normal PC with a decent GPU, so be prepared to\n",
      "invest the time to experiment.\n",
      "In most cases, it is a trade-off between time and the quality of training\n",
      "Embedding: [ 0.03317587 -0.04584331  0.01710927  0.03648234  0.03694669 -0.080616\n",
      " -0.12349267 -0.04517513 -0.06563586 -0.07265245]...\n",
      "Sentence: For\n",
      "example, suppose we want to train the agent to play the Space Invaders game “well,”\n",
      "we would need to deﬁne, monitor, and understand how well the model is learning\n",
      "and when to adjust or stop training\n",
      "Embedding: [ 0.05779774 -0.03381491 -0.02744913 -0.0202732   0.01127332  0.05474877\n",
      " -0.01943438  0.00516652 -0.00071469  0.04147256]...\n",
      "Sentence: Here are some strategies to effectively monitor\n",
      "the performance:\n",
      "•\n",
      "Track Cumulative Rewards per Episode: The most direct measure of performance\n",
      "in reinforcement learning is the cumulative reward obtained in each episode.\n",
      "Plotting this over episodes gives a clear view of whether the agent is improving.\n",
      "•\n",
      "Evaluate Loss During Training: Keep an eye on the loss of the neural network\n",
      "during the training process\n",
      "Embedding: [ 0.05970759 -0.03918059 -0.06299647 -0.03496988  0.00058418  0.04631723\n",
      " -0.01536804 -0.02461287  0.00832279  0.01355262]...\n",
      "Sentence: A decreasing loss trend indicates that the model\n",
      "is learning, but if the loss plateaus or increases, it might signal issues with the\n",
      "training process.\n",
      "•\n",
      "Use a Running Average: Due to the inherent variability in reinforcement learning,\n",
      "it’s useful to look at a running average of the rewards over a set number of\n",
      "episodes (e.g., the last 100 episodes)\n",
      "Embedding: [ 0.00333542 -0.01431294  0.05421038  0.05482324 -0.0018747   0.07119764\n",
      " -0.09475306  0.04701203  0.03280582 -0.01388266]...\n",
      "Sentence: This smooths out the noise and gives a\n",
      "clearer trend.\n",
      "•\n",
      "Test in a Fixed Environment: Periodically test our agent in a controlled environ-\n",
      "ment where the starting conditions are ﬁxed\n",
      "Embedding: [-0.02319469 -0.05706842  0.03416825  0.05901737  0.06321096 -0.07308745\n",
      "  0.0169783  -0.04007214 -0.01661973  0.01534526]...\n",
      "Sentence: This can give us a more consistent\n",
      "basis for comparison.\n",
      "•\n",
      "Performance Thresholds: Set performance benchmarks or thresholds\n",
      "Embedding: [-0.00287263 -0.02863023 -0.08576398 -0.00578118  0.02659256 -0.06893822\n",
      " -0.02983555  0.0440889   0.00625358 -0.0329316 ]...\n",
      "Sentence: For exam-\n",
      "ple, if the agent achieves a certain score or survives a certain number of frames\n",
      "consistently, it can be a sign of adequate learning.\n",
      "•\n",
      "Visual Inspection: Occasionally watch the agent play the game\n",
      "Embedding: [ 0.06537333 -0.02529138 -0.03178878 -0.07145858  0.02275244  0.04957471\n",
      "  0.04209186  0.02037226  0.04006624  0.0461034 ]...\n",
      "Sentence: This can give our\n",
      "qualitative insights into its learning progress and strategy development.\n",
      "•\n",
      "Log and Review Training Data: Regularly log important metrics, like rewards,\n",
      "loss, epsilon values, and speciﬁc actions taken\n",
      "Embedding: [ 0.0364255  -0.00553751 -0.03307129  0.0138391   0.01473361  0.02460895\n",
      " -0.03200357 -0.00804461 -0.03406455  0.03423099]...\n",
      "Sentence: Reviewing these logs can help\n",
      "identify patterns or issues.\n",
      "•\n",
      "Compare Against Baselines: If available, compare our agent’s performance\n",
      "against known baselines or benchmarks for the game\n",
      "Embedding: [ 0.02951823 -0.00743548 -0.08075096 -0.03762991  0.0436344  -0.01243315\n",
      " -0.03921429  0.0158499  -0.03336792  0.0564682 ]...\n",
      "Sentence: This gives a context to\n",
      "the performance.\n",
      "•\n",
      "Use Validation Episodes: Separate training and validation episodes can be useful.\n",
      "Train the agent for a number of episodes, then test it on different episodes\n",
      "without learning (i.e., no weights update during these test episodes)\n",
      "Embedding: [-0.0196299   0.01870825 -0.0699008   0.02733381  0.01833104  0.05390979\n",
      " -0.01115383 -0.04330933  0.02807153 -0.08464806]...\n",
      "Sentence: This helps\n",
      "in understanding how well the model generalizes.\n",
      "•\n",
      "Early Stopping: Implement an early stopping mechanism\n",
      "Embedding: [-0.03010407 -0.00604591  0.0803333   0.02393587  0.07152243  0.06120281\n",
      " -0.08034512  0.04185516  0.03127597  0.04571393]...\n",
      "Sentence: If the performance\n",
      "does not improve or starts to degrade over a certain number of episodes, stop the\n",
      "training to prevent overﬁtting or wasting resources.\n",
      "5.10\n",
      "Dense Network: Detection of Handwritten Digits Using MNIST Dataset\n",
      "91\n",
      "Figure 5-4 MNIST 28 × 28\n",
      "matrix of digit 5\n",
      "5.10\n",
      "Dense Network: Detection of Handwritten Digits Using\n",
      "MNIST Dataset\n",
      "Just to illustrate this point further, let us consider the problem of recognizing\n",
      "handwritten digits\n",
      "Embedding: [-0.00886939 -0.06999433  0.02342824 -0.05654958  0.03235693  0.041993\n",
      " -0.02741607 -0.07479198 -0.08795996 -0.07757451]...\n",
      "Sentence: This problem at ﬁrst seems nothing like the problem in the\n",
      "previous example, but with some minor code changes to digitize the images, we\n",
      "can use the same type of neural network to solve it.\n",
      "We are going to use the popular MNIST dataset\n",
      "Embedding: [-0.01037404 -0.06213846  0.05199166 -0.05671677 -0.0235634   0.00832752\n",
      " -0.03739035 -0.08428596 -0.07942936 -0.1153387 ]...\n",
      "Sentence: The MNIST dataset is so widely\n",
      "used in machine learning that it has been included as part of Keras’s standard built-in\n",
      "datasets\n",
      "Embedding: [-0.0713299  -0.06511033  0.01801573 -0.02892946  0.05720907  0.03354283\n",
      " -0.05900606 -0.03353693 -0.08931923  0.00092524]...\n",
      "Sentence: The dataset consists of 60,000 images of digits ranging from zero to nine,\n",
      "where each digit is represented as a 28×28 matrix of grayscale pixels\n",
      "Embedding: [ 0.02163355 -0.0155723  -0.07258477 -0.11717241 -0.03631601  0.01715047\n",
      " -0.03945389  0.00268684 -0.05062774 -0.05320817]...\n",
      "Sentence: In addition to\n",
      "the 60,000 training images, the dataset includes 10,000 images for testing purposes.\n",
      "An example of an MNIST digit is shown in Figure 5-4\n",
      "Embedding: [-0.00440124 -0.03469617 -0.04228048 -0.07354207  0.01111665 -0.00762907\n",
      " -0.03068654  0.01849199 -0.07766679 -0.01579551]...\n",
      "Sentence: Since this is a grayscale\n",
      "image, each pixel represents a brightness value from 0 (black) to 255 (white)\n",
      "Embedding: [ 0.03758728  0.06706679 -0.00454524 -0.02338433 -0.01684023 -0.10031743\n",
      "  0.04056908 -0.01619447  0.05548919 -0.04829454]...\n",
      "Sentence: The\n",
      "yTrain and yText arrays contain the actual number of the digit itself, so for the\n",
      "image, yTrain=5\n",
      "Embedding: [ 4.8516719e-03 -8.2110833e-05 -2.0463815e-02 -1.2017055e-01\n",
      "  5.0104801e-02  2.6830740e-02  4.1196860e-02  3.1072959e-02\n",
      " -1.4643036e-02 -1.2379345e-01]...\n",
      "Sentence: To use the model, we need to convert the 28 × 28 array of each\n",
      "input image to a vector of length 28*28=784 using the method reshape on the\n",
      "NumPy array so that the neural network can accept it\n",
      "Embedding: [ 0.02077384 -0.07399732  0.02774553 -0.01859075 -0.0170383   0.01565458\n",
      " -0.04922183  0.03858006 -0.05897978 -0.03330173]...\n",
      "Sentence: The particular type of neural\n",
      "network we are using for the example requires this input format, so we need to do\n",
      "the conversion\n",
      "Embedding: [ 0.0032002  -0.04059782 -0.04675097 -0.02211612 -0.01919521  0.06166993\n",
      " -0.08703369  0.01492631 -0.0152341  -0.06295837]...\n",
      "Sentence: The input layer differs for different networks, so there is no one\n",
      "ﬁxed format, but they all required numerical inputs.\n",
      "The code for the project is shown below:\n",
      "import numpy as np\n",
      "import keras\n",
      "import tensorflow as tf\n",
      "import matplotlib.pyplot as plt\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "from keras.optimizers import Adam\n",
      "from google.colab import files\n",
      "92\n",
      "5\n",
      "The Training Process\n",
      "# load mnist dataset\n",
      "# 60,000 images for xTrain, 10,000 for xTest\n",
      "mnist = tf.keras.datasets.mnist\n",
      "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
      "xTrainFlattened = xTrain.reshape(len(xTrain),784)\n",
      "xTestFlattened = xTest.reshape(len(xTest),784)\n",
      "#create the neural network as before\n",
      "model = Sequential()\n",
      "model.add(Dense(784, activation=’relu’,\n",
      "input_shape = (784,)))\n",
      "model.add(Dense(784, activation=’relu’))\n",
      "model.add(Dense(10,activation=’softmax’))\n",
      "model.compile(optimizer=Adam(),\n",
      "loss=’sparse_categorical_crossentropy’,\n",
      "metrics=[’accuracy’])\n",
      "model.fit(xTrainFlattened, yTrain, epochs=5)\n",
      "# test the accuracy using the xTest\n",
      "model.evaluate(xTestFlattened,yTest)\n",
      "313/313 [==============================] -\n",
      "1s 4ms/step - loss: 0.1969 - accuracy: 0.9597\n",
      "[0.19687649607658386, 0.9596999883651733]\n",
      "As we can see, the model setup is very similar to the previous example, although two\n",
      "differences are worth noting that the model uses “sparse_categorical_crossentropy”\n",
      "as the loss function and “softmax” for the activation of the output layer.\n",
      "Do not worry about these parameters or what they mean for the time being\n",
      "Embedding: [ 0.00406522 -0.13092116  0.02598576 -0.06717186  0.00052013  0.02389167\n",
      " -0.06006262  0.02249497 -0.05973336 -0.11270276]...\n",
      "Sentence: We\n",
      "will discuss these topics in the next few sections\n",
      "Embedding: [-0.05286596 -0.00423743 -0.02206793  0.00128833  0.04753823  0.03674899\n",
      "  0.03536209  0.01642592 -0.05372092 -0.0200856 ]...\n",
      "Sentence: The point to note here is how the\n",
      "same type of neural network could be used for two seemingly unrelated applications.\n",
      "Using just a few lines of code, we have managed to identify handwritten digits with\n",
      "96% accuracy.\n",
      "If we (correctly) feel that the whole machine learning process is relatively simple\n",
      "up to now, it is only because the complexity of machine learning has been wrapped\n",
      "up in the Keras library\n",
      "Embedding: [-0.09070547 -0.09748177  0.04608225 -0.02118512  0.04360244 -0.00366801\n",
      " -0.09250191 -0.02319975 -0.01356427 -0.09873858]...\n",
      "Sentence: This is an important point; in practice, if we are only\n",
      "interested in using machine learning in applications, then we only need to master\n",
      "a few important things:\n",
      "•\n",
      "Understand the whole process and the tools from beginning to end.\n",
      "•\n",
      "Learn to preprocess the input data to feed the models effectively.\n",
      "•\n",
      "Select and conﬁgure different models.\n",
      "•\n",
      "Know how to evaluate the model to improve its accuracy.\n",
      "However, while Keras simpliﬁes the machine learning process, it is important\n",
      "not to underestimate the complexity of the built-in libraries and to recognize the\n",
      "complex algorithms and computations that operate behind the scenes, making such\n",
      "simplicity possible.\n",
      "5.11\n",
      "RNN Network: Modeling an AutoRegressive Integrated Moving Average...\n",
      "93\n",
      "5.11\n",
      "RNN Network: Modeling an AutoRegressive Integrated\n",
      "Moving Average (ARIMA) Process\n",
      "So far, our discussions have revolved around the simplest type of deep neural net-\n",
      "work known as the feedforward neural network (FNN)\n",
      "Embedding: [-0.1112924  -0.11760677  0.07929835  0.02782352 -0.00701597  0.00959574\n",
      " -0.09345079 -0.01713623  0.01422759 -0.06323052]...\n",
      "Sentence: In this network, information\n",
      "ﬂows only in the forward direction: from the input layer, through various hidden\n",
      "layers, and to the output layer\n",
      "Embedding: [ 0.01035136  0.02150464 -0.04866422 -0.01457615  0.04139319  0.05155783\n",
      "  0.01845807 -0.07566901  0.06668122 -0.03445315]...\n",
      "Sentence: The backpropagation algorithm is used to update the\n",
      "weights of the feedforward network, and it does not involve creating loops or cycles\n",
      "in the physical connections between nodes.\n",
      "Feedforward networks are primarily employed for supervised learning tasks,\n",
      "such as object classiﬁcation or pattern recognition\n",
      "Embedding: [-0.03534607 -0.08168446 -0.05031484  0.01096616  0.00369665  0.02684869\n",
      " -0.0750301  -0.09889387 -0.02147434 -0.05159411]...\n",
      "Sentence: They excel at creating classi-\n",
      "ﬁcation boundaries between different classes of objects, particularly when the data\n",
      "to be learned is not time dependent nor sequential\n",
      "Embedding: [-0.05955927 -0.01855463 -0.04741265  0.00450159 -0.0224604  -0.01810418\n",
      " -0.0981409  -0.03661517  0.06425318 -0.01039127]...\n",
      "Sentence: However, for time series analysis\n",
      "or models that require self-learning, more complex network structures are necessary.\n",
      "In such cases, loops in the network are used to enforce dependencies between the\n",
      "current state and previous states of the network.\n",
      "Recurrent networks are typically used for time series analysis, such as an\n",
      "encoder-decoder network for sequence-to-sequence prediction problems\n",
      "Embedding: [-0.11754507 -0.04450988  0.0121305  -0.01432801 -0.01090111  0.02686738\n",
      " -0.01412446 -0.03028784  0.05302735 -0.06827128]...\n",
      "Sentence: Addition-\n",
      "ally, other networks, like generative and diffusion models, are utilized to generate\n",
      "additional instances similar to the training data\n",
      "Embedding: [-0.05505276 -0.13980964  0.00145678  0.05632972  0.05180189  0.04513106\n",
      " -0.05509459 -0.06270795  0.04302664 -0.07943543]...\n",
      "Sentence: Many renowned applications, such\n",
      "as ChatGPT, DALL-E, and other large language models (LLMs), currently employ\n",
      "variants of generative models with massive training data and computational power,\n",
      "resulting in impressive effects.\n",
      "One of the simplest alternative neural network structures is a recurrent neural\n",
      "network (RNN)\n",
      "Embedding: [-0.07758071 -0.13640602  0.12080834  0.00756665 -0.02456684  0.0756551\n",
      " -0.05710308 -0.00353734  0.08851397 -0.05626978]...\n",
      "Sentence: RNN is widely used to model time series and sequential tasks\n",
      "Embedding: [-0.14517109 -0.12357301  0.01028817  0.01014678 -0.02959547  0.08063624\n",
      " -0.04870921  0.00519408  0.05570957 -0.06082864]...\n",
      "Sentence: A\n",
      "sequential task involves input and output data sequences, such as text streams, stock\n",
      "prices, or video clips, which can be modeled using RNNs.\n",
      "If we look at Figure 5-5, the small diagram on the left shows the recurrent nature\n",
      "of the network\n",
      "Embedding: [-0.0572671  -0.12976909  0.0156051   0.00102872 -0.04162821  0.13048744\n",
      " -0.01052455 -0.01562058  0.1120446  -0.06941439]...\n",
      "Sentence: That is, it is a set of layers, with each input fed by the output of the\n",
      "preceding hidden layer\n",
      "Embedding: [-0.05744473 -0.00102309 -0.0758704   0.04030234  0.03380883  0.06803995\n",
      " -0.00455809 -0.06018271  0.0774098  -0.07962833]...\n",
      "Sentence: The diagram on the right displays the exact structure of the\n",
      "network\n",
      "Embedding: [-0.01251872  0.0169534  -0.00549938 -0.01387028  0.01213323  0.00653184\n",
      " -0.05000642  0.02624667  0.05078629 -0.04712319]...\n",
      "Sentence: {x1, x2, x3 \n",
      "Embedding: [ 0.04066263  0.04765544 -0.01938202 -0.04970254  0.02415946 -0.03628837\n",
      "  0.05198641 -0.06974798  0.00589939 -0.01914423]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: , xt} represents the sequence of input values which feed into\n",
      "Figure 5-5 Diagram showing a naive RNN network\n",
      "94\n",
      "5\n",
      "The Training Process\n",
      "the hidden neural network layer denoted by A\n",
      "Embedding: [-0.09398998 -0.04652629 -0.0005671  -0.04321744  0.04720651  0.06512323\n",
      "  0.02279084  0.03947166  0.03402486 -0.08534721]...\n",
      "Sentence: The node A represents the memory\n",
      "state at time t such that\n",
      "A(t) = f (w1Xt + w2A(t −1))\n",
      "In simpler terms, the current memory state at time t, denoted as A(t), is a nonlinear\n",
      "function f of the input value at time t, denoted as Xt, and the previous state value\n",
      "at time t −1\n",
      "Embedding: [-0.07101127  0.00877426 -0.08839617  0.07798118 -0.00477029  0.04504241\n",
      "  0.02877607  0.02648245  0.0385764   0.07293981]...\n",
      "Sentence: Each h0, h1, \n",
      "Embedding: [-0.00550039  0.00279378 -0.05524086 -0.04368138 -0.01231336 -0.0066321\n",
      "  0.00132077  0.07111853 -0.07945789 -0.0856339 ]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: , ht represents the output value at each step of the\n",
      "sequence\n",
      "Embedding: [-0.09649948  0.08717952 -0.06100664 -0.04870881  0.00581604  0.01901516\n",
      " -0.03109998  0.07127403  0.06154346 -0.05121854]...\n",
      "Sentence: Notably, ht corresponds to the ﬁnal output of the sequence\n",
      "Embedding: [-0.09091958  0.05726211 -0.04067308 -0.01427181  0.021676    0.04500156\n",
      " -0.02204417  0.05855199  0.06460291 -0.06424735]...\n",
      "Sentence: Structurally,\n",
      "node A can contain one or multiple layers, but for ease of implementation, all nodes\n",
      "A typically share the same activation function and hyperparameters.\n",
      "So far, we have not deﬁned the speciﬁc structure for node A\n",
      "Embedding: [-0.03360995 -0.05207261 -0.02694052 -0.0073284   0.04226073  0.04080696\n",
      " -0.0166963  -0.07603888  0.05096652 -0.02038524]...\n",
      "Sentence: However, it’s worth\n",
      "mentioning that RNN networks often encounter the vanishing gradient problem\n",
      "in practice\n",
      "Embedding: [-0.08714749 -0.13266502  0.03342681  0.02544255  0.00468624  0.06717471\n",
      " -0.06766338 -0.00643688 -0.00064432 -0.07517445]...\n",
      "Sentence: To mitigate this issue, a type of RNN called long short-term memory\n",
      "(LSTM) is commonly used.\n",
      "The structure of an RNN (recurrent neural network) enables it to effectively\n",
      "model both linear and nonlinear relationships\n",
      "Embedding: [-0.03927377 -0.07964244  0.02590962  0.06073254 -0.05969477  0.06040844\n",
      " -0.09075529 -0.03742008  0.03611021 -0.07059835]...\n",
      "Sentence: One signiﬁcant advantage of using\n",
      "an RNN model is its capability to handle different time series without the need to\n",
      "select alternative (linear and nonlinear) models\n",
      "Embedding: [-0.13823487 -0.1078206   0.03028057  0.03139877  0.0299168   0.08841634\n",
      " -0.11966687  0.03272504  0.09812712 -0.05468077]...\n",
      "Sentence: Moreover, an RNN model possesses\n",
      "memory, making it particularly suitable for modeling autoregressive (AR) models,\n",
      "where the value of the output Yt at time t depends on previous q values.\n",
      "To illustrate the effectiveness of RNNs in time series analysis, we will compare\n",
      "its forecasting performance against the ARIMA(p, d, q) model using 20 years of\n",
      "the Standard & Poor’s 500 closing prices.\n",
      "To begin with, let us model the time series using an ARIMA(p, d, q) model.\n",
      "This model has three parameters:\n",
      "Yt =\n",
      "p\n",
      "\u0002\n",
      "i=1\n",
      "ωt−iYt−i +\n",
      "q\n",
      "\u0002\n",
      "j=1\n",
      "θt−jϵt−j\n",
      "In this equation, Yt is the predicted value at time t\n",
      "Embedding: [-0.0960439  -0.0633121   0.01028586  0.11972933 -0.03542455  0.10155553\n",
      " -0.01922058  0.07080093  0.08696721 -0.04752933]...\n",
      "Sentence: The model combines three\n",
      "key components:\n",
      "•\n",
      "Autoregressive (AR) terms represented by \u0003p\n",
      "i=1 ωt−iYt−i, where p is the\n",
      "number of lag observations included in the model; ωt−i are the coefﬁcients for\n",
      "the lags of the series at times t −1, t −2, \n",
      "Embedding: [-0.08590864 -0.07065598  0.01259344  0.10314544  0.00128716  0.03132902\n",
      " -0.05265027  0.0068416   0.08815499 -0.04291276]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: , t −p; and Yt−i are the lagged\n",
      "values of the series.\n",
      "•\n",
      "Differencing order d, which is the number of times the data have had past values\n",
      "subtracted (not explicitly shown in the equation).\n",
      "•\n",
      "Moving average (MA) terms represented by \u0003q\n",
      "j=1 θt−jϵt−j, where q is the size\n",
      "of the moving average window, θt−j are the coefﬁcients for the lagged forecast\n",
      "errors in the prediction equation, and ϵt−j are the lagged forecast errors at times\n",
      "t −1, t −2, \n",
      "Embedding: [-0.09143819 -0.00660188  0.09563793  0.0546723   0.03315774  0.02313505\n",
      " -0.00874295  0.03101635  0.07636428 -0.01199718]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: , t −q.\n",
      "5.11\n",
      "RNN Network: Modeling an AutoRegressive Integrated Moving Average...\n",
      "95\n",
      "The ARIMA model thus captures the dynamics of a time series through a combi-\n",
      "nation of these autoregressive and moving average terms, adjusted by the level of\n",
      "differencing to ensure stationarity.\n",
      "We can use statistical tests, such as the Augmented Dickey-Fuller (ADF) and\n",
      "Canova-Hansen (CH), or (partial) autocorrelation tests (PACE and ACE) to choose\n",
      "the parameters’ values.\n",
      "Stock prices are usually nonstationary, so differencing using the d parameter\n",
      "is often necessary to stationary\n",
      "Embedding: [-0.07950357 -0.05401912  0.03989433  0.05607614 -0.01755466 -0.01471186\n",
      " -0.02036795 -0.0348828   0.05574311 -0.0554795 ]...\n",
      "Sentence: In practice, this condition is hard to achieve, and\n",
      "ﬁnding the right values for p, d, and q often requires experimentation.\n",
      "We will use 90% of the dataset for training and 20% for forecasting.\n",
      "Let’s implement the ARIMA model using Python’s statsmodels library:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from statsmodels.tsa.arima.model import ARIMA\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
      "data = pd.read_csv(’sp500_data.csv’,\n",
      "index_col=’Date’,parse_dates=True)\n",
      "ts_data = data[’Close’]\n",
      "train_size = int(len(ts_data) * 0.8)\n",
      "train, test = ts_data[:train_size], ts_data[train_size:]\n",
      "# Plot ACF and PACF\n",
      "plot_acf(ts_data, lags=20)\n",
      "plot_pacf(ts_data, lags=20)\n",
      "plt.show()\n",
      "P = 1\n",
      "d = 1\n",
      "q = 1\n",
      "model = ARIMA(train, order=(p,d,q))\n",
      "model_fit = model.fit()\n",
      "Now, let’s model the same time series using an RNN for comparison\n",
      "Embedding: [-0.01418859  0.01891734  0.0411873   0.08513228  0.00500191  0.02583529\n",
      " -0.04105316  0.06413379  0.02001759 -0.01530597]...\n",
      "Sentence: Instead of\n",
      "using ARIMA, we can use RNN to do the same task:\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "from tensorflow.keras.models import Sequential\n",
      "from tensorflow.keras.layers import Dense, LSTM\n",
      "import matplotlib.pyplot as plt\n",
      "data = pd.read_csv(’sp500_data.csv’)\n",
      "prices = data[’Close’].values.reshape(-1, 1)\n",
      "# Scale the data to values between 0 and 1\n",
      "scaler = MinMaxScaler(feature_range=(0, 1))\n",
      "scaled_prices = scaler.fit_transform(prices)\n",
      "96\n",
      "5\n",
      "The Training Process\n",
      "# Define the number of time steps for the RNN\n",
      "time_steps = 30\n",
      "# Create sequences for the RNN\n",
      "X, y = [], []\n",
      "for i in range(len(scaled_prices) - time_steps):\n",
      "X.append(scaled_prices[i : i + time_steps])\n",
      "y.append(scaled_prices[i + time_steps])\n",
      "X, y = np.array(X), np.array(y)\n",
      "# Split the data into training and testing sets\n",
      "train_size = int(0.8 * len(X))\n",
      "X_train, X_test = X[:train_size], X[train_size:]\n",
      "y_train, y_test = y[:train_size], y[train_size:]\n",
      "model = Sequential()\n",
      "model.add(LSTM(50, return_sequences=True,\n",
      "input_shape=(X_train.shape[1], 1)))\n",
      "model.add(LSTM(50))\n",
      "model.add(Dense(1))\n",
      "model.compile(optimizer=’adam’,\n",
      "loss=’mean_squared_error’)\n",
      "model.fit(X_train, y_train, epochs=50, batch_size=32,\n",
      "verbose=1)\n",
      "# Predict using the test data\n",
      "predicted_prices = model.predict(X_test)\n",
      "predicted_prices = scaler.\n",
      "inverse_transform(predicted_prices)\n",
      "# Transform the original test data back\n",
      "# to the original scale\n",
      "y_test = scaler.inverse_transform(y_test)\n",
      "# Calculate Mean Squared Error (MSE)\n",
      "mse = np.mean((predicted_prices - y_test) ** 2)\n",
      "print(\"Mean Squared Error:\", mse)\n",
      "# Plot the predictions against the actual values\n",
      "plt.figure(figsize=(12, 6))\n",
      "plt.plot(y_test, label=\"Actual Prices\", color=\"blue\")\n",
      "plt.plot(predicted_prices, label=\"Predicted Prices\",\n",
      "color=\"red\")\n",
      "plt.xlabel(\"Time\")\n",
      "plt.ylabel(\"S&P 500 Index Price\")\n",
      "plt.title(\"S&P 500 Index Prediction using RNN\")\n",
      "plt.legend()\n",
      "plt.show()\n",
      "5.12\n",
      "LSTM Network: BachBot\n",
      "97\n",
      "5.12\n",
      "LSTM Network: BachBot\n",
      "BachBot is a research application written by Feynman Liang [4] at Cambridge\n",
      "University, UK, to compose classical musical chorales in the style of composer\n",
      "J.S\n",
      "Embedding: [ 0.01203507 -0.04934491  0.0274902   0.012993    0.00027443 -0.00086173\n",
      " -0.0394535  -0.00624562 -0.03041407 -0.12401995]...\n",
      "Sentence: Bach using an LSTM network\n",
      "Embedding: [ 0.01826017 -0.10098042  0.00269085  0.00313639 -0.04610166  0.16016708\n",
      " -0.07010025  0.02448061 -0.06300429 -0.10570432]...\n",
      "Sentence: The code presented here is the basic version\n",
      "of the model inline with Feynman’s published paper and his thesis\n",
      "Embedding: [-0.15677509 -0.0259582  -0.00603006  0.02833128  0.03030609  0.01863964\n",
      " -0.06317942  0.03967997 -0.07164425  0.01660761]...\n",
      "Sentence: The original\n",
      "implementation was written in PyTorch and Lua and is a more sophisticated imple-\n",
      "mentation with more functionalities, including harmonization\n",
      "Embedding: [-0.14956574 -0.00597331 -0.04113698 -0.09319596 -0.01487775 -0.05555193\n",
      " -0.08125279  0.08104643 -0.02072304  0.0027694 ]...\n",
      "Sentence: The implementation\n",
      "in this book is not a straight conversion of the code but written from scratch using\n",
      "Keras\n",
      "Embedding: [-0.12608717  0.01443284 -0.02688253 -0.04005936 -0.05472597 -0.03907201\n",
      " -0.08021877 -0.02905086 -0.10844829 -0.02212708]...\n",
      "Sentence: I am grateful to Feynman for useful discussions and for allowing me to use\n",
      "some of his MusicXML utility code.\n",
      "5.12.1 Background\n",
      "Johann Sebastian Bach’s music is often described as mathematical due to its\n",
      "structure, precision, and the way it adheres to speciﬁc musical forms and rules.\n",
      "Bach, a master of counterpoint, skillfully interwove multiple independent melodies\n",
      "that harmonized with each other\n",
      "Embedding: [-0.06390707 -0.10379831  0.00421241 -0.07649685 -0.07964785  0.08310368\n",
      " -0.01377599  0.01842207 -0.05090168 -0.01277292]...\n",
      "Sentence: This technique, especially evident in his fugues,\n",
      "requires meticulous planning and a deep understanding of harmonic and melodic\n",
      "structures\n",
      "Embedding: [ 0.04012966  0.05551698 -0.00425318 -0.0823938  -0.10385498  0.01542371\n",
      " -0.01781349 -0.02657989 -0.01593453  0.01218239]...\n",
      "Sentence: The mathematical aspect lies in how these independent melodies ﬁt\n",
      "together in a precise, logical way, often following strict rules.\n",
      "J.S\n",
      "Embedding: [ 0.0276249  -0.05585197  0.01639414 -0.03948957 -0.03821919  0.06659735\n",
      "  0.02268566 -0.07057177  0.06502536 -0.03827367]...\n",
      "Sentence: Bach’s 400+ chorales are hymn tunes written to be sung by a congregation\n",
      "in a German Protestant church service\n",
      "Embedding: [ 0.00750891  0.00346175 -0.04125547 -0.04244431 -0.06190201  0.1254968\n",
      " -0.07982431  0.03781932  0.0697424  -0.0766542 ]...\n",
      "Sentence: In Bach’s time, these hymns were often\n",
      "harmonized for four voices (soprano, alto, tenor, and bass) for performance by a\n",
      "choir or used as the basis for more complex compositions\n",
      "Embedding: [ 0.0313264   0.00886723 -0.00061795 -0.09145784 -0.05415728  0.11863012\n",
      " -0.08983453  0.01060788  0.09098291 -0.07894392]...\n",
      "Sentence: The text of chorales is\n",
      "usually in German and reﬂects Lutheran religious themes, often based on biblical\n",
      "scriptures or liturgical texts.\n",
      "Bach’s chorales are known for their rich harmonic texture and complex coun-\n",
      "terpoint\n",
      "Embedding: [ 0.00709976  0.01458223 -0.01484987 -0.05060965 -0.07001866  0.16699101\n",
      " -0.02671016  0.01757568  0.12612347 -0.01370955]...\n",
      "Sentence: Each voice part is melodically interesting and contributes to the overall\n",
      "harmonic structure\n",
      "Embedding: [-0.05605422 -0.03521426  0.04825112 -0.0695262  -0.0521289   0.07291753\n",
      "  0.01077472 -0.07846259  0.06658237 -0.06627034]...\n",
      "Sentence: An example of his chorales is shown below\n",
      "Embedding: [-0.00920358  0.02975482 -0.04719102 -0.04646906 -0.10935582  0.11026482\n",
      "  0.08301204 -0.02999839  0.0250157  -0.04532301]...\n",
      "Sentence: Note that the four\n",
      "staffs are notes for the four voices: soprano (top), alto, tenor, and bass (bottom).\n",
      "Additionally, each chorale contains a series of phrases which Bach delimited using\n",
      "fermatas\n",
      "Embedding: [ 0.04127093 -0.02383267 -0.0234105  -0.02159435 -0.091648    0.11153277\n",
      " -0.00073254 -0.00039739  0.03851409 -0.05811684]...\n",
      "Sentence: Choosing an LSTM (long short-term memory) network for a project like\n",
      "BachBot, which is focused on generating music in the style of Johann Sebastian\n",
      "Bach, makes sense due to several key characteristics of LSTM networks that\n",
      "are particularly well suited for handling music and sequential data in general.\n",
      "Speciﬁcally\n",
      "•\n",
      "Handling of Sequential Data: Music is inherently sequential, with each note or\n",
      "chord depending on what came before\n",
      "Embedding: [ 0.00941033 -0.10492042  0.00638993  0.00081601 -0.03820858  0.1824709\n",
      " -0.09065181  0.01186549 -0.01725656 -0.07732204]...\n",
      "Sentence: LSTM networks excel at processing and\n",
      "generating sequential data because they can maintain information in “memory”\n",
      "over long sequences, which is crucial for capturing the structure and progression\n",
      "in music.\n",
      "98\n",
      "5\n",
      "The Training Process\n",
      "Figure 5-6 J.S\n",
      "Embedding: [ 0.02191559 -0.07553411  0.03518515 -0.01434727  0.02357456  0.15597263\n",
      " -0.08778939 -0.03179366 -0.01290267 -0.08887283]...\n",
      "Sentence: Bach—BWV 649—Ach bleib bei uns, Herr Jesu Christ\n",
      "Embedding: [-0.04095981  0.07011458  0.00192282 -0.03219845 -0.03078888  0.11419917\n",
      " -0.00200161  0.00875088 -0.02649387 -0.07136527]...\n",
      "Sentence: Notice phrasing using\n",
      "fematas [4]\n",
      "•\n",
      "Long-Term Dependencies: Bach’s compositions often contain long-term depen-\n",
      "dencies, where themes or motifs are developed and revisited over time\n",
      "Embedding: [-0.00905275 -0.04667095  0.08102705  0.03810003 -0.02131895  0.11115387\n",
      " -0.04314023 -0.08009226 -0.00900911 -0.06241817]...\n",
      "Sentence: LSTMs\n",
      "are speciﬁcally designed to capture such long-term dependencies in sequences,\n",
      "unlike traditional neural networks which struggle with long-range data depen-\n",
      "dencies.\n",
      "•\n",
      "Learning Patterns in Time: LSTMs can learn patterns in time-series data\n",
      "Embedding: [-0.05569731 -0.10408098  0.08707099  0.01407467  0.06085143  0.07520454\n",
      " -0.05631124 -0.06449567  0.00104424 -0.04949057]...\n",
      "Sentence: Bach’s\n",
      "music, with its complex rhythms, harmonies, and counterpoints, presents a rich\n",
      "temporal structure that LSTMs can learn and model.\n",
      "•\n",
      "Variability in Sequence Length: Musical pieces can vary signiﬁcantly in length,\n",
      "and LSTMs can handle this variability effectively\n",
      "Embedding: [ 0.06435058 -0.11161324  0.05304814 -0.02298092 -0.03065385  0.15854318\n",
      " -0.06766639 -0.03262006  0.0405764  -0.08052459]...\n",
      "Sentence: They can be trained on\n",
      "sequences of varying lengths and generate sequences that are not ﬁxed in size.\n",
      "•\n",
      "Flexibility in Modeling Different Elements: LSTMs can be used to model various\n",
      "aspects of music, such as melody, harmony, rhythm, and dynamics, by learning\n",
      "from a diverse range of musical features encoded in the input data.\n",
      "5.12.2 Preprocessing\n",
      "Once the network topology is chosen, Feynman encodes Bach’s music for digiti-\n",
      "zation in a very particular format\n",
      "Embedding: [-0.02781077 -0.13203636  0.00888946 -0.04299229 -0.01851909  0.12361317\n",
      " -0.0743236  -0.0545996  -0.01877574 -0.07876646]...\n",
      "Sentence: Firstly, all chorales are transposed to the key\n",
      "C-major for major scores and A-minor for minor ones\n",
      "Embedding: [ 4.65434082e-02 -3.09319654e-03 -1.74137973e-03 -1.01423636e-01\n",
      " -9.31136832e-02  1.44891798e-01 -8.69129151e-02  6.92916801e-05\n",
      "  2.53619272e-02  4.29866128e-02]...\n",
      "Sentence: The C-major or A-minor\n",
      "5.12\n",
      "LSTM Network: BachBot\n",
      "99\n",
      "Figure 5-7 Sample of a J.S\n",
      "Embedding: [ 0.00567567 -0.11735085  0.05560497  0.00470376 -0.00302181  0.11835672\n",
      " -0.08439231  0.07158025 -0.08361449 -0.04402049]...\n",
      "Sentence: Bach chorale [4]\n",
      "key is chosen to make the encoding process easier by removing all the sharps and\n",
      "ﬂats in the original key signature.\n",
      "Time quantization is also performed\n",
      "Embedding: [ 0.03034361  0.03174696 -0.0216266  -0.07747091 -0.07929672  0.11164869\n",
      " -0.03265278 -0.0295701   0.04929173 -0.05080545]...\n",
      "Sentence: Each note duration is transformed into\n",
      "a multiple of a semibreve duration, neglecting changes in timing (e.g., ritardan-\n",
      "dos), dynamics (e.g., crescendos), and additional notation (e.g., accents, staccatos,\n",
      "legatos)\n",
      "Embedding: [ 0.01570409  0.00670034  0.00956447 -0.05349457 -0.09207972  0.0729823\n",
      " -0.06782207  0.00103826  0.11278669 -0.055781  ]...\n",
      "Sentence: The pitch of each note is represented in MIDI speciﬁcation from 0 to 127\n",
      "representing ten octaves\n",
      "Embedding: [ 0.00530963  0.03540684 -0.06528988 -0.1501161  -0.10397066  0.0590506\n",
      " -0.08097603  0.04029259  0.06980676 -0.03849635]...\n",
      "Sentence: Although articulation marks are removed, the fermata,\n",
      "denoted by the symbol (.), is retained to help the model learn phrasing.\n",
      "Finally, akin to bar lines in standard music notation, a frame delimiter\n",
      "(|||)\n",
      "is used to segment the music into timing measures.\n",
      "The end result of the preprocessing stage is a series of tokens shown in\n",
      "Figure 5-8\n",
      "Embedding: [ 0.00566758  0.02476651 -0.03592786 -0.0521212  -0.01118107  0.07255841\n",
      "  0.0468455  -0.00433411  0.07470039 -0.09813847]...\n",
      "Sentence: A (true) boolean value in the token denotes a tied note.\n",
      "The generation of a corpus of token ﬁles for the 400+ Bach chorales is where we\n",
      "start\n",
      "Embedding: [ 0.01035596 -0.00496382 -0.0200584   0.00227204 -0.0555844   0.13640398\n",
      "  0.06521873 -0.01290498  0.05229661  0.00290795]...\n",
      "Sentence: Although this process only needs to be performed once, it completes quickly.\n",
      "Therefore, the code is kept in the program to run each time, avoiding additional\n",
      "logic that could clutter the main program.\n",
      "100\n",
      "5\n",
      "The Training Process\n",
      "Figure 5-8 An example of\n",
      "the tokenized ﬁle for the J.S.\n",
      "Bach score BWV 133.6\n",
      "5.12.3 Model Implementation and Training\n",
      "The Keras model for BachBot is shown below\n",
      "Embedding: [-0.07506528 -0.03495565 -0.01701036 -0.01184622 -0.02314265  0.09861109\n",
      " -0.07240122  0.02899613 -0.02865988 -0.08324127]...\n",
      "Sentence: Feynman’s thesis detailed the\n",
      "hyperparameters for PyTorch\n",
      "Embedding: [-0.12069957 -0.05272333 -0.01394184 -0.01508663 -0.00194866  0.0020864\n",
      " -0.0195375  -0.00120895 -0.05578038 -0.02926132]...\n",
      "Sentence: Fortunately, the corresponding Keras parameters are\n",
      "compatible, which makes the implementation much easier\n",
      "Embedding: [-0.09384152 -0.07520338  0.02464453 -0.05131725 -0.03506501  0.00401547\n",
      " -0.12622197 -0.04146045 -0.09832069 -0.0760759 ]...\n",
      "Sentence: One particular aspect of\n",
      "the training process that is nonstandard is the use of teacher forcing for the RNN\n",
      "network.\n",
      "5.12.4 Teacher Forcing\n",
      "Teacher forcing is a training methodology where, instead of using the model’s\n",
      "own predictions as inputs during training, the model is provided with the actual\n",
      "or expected output from the previous time step\n",
      "Embedding: [-0.10013324 -0.06885324  0.00693659  0.05468573  0.03748789  0.03879716\n",
      " -0.09764149 -0.03167671 -0.00329553 -0.02031918]...\n",
      "Sentence: In other words, during training, the\n",
      "network is “forced” to consider the correct output (as provided by the teacher, which\n",
      "in this case is the training data) at each step, instead of its own predictions.\n",
      "In standard RNN training without teacher forcing, the predicted output from the\n",
      "previous time step is fed back into the network as input for the next time step\n",
      "Embedding: [-0.0772939  -0.0523231   0.03593449  0.08175519  0.025261    0.02669879\n",
      " -0.08179091 -0.06153504  0.04403926 -0.05407447]...\n",
      "Sentence: Instead\n",
      "5.12\n",
      "LSTM Network: BachBot\n",
      "101\n",
      "of using the RNN’s own predictions from the previous step, teacher forcing uses the\n",
      "actual previous output from the training dataset.\n",
      "The advantages of teacher forcing include faster convergence and stability during\n",
      "training\n",
      "Embedding: [-0.08652978 -0.07473844  0.09154826  0.06099854  0.08002847  0.08525314\n",
      " -0.12397499 -0.01459389 -0.03877412 -0.0164886 ]...\n",
      "Sentence: However, a major drawback of teacher forcing is the discrepancy between\n",
      "training and inference\n",
      "Embedding: [-0.01689841 -0.02127888  0.02713905  0.06552914  0.03995072  0.09183202\n",
      " -0.09862374 -0.03383578  0.00421398  0.0574297 ]...\n",
      "Sentence: During training, the model always sees the correct previous\n",
      "output, but at inference, it must generate sequences based on its own predictions.\n",
      "This difference can lead to issues such as exposure bias, where the model may not\n",
      "perform well during inference.\n",
      "def teacher_forcing_encode(corpus, files, time_steps):\n",
      "# Tokenize the corpus\n",
      "corpus_tokens = corpus.split(’@’)\n",
      "tokenizer = Tokenizer(filters=’’, split=’@’,\n",
      "lower=False)\n",
      "tokenizer.fit_on_texts(corpus_tokens)\n",
      "# Convert tokens to numeric values\n",
      "sequences = tokenizer.texts_to_sequences(corpus_tokens)\n",
      "d_tokens = np.array([item for sublist in sequences\n",
      "for item in sublist])\n",
      "# Unique tokens and vocabulary size\n",
      "unique_tokens = tokenizer.word_index\n",
      "vocabulary_size = len(unique_tokens)\n",
      "# Prepare X and Y\n",
      "num_files = len(files)\n",
      "X = []\n",
      "Y = []\n",
      "# Find start and end indices for each file\n",
      "start_indices = [i for i, x in enumerate(corpus_tokens)\n",
      "if x == ’START’]\n",
      "end_indices = [i for i, x in enumerate(corpus_tokens)\n",
      "if x == ’END’]\n",
      "end_token = 0\n",
      "for i in range(num_files):\n",
      "file_seq = d_tokens[start_indices[i]:end_indices[i]]\n",
      "X.append(np.array(file_seq[:-1]))\n",
      "Y.append(np.array(file_seq[1:]))\n",
      "x_chunks_list = [split_and_pad_sequence(seq,\n",
      "time_steps,end_token) for seq in X]\n",
      "X = [chunk for sublist in x_chunks_list for chunk\n",
      "in sublist]\n",
      "X = np.array(X)\n",
      "y_chunks_list = [split_and_pad_sequence(seq,\n",
      "time_steps, end_token) for seq in Y]\n",
      "Y = [chunk for sublist in y_chunks_list for chunk\n",
      "in sublist]\n",
      "Y = np.array(Y)\n",
      "# Convert labels to one-hot encoding\n",
      "102\n",
      "5\n",
      "The Training Process\n",
      "Y_train_one_hot = to_categorical(Y,\n",
      "num_classes=vocab_size+1)\n",
      "return X, Y_train_one_hot, tokenizer, corpus_tokens\n",
      "The code above does set up the conditions for implementing teacher forcing during\n",
      "the training of the LSTM model, although the actual implementation of teacher\n",
      "forcing happens within the model’s training process itself.\n",
      "The function teacher_forcing_encode prepares the training data (X_train and\n",
      "Y_train) in a format suitable for teacher forcing\n",
      "Embedding: [-0.03513205 -0.07726216  0.03750912  0.02885844  0.06921432 -0.00611642\n",
      " -0.02456171 -0.00658792 -0.04579892  0.00505022]...\n",
      "Sentence: In this setup, for each sequence\n",
      "in X_train, the corresponding sequence in Y_train is the same sequence but shifted\n",
      "by one time step, providing the “next token” as the target for each input sequence.\n",
      "The model is trained using X_train and Y_train\n",
      "Embedding: [-0.1106493  -0.07590076  0.05791335 -0.0243051   0.04746579  0.05668377\n",
      " -0.0260533  -0.01042544  0.04879533 -0.11807691]...\n",
      "Sentence: During training, the LSTM\n",
      "model receives a sequence from X_train and learns to predict the next token in the\n",
      "sequence\n",
      "Embedding: [-0.073456   -0.07563888  0.0493734   0.03111881  0.10003487  0.08346698\n",
      " -0.00607879  0.00154359  0.02152562 -0.066858  ]...\n",
      "Sentence: The correct next token is always the corresponding element in Y_train.\n",
      "This means the model is trained with the actual next token from the training data as\n",
      "the target for each time step, which is the essence of teacher forcing.\n",
      "The create_bachbot_lstm_model function constructs the LSTM model using the\n",
      "speciﬁed parameters\n",
      "Embedding: [-0.03236358 -0.0980055   0.02051796  0.02878127  0.01932939  0.1051956\n",
      " -0.08247928  0.03384187 -0.04352445 -0.01812848]...\n",
      "Sentence: When this model is trained with the X_train and Y_train data,\n",
      "it implicitly uses teacher forcing because of how the training data is structured.\n",
      "I found that the implementation works well when producing music when the\n",
      "initial feed from Bach’s choral works but not so when asked to produce long\n",
      "passages of music\n",
      "Embedding: [-0.00835924 -0.05376361  0.07233221 -0.01151351 -0.01810537  0.12219259\n",
      " -0.1256038  -0.05535343 -0.0375527  -0.0247822 ]...\n",
      "Sentence: Scheduled sampling is a recent alternative training method for\n",
      "resolving this discrepancy, but it is a matter of experimentation and is beyond the\n",
      "scope of the project.\n",
      "5.12.5 BachBot Model\n",
      "The model used by BachBot is a fairly standard LSTM model to generate music\n",
      "sequences.\n",
      "def create_bachbot_lstm_model(num_layers, rnn_size,\n",
      "embedding_dim, seq_length, dropout_rate,\n",
      "vocab_size):\n",
      "model = Sequential()\n",
      "model.add(Embedding(input_dim=vocab_size,\n",
      "output_dim=embedding_dim, input_length=seq_length))\n",
      "model.add(BatchNormalization())\n",
      "model.add(Dropout(dropout_rate))\n",
      "for _ in range(num_layers):\n",
      "model.add(LSTM(rnn_size, return_sequences=True))\n",
      "model.add(BatchNormalization())\n",
      "model.add(Dropout(dropout_rate))\n",
      "model.add(TimeDistributed(Dense(vocab_size+1,\n",
      "activation=’softmax’)))\n",
      "5.12\n",
      "LSTM Network: BachBot\n",
      "103\n",
      "using these following constants as parameters as speciﬁed in the research paper:\n",
      "num_layers = 3, rnn_size = 256, embedding_dim = 32, seq_length = 128,\n",
      "and dropout_rate = 0.3.\n",
      "Essentially, this is a sequential RNN model with 128 time steps\n",
      "Embedding: [-0.03175607 -0.12934737 -0.00293287  0.03445973 -0.0308188   0.1198341\n",
      " -0.08179239 -0.00225413 -0.05175137 -0.14102985]...\n",
      "Sentence: The rnn_size,\n",
      "sets to 256, deﬁnes the number of units in each LSTM layer, which is three in this\n",
      "case\n",
      "Embedding: [ 0.03313103 -0.09653383 -0.04975668 -0.01486665 -0.00586127  0.08085231\n",
      " -0.05890875  0.00796653 -0.00832002 -0.07702533]...\n",
      "Sentence: Before the input data enters the LSTM network, it is embedded to a lower\n",
      "dimension of 32\n",
      "Embedding: [ 0.10611314 -0.04426844 -0.01478265  0.01257588 -0.0040814   0.03744968\n",
      " -0.12133949  0.04314849 -0.02008344 -0.04637755]...\n",
      "Sentence: Although embedding is used to reﬂect the conﬁguration of the\n",
      "paper, in practice it does not affect the result signiﬁcantly and can be removed to\n",
      "improve the speed if needed.\n",
      "When we set return_sequences=True for an LSTM layer in a neural network, it\n",
      "means that the layer will return the full sequence of outputs for each time step in the\n",
      "input sequence\n",
      "Embedding: [-0.11451925 -0.0631813   0.02576901  0.04609519  0.03637699  0.12370102\n",
      " -0.07771488 -0.03817177  0.0179083  -0.10674238]...\n",
      "Sentence: This is in contrast to the default setting (return_sequences=False),\n",
      "where the LSTM layer only returns the output of the last time step.\n",
      "With return_sequences=True, the LSTM layer produces an output for each\n",
      "time step in the input data, preserving the temporal sequence information\n",
      "Embedding: [-0.0509223  -0.04679886  0.0367669   0.00800649  0.03982146  0.10770284\n",
      " -0.06464    -0.03912722  0.06909962 -0.09634334]...\n",
      "Sentence: This is\n",
      "essential when subsequent layers in the model also expect time series data, such as\n",
      "in sequence-to-sequence models, or when we are stacking multiple LSTM layers in\n",
      "this case.\n",
      "The TimeDistributed layer is used in combination with a dense layer\n",
      "Embedding: [-0.05805953 -0.05806502  0.06172049  0.02199528  0.03837562  0.0681212\n",
      " -0.08028153  0.00161174  0.08383013 -0.10821915]...\n",
      "Sentence: This setup\n",
      "is used so that after processing the sequence data through LSTM layers, we want\n",
      "to make a decision for each note at each time step of the sequence, rather than\n",
      "collapsing the entire sequence into a single output at the end.\n",
      "The dense layer with a softmax activation is applied to each time step output\n",
      "of the preceding LSTM layer\n",
      "Embedding: [-0.10580547 -0.05996137  0.05670394 -0.01711123  0.02818807  0.09634482\n",
      " -0.05044188 -0.00230331  0.02014022 -0.08778586]...\n",
      "Sentence: This setup allows the model to make predictions of\n",
      "the next musical note at each step in the sequence\n",
      "Embedding: [-0.10203692 -0.06313627  0.00024925 -0.03597587 -0.03901514  0.1173708\n",
      " -0.09161323 -0.01346666  0.07126232 -0.04714982]...\n",
      "Sentence: After training, the result can be\n",
      "exported to an xml ﬁle format and read and played using a software package, such as\n",
      "MuseScore\n",
      "Embedding: [ 0.01953154 -0.01646044 -0.06357569 -0.0357383  -0.02846756  0.09430533\n",
      " -0.04462067  0.00519498 -0.06097547 -0.01314833]...\n",
      "Sentence: An example of the BachBot’s composition using the program is shown\n",
      "in Figure 5-9.\n",
      "104\n",
      "5\n",
      "The Training Process\n",
      "Figure 5-9 BachBot’s musical composition\n",
      "6\n",
      "Generative Models\n",
      "So far in this book, we have introduced several architectures predominantly to clas-\n",
      "sify objects\n",
      "Embedding: [-0.02396318 -0.07273959  0.02840089 -0.04170882 -0.0712833   0.06439175\n",
      " -0.06390984 -0.01477004 -0.01178421 -0.05494066]...\n",
      "Sentence: These models aim to minimize the differences between the predicted\n",
      "object and the trained ones to make accurate predictions\n",
      "Embedding: [-0.03608849  0.00052897  0.00894434  0.07520883  0.09433974 -0.00251989\n",
      " -0.05570399  0.01756264  0.06220303 -0.0467911 ]...\n",
      "Sentence: Recently, there have been\n",
      "huge interests in machine learning, not to classify objects but to generate new\n",
      "contents based on learned ideas\n",
      "Embedding: [-0.06388125 -0.08024157 -0.01612234  0.01846524  0.07543602 -0.02202086\n",
      " -0.03419691 -0.06890409 -0.02196884  0.01036973]...\n",
      "Sentence: This class of machine is referred to as generative\n",
      "AI.\n",
      "6.1\n",
      "Variational Autoencoders\n",
      "Generative AI refers to a class of artiﬁcial intelligence systems that are capable\n",
      "of generating new content that resembles some input data they were trained on.\n",
      "These systems use machine learning algorithms, particularly deep learning, to learn\n",
      "patterns and structures from existing data and then use that knowledge to create new\n",
      "content.\n",
      "As of 2023, the primary architectures in generative AI include generative adver-\n",
      "sarial networks (GANs), variational autoencoders (VAEs), and diffusive models.\n",
      "The three architectures are very different, and each model is preferred for alternative\n",
      "applications\n",
      "Embedding: [-8.9904048e-02 -1.0107489e-01  1.8556461e-02  1.1985172e-02\n",
      " -2.9841624e-02  1.4740925e-02 -3.2048095e-02 -5.7905994e-02\n",
      " -5.2630890e-05 -3.9453264e-02]...\n",
      "Sentence: The diffusive model class is the newest and is the most complicated,\n",
      "but it requires a very large dataset and is extremely computing intensive and time-\n",
      "consuming to train.\n",
      "The main idea behind VAEs is to sample data from a learned distribution of\n",
      "trained data\n",
      "Embedding: [-0.07054543 -0.0532645   0.07175069 -0.0235026   0.00701423 -0.04564224\n",
      " -0.04227877  0.03738404  0.00507904  0.03700626]...\n",
      "Sentence: A VAE model consists of two parts: an encoder and a decoder\n",
      "Embedding: [-0.05018253 -0.02333079  0.04544545 -0.03054124 -0.02284063  0.01437746\n",
      " -0.04055175 -0.0271264   0.0567776  -0.02658145]...\n",
      "Sentence: The\n",
      "job of the encoder is to encode data into a smaller set of data, often referred to\n",
      "as the latent space, using a feedforward neural network as before\n",
      "Embedding: [-0.05367814 -0.09309544 -0.03134206 -0.00067909  0.01019013  0.03371341\n",
      " -0.08195035 -0.10637929  0.04174805 -0.03325369]...\n",
      "Sentence: However, the\n",
      "encoder output is not an encoded vector but the parameters of a distribution\n",
      "Embedding: [-0.04015853 -0.0413545  -0.07897418 -0.05129168 -0.00485519 -0.00769042\n",
      " -0.06549532 -0.08331047 -0.01236494 -0.05446659]...\n",
      "Sentence: Often,\n",
      "the output parameters are the mean μ and the standard deviation σ that represent a\n",
      "compressed Gaussian distribution of the input data\n",
      "Embedding: [-0.05788466 -0.03041573 -0.0743052   0.0354276  -0.02634246 -0.0097282\n",
      " -0.0177872   0.0238026   0.03265067 -0.021155  ]...\n",
      "Sentence: The latent space can be thought\n",
      "of as encoding the most important features of the data\n",
      "Embedding: [ 0.01663315 -0.05231553 -0.02389893  0.00319628  0.04367378  0.08048952\n",
      "  0.01374497 -0.07212953  0.08998116  0.00729444]...\n",
      "Sentence: To ﬁne-tune our newly\n",
      "© Philip Hua 2024\n",
      "P\n",
      "Embedding: [-0.01142623  0.03187173 -0.01791589 -0.02220494 -0.05905133  0.01211866\n",
      " -0.01672005 -0.06552181 -0.0221609   0.00933059]...\n",
      "Sentence: Hua, Neural Networks with TensorFlow and Keras,\n",
      "https://doi.org/10.1007/979-8-8688-1020-6_6\n",
      "105\n",
      "106\n",
      "6\n",
      "Generative Models\n",
      "generated data, we often need these features to be independent from one another.\n",
      "This sometimes can be done using disentanglement techniques, which are beyond\n",
      "the scope of this book.\n",
      "The decoder part of the network then draws a sample from the latent space and\n",
      "passes through another neural network to get an approximation of a reconstructed\n",
      "version of the data\n",
      "Embedding: [-0.12447058 -0.09081049  0.06575877  0.03015021  0.04440908  0.03433067\n",
      " -0.04438367 -0.15839514  0.01121569 -0.08646502]...\n",
      "Sentence: This allows us to sample from the approximated distribution to\n",
      "generate new data.\n",
      "To aid understanding of a VAE network, think of an example of Identikit\n",
      "Embedding: [-0.11187863  0.00668716  0.0518841  -0.0112813  -0.02886477 -0.06747231\n",
      " -0.01310013  0.03145985  0.05848178  0.00118041]...\n",
      "Sentence: A\n",
      "likeness of a person’s face constructed from descriptions given to police uses a set\n",
      "of transparencies of various facial features that can be combined to build up a picture\n",
      "of the person sought\n",
      "Embedding: [-7.07260370e-02  1.09669134e-01 -1.05327228e-04 -5.35175838e-02\n",
      "  1.70080308e-02  4.68417928e-02  1.70308538e-02 -1.51840178e-02\n",
      " -3.10599040e-02 -2.45008282e-02]...\n",
      "Sentence: The encoder basically generates the set of facial features for\n",
      "the decoder to choose from.\n",
      "More formally, in probabilistic terms, the encoder outputs the parameters set λ\n",
      "for the Gaussian probability density function qλ(z|x), where z is the latent variable\n",
      "for input x\n",
      "Embedding: [-0.05681945 -0.06344627 -0.03448101 -0.05607468  0.0197406   0.03477919\n",
      "  0.01136346 -0.09891483  0.00915442  0.01130349]...\n",
      "Sentence: The decoder takes the latent input z and output the trained PDF p(ˆx|z)\n",
      "from which new data is generated.\n",
      "The loss function that we want to optimize is called ELBO (evidence lower\n",
      "bound) rather than the common mean squared error (MSE) which does not make\n",
      "sense for the purposes of VAEs\n",
      "Embedding: [-0.05633042 -0.03637701 -0.05602077 -0.01335825  0.0202097   0.02257526\n",
      " -0.03739439  0.02403066  0.05036557  0.02156513]...\n",
      "Sentence: This loss function guides the VAE to learn a balance\n",
      "between accurately reconstructing the input data and maintaining a structured latent\n",
      "space.\n",
      "The ELBO function has two parts:\n",
      "•\n",
      "A Log-Likelihood: This is used to minimize the difference between the input\n",
      "data and the trained output.\n",
      "•\n",
      "A KL Divergence: This metric measures the difference between the latent\n",
      "distribution and the reconstructed distribution\n",
      "Embedding: [-0.06011594 -0.03866895  0.00725618 -0.06966113  0.04747356  0.06927054\n",
      " -0.00362817 -0.00071968  0.128255    0.00232584]...\n",
      "Sentence: It takes in two distributions as\n",
      "arguments and outputs the KL divergence.\n",
      "To see how a VAE works in practice, we can use it to create new faces by training\n",
      "the model using the CelebFaces dataset images, which can be downloaded from the\n",
      "Internet.\n",
      "6.1.1\n",
      "Preprocessing\n",
      "The images are normalized to [0,1] as input tensors using the following line of code:\n",
      "validationData = utils.image_dataset_from_directory(\n",
      "os.path.dirname(\"C:/AI/Data/VAE/validation\"),\n",
      "image_size=(img_height,img_width),batch_size=batch_size)\n",
      "dsValidation = validationData.map(lambda x, y: x/255.0)\n",
      "6.1\n",
      "Variational Autoencoders\n",
      "107\n",
      "6.1.2\n",
      "VAE Architecture\n",
      "The encoder, a convolutional neural network, encodes input images into a latent\n",
      "space representation\n",
      "Embedding: [-0.07021107 -0.04107387  0.04171795 -0.02491195 -0.03233811  0.00197672\n",
      " -0.04110425  0.02591611 -0.02178016 -0.06149687]...\n",
      "Sentence: It outputs two vectors: z_mean and z_log_var\n",
      "Embedding: [-0.00625496 -0.00493191 -0.0774139   0.00697446  0.0373523  -0.0877494\n",
      "  0.02789595  0.04519022 -0.00187239 -0.00356692]...\n",
      "Sentence: The sampling\n",
      "layer samples from the latent space using the reparameterization trick, which is\n",
      "then passed to the decoder which decodes the latent space representation back into\n",
      "images.\n",
      "def compute_loss(self, x):\n",
      "z_mean, z_log_var = self.encoder(x)\n",
      "z = self.sampling((z_mean, z_log_var))\n",
      "x_reconstructed = self.decoder(z)\n",
      "reconstruction_loss = tf.reduce_mean(\n",
      "tf.keras.losses.binary_crossentropy(x, x_reconstructed)\n",
      ") * 64 * 64 * 3\n",
      "# fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
      "# Display the first image in the first subplot\n",
      "# axes[0].imshow(tf.keras.backend.eval(x[1].numpy()))\n",
      "# axes[1].imshow(tf.keras.backend.eval(x_reconstructed[1]\n",
      ".numpy()))\n",
      "# plt.tight_layout()\n",
      "# tf.print(\"reconstruct:\",reconstruction_loss)\n",
      "kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var -\n",
      "tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
      "kl_loss = tf.reduce_mean(kl_loss)\n",
      "#tf.print(\"kl loss:\",kl_loss)\n",
      "vae_loss = reconstruction_loss + kl_loss\n",
      "return vae_loss\n",
      "In the code above, the compute_loss function in our script is designed to calculate\n",
      "the loss for a variational autoencoder (VAE)\n",
      "Embedding: [-0.04715643 -0.07649086  0.03175759 -0.04373119  0.08654182 -0.04051945\n",
      " -0.00405948 -0.01207327  0.04501253 -0.00266452]...\n",
      "Sentence: This function implements the key\n",
      "components of the VAE loss, which includes both the reconstruction loss and the\n",
      "Kullback-Leibler (KL) divergence:\n",
      "•\n",
      "z_mean, z_log_var = self.encoder(x): This line encodes the input data x using\n",
      "the VAE’s encoder to get the mean, z_mean, and log variance, z_log_var, of the\n",
      "latent variables.\n",
      "z = self.sampling( z_mean, z_log_var)\n",
      "The sampling layer uses z_mean and z_log_var to generate a sample z from the\n",
      "latent space.\n",
      "x_reconstructed = self.decoder(z)\n",
      "The sampled latent variables z are then decoded back into the reconstructed\n",
      "data\n",
      "Embedding: [-0.09898269 -0.01347128  0.04459905 -0.00804884 -0.00169839 -0.00556774\n",
      " -0.00092754 -0.01903702  0.08848757 -0.02439877]...\n",
      "Sentence: The reconstruction loss is computed using binary cross-entropy between\n",
      "the original input x and the reconstructed output x_reconstructed.\n",
      "This loss measures how well the VAE can reconstruct the input data from the\n",
      "latent variables\n",
      "Embedding: [-0.02715615  0.03121192  0.02125867 -0.01049938  0.06227386  0.06540711\n",
      " -0.02053711 -0.04044055  0.03948883 -0.00635077]...\n",
      "Sentence: It is scaled by the dimensions of the input data (64 * 64 * 3), to\n",
      "account for the total number of pixels and color channels in the input images.\n",
      "108\n",
      "6\n",
      "Generative Models\n",
      "Figure 6-1 Left to right: Generated faces after 50 and 1000 epochs\n",
      "•\n",
      "KL Divergence Loss\n",
      "kl_loss = –0.5 * tf.reduce_sum(1 + z_log_var – tf.square(z_mean) –\n",
      "tf.exp(z_log_var), axis=1)\n",
      "This line computes the KL divergence between the approximate posterior deﬁned\n",
      "by z_mean and z_log_var and the prior distribution which is assumed to\n",
      "be a standard normal distribution\n",
      "Embedding: [-0.01011922 -0.05543848  0.08296397 -0.05311782 -0.00769204 -0.01744808\n",
      " -0.06273319  0.0530343   0.06730434 -0.00769876]...\n",
      "Sentence: The KL divergence acts as a regularizer,\n",
      "encouraging the distribution of the latent variables to be close to a standard\n",
      "normal distribution.\n",
      "This is crucial for ensuring a well-structured and meaningful latent space.\n",
      "kl_loss = tf.reduce_mean(kl_loss)\n",
      "The KL divergence is averaged over the batch.\n",
      "•\n",
      "Total VAE Loss\n",
      "vae_loss = reconstruction_loss + kl_loss\n",
      "The total loss for the VAE is the sum of the reconstruction loss and the KL\n",
      "divergence\n",
      "Embedding: [-0.04439416 -0.03243001  0.09307414 -0.00694509 -0.02146804  0.03431726\n",
      " -0.03897512 -0.02864352  0.11495776  0.01047123]...\n",
      "Sentence: This combined loss function is what the VAE will try to minimize\n",
      "during training.\n",
      "The output of generated faces from the VAE networks is shown in Figure 6-1.\n",
      "More realistic faces will be produced with longer training and more experimentation\n",
      "with hyperparameters\n",
      "Embedding: [-0.05768941  0.07636854  0.06167409  0.00695031 -0.00286723  0.03929061\n",
      " -0.0264599  -0.02226666  0.01643642 -0.0481867 ]...\n",
      "Sentence: Figure 6-2 shows the original and reconstructed face images.\n",
      "One major disadvantage of VAEs is that they can have a problem known as\n",
      "posterior collapsing where the resultant images are blurred\n",
      "Embedding: [-0.09715305  0.10020271  0.08859652 -0.03527861  0.01279316  0.0197428\n",
      " -0.04888627  0.04620963  0.02126507  0.01118911]...\n",
      "Sentence: There are techniques\n",
      "to minimize this, but generally a GAN will produce higher-quality images at the\n",
      "cost of training time.\n",
      "6.1\n",
      "Variational Autoencoders\n",
      "109\n",
      "Figure 6-2 VAE image reconstruction\n",
      "110\n",
      "6\n",
      "Generative Models\n",
      "The Python code supplied provides one interesting tool for visualizing the\n",
      "distribution of data points in the latent space of a neural network that is worth noting:\n",
      "# Function to plot the latent space\n",
      "def plot_latent_space(model, data, num_samples=1000):\n",
      "sampled_data = data.take(num_samples)\n",
      "images = []\n",
      "for img, _ in sampled_data:\n",
      "images.append(img)\n",
      "images = tf.concat(images, axis=0)\n",
      "z_mean, _ = model.encoder.predict(images)\n",
      "tsne = TSNE(n_iter=300, perplexity=30,\n",
      "learning_rate=200)\n",
      "z_mean_reduced = tsne.fit_transform(z_mean)\n",
      "plt.scatter(z_mean_reduced[:,0],z_mean_reduced[:,1])\n",
      "plt.xlabel(’Dimension 1’)\n",
      "plt.ylabel(’Dimension 2’)\n",
      "plt.title(’Latent Space Visualization’)\n",
      "plt.show()\n",
      "The purpose of this code is to provide a visual representation of how data points\n",
      "are distributed in the latent space of the VAE after encoding\n",
      "Embedding: [-0.03439764 -0.0809437   0.0478053   0.01371963  0.02469582 -0.02828152\n",
      " -0.03842364  0.00062704  0.00639677 -0.0636816 ]...\n",
      "Sentence: It can help you gain\n",
      "insights into the structure and separability of the latent space, which is useful for\n",
      "assessing the quality of the learned representations and understanding how well the\n",
      "VAE has disentangled the underlying factors of variation in the data.\n",
      "The provided code deﬁnes a function to plot the latent space of a variational\n",
      "autoencoder (VAE) or similar neural network model\n",
      "Embedding: [-0.04740875 -0.10817521  0.03291061 -0.01289776  0.01174658  0.06693058\n",
      " -0.00737686 -0.02457573  0.04328714 -0.04649414]...\n",
      "Sentence: Here’s a breakdown of what\n",
      "the code does.\n",
      "The function takes three arguments:\n",
      "Model This argument represents the VAE model or a similar model that has an\n",
      "encoder capable of encoding data into a latent space.\n",
      "Data This argument represents a TensorFlow dataset (data) containing input data\n",
      "samples.\n",
      "Num Samples This argument speciﬁes the number of samples to use for visualiza-\n",
      "tion\n",
      "Embedding: [-0.04650903 -0.05116845 -0.05569655 -0.00238421  0.03875915  0.02796484\n",
      "  0.03138867  0.00898076  0.01557671 -0.05638167]...\n",
      "Sentence: The default value is set to 1000.\n",
      "The function starts by sampling a subset of data points from the dataset\n",
      "Embedding: [-0.00597898 -0.0091383  -0.06883368 -0.04493141 -0.02281589 -0.01937976\n",
      "  0.01613959  0.04947671 -0.0006011   0.01237842]...\n",
      "Sentence: It takes\n",
      "the ﬁrst numsamples samples from the dataset.\n",
      "For the sampled data, it encodes the data using the VAE’s encoder\n",
      "(model.encoder) to obtain the mean (zmean) of the latent space representation.\n",
      "Then, it applies t-Distributed Stochastic Neighbor Embedding (t-SNE), a\n",
      "dimensionality reduction technique, to reduce the dimensionality of the latent\n",
      "space representation from its original dimensionality to a two-dimensional space.\n",
      "After reducing the dimensionality, it creates a scatter plot of the two-dimensional\n",
      "latent space\n",
      "Embedding: [-0.02361719 -0.06015612 -0.01660487 -0.05020771  0.05068579  0.061334\n",
      " -0.05465911 -0.00762259  0.05938355 -0.00577253]...\n",
      "Sentence: Each point in the scatter plot represents a data point, and its position is\n",
      "determined by the reduced latent space representation obtained using t-SNE.\n",
      "6.1\n",
      "Variational Autoencoders\n",
      "111\n",
      "Finally, it displays the scatter plot, allowing you to visualize the distribution and\n",
      "clustering of data points in the latent space.\n",
      "The purpose of this code is to provide a visual representation of how data points\n",
      "are distributed in the latent space of the VAE after encoding\n",
      "Embedding: [-0.00589662 -0.03833975  0.00019709 -0.04604459  0.05753594  0.09275013\n",
      " -0.01442147 -0.00489567  0.04439031 -0.0388761 ]...\n",
      "Sentence: It can help you gain\n",
      "insights into the structure and separability of the latent space, which is useful for\n",
      "assessing the quality of the learned representations and understanding how well the\n",
      "VAE has disentangled the underlying factors of variation in the data.\n",
      "6.1.3\n",
      "Morphing Images\n",
      "Morphing images in the latent space from one image to another is a fascinating\n",
      "application using VAE\n",
      "Embedding: [-0.03050119 -0.06281295  0.09306198 -0.0398569   0.03312312  0.0384907\n",
      " -0.01857915 -0.03270548  0.06704192 -0.02370723]...\n",
      "Sentence: Morphing in a variational autoencoder (VAE) involves\n",
      "smoothly transitioning between two input images by navigating the latent space\n",
      "of the VAE\n",
      "Embedding: [-0.0160803  -0.07851762  0.13855338 -0.02789305 -0.01884853  0.02581926\n",
      " -0.01359026 -0.02429819  0.04667636 -0.0511581 ]...\n",
      "Sentence: Normally, morphing between two images involves linear interpolation\n",
      "between the two vectors representing the two from-and-to images, but the interpo-\n",
      "lation can follow other paths depending on the desired transitional effect\n",
      "Embedding: [-0.05046715 -0.03984024  0.11661635 -0.07167999  0.00856407 -0.02513657\n",
      " -0.05699785 -0.02015531  0.03420532 -0.03853147]...\n",
      "Sentence: Using\n",
      "a pretrained VAE network for morphing is straightforward using the following\n",
      "steps:\n",
      "•\n",
      "Load our pretrained VAE model.\n",
      "•\n",
      "Encode the source and target images to obtain their latent representations.\n",
      "•\n",
      "Linearly interpolate between the latent vectors and decode them to produce a\n",
      "sequence of morphed images.\n",
      "•\n",
      "Finally, we display or save the morphed images.\n",
      "The resulting images will smoothly transition from the source to the target, creating\n",
      "a morphing effect\n",
      "Embedding: [-0.01208147 -0.02724645  0.1364262  -0.02039078 -0.03283262  0.05751654\n",
      " -0.02719274 -0.00802309 -0.0118898  -0.02713846]...\n",
      "Sentence: We can adjust the number of frames and interpolation method\n",
      "to control the smoothness and speed of the morphing\n",
      "Embedding: [-0.0267576  -0.02467818  0.0544338  -0.08563774 -0.01411105 -0.03328985\n",
      " -0.06205562 -0.01477809 -0.01244495 -0.07031729]...\n",
      "Sentence: Using our pretrained VAE\n",
      "code, we can perform morphing from one face to another\n",
      "Embedding: [-0.06619384  0.00806697  0.09407877 -0.04256561 -0.06693466 -0.00793026\n",
      " -0.01111673 -0.00932818 -0.07138032 -0.02289235]...\n",
      "Sentence: The result is shown in\n",
      "Figure 6-3\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from keras.models import load_model\n",
      "# Load your pre-trained VAE model\n",
      "vae = load_model(’celeb_vae_model.h5’)\n",
      "# Encode source and target images\n",
      "source_image = ...\n",
      "# Load your source image\n",
      "target_image = ...\n",
      "# Load your target image\n",
      "latent_source, _ = vae.encoder.predict(source_image)\n",
      "latent_target, _ = vae.encoder.predict(target_image)\n",
      "# Specify the number of frames for morphing\n",
      "num_frames = 10\n",
      "112\n",
      "6\n",
      "Generative Models\n",
      "Figure 6-3 Transition from one image to another in latent space\n",
      "# Linear interpolation in latent space\n",
      "morphed_images = []\n",
      "for alpha in np.linspace(0, 1, num_frames):\n",
      "interpolated_latent = (1 - alpha) *\n",
      "latent_source + alpha * latent_target\n",
      "decoded_image = vae.decoder.predict(interpolated_latent)\n",
      "morphed_images.append(decoded_image)\n",
      "# Display or save morphed images\n",
      "for i, image in enumerate(morphed_images):\n",
      "plt.imshow(image.squeeze(), cmap=’gray’)\n",
      "plt.axis(’off’)\n",
      "plt.title(f’Interpolation Step {i}’)\n",
      "plt.show()\n",
      "6.1.4\n",
      "Feature Disentanglement\n",
      "As we perform morphing using the above code, it is clear that the latent space\n",
      "using VAE is highly entangled\n",
      "Embedding: [-0.03696394 -0.08705468  0.0514188  -0.06092081  0.07250506  0.01860353\n",
      " -0.05670441  0.01397466 -0.01471491 -0.06192746]...\n",
      "Sentence: Features are added to the intermediate steps in\n",
      "an uncontrolled fashion\n",
      "Embedding: [-0.01653365  0.02660181  0.06634481  0.02688666  0.0664969   0.04610781\n",
      " -0.10230193 -0.0293203  -0.06992405 -0.01498967]...\n",
      "Sentence: Disentangled VAEs have become a prominent area of\n",
      "research in machine learning due to their potential for creating more interpretable\n",
      "and controllable generative models.\n",
      "Having disentangled latent space is potentially very useful\n",
      "Embedding: [-0.09397531 -0.09237032  0.09003985  0.04914388 -0.05531934  0.02205283\n",
      "  0.01378383 -0.09755112  0.06693432 -0.01892949]...\n",
      "Sentence: The latent space\n",
      "learned by these models can have practical applications in areas such as image\n",
      "manipulation, style transfer, and data generation\n",
      "Embedding: [-0.03050183 -0.08893931  0.00700568  0.01263083  0.05168406  0.03247827\n",
      " -0.05524787 -0.07057551  0.06670807 -0.01516866]...\n",
      "Sentence: By changing the values of\n",
      "individual dimensions in the latent space, we can control speciﬁc attributes of\n",
      "the generated data\n",
      "Embedding: [ 0.00056232  0.02318116 -0.03981183  0.04563056  0.01596133  0.0464359\n",
      " -0.03331635 -0.12224451  0.02493073  0.00337625]...\n",
      "Sentence: For example, in image generation, we might have separate\n",
      "dimensions for factors like pose, color, and style.\n",
      "Currently, achieving perfect disentanglement is still an area of research\n",
      "Embedding: [ 0.02948243  0.01455387  0.0293491   0.00438861  0.0468117  -0.03141052\n",
      " -0.05318046 -0.03323282  0.03070292 -0.02983638]...\n",
      "Sentence: How-\n",
      "ever, there are various approaches to produce reasonable disentanglement in VAEs,\n",
      "including\n",
      "•\n",
      "Conditional VAE (CVAE): A CVAE extends the VAE to condition the latent\n",
      "space on certain variables or features\n",
      "Embedding: [-0.05731696  0.04133851  0.0587527  -0.02454979 -0.02039577 -0.0074021\n",
      "  0.03612449 -0.04517321  0.03497864  0.01473239]...\n",
      "Sentence: You can design the model to generate a\n",
      "latent space representation that explicitly encodes these features\n",
      "Embedding: [-0.04922654 -0.07594667 -0.00499438  0.0297449   0.03382207  0.09445402\n",
      " -0.04011336 -0.11381473  0.02198487 -0.06264909]...\n",
      "Sentence: This is often\n",
      "used in conditional image generation tasks.\n",
      "•\n",
      "Disentangled VAE (β-VAE, Factor-VAE): These are variations of VAEs that\n",
      "aim to encourage the latent dimensions to capture independent and interpretable\n",
      "6.1\n",
      "Variational Autoencoders\n",
      "113\n",
      "factors of variations in the data\n",
      "Embedding: [-0.01912328 -0.03471233  0.06049265  0.03853802  0.04271117  0.05115502\n",
      "  0.01510248 -0.04500723  0.0673309  -0.03519522]...\n",
      "Sentence: While they may not directly encode separate fea-\n",
      "tures, they can help create more interpretable and disentangled representations.\n",
      "•\n",
      "InfoGAN: Information Maximizing Generative Adversarial Networks (Info-\n",
      "GANs) are a type of VAE-GAN hybrid that introduces an auxiliary network\n",
      "to explicitly maximize the mutual information between a subset of the latent\n",
      "variables and the generated data\n",
      "Embedding: [-0.1184435  -0.0561621  -0.00272432  0.01390502  0.04865599 -0.01024723\n",
      "  0.01686698 -0.06828669  0.03952211 -0.08847446]...\n",
      "Sentence: This encourages those variables to capture\n",
      "speciﬁc attributes of the data.\n",
      "•\n",
      "Joint-VAE: Joint-VAE combines a VAE with a clustering algorithm to encourage\n",
      "the model to learn a more disentangled representation.\n",
      "To see how factor disentanglement works in practice, we can modify our VAE\n",
      "model to implement the Factor-VAE, a model proposed by Hyunjik Kim and\n",
      "Andriy Mnih in their paper “Disentangling by Factorising.” Implementing Factor-\n",
      "VAE using Keras involves modifying a standard variational autoencoder (VAE)\n",
      "loss function slightly to include a factor disentanglement term in the loss function.\n",
      "The disentanglement term encourages the VAE to learn a more structured and\n",
      "disentangled latent representation as below\n",
      "Embedding: [-0.00695744 -0.0362572   0.07235397  0.04149102  0.01249272  0.07878911\n",
      " -0.00530292 -0.05089455  0.02460257 -0.05899269]...\n",
      "Sentence: The remaining code for the VAE\n",
      "program remains as before:\n",
      "def compute_loss(self, x):\n",
      "z_mean, z_log_var = self.encoder(x)\n",
      "z = self.sampling((z_mean, z_log_var))\n",
      "x_reconstructed = self.decoder(z)\n",
      "reconstruction_loss = tf.reduce_mean(\n",
      "tf.keras.losses.\n",
      "binary_crossentropy(x, x_reconstructed)\n",
      ") * img_width * img_height * 3\n",
      "kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var -\n",
      "tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
      "kl_loss = tf.reduce_mean(kl_loss)\n",
      "# Factor disentanglement term\n",
      "factor_disentanglement_loss = tf.\n",
      "reduce_mean(tf.abs(z_mean))\n",
      "vae_loss = reconstruction_loss + kl_loss +\n",
      "factor_disentanglement_loss\n",
      "return vae_loss\n",
      "Once we have encoded the data, it will not be obvious to determine what each\n",
      "encoded dimension actually represents\n",
      "Embedding: [-0.00940524 -0.01968103  0.00198388 -0.00097731 -0.0066827  -0.05083768\n",
      " -0.01412322  0.02275668 -0.04042514 -0.00185403]...\n",
      "Sentence: In general, Factor-VAE, and other VAE\n",
      "models, cannot produce an independent axis of feature representation, so if we\n",
      "examine a particular dimension, it is unlikely that the single dimension is a unique\n",
      "feature\n",
      "Embedding: [ 0.02146769 -0.11105186  0.04809386  0.01083991  0.03484097  0.0713353\n",
      " -0.04273136 -0.03876524  0.03572837 -0.08984654]...\n",
      "Sentence: The metric for measuring disentanglement is not straightforward but is\n",
      "needed for commercial work\n",
      "Embedding: [-0.00935319 -0.01311618  0.01881657 -0.05346632 -0.03898109 -0.01459419\n",
      "  0.0385264   0.01627054  0.04047848 -0.05812908]...\n",
      "Sentence: For educational purposes however, it is sufﬁcient to\n",
      "view visually the effect along feature changes to guess the resultant purpose of each\n",
      "114\n",
      "6\n",
      "Generative Models\n",
      "latent dimension\n",
      "Embedding: [ 0.00367312 -0.08823922  0.05898445 -0.02142947  0.06868839  0.08748055\n",
      " -0.15587647 -0.02338726  0.02517947 -0.00502592]...\n",
      "Sentence: The code below does this by looping through all dimensions and\n",
      "modifying one dimension at a time to see the result:\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "# Load your trained FactorVAE model and encoder here\n",
      "factorvae = tf.keras.models.load_model(’vae_model.h5’)\n",
      "encoder = tf.keras.models.load_model(’encoder_model.h5’)\n",
      "# Load or generate an input data point for reconstruction\n",
      "input_data = np.random.randn(1, input_dim)\n",
      "# Encode the input data\n",
      "latent_representation = encoder.predict(input_data)\n",
      "# Get the dimensionality of the latent space\n",
      "latent_dim = latent_representation.shape[1]\n",
      "# Initialize an empty array to store\n",
      "# reconstructed data along each dimension\n",
      "reconstructed_data_per_dim = []\n",
      "# Loop through each dimension and\n",
      "# modify it while keeping others fixed\n",
      "for dim_index in range(latent_dim):\n",
      "# Create a copy of the original latent representation\n",
      "modified_latent_representation =\n",
      "latent_representation.copy()\n",
      "# Set a new value for the current dimension\n",
      "# You can modify this value based\n",
      "# on your desired transformation\n",
      "new_value = 2.0\n",
      "# Example: Set a new value\n",
      "# Modify the current dimension\n",
      "modified_latent_representation[0, dim_index] = new_value\n",
      "# Decode the modified latent representation\n",
      "# to generate reconstructed data\n",
      "reconstructed_data = factorvae.decoder.\n",
      "predict(modified_latent_representation)\n",
      "# Append the reconstructed data to the list\n",
      "reconstructed_data_per_dim.append(reconstructed_data)\n",
      "# Plot the original data and reconstructed\n",
      "# data along each dimension\n",
      "plt.figure(figsize=(4 * latent_dim, 4))\n",
      "for dim_index in range(latent_dim):\n",
      "plt.subplot(1, latent_dim, dim_index + 1)\n",
      "plt.imshow(reconstructed_data_per_dim[dim_index][0].\n",
      "#reshape(image_shape), cmap=’gray’)\n",
      "6.2\n",
      "CartoonGAN\n",
      "115\n",
      "plt.title(f’Dimension {dim_index}’)\n",
      "plt.axis(’off’)\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "6.2\n",
      "CartoonGAN\n",
      "The project “CartoonGAN: Generative Adversarial Networks for Photo Cartooniza-\n",
      "tion” was proposed by Yang Chen et al\n",
      "Embedding: [ 0.05100439 -0.07268738  0.05054865 -0.00739577  0.06940084  0.06709911\n",
      " -0.04938968 -0.04953969 -0.06617649 -0.04103033]...\n",
      "Sentence: [5] as a solution for transforming photos\n",
      "of real-world scenes into cartoon-style images\n",
      "Embedding: [-0.04580297  0.00450739  0.01267144 -0.04962489  0.09879497 -0.03991606\n",
      " -0.02212308 -0.06148101 -0.02458996 -0.07663345]...\n",
      "Sentence: There have been many previous\n",
      "attempts to do the same, but they tend to use pair images and cartoons which are very\n",
      "time-consuming to generate\n",
      "Embedding: [-0.10632318 -0.05638364 -0.06095986 -0.01556825  0.01271607  0.02163305\n",
      " -0.11423969 -0.0841038  -0.01255427 -0.06370607]...\n",
      "Sentence: Often, this process would involve an artist drawing the\n",
      "required cartoon to pair up the original image.\n",
      "These following points are taken from their published paper, which states the\n",
      "main contributions of the model:\n",
      "•\n",
      "(1) We propose a dedicated GAN-based approach that effectively learns the\n",
      "mapping from real-world photos to cartoon images using unpaired image sets\n",
      "for training\n",
      "Embedding: [-0.09023633 -0.07039008 -0.00069327 -0.00968873 -0.01057061  0.03755909\n",
      " -0.0389723  -0.11154636 -0.02479442 -0.09992339]...\n",
      "Sentence: Our method is able to generate high-quality stylized cartoons, which\n",
      "are substantially better than state-of-the-art methods\n",
      "Embedding: [-0.06859091 -0.02787588  0.00252266 -0.07578165 -0.01692642 -0.00903551\n",
      " -0.05594169 -0.06284235 -0.00148505 -0.06809223]...\n",
      "Sentence: When cartoon images from\n",
      "individual artists are used for training, our method is able to reproduce their\n",
      "styles.\n",
      "•\n",
      "(2) We propose two simple yet effective loss functions in GAN-based archi-\n",
      "tecture\n",
      "Embedding: [-0.08584286  0.04687716  0.06720568 -0.04164793 -0.00364944 -0.03697584\n",
      " -0.02862239 -0.09177567  0.01457979 -0.10778345]...\n",
      "Sentence: In the generative network, to cope with substantial style variation\n",
      "between photos and cartoons, we introduce a semantic loss deﬁned as an L1\n",
      "sparse regularization in the high-level feature maps of the VGG network\n",
      "Embedding: [ 0.01598116 -0.03221359  0.08841045  0.02360657  0.06987848  0.06887004\n",
      " -0.05519916 -0.06152421 -0.06369462 -0.09006598]...\n",
      "Sentence: In\n",
      "the discriminator network, we propose an edge-promoting adversarial loss for\n",
      "preserving clear edges.\n",
      "•\n",
      "(3) We further introduce an initialization phase to improve the convergence of\n",
      "the network to the target manifold\n",
      "Embedding: [-0.10309669 -0.01233527 -0.00420228  0.02510591  0.04021595  0.04252552\n",
      "  0.02889336 -0.15772183 -0.0282033  -0.02586543]...\n",
      "Sentence: Our method is much more efﬁcient to train\n",
      "than existing methods.\n",
      "6.2.1\n",
      "GAN\n",
      "GANs consist of two neural networks, a generator and a discriminator, which are\n",
      "trained simultaneously through adversarial processes\n",
      "Embedding: [-0.14898494 -0.09532938  0.01479045  0.05094722  0.00947628  0.03683015\n",
      " -0.05246106 -0.06620335  0.00059241 -0.07868639]...\n",
      "Sentence: The generator generates data\n",
      "that is as realistic as possible, while the discriminator evaluates this data, trying to\n",
      "distinguish between real and generated (fake) data.\n",
      "The goal of GANs is to generate data, often images but also other data types, that\n",
      "are indistinguishable from real data\n",
      "Embedding: [-0.14894216 -0.01442447 -0.04143936  0.01127287  0.01372996 -0.04574957\n",
      " -0.023934   -0.06436681  0.05272603 -0.07999035]...\n",
      "Sentence: As training progresses, the generator improves\n",
      "in producing more realistic data, while the discriminator becomes better at telling\n",
      "real from fake.\n",
      "116\n",
      "6\n",
      "Generative Models\n",
      "Figure 6-4 The CartoonGAN architecture [5]\n",
      "GANs are primarily used in tasks involving data generation, such as image and\n",
      "video generation, style transfer, data augmentation, and more.\n",
      "The architecture for CartoonGAN in Figure 6-4 is relatively standard\n",
      "Embedding: [-0.08969878 -0.07729883 -0.01787041 -0.03217112  0.00439919  0.00347674\n",
      " -0.07063365 -0.05793716  0.02060206 -0.0716955 ]...\n",
      "Sentence: Both\n",
      "generator and discriminator networks are CNN networks as shown below, which we\n",
      "have implemented in Keras\n",
      "Embedding: [-0.14026566 -0.0225175  -0.0304382  -0.01422497 -0.00679629  0.05221548\n",
      " -0.01202655 -0.0732445   0.00664081 -0.09695113]...\n",
      "Sentence: In their original paper, the authors use pictures taken\n",
      "from the ﬁlm Spirited Away, which for copyright reasons, we cannot include in our\n",
      "dataset\n",
      "Embedding: [-0.06415629  0.0975254  -0.02196376  0.04804653  0.12232814 -0.02543654\n",
      " -0.0567018  -0.05825978  0.02777728 -0.0153341 ]...\n",
      "Sentence: However, we will now discuss the tools needed to replicate the data used in\n",
      "the research paper from Flickr and the movie for the interested reader.\n",
      "6.2.2\n",
      "Data Preparation\n",
      "The research paper used images from two sources: Flickr and Spirited Away\n",
      "Embedding: [-0.08958225 -0.02382818 -0.01505434  0.03830444  0.05728377 -0.04736371\n",
      " -0.08110459 -0.02764835 -0.01184532  0.01886857]...\n",
      "Sentence: Both\n",
      "of these sources have limited distribution rights, so we would need to create our own\n",
      "set of data using the procedure below to train the model.\n",
      "For Flickr, Jeff Heaton [6] provided an excellent and easy-to-use utility to\n",
      "automate the download which have been included in the source ﬁle\n",
      "Embedding: [-0.0764473  -0.12195433 -0.10842718  0.03020654  0.04941091 -0.00970267\n",
      " -0.07043139 -0.0087837  -0.05029564  0.01121458]...\n",
      "Sentence: However,\n",
      "we need to edit the conﬁg_ﬂickr.ini ﬁle to search for the images required\n",
      "Embedding: [-0.05636743  0.02164475 -0.04159268  0.0146652   0.08028331 -0.03658537\n",
      " -0.046155   -0.00995042 -0.00262526 -0.05371632]...\n",
      "Sentence: In this\n",
      "instance, I have downloaded images related to the theme “nature” of size 256 × 256\n",
      "into the local directory /home/philip/AI/Data/CartoonGAN/PhotoFlickr.\n",
      "[FLICKR]\n",
      "id = your account id\n",
      "secret = your secret id\n",
      "[Download]\n",
      "path = /home/philip/AI/Data/CartoonGAN/PhotoFlickr\n",
      "6.2\n",
      "CartoonGAN\n",
      "117\n",
      "search = Nature\n",
      "prefix = Nature\n",
      "update_minutes = 1\n",
      "license = 0,1,2,3,4,5,6,7,8,9,10\n",
      "max_download = 100000\n",
      "sources_file = sources.csv\n",
      "[Process]\n",
      "process = True\n",
      "crop_square = True\n",
      "min_width = 256\n",
      "min_height = 256\n",
      "scale_width = 256\n",
      "scale_height = 256\n",
      "image_format = jpg\n",
      "Running the ﬂickr-download.py code should download approximately 4000–5000\n",
      "images into the local directories.\n",
      "Capturing frames from the movie Spirited Away is trickier\n",
      "Embedding: [-0.00501303  0.00990577 -0.06227603 -0.00392796  0.15334862 -0.07551536\n",
      " -0.03619732  0.02722397 -0.01283566 -0.0310908 ]...\n",
      "Sentence: We would need to\n",
      "have the movie in .mov format on the local drive, then download FFmpeg, and use\n",
      "the following command to extract frames every four seconds (or whatever interval\n",
      "we need):\n",
      "ffmpeg -i input.mov -r 0.25 output_%04d.jpg\n",
      "We would need to remove the blank images at the beginning and end\n",
      "Embedding: [ 0.05697382 -0.00557602  0.00534533 -0.02816025  0.05986495  0.02054444\n",
      " -0.09892382 -0.04290477  0.07413818 -0.14140877]...\n",
      "Sentence: These should\n",
      "be placed into a separate directory.\n",
      "The next step is to crop these images to 256 × 256 using the function\n",
      "crop_images_in_directory() in pre_process.py\n",
      "Embedding: [ 0.03923872  0.03807244 -0.05204101 -0.05744297  0.06785488 -0.11892576\n",
      " -0.09547006  0.04926295 -0.07428198  0.00378954]...\n",
      "Sentence: These cropped images are then\n",
      "augmented using augment_images(), which ﬂips the images left to right to create\n",
      "more images.\n",
      "CartoonGAN requires smooth images, which can be done by running smooth.py\n",
      "with the appropriate directory for the captured cartoon images\n",
      "Embedding: [-0.03489415 -0.01742822 -0.01379275 -0.0497371   0.05214737 -0.08159026\n",
      " -0.01906325 -0.04124441 -0.07289217 -0.0621051 ]...\n",
      "Sentence: Ensure that the\n",
      "output directory is different to the unsmoothed images.\n",
      "We should now have three separate directories containing the photos, cartoons,\n",
      "and smoothed cartoons; each image of size 256 × 256 is nearly ready to be fed into\n",
      "the model\n",
      "Embedding: [ 0.00073592 -0.06393901  0.03146441  0.00456902  0.05375803 -0.05846728\n",
      " -0.10317677 -0.02991823 -0.05164365 -0.04793405]...\n",
      "Sentence: The directories for these images should be set in main.py under three\n",
      "separate directories\n",
      "Embedding: [ 0.01160329 -0.03740888 -0.01565347 -0.04716721  0.08094937 -0.10037363\n",
      " -0.04336989  0.06499796 -0.03397989 -0.05740375]...\n",
      "Sentence: For example:\n",
      "photo_paths_norm = ’~/AI/Data/CartoonGAN/PhotoNorm/’\n",
      "cartoon_paths_norm = ’~/AI/Data/CartoonGAN/CartoonNorm/’\n",
      "smoothed_paths_norm = ’~/AI/Data/CartoonGAN/CartoonSmoothNorm/’\n",
      "6.2.3\n",
      "Preprocessing CartoonGAN\n",
      "The images are normalized in create_dataset() to a range of [−1,1]\n",
      "Embedding: [ 0.02181513 -0.06358612 -0.00452816 -0.01274912  0.01369549 -0.09591256\n",
      " -0.01728974 -0.02562712 -0.08801091 -0.02550592]...\n",
      "Sentence: This range is\n",
      "needed because we are using tanh as the activation function instead of sof tmax.\n",
      "tanh is generally used in hidden layers or in recurrent network structures to\n",
      "normalize and regulate the ﬂow of data, whereas softmax is used in the output layer\n",
      "for classiﬁcation tasks to represent the likelihood of the input belonging to each\n",
      "118\n",
      "6\n",
      "Generative Models\n",
      "class\n",
      "Embedding: [ 0.00429679 -0.06241701 -0.02722555 -0.06641928  0.00824651  0.11807203\n",
      " -0.04971273  0.05594402  0.05623264 -0.10213162]...\n",
      "Sentence: However, the difference in result is marginal in this case, and either activation\n",
      "function could be used.\n",
      "def create_dataset(image_directory, batch_size=1):\n",
      "image_paths = [os.path.join(image_directory, fname)\n",
      "for fname in sorted(os.listdir(image_directory))\n",
      "if os.path.isfile(os.path.join(image_directory, fname))\n",
      "and fname.lower().endswith(’.jpg’)]\n",
      "# Define a function to process the images\n",
      "dataset = tf.data.Dataset.\n",
      "from_tensor_slices(image_paths)\n",
      "dataset = dataset.map(lambda x:\n",
      "load_and_preprocess_image(x, 256, 256))\n",
      "dataset = dataset.batch(batch_size)\n",
      ".prefetch(tf.data.AUTOTUNE)\n",
      "return dataset\n",
      "def load_and_preprocess_image(path,target_height,\n",
      "target_width):\n",
      "image = tf.io.read_file(path)\n",
      "image = tf.image.decode_jpeg(image, channels=3)\n",
      "image = tf.image.convert_image_dtype(image,\n",
      "dtype=tf.float32)\n",
      "image = (image - 0.5) * 2\n",
      "# Scale to [-1, 1]\n",
      "return image\n",
      "The AUTOTUNE parameter is used to optimize data transfer in batches in Tensor-\n",
      "Flow\n",
      "Embedding: [ 0.00511176 -0.06652879 -0.00533348  0.00063589  0.02130686 -0.07847699\n",
      "  0.01846121  0.07969349 -0.08614304 -0.060046  ]...\n",
      "Sentence: When loading and preprocessing large datasets, the efﬁciency of operations\n",
      "like data fetching, batching, and preprocessing can signiﬁcantly impact training\n",
      "speed\n",
      "Embedding: [-0.00902623  0.01570514 -0.03452636  0.01247219  0.00081401 -0.08811082\n",
      " -0.05823469 -0.06374624 -0.07371238 -0.04090371]...\n",
      "Sentence: AUTOTUNE allows TensorFlow to automatically determine the optimal\n",
      "number of batches to process in parallel and the best conﬁguration for other\n",
      "performance-related settings.\n",
      "The tensors created by the code above are suitable for the generator and\n",
      "discriminator models deﬁned in the project\n",
      "Embedding: [-0.10175733 -0.06143875 -0.08651332  0.01302679 -0.01691805  0.03248768\n",
      " -0.01983394 -0.00955436 -0.06967608 -0.06622896]...\n",
      "Sentence: However, CartoonGAN uses a VGG\n",
      "network for training content in the generator, and this model needs tensors of size\n",
      "224 × 224 in the range of [0,1], so our tensors need to be converted\n",
      "Embedding: [-0.00365901 -0.07453233 -0.04020921 -0.0256928   0.02442368 -0.00520703\n",
      " -0.06913225 -0.05970018 -0.07035171 -0.10171162]...\n",
      "Sentence: This is done in\n",
      "the function preprocess_for_vgg().\n",
      "def preprocess_for_vgg(image):\n",
      "# Resize to VGG input size\n",
      "image = tf.image.resize(image, (224, 224))\n",
      "image = (image + 1) / 2\n",
      "# convert [-1,1] to [0,1]\n",
      "return preprocess_input(image)\n",
      "# Normalize for VGG\n",
      "6.2.4\n",
      "The Discriminator Model\n",
      "Of the two, the discriminator model is the simpler one\n",
      "Embedding: [ 0.00159095  0.00619566 -0.05478994 -0.0522021   0.01110393 -0.04777702\n",
      "  0.03459864  0.04870631 -0.04738043 -0.02180493]...\n",
      "Sentence: The topology of the neural\n",
      "network follows closely the discriminator structure stated in the research paper [5].\n",
      "6.2\n",
      "CartoonGAN\n",
      "119\n",
      "The loss function needs more explaining, although, in general, it follows the form\n",
      "of a typical GAN model except for the loss due to the smoothing of images.\n",
      "def loss(real_images, g_generated_images, smoothed_images):\n",
      "real_output = discriminator(real_images,training=True)\n",
      "fake_output = discriminator(g_generated_images,\n",
      "training=True)\n",
      "edge_output = discriminator(smoothed_images,\n",
      "training=True)\n",
      "real_losstf.keras.losses.BinaryCrossentropy\n",
      "(from_logits=False)\n",
      "(tf.ones_like(real_output), real_output)\n",
      "fake_loss= tf.keras.losses.BinaryCrossentropy\n",
      "(from_logits=False)\n",
      "(tf.zeros_like(fake_output), fake_output)\n",
      "edge_loss = tf.keras.losses.BinaryCrossentropy\n",
      "(from_logits=False)\n",
      "(tf.zeros_like(edge_output), edge_output)\n",
      "discriminator_loss = real_loss +fake_loss +edge_loss\n",
      "return discriminator_loss\n",
      "The function takes three parameters: real_images are images from the Flickr\n",
      "dataset, g_generated_images are the fake images generated by the generator, and\n",
      "smoothed_images are the cartoon images which have been smoothed\n",
      "Embedding: [-0.11330198 -0.05596965  0.00493846 -0.02929537  0.0095215   0.00888789\n",
      " -0.01901764 -0.00959282 -0.02003834 -0.04662391]...\n",
      "Sentence: At ﬁrst\n",
      "glance, it is counterintuitive to consider that we do not need to feed the same images\n",
      "into the discriminator\n",
      "Embedding: [-0.0265801  -0.03674307 -0.00530997 -0.05852955  0.07605282 -0.00426152\n",
      " -0.00400079 -0.07568369  0.09142943 -0.03440619]...\n",
      "Sentence: However, it makes sense when we realize that the model is\n",
      "targeting style and feature transfer, and the loss due to content, fake_loss, is only\n",
      "one of the three losses being considered.\n",
      "Setting training=True indicates that the model should run in training mode, which\n",
      "might include behaviors like dropout.\n",
      "The loss calculation calculates three different types of losses for the images\n",
      "generated by the discriminator using binary cross-entropy, a common loss function\n",
      "for binary classiﬁcation tasks:\n",
      "•\n",
      "real_loss: Measures how well the discriminator can identify real images\n",
      "Embedding: [-0.03610818 -0.011533   -0.00771592  0.052968    0.11407758  0.03052587\n",
      "  0.03898295 -0.02101342  0.04786229 -0.04137743]...\n",
      "Sentence: It\n",
      "compares the discriminator’s output for real images (real_output) with a tensor\n",
      "of ones (tf.ones_like(real_output)), representing the correct classiﬁcation of real\n",
      "images.\n",
      "•\n",
      "fake_loss: Measures how well the discriminator can identify fake images gen-\n",
      "erated by the generator\n",
      "Embedding: [-0.10743172 -0.02859318 -0.05909263 -0.0141616   0.10488991 -0.00306295\n",
      "  0.04473523 -0.00392536  0.00721308 -0.04202658]...\n",
      "Sentence: It compares the discriminator’s output for fake images\n",
      "(fake_output) with a tensor of zeros (tf.zeros_like(fake_output)), representing the\n",
      "correct classiﬁcation of fake images since all generator images are fake.\n",
      "•\n",
      "edge_loss: This is an additional loss term for the smoothed images\n",
      "Embedding: [-0.11106116  0.00463323 -0.03068253 -0.01919963  0.10334177 -0.05632989\n",
      "  0.04215958  0.00386319 -0.02087687 -0.05668327]...\n",
      "Sentence: This is one\n",
      "of the features of CartoonGAN where real cartoons are distinguished from the\n",
      "real images by sharp edges, so the edge_loss can be considered as a style loss.\n",
      "120\n",
      "6\n",
      "Generative Models\n",
      "6.2.5\n",
      "The Generator Model\n",
      "The generator role is to produce realistic cartoons to fool the discriminator\n",
      "Embedding: [-0.09722881 -0.00209474  0.02070241 -0.01791666  0.01653395  0.01413839\n",
      " -0.03720285 -0.02721343  0.00455623 -0.05543466]...\n",
      "Sentence: In a\n",
      "typical GAN, the initial images are usually just random noise\n",
      "Embedding: [-0.0703327  -0.0929534   0.05852556  0.01805869 -0.01123612 -0.07365938\n",
      " -0.01432841 -0.11246039  0.05973816 -0.09758019]...\n",
      "Sentence: For CartoonGAN,\n",
      "the initialization stage relies on the VGG network to initialize the network weights\n",
      "to produce reasonably realistic images so that the second phase mainly deals with\n",
      "style transfer.\n",
      "Hence, for the initialization phase, no discriminator is involved\n",
      "Embedding: [-0.05863472 -0.05806441  0.02408582 -0.0484584   0.02710485  0.00332008\n",
      " -0.03345876 -0.0490257  -0.01812271 -0.0615489 ]...\n",
      "Sentence: We simply make\n",
      "use of the deep layer “block4_conv3” in VGG-19 to teach the generator to learn\n",
      "important features of the images\n",
      "Embedding: [-0.10030508  0.04525608 -0.0261022  -0.00723623  0.07305105 -0.01746175\n",
      " -0.07069494 -0.04325518 -0.02853353 -0.06489199]...\n",
      "Sentence: Once this is completed, the adversarial nature of\n",
      "the GAN starts\n",
      "Embedding: [-0.15041994 -0.01235623  0.01492232  0.04233203  0.0199336   0.00610217\n",
      " -0.04783512 -0.11733136  0.00809453 -0.06898189]...\n",
      "Sentence: We see the logic for the two phases in the main loop.\n",
      "for cartoon_images, photo_images, smoothed_images in\n",
      "zip(cartoon_dataset,\n",
      "photo_dataset, smoothed_dataset):\n",
      "if is_initialization:\n",
      "# Generator Initialization Phase\n",
      "gen_loss, content_loss = generator.init_train(\n",
      "photo_images,content_lambda)\n",
      "disc_loss = 0\n",
      "adversarial_loss = 0\n",
      "style_loss = 0\n",
      "else:\n",
      "# Adversarial Training Phase\n",
      "gen_loss, content_loss, adversarial_loss,\n",
      "style_loss =\n",
      "generator.train(discriminator.discriminator,\n",
      "photo_images, cartoon_images,\n",
      "g_adv_lambda, content_lambda,\n",
      "style_lambda)\n",
      "disc_loss = discriminator.train(generator.generator,\n",
      "photo_images, smoothed_images)\n",
      "with writer.as_default():\n",
      "# Log discriminator metrics\n",
      "tf.summary.scalar(’Discriminator Loss’,\n",
      "disc_loss, step=n)\n",
      "tf.summary.scalar(’Generator Loss’,\n",
      "gen_loss, step=n)\n",
      "tf.summary.scalar(’Content Loss’,\n",
      "content_loss, step=n)\n",
      "tf.summary.scalar(’Adversarial Loss’,\n",
      "adversarial_loss, step=n)\n",
      "tf.summary.scalar(’Style Loss’, style_loss, step=n)\n",
      "n += 1\n",
      "print(f\"epoch, n, g_loss:gen_loss,\n",
      "d_loss:disc_loss,\n",
      "c_loss:content_loss,\n",
      "adv_loss:adversarial_loss,\n",
      "style_loss:style_loss\")\n",
      "checkpoint_manager.save()\n",
      "test_picture = next(iter(photo_dataset.take(1)))\n",
      "print(test_picture.shape)\n",
      "preprocess.generate_and_save_images(\n",
      "generator.generator,\n",
      "test_picture, epoch)\n",
      "6.2\n",
      "CartoonGAN\n",
      "121\n",
      "In the initial phase, the model returns the generator loss, which is the content loss\n",
      "produced from the VGG-19 network.\n",
      "In the second phase, both the generator and discriminator are trained\n",
      "Embedding: [-0.06086039 -0.02845884  0.02413766  0.03803473  0.08682119 -0.0354218\n",
      "  0.03347231 -0.05987858 -0.09886552 -0.0938302 ]...\n",
      "Sentence: This time,\n",
      "however, several losses are computed: content, adversarial, and style losses are all\n",
      "calculated.\n",
      "Content loss ensures the generated image content resembles the real images,\n",
      "adversarial loss makes the generated images indistinguishable from real ones, and\n",
      "style loss ensures the generated images have the desired artistic style.\n",
      "Each loss is associated with a hyperparameter that adjusts its weight, thereby\n",
      "determining its importance in the overall loss calculation\n",
      "Embedding: [-0.03307854  0.08167975  0.03542699  0.03648639  0.06778068  0.02824643\n",
      " -0.04825996 -0.04621475  0.09815059 -0.02322825]...\n",
      "Sentence: In practice, by varying\n",
      "the ratios, we can produce a spectrum of images—from realistic looking photos to\n",
      "abstract blobs of color cartoons.\n",
      "Through these two phases, the CartoonGAN model adeptly balances content\n",
      "ﬁdelity and artistic stylization, enabling the creation of a diverse range of images,\n",
      "from photorealistic to highly stylized cartoons.\n",
      "def train(discriminator, real_photos, cartoons,\n",
      "g_adv_lambda,content_lambda, style_lambda):\n",
      "with tf.GradientTape() as tape:\n",
      "generated_images = generator(real_photos,\n",
      "training=True)\n",
      "d_g_generated_images = discriminator(generated_images,\n",
      "training=False)\n",
      "cont_loss = content_lambda *\n",
      "content_loss(real_photos,\n",
      "generated_images)\n",
      "adv_loss = g_adv_lambda *\n",
      "adversarial_loss(d_g_generated_images)\n",
      "s_loss = style_lambda *\n",
      "style_loss(cartoons, generated_images)\n",
      "total_generator_loss = adv_loss +cont_loss +s_loss\n",
      "gradients = tape.gradient(total_generator_loss,\n",
      "generator.trainable_variables)\n",
      "optimizer.apply_gradients(zip(gradients,\n",
      "generator.trainable_variables))\n",
      "return total_generator_loss,cont_loss,adv_loss,s_loss\n",
      "The style loss included in the code uses the Gram matrix to help with style transfer.\n",
      "A Gram matrix is a mathematical representation used to measure the correlation\n",
      "between different feature maps in a convolutional neural network (CNN)\n",
      "Embedding: [-0.05871933 -0.09128661 -0.02192896 -0.02760209  0.04370595  0.01489302\n",
      " -0.03830943 -0.03767465 -0.05169039 -0.08495276]...\n",
      "Sentence: It is\n",
      "calculated by multiplying a matrix of feature maps by its transpose\n",
      "Embedding: [ 0.05477352  0.00098283  0.00015592 -0.05469332 -0.01454654  0.02464565\n",
      " -0.02756927  0.01086951 -0.05401974  0.02100459]...\n",
      "Sentence: If we have a\n",
      "set of feature maps, which can be thought of as different ﬁlters applied to an image,\n",
      "the Gram matrix gives us a measure of how these feature maps activate together,\n",
      "essentially capturing the texture or style information of the image.\n",
      "The output of the network after the initialization and the second phase are shown\n",
      "below in Figure 6-5\n",
      "Embedding: [-0.00759058 -0.05958709  0.0398125  -0.09366672  0.03183336  0.07274646\n",
      "  0.023463   -0.04337519 -0.00720888 -0.06077709]...\n",
      "Sentence: As can be seen, the image after the initialization phase is\n",
      "quite close to the original photo but contains some stripey artifacts from the CNN\n",
      "network.\n",
      "122\n",
      "6\n",
      "Generative Models\n",
      "Figure 6-5 Left to right: Original image, after initialization and ﬁnal output\n",
      "The second phase image is much more cartoon like\n",
      "Embedding: [-0.10464327 -0.02028258  0.09075124  0.00413971  0.00165002 -0.03951432\n",
      " -0.06536547 -0.06060625 -0.00387537 -0.08023903]...\n",
      "Sentence: As stated below, the\n",
      "appearance can be changed by altering the parameters of the losses and rerunning\n",
      "the model as the quality or style of the output is achieved or, more likely, our\n",
      "patience runs out!\n",
      "6.3\n",
      "Stable Diffusion\n",
      "In concluding our chapter on generative models, we turn our attention to the\n",
      "state-of-the-art Stable Diffusion AI model\n",
      "Embedding: [-0.01174521 -0.07822524  0.07775994  0.07360513  0.0057167   0.0187248\n",
      " -0.11228446 -0.07319578  0.01062423  0.00853199]...\n",
      "Sentence: Released in 2022, Stable Diffusion is\n",
      "an advanced deep learning model designed for text-to-image conversion, utilizing\n",
      "diffusion techniques\n",
      "Embedding: [ 0.00737079 -0.07164742 -0.01344218  0.02881909  0.01791365 -0.01296272\n",
      " -0.08284745 -0.03208766 -0.01022425 -0.04691374]...\n",
      "Sentence: A notable distinction from its contemporaries like DALL-E\n",
      "and Midjourney, which operate as cloud services, is Stable Diffusion’s ability to\n",
      "function on consumer PCs equipped with a GPU boasting at least 4 GB of RAM.\n",
      "A key aspect of this model is its utilization of techniques discussed earlier in\n",
      "this chapter, speciﬁcally latent embedding, variational autoencoders (VAEs), and a\n",
      "convolutional neural network architecture known as U-Net\n",
      "Embedding: [-0.05000927 -0.07551138  0.04776796 -0.015959    0.02045017  0.04857698\n",
      "  0.00354185 -0.06771321  0.04458763 -0.06454118]...\n",
      "Sentence: Originally developed for\n",
      "biomedical image segmentation, U-Net has been effectively adapted for generating\n",
      "images with ﬁne-grained details, which are crucial for Stable Diffusion.\n",
      "The training process of diffusion models is centered around the strategic addition\n",
      "and subsequent removal of Gaussian noise from training images\n",
      "Embedding: [ 0.02354341 -0.06438237  0.05367978 -0.01496147  0.04970229 -0.09969164\n",
      "  0.02285039 -0.11201929  0.01624863 -0.03400847]...\n",
      "Sentence: The Stable\n",
      "Diffusion model operates in three distinct phases:\n",
      "•\n",
      "First, a variational autoencoder (VAE) compresses the image into a latent space,\n",
      "capturing the semantic relationships within the image.\n",
      "•\n",
      "During the forward diffusion stage, Gaussian noise is incrementally added to this\n",
      "latent representation\n",
      "Embedding: [ 0.03149292 -0.10008107  0.04758196  0.00789543  0.04024506  0.01488877\n",
      " -0.04487931 -0.08905764  0.06170427 -0.03090258]...\n",
      "Sentence: The U-Net architecture then comes into play, de-noising\n",
      "the diffused representation in the latent space, aiming to produce an output that\n",
      "aligns with the intended text association.\n",
      "6.3\n",
      "Stable Diffusion\n",
      "123\n",
      "•\n",
      "Finally, the VAE decoder reconstructs the image from the latent space back into\n",
      "pixel space.\n",
      "The integration of a diffusion model alongside a VAE might raise questions.\n",
      "One could hypothesize about embedding the text prompt with the image directly\n",
      "in the latent space and generating the image using solely a VAE network\n",
      "Embedding: [-0.01860663 -0.01005299  0.03533702 -0.0010272   0.06924437  0.01953026\n",
      " -0.01637078 -0.03173833  0.06740046 -0.04575203]...\n",
      "Sentence: However,\n",
      "employing a diffusion network has several advantages.\n",
      "Diffusion models have demonstrated superior capabilities in generating images\n",
      "of high quality and resolution\n",
      "Embedding: [ 0.04776678 -0.08188366  0.01351796 -0.01981292  0.01010904 -0.08992774\n",
      " -0.10301118 -0.06647723  0.08390563 -0.01123613]...\n",
      "Sentence: This excellence stems from their adeptness at\n",
      "modeling complex, high-dimensional data distributions, enabling them to capture\n",
      "and reproduce ﬁne details and a wide variety of image features.\n",
      "These models beneﬁt from a more stable training process\n",
      "Embedding: [-0.01312569 -0.09206051  0.04908001 -0.02652723  0.04223739 -0.0048791\n",
      " -0.07501038 -0.04748322 -0.01482002 -0.06057458]...\n",
      "Sentence: By transforming the\n",
      "data into Gaussian noise in a controlled manner and subsequently learning to reverse\n",
      "this process, diffusion models exploit the well-understood properties of Gaussian\n",
      "noise\n",
      "Embedding: [-0.0004397  -0.10240448  0.08309721  0.06657346 -0.02349169 -0.08008178\n",
      " -0.01774314 -0.1236517   0.00499335  0.03217899]...\n",
      "Sentence: This approach provides signiﬁcant control over the image generation process,\n",
      "which can be ﬁnely tuned by adjusting the levels of noise and the sampling\n",
      "methodology.\n",
      "The VAE encoder and decoder are similar to the previous example; hence, we\n",
      "will focus on the two remaining components of the model: injecting and removing\n",
      "noise and the U-Net topology.\n",
      "6.3.1\n",
      "Text Embedding in Stable Diffusion\n",
      "In the context of generative models, like Stable Diffusion, a latent space is a\n",
      "high-dimensional space where complex data (like images) are represented in a\n",
      "compressed, abstract form\n",
      "Embedding: [-0.00756379 -0.06117979  0.03665497  0.01386384  0.04324926 -0.00659782\n",
      " -0.01653309 -0.09785792  0.05970488 -0.02309215]...\n",
      "Sentence: This latent space captures the essential characteristics\n",
      "and variations of the data, making it easier for the model to manipulate and generate\n",
      "new data instances.\n",
      "In Stable Diffusion, images are ﬁrst encoded into this latent space using a\n",
      "variational autoencoder (VAE)\n",
      "Embedding: [-0.01569414 -0.05789858  0.05127229  0.00781472  0.04648026  0.02926054\n",
      " -0.0210808  -0.033403    0.07469176 -0.02782214]...\n",
      "Sentence: The VAE compresses an image into a lower-\n",
      "dimensional latent representation, which retains the key features and semantic\n",
      "content of the original image\n",
      "Embedding: [-0.00758587  0.0596317   0.05898721 -0.00951841  0.05177183  0.03890264\n",
      " -0.01148539 -0.01885282  0.08711708 -0.00075388]...\n",
      "Sentence: This process facilitates the manipulation of the\n",
      "image at a more abstract level, which is computationally efﬁcient and conceptually\n",
      "powerful.\n",
      "The latent space is designed to have desirable properties, like continuity and\n",
      "smoothness, meaning small changes in the latent representation result in small\n",
      "and predictable changes in the output image\n",
      "Embedding: [-0.0146685  -0.01549698 -0.00160389 -0.02851216  0.04095323  0.01768087\n",
      " -0.00828945 -0.06572758  0.11679225  0.01482207]...\n",
      "Sentence: This is crucial for the gradual\n",
      "transformation and generation processes in the model.\n",
      "For text prompt integration, the model receives textual descriptions or prompts\n",
      "as input\n",
      "Embedding: [ 0.03146309  0.0035662   0.00753676 -0.00464355  0.0080584   0.01578807\n",
      " -0.03749187  0.03490954  0.08790042 -0.0240765 ]...\n",
      "Sentence: These prompts describe the desired output image, such as “a sunny beach”\n",
      "or “a futuristic cityscape.”\n",
      "The challenge lies in mapping these text prompts to the latent space\n",
      "Embedding: [ 0.06968778  0.03987674  0.02924979 -0.02159877  0.0671578  -0.01233774\n",
      "  0.01505953 -0.06674147 -0.01814922 -0.03431608]...\n",
      "Sentence: This is\n",
      "typically achieved using a text encoder, which converts the text prompt into a feature\n",
      "124\n",
      "6\n",
      "Generative Models\n",
      "Figure 6-6 Stable diffusion architecture [7]\n",
      "vector in the same latent space or a compatible one\n",
      "Embedding: [ 0.05447593 -0.063033   -0.03305309  0.01258285  0.05191483  0.06399702\n",
      " -0.06718838 -0.02995317  0.02339983 -0.02636862]...\n",
      "Sentence: This encoding captures the\n",
      "semantic meaning of the text.\n",
      "The encoded text prompt and the latent image representation are combined or\n",
      "aligned in such a way that the text inﬂuences the image generation process\n",
      "Embedding: [ 0.03944653  0.05446613 -0.06387565 -0.03652306  0.05233144  0.01375185\n",
      "  0.01881186 -0.01829509  0.12419679 -0.03765991]...\n",
      "Sentence: This\n",
      "could involve conditioning the diffusion process on the text features or directly\n",
      "modifying the latent image representation based on the text features.\n",
      "The integrated text prompt guides the de-noising process of the diffusion model.\n",
      "As the model iteratively removes noise from the latent representation, it is inﬂuenced\n",
      "by the text features, leading it to generate an image that corresponds to the textual\n",
      "description.\n",
      "The text conditioning process in Stable Diffusion is shown graphically in\n",
      "Figure 6-6\n",
      "Embedding: [ 0.06471845  0.01062457  0.02391275  0.00941386  0.08886634  0.00628793\n",
      " -0.01452229 -0.08558988  0.07140665 -0.03661621]...\n",
      "Sentence: The output of the text transformer is used after word embedding\n",
      "Embedding: [-0.04453928  0.02433785 -0.00233269 -0.02269713  0.00575754  0.04670645\n",
      " -0.01803997  0.02972854  0.10943356 -0.04248039]...\n",
      "Sentence: It\n",
      "is used to generate conditioning text that describes the desired attributes, features,\n",
      "or content that the diffusion model should produce\n",
      "Embedding: [ 0.0080055   0.0090512  -0.04972778  0.07225921  0.06419843  0.03294466\n",
      "  0.01527401  0.01149302  0.06798737 -0.01083949]...\n",
      "Sentence: For example, if you want to\n",
      "generate images of “red apples,” the text transformer might generate the prompt “a\n",
      "picture of a red apple.”\n",
      "6.3.2\n",
      "Gaussian Noise Injection and Removal\n",
      "Adding Gaussian noise to an image is straightforward in TensorFlow\n",
      "Embedding: [-0.03493879 -0.04473055  0.02109947 -0.0020138   0.03550102 -0.04251361\n",
      "  0.04633235 -0.11622632 -0.01842303 -0.12111189]...\n",
      "Sentence: If we have an\n",
      "image as a NumPy array, we can simply generate a random tensor from the normal\n",
      "distribution and add the two tensors together:\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "image = image.astype(’float32’) / 255.0\n",
      "def add_noise(img, noise_level):\n",
      "noise = tf.random.normal(shape=img.shape,\n",
      "6.3\n",
      "Stable Diffusion\n",
      "125\n",
      "mean=0.0, stddev=noise_level)\n",
      "noisy_img = img + noise\n",
      "# Clip the values to maintain them within [0, 1]\n",
      "noisy_img = tf.clip_by_value(noisy_img,\n",
      "clip_value_min=0.0, clip_value_max=1.0)\n",
      "return noisy_img\n",
      "noise_level = 0.1\n",
      "# Adjust the noise level as needed\n",
      "noisy_image = add_noise(image, noise_level)\n",
      "The amount of noise at each stage and the total number of stages are important to\n",
      "the model and the nature of the dataset\n",
      "Embedding: [ 0.04096759 -0.08860758  0.06338503 -0.01461827  0.00886195 -0.07035283\n",
      " -0.00477133 -0.06799877 -0.02740773 -0.07367808]...\n",
      "Sentence: More time steps generally allow for a more\n",
      "gradual and controlled diffusion process, potentially leading to better-quality image\n",
      "generation\n",
      "Embedding: [ 0.01282929 -0.02806653  0.06753463 -0.01495668  0.09506305 -0.09191636\n",
      " -0.141343   -0.05712594  0.0714763   0.00286391]...\n",
      "Sentence: However, this comes at the cost of increased computational complexity\n",
      "and longer training times\n",
      "Embedding: [ 0.00161912 -0.01966293 -0.02874001  0.03044249  0.08642705 -0.0669761\n",
      " -0.1056385  -0.01287     0.03791451 -0.01980644]...\n",
      "Sentence: Typical values for the number of time steps range from\n",
      "25 to several thousands\n",
      "Embedding: [-0.01528636  0.00022355 -0.00911776 -0.02732708 -0.05189179 -0.01283917\n",
      " -0.08863369  0.06768865  0.00037219 -0.02314876]...\n",
      "Sentence: More stages and carefully tuned noise levels can lead to\n",
      "higher ﬁdelity in generated images, but also require more complex and potentially\n",
      "slower models\n",
      "Embedding: [-3.95564688e-03 -8.32807049e-02  6.91510215e-02  7.06938372e-05\n",
      "  4.77238707e-02 -1.07505888e-01 -1.17435604e-01 -7.05607161e-02\n",
      "  6.34421408e-02 -7.17545003e-02]...\n",
      "Sentence: Datasets with more complex and varied images might beneﬁt from\n",
      "more stages and a carefully designed noise schedule.\n",
      "Generally, we would start a low number of time steps, observe the quality of\n",
      "the result, and then increase gradually according to a noise schedule\n",
      "Embedding: [-0.00842095 -0.04070201  0.09034149 -0.02298441  0.02369121 -0.09991103\n",
      " -0.06775875 -0.10069392  0.0203154  -0.07059135]...\n",
      "Sentence: The noise\n",
      "schedules can be linear or nonlinear\n",
      "Embedding: [-0.09048793 -0.09451592  0.01100292  0.03974317 -0.07536696 -0.00273489\n",
      " -0.02714341 -0.12591468  0.02151497 -0.02163229]...\n",
      "Sentence: A linear schedule increases the noise linearly\n",
      "over time, whereas a nonlinear schedule might increase noise more quickly or\n",
      "slowly at different stages\n",
      "Embedding: [-0.09041857 -0.05671176  0.05015106  0.05511112  0.00245987 -0.04577308\n",
      " -0.092549   -0.07775289  0.0562516   0.0140231 ]...\n",
      "Sentence: Nonlinear schedules are often used because they can better\n",
      "model the data distribution of natural images.\n",
      "The code shown above is actually a simpliﬁcation of the noise injection process\n",
      "in a forward diffusion process\n",
      "Embedding: [-0.10200235 -0.05652897  0.04611451  0.04180112 -0.0095487  -0.06241033\n",
      " -0.035433   -0.06887107  0.01172455 -0.01506507]...\n",
      "Sentence: The actual code used is coded slightly differently to\n",
      "allow better control of noise injection\n",
      "Embedding: [-0.05265263 -0.03748471 -0.01682746  0.02341793 -0.02829936 -0.07874317\n",
      "  0.05452709 -0.09838189 -0.07269134 -0.03827088]...\n",
      "Sentence: Denoting the current image at step t as xt,\n",
      "then we create the image at t + 1 as a combination of the original image xt and\n",
      "Gaussian noise, where the proportion of noise versus the original data is determined\n",
      "by the time step t and the parameter βt\n",
      "Mathematically, the image xt+1 at time t + 1 is expressed in a form xt+1 =\n",
      "√1 −βtxt + βtϵ where βt is the noise level at time step t and ϵ is a noise term\n",
      "sampled from a normal distribution N(0, 1)\n",
      "Embedding: [-0.07579348 -0.00130138  0.09186256 -0.0134478   0.0361572  -0.06913516\n",
      "  0.08179501 -0.01407369  0.01407437 -0.02874933]...\n",
      "Sentence: A nice property for Gaussian noise\n",
      "is that it is additive, meaning that instead of calculating xt from xt−1, xt could be\n",
      "calculated from x0 directly as follows:\n",
      "Let αt = 1 −βt, then\n",
      "x1 = √α1.x0 + ϵ\n",
      "\u0002\n",
      "1 −α1\n",
      "x2 = √α2(√α1.x0 +\n",
      "\u0002\n",
      "1 −α1.ϵ) +\n",
      "\u0002\n",
      "1 −α2.ϵ\n",
      "x2 = √α2α1.x0 + ϵ(\n",
      "\u0002\n",
      "1 −α2 +\n",
      "\u0002\n",
      "α2(1 −α1))\n",
      "126\n",
      "6\n",
      "Generative Models\n",
      "The additive variance noise property for a Gaussian noise means that we can add\n",
      "the two terms together to give\n",
      "ϵ(\n",
      "\u0002\n",
      "1 −α2 +\n",
      "\u0002\n",
      "(α2(1 −α1))) = ϵ\n",
      "\u0002\n",
      "1 −α1α2\n",
      "such that we can express xt in terms of x0 succinctly as follows:\n",
      "xt = x0\n",
      "t\u0003\n",
      "i=1\n",
      "√αi + ϵ\n",
      "\u0004\n",
      "\u0005\n",
      "\u0005\n",
      "\u00061 −\n",
      "t\u0003\n",
      "i=1\n",
      "αi\n",
      "So in Python, we have two ways of implementing noise injection\n",
      "Embedding: [-0.05947491 -0.0904327   0.13111076 -0.01579773 -0.00180976 -0.11623451\n",
      "  0.09952974 -0.05494641 -0.0591778  -0.07851855]...\n",
      "Sentence: The original\n",
      "equation is clearer to code, so I prefer to use it.\n",
      "import numpy as np\n",
      "def forward_diffusion(x_0, beta_schedule, t):\n",
      "x_t = x_0\n",
      "for i in range(1, t+1):\n",
      "beta_t = beta_schedule[i-1]\n",
      "noise = np.random.normal(size=x_0.shape)\n",
      "x_t = np.sqrt(1 - beta_t) *\n",
      "x_t + np.sqrt(beta_t) * noise\n",
      "return x_t\n",
      "Using either method produces a sequence of noise-added images as shown in\n",
      "Figure 6-7.\n",
      "This process of adding controlled noise is referred to as reparameterization trick.\n",
      "In the context of Stable Diffusion, it is thus a crucial technique for the effective\n",
      "training of the diffusion process\n",
      "Embedding: [-0.03343391 -0.11072152  0.0349688   0.06248405  0.00887767 -0.09036747\n",
      "  0.001994   -0.04668457 -0.02560837  0.00586415]...\n",
      "Sentence: It allows the model to learn how to add noise in\n",
      "a controlled manner and, more importantly, how to reverse this process during the\n",
      "generation phase\n",
      "Embedding: [-0.0739035  -0.01775763  0.02638917  0.04631007  0.00783119 -0.0193461\n",
      " -0.03628223 -0.06078394  0.01608762  0.00536288]...\n",
      "Sentence: This technique helps in maintaining differentiability of the model,\n",
      "which is essential for training deep learning models using gradient descent.\n",
      "The process of de-noising a noisy image involves the reverse process of the\n",
      "forward diffusion\n",
      "Embedding: [-0.0460431  -0.04588894  0.05093257 -0.01385735  0.01245304 -0.08134539\n",
      " -0.02595082 -0.15692684 -0.01069359 -0.0604852 ]...\n",
      "Sentence: The de-noising process, which is the core of image generation\n",
      "Figure 6-7 Adding noise to an image [8]\n",
      "6.3\n",
      "Stable Diffusion\n",
      "127\n",
      "in Stable Diffusion, involves iteratively removing this noise to reconstruct an image\n",
      "or generate a new one.\n",
      "Begin with a highly noisy image, which could be the result of the forward\n",
      "diffusion process applied to an original image, or it could be a randomly initialized\n",
      "noise image if we are generating new images\n",
      "Embedding: [-0.0447859  -0.04343143  0.0545693   0.01330909  0.01987476 -0.11760364\n",
      " -0.01376814 -0.09807859  0.06092895 -0.02646523]...\n",
      "Sentence: Similar to the forward diffusion\n",
      "process, the de-noising process is iterative and goes through the time steps in reverse\n",
      "order, starting from the last time step and going back to the ﬁrst\n",
      "Embedding: [-0.03966439 -0.07138041  0.02787613 -0.0227795  -0.01338363 -0.05563246\n",
      " -0.06050727 -0.0491151   0.0669777   0.00555604]...\n",
      "Sentence: At each time step,\n",
      "the model predicts the noise that was added at that particular step during the forward\n",
      "process and subtracts it from the current image state.\n",
      "A neural network, typically a U-Net architecture, is used for the de-noising task.\n",
      "This network is trained to predict the noise that was added to the image at each\n",
      "time step\n",
      "Embedding: [-0.06181231 -0.04793271  0.0459301   0.03223639  0.07307446 -0.0064866\n",
      "  0.06692183 -0.09093371  0.05882879 -0.06127792]...\n",
      "Sentence: During the reverse process, the U-Net takes the noisy image and possibly\n",
      "additional conditioning information (like text embeddings in text-to-image models)\n",
      "as input and outputs an estimate of the noise that needs to be removed.\n",
      "The estimated noise is then subtracted from the noisy image, resulting in a less\n",
      "noisy version of the image\n",
      "Embedding: [ 0.00150451 -0.03184823  0.11178505  0.03679793  0.06596392 -0.05813297\n",
      "  0.04403748 -0.13223141  0.08199779 -0.04844855]...\n",
      "Sentence: This process is repeated at each time step, progressively\n",
      "reducing the noise and bringing the image closer to a clear state.\n",
      "By the end of this reverse process, the image has undergone a series of\n",
      "reﬁnements, and, ideally, we are left with a clear, coherent image that either closely\n",
      "resembles the original (in case of image reconstruction) or represents a new image\n",
      "generated based on the provided conditioning (like a text description).\n",
      "The efﬁciency and quality of de-noising depend heavily on the training and\n",
      "architecture of the U-Net model, as well as on the accuracy of the noise prediction at\n",
      "each step\n",
      "Embedding: [-0.0477067  -0.02893805  0.07216663 -0.00489307  0.03673401 -0.06162567\n",
      "  0.01498024 -0.16079609  0.04114806 -0.05077517]...\n",
      "Sentence: A high-level extract for the de-noising process is shown below\n",
      "Embedding: [-0.09469742 -0.02221636  0.02446283 -0.06739653  0.05994065 -0.0834171\n",
      " -0.01372711 -0.069416   -0.02806986 -0.02852493]...\n",
      "Sentence: It assumes\n",
      "we have a pretrained model which can make predictions on the noise.\n",
      "def denoise_image(noisy_image, model, num_timesteps,\n",
      "conditioning_info=None):\n",
      "current_image = noisy_image\n",
      "for time step in reversed(range(num_timesteps)):\n",
      "# U-Net model predicts the noise\n",
      "predicted_noise = model.predict(current_image,\n",
      "time step, conditioning_info)\n",
      "# Subtract the predicted noise from the image\n",
      "current_image = current_image - predicted_noise\n",
      "return current_image\n",
      "At this stage, it is worth to pause the explanation on the de-noising process and\n",
      "discuss the architecture of the U-Net model and how its network is used to predict\n",
      "the noise process.\n",
      "6.3.3\n",
      "The U-Net Model\n",
      "The U-Net model is a type of convolutional neural network (CNN) that is partic-\n",
      "ularly effective for tasks like image segmentation and, as seen in recent advance-\n",
      "ments, for de-noising in diffusion models.\n",
      "128\n",
      "6\n",
      "Generative Models\n",
      "Image segmentation is a process in computer vision where an image is divided\n",
      "into multiple segments (sets of pixels, also known as superpixels)\n",
      "Embedding: [-0.08240532 -0.09213351  0.08928609  0.02586094  0.03472364 -0.06233536\n",
      "  0.01997207 -0.08688165 -0.01872542 -0.08405074]...\n",
      "Sentence: The goal of\n",
      "image segmentation is to simplify or change the representation of an image into\n",
      "something that is more meaningful and easier to analyze\n",
      "Embedding: [ 0.0284457   0.04862168 -0.01161632 -0.04338643  0.05220827 -0.07009082\n",
      " -0.0068966  -0.012649    0.08612766 -0.04699328]...\n",
      "Sentence: It is used to locate objects\n",
      "and boundaries (lines, curves, etc.) in images\n",
      "Embedding: [-0.04117184  0.03481391 -0.07706236 -0.05098831  0.02207234 -0.06441746\n",
      "  0.00733802  0.06235817  0.07326512 -0.02536082]...\n",
      "Sentence: In contrast to image classiﬁcation,\n",
      "which provides a label to the whole image, segmentation adds labels to each pixel\n",
      "or superpixels, thereby splitting (or segmenting) the image into signiﬁcant parts.\n",
      "There are different types of segmentation: semantic, instance, and panoptic, for\n",
      "example\n",
      "Embedding: [ 0.03894532  0.00615992 -0.00598386 -0.05227981  0.03940887 -0.05136339\n",
      "  0.04336018  0.02189399  0.05001079 -0.06240994]...\n",
      "Sentence: They differ mainly in the way the pixels are classiﬁed\n",
      "Embedding: [-0.03345006 -0.06441954 -0.01365469 -0.10369606  0.02176017 -0.10640343\n",
      " -0.03174958  0.00876689  0.06336537 -0.02580383]...\n",
      "Sentence: Semantic segmenta-\n",
      "tion categorizes the pixels into predeﬁned classes; instance segmentation categorizes\n",
      "each class into different instances of the same class\n",
      "Embedding: [ 0.00200407 -0.01156499 -0.0297706  -0.07088374 -0.01560806 -0.06770748\n",
      "  0.05505612 -0.06451605 -0.01306088 -0.04797873]...\n",
      "Sentence: Instance segmentation in the\n",
      "context of Stable Diffusion models would involve generating or modifying an image\n",
      "based on text input, where the model not only recognizes and manipulates different\n",
      "objects within the image but also distinguishes between individual instances of the\n",
      "same type of object\n",
      "Embedding: [ 0.03740254 -0.05953524 -0.00083752  0.01645573  0.06085894 -0.03464726\n",
      "  0.00404062 -0.02085852  0.05919863 -0.10095099]...\n",
      "Sentence: For example, if the prompt text is to generate “picture of\n",
      "a garden with tulips, roses, and daffodils,” instance segmentation would need to\n",
      "identify that the picture needs ﬂowers of different types and generate the image for\n",
      "each ﬂower separately.\n",
      "Panoptic segmentation combines both semantic and instance segmentation and\n",
      "guides the model to generate or modify an image based on text input where\n",
      "the model recognizes, differentiates, and visually represents both “thing” classes\n",
      "(countable objects like animals, vehicles, furniture) and “stuff” classes (uncountable\n",
      "regions like grass, sky, water) in a single coherent image.\n",
      "Stable Diffusion employs a U-Net network in the backward diffusion process\n",
      "to de-noise the image\n",
      "Embedding: [ 0.06102108 -0.04024652  0.01781217 -0.01538355  0.08724023 -0.03916274\n",
      "  0.01594919 -0.0600591   0.07136571 -0.07629912]...\n",
      "Sentence: The U-Net architecture is characterized by a symmetric “U”\n",
      "shape, which includes a contracting path to capture global context (this is equivalent\n",
      "to an encoder network) and an expansive or decoding path that enables precise local\n",
      "information collection\n",
      "Embedding: [-0.00645116 -0.03459954 -0.02657788 -0.06144311  0.00622617 -0.00999909\n",
      " -0.00030217 -0.07009522  0.03771412 -0.02637245]...\n",
      "Sentence: The output of the last layer in the expansive path is usually\n",
      "passed through a 1 × 1 convolution to map the feature vector to the desired number\n",
      "of output classes or dimensions.\n",
      "Linking the encoder and the decoder networks is the skip connections\n",
      "Embedding: [-0.01655058 -0.08444065  0.0229491   0.01765618  0.02227752  0.0318722\n",
      " -0.01518168 -0.08422799 -0.01121968 -0.08483984]...\n",
      "Sentence: They\n",
      "connect the feature maps from the contracting path to the expansive path\n",
      "Embedding: [ 0.04683632 -0.03069248  0.03391916 -0.00585805 -0.02610995  0.05344751\n",
      " -0.051867    0.00918499 -0.00884836  0.0090615 ]...\n",
      "Sentence: Skip\n",
      "connections help in transferring ﬁne-grained details and context information, which\n",
      "is essential for precise localization in tasks like segmentation or for detailed feature\n",
      "reconstruction in de-noising.\n",
      "The architecture is often modiﬁed to include additional inputs, like text embed-\n",
      "dings in text-to-image models, allowing the U-Net to condition its predictions on\n",
      "external information\n",
      "Embedding: [-0.03284286 -0.02624324  0.01376834  0.0237227   0.05010483  0.02221647\n",
      "  0.02612952 -0.0991056   0.05010672 -0.1061376 ]...\n",
      "Sentence: A diagram of a U-Net network is shown in Figure 6-8.\n",
      "6.3\n",
      "Stable Diffusion\n",
      "129\n",
      "Figure 6-8 Diagram of a typical U-Net architecture\n",
      "Embedding: [ 0.03827064 -0.05243386  0.00119154 -0.02163375  0.01024007  0.00371974\n",
      " -0.02477009  0.00852256 -0.01975149 -0.03708073]...\n",
      "Sentence: Note the use of skip connections between\n",
      "the encoder and the decoder networks [9]\n",
      "7\n",
      "Reinforcement Learning\n",
      "Reinforcement learning (RL) is a type of machine learning where an agent learns\n",
      "to make decisions by performing actions in an environment that maximized the\n",
      "reward\n",
      "Embedding: [-0.11938049 -0.072166   -0.00895929  0.03084881 -0.00941646  0.03617667\n",
      " -0.01211955 -0.07764196  0.05114499  0.01283851]...\n",
      "Sentence: The learning process involves the agent interacting with the environment,\n",
      "receiving feedback in terms of rewards or penalties, and using this feedback to reﬁne\n",
      "its decision-making process\n",
      "Embedding: [ 0.06760891  0.03329641 -0.07062864  0.00753407  0.04239763  0.00673595\n",
      "  0.04753596  0.02418545  0.03646459  0.08286496]...\n",
      "Sentence: Gymnasium (formerly known as Gym), developed by\n",
      "OpenAI, is a popular toolkit for developing and comparing reinforcement learning\n",
      "algorithms\n",
      "Embedding: [-0.01858198 -0.02381296 -0.0401948   0.00016786  0.01882459 -0.04001207\n",
      " -0.03288509  0.02193586  0.02087391 -0.01856062]...\n",
      "Sentence: It provides a variety of environments ranging from simple toy tasks to\n",
      "complex real-world problems.\n",
      "RL is a very useful tool in machine learning, but it does involve understanding a\n",
      "fair bit of mathematics to comprehend why the model chooses certain actions\n",
      "Embedding: [-0.09687991 -0.07409923 -0.01178643  0.01489092  0.0447292   0.02798638\n",
      " -0.03051009  0.00676495  0.05526171  0.05656227]...\n",
      "Sentence: If the\n",
      "reader is not familiar with Q-learning and deep network Q-learning, then I suggest\n",
      "the reader studies relevant literature before proceeding\n",
      "Embedding: [-0.0420201  -0.02988473  0.02012924  0.00631223 -0.09392066  0.07721358\n",
      " -0.01551783 -0.00692944 -0.03678712 -0.01230791]...\n",
      "Sentence: Here, we will only discuss\n",
      "the RL at a high level, so the reader can follow the code.\n",
      "7.1\n",
      "Explanations of Reinforcement Learning\n",
      "Reinforcement learning primarily revolves around the concepts of Markov decision\n",
      "processes (MDPs), providing a formal framework for decision-making where\n",
      "outcomes are partly random and partly under the agent’s control\n",
      "Embedding: [-0.11272372  0.00986299  0.02501222 -0.00911074  0.03920596  0.03329578\n",
      "  0.05407651 -0.02531456 -0.00624183  0.10663997]...\n",
      "Sentence: RL algorithms\n",
      "seek to learn “optimal” policies in this context\n",
      "Embedding: [-0.05264163  0.00307141 -0.0006006  -0.01929117  0.03548045  0.01994461\n",
      "  0.0337421  -0.03098967 -0.00071033  0.07330221]...\n",
      "Sentence: The optimal policy, in this context,\n",
      "maximizes the average of future rewards.\n",
      "Imagine trying to deal with a discrete state problem where we are trying to act\n",
      "in an optimal way to maximize future rewards\n",
      "Embedding: [-0.03863128  0.05190753  0.05597483 -0.04380754 -0.01354102  0.03719837\n",
      "  0.0204176   0.04089949  0.04476565  0.12422247]...\n",
      "Sentence: Discrete state means considering\n",
      "discrete time steps and a manageable number of outcomes at any time step\n",
      "Embedding: [-0.05860351  0.04207132 -0.02445411 -0.02036787 -0.05205807  0.02977215\n",
      "  0.03091452 -0.04956535  0.07154407  0.03969784]...\n",
      "Sentence: These\n",
      "two assumptions are necessary to ensure that the problem is solvable\n",
      "Embedding: [-1.0664241e-01  2.9107474e-02  2.4171667e-02  4.8216879e-02\n",
      "  6.4134416e-05  1.5164348e-02  2.0677259e-02 -2.4127757e-02\n",
      " -2.6845073e-02  2.4557311e-02]...\n",
      "Sentence: We further\n",
      "assume that future states depend only on the current state, known as the Markov\n",
      "process’s memoryless assumption.\n",
      "© Philip Hua 2024\n",
      "P\n",
      "Embedding: [-0.08675993  0.01027603  0.00609934  0.02804173  0.00873975  0.04026334\n",
      "  0.00151803 -0.06314642  0.07523552  0.06397151]...\n",
      "Sentence: Hua, Neural Networks with TensorFlow and Keras,\n",
      "https://doi.org/10.1007/979-8-8688-1020-6_7\n",
      "131\n",
      "132\n",
      "7\n",
      "Reinforcement Learning\n",
      "Equation 7-1 Bellman’s equation in general form\n",
      "The main point of these assumptions is that the optimal policy for reinforcement\n",
      "learning is speciﬁc to the Markov process\n",
      "Embedding: [-0.11336222 -0.0441708   0.07779127 -0.01851797 -0.05866486  0.11046548\n",
      "  0.01619263 -0.05569616 -0.02356808  0.1043537 ]...\n",
      "Sentence: If we were to follow the same strategy\n",
      "for our daily life activities, such as making future investments, the optimal strategy\n",
      "would not be one suggested by Bellman’s equation\n",
      "Embedding: [-0.02882026  0.03405591  0.00806956 -0.02777776 -0.04515562  0.02257339\n",
      " -0.01364512 -0.03139571  0.00340103  0.09443589]...\n",
      "Sentence: Equation 7-1 states that the\n",
      "optimal value Q, following a policy π in state S with action a, is the immediate\n",
      "reward after taking action a plus the discounted sum of future rewards, which needs\n",
      "to be estimated\n",
      "Embedding: [-0.13963647  0.0685913   0.03550952  0.0338592  -0.03684077  0.15561755\n",
      "  0.07318343  0.04315581  0.00767722  0.14054742]...\n",
      "Sentence: There are several ways to estimate this, including storing a very\n",
      "large table for every state-action pair S and A or run simulation.\n",
      "For deep neural network learning, DQN uses a deep neural network to approxi-\n",
      "mate the Q-value function in Equation 7-1\n",
      "Embedding: [-0.07233293 -0.08298208 -0.04645159  0.01335902 -0.06009296  0.09050878\n",
      " -0.03500846  0.02060211  0.03214516  0.02387067]...\n",
      "Sentence: This network takes the state as input and\n",
      "outputs Q-values for all possible actions.\n",
      "The network is trained by minimizing the loss function deﬁned as the difference\n",
      "between the current Q-value estimate and the target Q-value from Bellman’s\n",
      "equation\n",
      "Embedding: [-0.07931601  0.03009192  0.00112528  0.04552568 -0.04479551  0.12743841\n",
      "  0.0200278  -0.03757156  0.04159701  0.02126325]...\n",
      "Sentence: The loss function often used is the mean squared error:\n",
      "L(θ) = E(Rt + γ maxa′Qπ(St+1, a′|St = s, a; θ) −Q(St, At; θ))2\n",
      "(7.1)\n",
      "θ are the weights in the neural network\n",
      "Embedding: [-0.09284806 -0.0139687   0.01872673  0.00251737  0.00675977  0.08795198\n",
      " -0.01019757  0.07866796  0.05768851 -0.02547046]...\n",
      "Sentence: In a standard DQN setup, there are\n",
      "two neural networks: the main network and the target network\n",
      "Embedding: [-0.05486982 -0.06544288 -0.00383585  0.00264205  0.00507981  0.09508632\n",
      " -0.02660626 -0.0137241   0.03711691 -0.05532489]...\n",
      "Sentence: The main network\n",
      "estimates the Q-values, while the target network, which is a delayed copy of the\n",
      "main network, provides the target Q-values for the loss calculation\n",
      "Embedding: [-0.04677076  0.05969975  0.02843255  0.0560074   0.02955962  0.09097932\n",
      " -0.02169341  0.03699864  0.10002693 -0.00198331]...\n",
      "Sentence: This separation\n",
      "helps mitigate the problem of moving targets in the training process.\n",
      "However, to simplify our code, we only use one neural network both for training\n",
      "and targeting, so it will take longer to train and be less stable, but it will still work\n",
      "as intended.\n",
      "7.2\n",
      "Gymnasium Library\n",
      "For the purposes of reinforcement learning, we will be using the Gymnasium\n",
      "library, provided by the Farama Foundation\n",
      "Embedding: [-0.05631017 -0.07418722  0.01033906 -0.00392128  0.08237136  0.05436181\n",
      "  0.00134435 -0.06092342  0.02044453 -0.03286639]...\n",
      "Sentence: The Farama Foundation is a nonproﬁt\n",
      "organization dedicated to advancing the ﬁeld of reinforcement learning through\n",
      "promoting better standardization and open source tooling for both researchers and\n",
      "industry.\n",
      "The Gymnasium project’s API contains four key functions: make, reset, step,\n",
      "and render\n",
      "Embedding: [-0.01454062  0.00285346 -0.05720545 -0.00291417  0.03932272  0.03021366\n",
      " -0.06037017 -0.02587199  0.00800092  0.04591376]...\n",
      "Sentence: At the core of Gymnasium is Env, a Python class representing a Markov\n",
      "decision process (MDP) from reinforcement learning theory\n",
      "Embedding: [-0.03968341  0.00985039  0.00200316 -0.10907403  0.02652069 -0.03739964\n",
      "  0.00977538 -0.01300092  0.0006576   0.05744969]...\n",
      "Sentence: Within Gymnasium,\n",
      "environments are implemented as Env classes, along with wrappers, which provide\n",
      "helpful utilities to alter the environment without writing boilerplate code\n",
      "Embedding: [ 0.01910137  0.04059862  0.01629939 -0.04444967  0.06382175 -0.03731823\n",
      " -0.02721596  0.02524146 -0.06750967  0.03170045]...\n",
      "Sentence: For\n",
      "7.2\n",
      "Gymnasium Library\n",
      "133\n",
      "example, in our Space Invaders game, we use a wrapper code to stack screen frames\n",
      "and change the environment into grayscale for more optimized training.\n",
      "Before we can use Gymnasium, we need to install it\n",
      "Embedding: [ 0.01811483 -0.02477969  0.00064624 -0.08017074  0.03825098  0.00138307\n",
      "  0.01213336  0.00974637 -0.05983114 -0.01916242]...\n",
      "Sentence: As Gymnasium licensing is\n",
      "non-distributable, the reader would need to install the library themselves using the\n",
      "procedure below.\n",
      "7.2.1\n",
      "Installing Gymnasium\n",
      "Gymnasium can be installed using pip as follows:\n",
      "pip install gymnasium[atari]\n",
      "pip install gymnasium[accept-rom-license]\n",
      "AutoROM --install-dir /path/to/install\n",
      "pip install ale-py\n",
      "ale-import-roms --import-from-pkg /path/to/install\n",
      "This procedure not only installs Space Invaders but other Atari game environments\n",
      "as well.\n",
      "7.2.2\n",
      "Gymnasium\n",
      "OpenAI Gymnasium is a project that provides an API for all single-agent reinforce-\n",
      "ment learning environments, including implementations of common environments,\n",
      "such as cartpole, pendulum, mountain-car, mujoco, Atari, and more\n",
      "Embedding: [ 0.04422003 -0.04289875 -0.01749346 -0.07655209 -0.00046711  0.02453644\n",
      "  0.00519494  0.01097769 -0.04446366 -0.03249611]...\n",
      "Sentence: In this book,\n",
      "we will use Gymnasium to teach a machine how to play Space Invaders\n",
      "Embedding: [ 0.03150834 -0.0401944   0.03279597 -0.06534092 -0.11199555 -0.00864395\n",
      "  0.01834381 -0.00055442 -0.02759076  0.05521801]...\n",
      "Sentence: For readers\n",
      "who do not know the game, Space Invaders is a 1978 shoot ’em up arcade video\n",
      "game developed and released by Taito in Japan\n",
      "Embedding: [ 0.03124614  0.01944337  0.01685254 -0.09176644 -0.07265665 -0.00145782\n",
      "  0.05461052  0.02390585 -0.02614038  0.08097164]...\n",
      "Sentence: Commonly considered as one of the\n",
      "most inﬂuential video games of all time, Space Invaders was the ﬁrst ﬁxed shooter\n",
      "and set the template for the genre, such as Galaxy and Missile Command\n",
      "Embedding: [ 0.01093006 -0.02456495  0.00229066 -0.11642452 -0.04862553  0.05671395\n",
      "  0.01852622  0.01775437  0.00404731  0.08187697]...\n",
      "Sentence: The goal\n",
      "is to defeat wave after wave of descending aliens with a horizontally moving laser\n",
      "to earn as many points as possible.\n",
      "The Gymnasium API provides a convenient way to explore RL, creating an\n",
      "environment that renders the game on-screen for a speciﬁc game\n",
      "Embedding: [-0.06249553 -0.00374619 -0.02257859 -0.04008291 -0.0399661  -0.02748697\n",
      " -0.02613106 -0.00646627 -0.00311773  0.020758  ]...\n",
      "Sentence: In our case, it\n",
      "displays the Space Invaders game in a window.\n",
      "The agent, represented by our laser gun at the bottom of the screen, acts (moving\n",
      "left and right, staying still, or ﬁring) as shown in Figure 7-1 as dictated by our RL\n",
      "policy and gets rewarded by the environment based on the number of aliens it shoots\n",
      "down\n",
      "Embedding: [-0.00375077  0.03412327 -0.04017426 -0.05379924  0.06049751  0.04400702\n",
      "  0.06870334 -0.04487165  0.05497075  0.0236555 ]...\n",
      "Sentence: Our agent observes the game, which is a digitized version of the screen, in\n",
      "the form of a tensor\n",
      "Embedding: [ 0.00945334  0.01986085 -0.07377875 -0.14476608  0.060458    0.04282743\n",
      "  0.06299748 -0.02337454  0.03888648  0.03105202]...\n",
      "Sentence: Incidentally, instead of the RGB tensor, Gymnasium also offers\n",
      "a 128K representation of the Atari environment, which is a compact state encoding\n",
      "designed to streamline training\n",
      "Embedding: [ 0.02090886 -0.06376767 -0.04121728 -0.05805377  0.01769956  0.07856119\n",
      " -0.03925938 -0.03620998 -0.04476377 -0.0583609 ]...\n",
      "Sentence: Some researchers prefer this representation for its\n",
      "efﬁciency during training, particularly in resource-constrained settings\n",
      "Embedding: [-0.01100319  0.03568914 -0.06184741  0.07041628  0.06399163  0.04488374\n",
      "  0.00515096  0.01444282  0.05336116 -0.0768468 ]...\n",
      "Sentence: However,\n",
      "we will use the RGB tensor because it provides a more general framework that can\n",
      "be easily extended to non-Atari games.\n",
      "134\n",
      "7\n",
      "Reinforcement Learning\n",
      "Figure 7-1 A Space Invaders screenshot\n",
      "7.2.3\n",
      "Explaining the Gymnasium Environment\n",
      "Refer to Figure 7-2\n",
      "Embedding: [-0.003604   -0.08332543  0.00484088 -0.06921244  0.05102656  0.08541346\n",
      "  0.0158103  -0.01805661 -0.01576479  0.01188596]...\n",
      "Sentence: This is a brief explanation of the Gymnasium environment for\n",
      "our game, but the environment for other games operates in the same manner.\n",
      "First, an environment is created using make with an additional keyword “ren-\n",
      "der_mode” that speciﬁes how the environment should be visualized\n",
      "Embedding: [ 0.07585751  0.04566904  0.03774462 -0.04875047  0.07611742 -0.05022757\n",
      "  0.03125983  0.01902178 -0.01111494  0.02079505]...\n",
      "Sentence: See render for\n",
      "details on the default meaning of different render modes\n",
      "Embedding: [ 0.01421314  0.02116754  0.02796843  0.04332964  0.10222235 -0.04269922\n",
      "  0.01047499  0.04271109 -0.04557322 -0.0216699 ]...\n",
      "Sentence: In this example, we use\n",
      "the Space Invaders environment where the agent controls a laser to shoot aliens.\n",
      "After initializing the environment, we reset it to obtain the ﬁrst observation\n",
      "Embedding: [-0.01658496 -0.04235199 -0.00849221  0.04821117  0.02037571 -0.01690786\n",
      "  0.04214441 -0.02614555 -0.00553545  0.04350236]...\n",
      "Sentence: At\n",
      "initialization, we have the option to start the environment with a particular random\n",
      "seed or options to reset the game.\n",
      "Next, the agent performs an action in the environment, step; this can be imagined\n",
      "as moving a robot or pressing a button on a game’s controller that causes a change\n",
      "within the environment\n",
      "Embedding: [-0.00831454 -0.0286696  -0.01135666  0.01021513  0.06641608  0.00575951\n",
      "  0.02545499 -0.01209154  0.00628047  0.0732795 ]...\n",
      "Sentence: As a result, the agent receives a new observation from the\n",
      "updated environment along with a reward for taking the action\n",
      "Embedding: [-0.01031895  0.01029401  0.02074997  0.02356528  0.09037257  0.00526502\n",
      "  0.07427249 -0.07516624  0.04753793  0.09679948]...\n",
      "Sentence: This reward could\n",
      "be, for instance, positive for destroying an enemy or a negative reward for moving\n",
      "into lava\n",
      "Embedding: [-0.0046773   0.04572925  0.06414504  0.00051345  0.04641149  0.0570301\n",
      "  0.05208183 -0.02671874  0.0242262   0.05049947]...\n",
      "Sentence: One such action-observation exchange is referred to as a time step.\n",
      "However, after some time steps, the environment may reach an end, known as\n",
      "the terminal state\n",
      "Embedding: [-0.01975171 -0.03798806 -0.01620394  0.03486784  0.06222374 -0.00801312\n",
      " -0.00615894 -0.00194123  0.09169367  0.07058478]...\n",
      "Sentence: For instance, if the number of lives has been exhausted, or the\n",
      "agent has succeeded in completing a task, the environment will need to stop as the\n",
      "7.2\n",
      "Gymnasium Library\n",
      "135\n",
      "Figure 7-2 The agent-environment loop implemented in Gymnasium [10]\n",
      "agent cannot continue\n",
      "Embedding: [ 0.0436853   0.02274766 -0.04028469 -0.03815947  0.08113404  0.00832454\n",
      "  0.00578241 -0.03360085 -0.04565463  0.02949936]...\n",
      "Sentence: In Gymnasium, if the environment has terminated, this is\n",
      "returned by step\n",
      "Embedding: [ 0.0456224   0.06007512  0.02167109 -0.01174588  0.09319966 -0.00880537\n",
      " -0.04740957  0.01837582  0.00619465  0.00786966]...\n",
      "Sentence: Similarly, we may also want the environment to end after a ﬁxed\n",
      "number of time steps; in this case, the environment issues a truncated signal\n",
      "Embedding: [-0.01023775 -0.00864123  0.11226753 -0.00118416  0.06227078 -0.08808369\n",
      " -0.12185135  0.02416738  0.03368071 -0.02825412]...\n",
      "Sentence: If\n",
      "either of terminated or truncated is true, then reset should be called next to restart\n",
      "the environment.\n",
      "Gymnasium Action and Observation Spaces\n",
      "Each environment speciﬁes the format of valid actions and observations with its\n",
      "action_space and observation_space attributes\n",
      "Embedding: [ 0.07800474 -0.05886165  0.04507071 -0.00555686  0.02308235  0.05581772\n",
      "  0.02536434 -0.0317022  -0.00197679  0.03651419]...\n",
      "Sentence: This is helpful for both knowing the\n",
      "expected input and output of the environment as all valid actions and observation\n",
      "should be contained with the respective space.\n",
      "To control the laser, we use an agent policy, mapping observations to one in the\n",
      "set of possible actions at each step.\n",
      "Every environment should have the attributes action_space and observa-\n",
      "tion_space, both of which should be instances of classes that inherit from space.\n",
      "Gymnasium has support for a majority of possible spaces users might need:\n",
      "1\n",
      "Embedding: [-0.00074333 -0.08017262 -0.03789602 -0.01663722 -0.05939399  0.01797692\n",
      "  0.09300122 -0.05517191 -0.05299525  0.01011401]...\n",
      "Sentence: Box: Describes an n-dimensional continuous space\n",
      "Embedding: [ 0.04261746 -0.02118838 -0.04101121  0.01562892 -0.0211854   0.07435191\n",
      "  0.02229584 -0.0860013   0.04676817 -0.02185352]...\n",
      "Sentence: It is a bounded space where\n",
      "we can deﬁne the upper and lower limits which describe the valid values our\n",
      "observations can take.\n",
      "136\n",
      "7\n",
      "Reinforcement Learning\n",
      "2\n",
      "Embedding: [-0.07985664 -0.03518263 -0.0106501   0.00576915 -0.01845201  0.05619205\n",
      "  0.02075074  0.00493391  0.00178473  0.03485013]...\n",
      "Sentence: Discrete: Describes a discrete space where 0, 1, \n",
      "Embedding: [-0.01282886 -0.01703055 -0.06473939 -0.01565028 -0.05390934 -0.02304642\n",
      "  0.11916873 -0.07249688  0.13847795 -0.01401403]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: ., n −1 are the possible values\n",
      "our observation or action can take\n",
      "Embedding: [-0.04970679 -0.01649085 -0.02865898  0.01919478  0.03173847  0.06444986\n",
      "  0.06561808 -0.04165873  0.04091668  0.00661915]...\n",
      "Sentence: Values can be shifted to a, a+1, \n",
      "Embedding: [-0.08426496  0.02875997 -0.05053202 -0.04386751 -0.09685417  0.03621992\n",
      "  0.02120835 -0.07107538  0.05903027  0.05364054]...\n",
      "Sentence: \n",
      "Embedding: [-0.11883847  0.04829872 -0.00254813 -0.0110112   0.05195084  0.01029176\n",
      "  0.11543327  0.00070075 -0.08592542 -0.07065409]...\n",
      "Sentence: ., a+n−1\n",
      "using an optional argument.\n",
      "Preprocessing\n",
      "The code for creating the environment is shown below, where we perform some\n",
      "preprocessing on the standard environment to optimize the learning process\n",
      "Embedding: [-0.02674392  0.05765654 -0.03161416 -0.01517092 -0.02089391 -0.06513298\n",
      "  0.03812877 -0.06083075 -0.0609309   0.04768099]...\n",
      "Sentence: The\n",
      "initial environment is deﬁned as\n",
      "env = gym.make(\"ALE/SpaceInvaders-v5\",render_mode=\"rgb_array\",\n",
      "repeat_action_probability=0.1,\n",
      "frameskip=1, obs_type=’rgb’)\n",
      "•\n",
      "gym.make(\"ALE/SpaceInvaders-v5\"): This command creates an instance of the\n",
      "Space Invaders game.\n",
      "•\n",
      "render_mode=\"rgb_array\": Sets the mode of rendering to return the game state\n",
      "as an RGB array.\n",
      "•\n",
      "repeat_action_probability=0.1: Sets the probability that an action will be\n",
      "repeated instead of executing a new action\n",
      "Embedding: [ 0.0053004  -0.03022194 -0.01150421 -0.01132014 -0.03809322  0.02657014\n",
      "  0.07202994 -0.01720289 -0.02453618 -0.04038557]...\n",
      "Sentence: The reason why we need to do\n",
      "this is to introduce the exploration instead of exploitation in the action\n",
      "Embedding: [-0.02914207 -0.00050179 -0.01326112  0.01717591  0.03401762  0.05898965\n",
      "  0.0474581  -0.03217746  0.0408536   0.06172726]...\n",
      "Sentence: The\n",
      "environment will, on average, move the laser randomly every one in ten actions.\n",
      "•\n",
      "frameskip=1: Number of frames to skip between each action\n",
      "Embedding: [ 0.03111627 -0.1130407   0.02017128 -0.04372147  0.02269859 -0.01413275\n",
      "  0.09138098 -0.11694377  0.00433784 -0.05659074]...\n",
      "Sentence: Here, it is set to 1,\n",
      "meaning no frame skipping.\n",
      "•\n",
      "obs_type=’rgb’: Sets the observation type to RGB, meaning the agent observes\n",
      "the game state in RGB color.\n",
      "After setting up the standard environment, we introduce some preprocessing using\n",
      "the Atari wrapper library\n",
      "Embedding: [ 0.04595944 -0.0477509  -0.02734212 -0.07248098  0.07363608  0.03282676\n",
      "  0.1056067  -0.04862182 -0.05319279 -0.0430468 ]...\n",
      "Sentence: These settings are chosen to simplify and standardize the\n",
      "input for the learning algorithm, making it easier for the algorithm to process and\n",
      "learn from the game environment:\n",
      "env = gym.wrappers.AtariPreprocessing(env=env, noop_max=30,\n",
      "frame_skip=4,screen_size=84,\n",
      "terminal_on_life_loss=False,\n",
      "grayscale_obs=True,\n",
      "grayscale_newaxis=False,\n",
      "scale_obs=False)\n",
      "•\n",
      "env=env: Passes the original Space Invaders environment.\n",
      "•\n",
      "noop_max=30: Maximum number of “no-operation” (do nothing) actions to be\n",
      "performed at the start of an episode.\n",
      "•\n",
      "frame_skip=4: The number of frames to skip (or repeat the same action) for each\n",
      "step\n",
      "Embedding: [ 0.04696897 -0.03280677  0.00468699 -0.12116376 -0.00297821  0.0555495\n",
      " -0.04119527 -0.01951389 -0.03602532 -0.03417302]...\n",
      "Sentence: Here, it is set to 4.\n",
      "•\n",
      "screen_size=84: Resizes the game screen to an 84x84 square for the observations.\n",
      "•\n",
      "terminal_on_life_loss=False: If set to True, the episode ends when the player\n",
      "loses a life\n",
      "Embedding: [ 0.07867796  0.02928286 -0.03351766 -0.06748143  0.02617561  0.07356149\n",
      " -0.03128489  0.1219096  -0.02985845  0.05508443]...\n",
      "Sentence: Here, it is False, so the episode continues until all three lives are lost.\n",
      "7.2\n",
      "Gymnasium Library\n",
      "137\n",
      "•\n",
      "grayscale_obs=True: Converts the RGB observation to grayscale, reducing the\n",
      "complexity of the input.\n",
      "•\n",
      "grayscale_newaxis=False: Indicates whether a new axis should be added to the\n",
      "grayscale observation (not needed here)\n",
      "Embedding: [ 0.02284596 -0.04656998 -0.0020318  -0.03403703  0.06777702  0.0084175\n",
      " -0.01638174 -0.08256734  0.0222035   0.03086331]...\n",
      "Sentence: Since grayscale by default has only one\n",
      "channel, instead of passing in a 3D tensor, (W,H,3), we just use a 2D tensor\n",
      "(W,H).\n",
      "•\n",
      "scale_obs=False: Decides whether to scale observations\n",
      "Embedding: [ 0.07496845 -0.05821037  0.01743992 -0.00771755  0.00509994 -0.03099641\n",
      "  0.02587748 -0.07518168 -0.06010459 -0.05132875]...\n",
      "Sentence: Here, it is set to False,\n",
      "so observations are not scaled.\n",
      "The line\n",
      "env = gym.wrappers.FrameStack(env=env, num_stack=4,\n",
      "lz4_compress=False)\n",
      "uses the wrapper provided by Gym that stacks consecutive frames of the game\n",
      "environment\n",
      "Embedding: [ 0.04667781 -0.0582631  -0.05567839 -0.01717871  0.04334085 -0.00449874\n",
      "  0.03001961  0.04564204 -0.0524684  -0.0351376 ]...\n",
      "Sentence: This technique is often used in training reinforcement learning agents\n",
      "for video games because it helps the agent to understand motion and the temporal\n",
      "dynamics of the environment\n",
      "Embedding: [-0.04330233  0.0234499  -0.05218728 -0.02145611  0.01138266  0.01064194\n",
      "  0.04990109  0.00449102  0.04158562  0.02223566]...\n",
      "Sentence: By stacking frames, the agent can infer motion\n",
      "from the sequence of images, which is particularly important in games where\n",
      "understanding the dynamics (like the trajectory of moving objects) is crucial for\n",
      "performance\n",
      "Embedding: [ 0.02207408 -0.07952312 -0.04191566 -0.09324239  0.02681747  0.01882094\n",
      "  0.00945043 -0.02646747  0.09527797 -0.02533841]...\n",
      "Sentence: In Space Invaders, knowing the direction and speed of the invaders\n",
      "and projectiles can signiﬁcantly improve the agent’s ability to make decisions.\n",
      "Let’s consider frame_skip=4 and num_stack=4 in more detail:\n",
      "Time step 1: The agent makes a decision, and the corresponding frame (Frame\n",
      "1) is recorded.\n",
      "Time steps 2–4: The agent’s action from Time step 1 is repeated\n",
      "Embedding: [ 0.08015731 -0.0057946  -0.00413258 -0.08112239  0.01871814 -0.00309268\n",
      "  0.02729947 -0.04092772  0.03013298  0.08157279]...\n",
      "Sentence: Frames from\n",
      "these time steps are not recorded (due to frame skipping).\n",
      "Time step 5: The agent makes another decision, and this frame (Frame 5) is\n",
      "recorded.\n",
      "Time steps 6–8: Similar to Time steps 2–4, the action from Time step 5 is\n",
      "repeated, and these frames are not recorded.\n",
      "Time step 9: Another decision is made, and Frame 9 is recorded.\n",
      "Now, if we consider the stacked observation at Time step 9, it will consist of\n",
      "Frames 1, 5, and 9 for sure\n",
      "Embedding: [-0.07637696 -0.06684009  0.00958207 -0.05024815  0.10474824  0.03002814\n",
      " -0.00688437 -0.00862334  0.07796476 -0.02897599]...\n",
      "Sentence: The fourth frame in the stack is Frame 13 from the next\n",
      "decision point\n",
      "Embedding: [ 0.0234124  -0.04770149 -0.08690254 -0.10110447  0.02515468  0.06259841\n",
      "  0.03143222  0.03096695  0.10824393 -0.04402032]...\n",
      "Sentence: There is an overlap between these stacked frames because Frame 5\n",
      "was inﬂuenced by the decision made at Frame 1, and Frame 9 was inﬂuenced by the\n",
      "decision at Frame 5, and so on.\n",
      "This overlapping of frames due to the combination of frame skipping and\n",
      "stacking provides the agent with a sense of temporal continuity, helping it to\n",
      "understand the consequences of its actions over several time steps, despite not\n",
      "observing every single frame in the sequence.\n",
      "7.2.4\n",
      "The Agent\n",
      "class DQNAgent:\n",
      "def __init__(self, state_shape, action_size):\n",
      "138\n",
      "7\n",
      "Reinforcement Learning\n",
      "self.state_shape = state_shape # (4, 84, 84)\n",
      "self.action_size = action_size\n",
      "self.memory = deque(maxlen=2000)\n",
      "self.gamma = 0.95 # discount rate\n",
      "self.epsilon = 1.0 # exploration rate\n",
      "self.epsilon_min = 0.01\n",
      "self.epsilon_decay = 0.995\n",
      "self.learning_rate = 0.001\n",
      "self.model = self._build_model()\n",
      "def _build_model(self):\n",
      "# Neural Net for Deep-Q learning Model\n",
      "model = Sequential()\n",
      "model.add(Conv2D(32, (8, 8), strides=(4, 4),\n",
      "activation=’relu’,\n",
      "input_shape=self.state_shape,\n",
      "data_format=’channels_first’))\n",
      "model.add(Conv2D(64, (4, 4), strides=(2, 2),\n",
      "activation=’relu’,\n",
      "data_format=’channels_first’))\n",
      "model.add(Conv2D(64, (3, 3), activation=’relu’,\n",
      "data_format=’channels_first’))\n",
      "model.add(Flatten())\n",
      "model.add(Dense(512, activation=’relu’))\n",
      "model.add(Dense(256, activation=’relu’))\n",
      "model.add(Dense(self.action_size,\n",
      "activation=’linear’))\n",
      "model.compile(loss=’mse’, optimizer=\n",
      "Adam(learning_rate=self.learning_rate))\n",
      "return model\n",
      "def remember(self, state, action, reward,\n",
      "next_state, done):\n",
      "self.memory.append((state, action, reward,\n",
      "next_state, done))\n",
      "def act(self, state):\n",
      "if np.random.rand() <= self.epsilon:\n",
      "return random.randrange(self.action_size)\n",
      "act_values = self.model.predict(state,verbose=0)\n",
      "return np.argmax(act_values[0])\n",
      "def replay(self, batch_size):\n",
      "minibatch = random.sample(self.memory, batch_size)\n",
      "for state, action, reward, next_state,\n",
      "done in minibatch:\n",
      "target = reward if done else reward +\n",
      "self.gamma *\n",
      "np.amax(self.model.predict(next_state,\n",
      "verbose=0)[0])\n",
      "target_f = self.model.predict(state,verbose=0)\n",
      "target_f[0][action] = target\n",
      "self.model.train_on_batch(state, target_f)\n",
      "7.2\n",
      "Gymnasium Library\n",
      "139\n",
      "if self.epsilon > self.epsilon_min:\n",
      "self.epsilon *= self.epsilon_decay\n",
      "def load(self, name):\n",
      "self.model.load_weights(name)\n",
      "def save(self, name):\n",
      "self.model.save_weights(name)\n",
      "This Python class, DQNAgent, represents a Deep Q-Network (DQN) agent for\n",
      "reinforcement learning and is a typical implementation of a deep network agent.\n",
      "The constructor initializes the agent with the shape of the state space and the\n",
      "number of possible actions, action_size\n",
      "Embedding: [-4.4488497e-02 -1.0864711e-01 -2.7312001e-02  1.1489940e-03\n",
      "  4.9489781e-06  1.7293582e-02 -1.2803197e-05  1.9152043e-02\n",
      "  4.6201143e-02 -1.3410619e-02]...\n",
      "Sentence: It sets up a memory buffer using deque\n",
      "for experience replay, which stores past experiences up to a maximum length,\n",
      "2000 in this case\n",
      "Embedding: [ 0.015093   -0.01460323 -0.05652934 -0.06246671 -0.04001597  0.01295285\n",
      " -0.007312    0.03060328  0.05705834 -0.02508222]...\n",
      "Sentence: It also deﬁnes the discount factor gamma for future rewards, the\n",
      "initial exploration rate epsilon, its minimum value epsilon_min, and the decay rate\n",
      "epsilon_decay\n",
      "Embedding: [-0.06898939  0.01304623 -0.03731495  0.01906283  0.02076845  0.04254903\n",
      "  0.04854398  0.08149663  0.04961176  0.03781407]...\n",
      "Sentence: These are all the parameters for an RL model.\n",
      "The model itself is a convolutional neural network (CNN) model for the Q-value\n",
      "function\n",
      "Embedding: [-0.11036993 -0.04621067 -0.02319533  0.02325098 -0.05733625  0.09309772\n",
      " -0.02124602  0.02093597  0.10584953 -0.05112023]...\n",
      "Sentence: The network takes the state frame stack as input and outputs Q-values for\n",
      "each action\n",
      "Embedding: [-0.02536147 -0.05238334 -0.05854087 -0.00501782 -0.08999451  0.12185414\n",
      "  0.00322279 -0.02475988  0.0814976   0.00490136]...\n",
      "Sentence: The output layer has a size equal to the number of actions, with linear\n",
      "activation since Q-values can be any real number.\n",
      "The constructor also sets the learning rate for the neural network and builds the\n",
      "model.\n",
      "Method Remember Stores experiences (state, action, reward, next state, and done\n",
      "ﬂag) in the replay memory\n",
      "Embedding: [-0.06699523 -0.05507283 -0.06051462  0.02218731 -0.04880086  0.16140588\n",
      "  0.01847942 -0.01108949  0.10600886  0.03854436]...\n",
      "Sentence: This data is used for training the model.\n",
      "Method Act Implements the ϵ-greedy policy for action selection\n",
      "Embedding: [-0.04673979 -0.02719562 -0.01193357  0.0115535   0.06538484  0.09667885\n",
      "  0.03908832  0.02498601  0.01086786  0.08356924]...\n",
      "Sentence: With probability\n",
      "ϵ, it selects a random action (exploration), and with probability 1-ϵ, it chooses the\n",
      "best action based on the model’s predictions (exploitation).\n",
      "Method Replay Samples a mini batch from the memory and performs a learning\n",
      "step\n",
      "Embedding: [-0.04227084 -0.0839468  -0.02435396  0.04481223  0.01925007  0.04672389\n",
      "  0.08444513 -0.0161879   0.06718679  0.04596767]...\n",
      "Sentence: The method updates the Q-values using the Bellman equation\n",
      "Embedding: [-0.08723394  0.03968051 -0.00444817 -0.00217118 -0.14794847  0.03172345\n",
      "  0.00559437  0.00306693  0.02552645  0.0564932 ]...\n",
      "Sentence: The agent uses\n",
      "experience replay to break the correlation between consecutive experiences and\n",
      "stabilize the learning process.\n",
      "7.2.5\n",
      "Memory Replay\n",
      "It is worth understanding why we need a replay buffer as this is not part of the\n",
      "standard RL literature\n",
      "Embedding: [ 0.03468134 -0.08062036 -0.03387135 -0.01067986 -0.01635046  0.08625666\n",
      "  0.03454768 -0.05309754  0.094315   -0.0083893 ]...\n",
      "Sentence: However, it is often used in RL for games for several reasons:\n",
      "1\n",
      "Embedding: [-0.07545247 -0.02260472 -0.07722872 -0.04612922  0.03927943  0.02727309\n",
      "  0.03498577  0.04884554  0.11624782  0.02949328]...\n",
      "Sentence: Reducing the Correlation Between Consecutive Experiences: In a sequential\n",
      "learning process, consecutive experiences are often highly correlated\n",
      "Embedding: [ 0.06819593 -0.05048229  0.05578708  0.02514365 -0.02817161  0.07804126\n",
      " -0.01425721 -0.05379054  0.08595451 -0.05988846]...\n",
      "Sentence: In the case\n",
      "of Space Invaders, consecutive frames are highly correlated with the preceding\n",
      "frames because of the movement of objects on the screen\n",
      "Embedding: [ 0.04980109 -0.07940196  0.05361358 -0.09904002  0.07547874  0.02240366\n",
      "  0.0221996  -0.08115642  0.11228587 -0.0462536 ]...\n",
      "Sentence: This correlation can\n",
      "140\n",
      "7\n",
      "Reinforcement Learning\n",
      "lead to instability and inefﬁciency in the learning process, as the model might\n",
      "overﬁt to recent experiences and not learn effectively from a more diverse set\n",
      "of experiences\n",
      "Embedding: [ 0.01386636 -0.06111217  0.02953529  0.07773687 -0.04384044  0.00906594\n",
      " -0.08214545  0.00836925 -0.00192886  0.02254432]...\n",
      "Sentence: By sampling randomly from the replay buffer, the experiences\n",
      "used in training are more varied, reducing the correlation and improving learning\n",
      "stability.\n",
      "2\n",
      "Embedding: [ 0.0520506  -0.06936775  0.00780261 -0.01463711  0.01079547  0.05463009\n",
      "  0.05428428 -0.02056801  0.07265646 -0.04239435]...\n",
      "Sentence: More Efﬁcient Use of Past Experiences: In standard online learning, an experi-\n",
      "ence would contribute to learning only at the time it occurs\n",
      "Embedding: [ 0.00249135  0.01143259 -0.01612579  0.01142025  0.05576076  0.03371432\n",
      " -0.00693067  0.01202421  0.05708683  0.00887516]...\n",
      "Sentence: With a replay buffer,\n",
      "past experiences are stored and reused in multiple learning updates, allowing\n",
      "the agent to learn more efﬁciently from a limited set of experiences\n",
      "Embedding: [ 0.06068017 -0.05193468 -0.04768011 -0.00753595 -0.03075455  0.05413567\n",
      "  0.02729274 -0.06592094  0.06421397 -0.02973478]...\n",
      "Sentence: This is\n",
      "particularly important in environments where obtaining new experiences can be\n",
      "costly or time-consuming.\n",
      "3\n",
      "Embedding: [ 0.03676231 -0.04348981  0.01054946  0.02087156  0.0684885  -0.0456178\n",
      " -0.02553483 -0.00771053  0.0263896   0.01216369]...\n",
      "Sentence: Reducing Variance in Updates: Learning from a batch of experiences, as opposed\n",
      "to learning from a single experience at a time, can help reduce the variance in the\n",
      "learning updates\n",
      "Embedding: [ 0.04576685 -0.00239772  0.06201496  0.06320984  0.02695487  0.00890483\n",
      "  0.00101625 -0.04746393  0.04325638  0.00203727]...\n",
      "Sentence: This batch learning approach tends to lead to smoother, more\n",
      "stable learning over time.\n",
      "4\n",
      "Embedding: [-0.04610222 -0.06229194  0.02466956  0.02453736 -0.01725949  0.00344391\n",
      " -0.02111556 -0.04737319 -0.11762923 -0.03759301]...\n",
      "Sentence: Improving Data Efﬁciency: In complex environments, it’s crucial to make the\n",
      "most of each piece of data\n",
      "Embedding: [ 0.05259467  0.0150532   0.00472823  0.00688037  0.02984403 -0.07857575\n",
      " -0.05807914 -0.0156998  -0.00411321  0.02827688]...\n",
      "Sentence: Experience replay allows the agent to learn from each\n",
      "experience multiple times, which is more data efﬁcient than learning once and\n",
      "discarding the experience.\n",
      "5\n",
      "Embedding: [ 0.00743631 -0.07395486 -0.03656822  0.00432785  0.01015712  0.06502803\n",
      "  0.04308069 -0.07133598  0.06986362 -0.04227088]...\n",
      "Sentence: Balancing the Distribution of Experiences: Certain experiences may be rare\n",
      "but signiﬁcant (like critical mistakes or successful strategies)\n",
      "Embedding: [ 0.03245805  0.0139148   0.01987283  0.01934261 -0.01227838  0.00288903\n",
      " -0.01980469  0.0461853   0.04260795 -0.02830179]...\n",
      "Sentence: A replay buffer\n",
      "ensures that these experiences have a lasting impact and are considered over\n",
      "many learning updates, rather than being quickly overshadowed by more frequent\n",
      "but less important experiences.\n",
      "6\n",
      "Embedding: [ 0.04920636 -0.06422307  0.03274462 -0.03714714  0.02807465  0.04715679\n",
      "  0.03888519 -0.02434494  0.11069435 -0.01471446]...\n",
      "Sentence: Stabilizing Learning in Deep Learning Models: When using deep neural net-\n",
      "works for function approximation (as in DQN), training on correlated data\n",
      "can lead to catastrophic forgetting or unstable convergence\n",
      "Embedding: [-0.06221585 -0.12106892  0.05778244  0.0627695  -0.03492353  0.04840583\n",
      " -0.03989928 -0.07074063 -0.04411145 -0.05322396]...\n",
      "Sentence: Experience replay\n",
      "mitigates this by providing a more stable, diverse set of experiences for training.\n",
      "The most challenging part to explain, particularly if the reader is unfamiliar with\n",
      "Q-learning, involves the following lines of code:\n",
      "target = reward if done else reward + self.gamma *\n",
      "np.amax(self.model.predict(next_state,verbose=0)[0])\n",
      "target_f = self.model.predict(state,verbose=0)\n",
      "target_f[0][action] = target\n",
      "This code is part of the Q-learning update rule in a DQN\n",
      "Embedding: [-0.06023987 -0.05844051  0.02941022  0.08819981 -0.00520735  0.05810951\n",
      "  0.06743091 -0.01203471  0.04808991  0.01588522]...\n",
      "Sentence: It adjusts the model’s\n",
      "predictions based on the new information gained from taking an action and\n",
      "observing the outcome (reward and next state)\n",
      "Embedding: [-0.04722891 -0.0090171   0.01615199  0.05565004  0.07193583  0.09749187\n",
      "  0.00189688  0.00787384  0.08989967  0.05573028]...\n",
      "Sentence: The goal is to make the model’s\n",
      "predictions of Q-values as accurate as possible, enabling the agent to make better\n",
      "decisions about which actions to take in different states.\n",
      "To calculate the target Q-value, we use\n",
      "target = reward if done else reward + self.gamma *\n",
      "np.amax(self.model.predict(next_state, verbose=0)[0])\n",
      "7.2\n",
      "Gymnasium Library\n",
      "141\n",
      "This line calculates the target Q-value for the current state-action pair\n",
      "Embedding: [-0.0871617   0.00932943 -0.01906114  0.0617683  -0.04413633  0.04380651\n",
      "  0.07504051  0.05150428  0.02207268  0.0429365 ]...\n",
      "Sentence: If the game\n",
      "is over, then done is True, and the target is simply the immediate reward\n",
      "Embedding: [-0.01246405  0.04835222  0.00047458 -0.02805157  0.09533805  0.07258872\n",
      "  0.02748221 -0.04171829  0.01328315  0.08130693]...\n",
      "Sentence: This is\n",
      "because there are no future rewards to consider if the episode has ended.\n",
      "If done is False, the target is calculated using the Bellman equation:\n",
      "reward + self.gamma ∗np.amax(...) :\n",
      "Here, self.gamma is the discount factor\n",
      "Embedding: [-0.03811918 -0.03039231  0.0671472  -0.03454111  0.07774263  0.05621758\n",
      "  0.03497578  0.0474811   0.09222233  0.10189918]...\n",
      "Sentence: It discounts the value of future rewards,\n",
      "reﬂecting the idea that immediate rewards are more valuable than distant rewards.\n",
      "np.amax(self.model.predict(next_state, verbose=0)[0]): This predicts the Q-values\n",
      "for all possible actions in the next state (next_state) and takes the maximum\n",
      "Embedding: [-0.11150889  0.0088446   0.02667898  0.07698564  0.04206061  0.02214551\n",
      "  0.03177113  0.03888175  0.07429394  0.07171282]...\n",
      "Sentence: This\n",
      "represents the best possible future reward that can be obtained from the next state,\n",
      "according to the current model.\n",
      "The line\n",
      "target_f = self.model.predict(state, verbose=0)\n",
      "predicts the Q-values for all actions given the current state using the model\n",
      "Embedding: [-0.1355157   0.02162159 -0.0400387   0.0528326  -0.01026513  0.08246212\n",
      "  0.01210369  0.03499462  0.02451501  0.03262273]...\n",
      "Sentence: It\n",
      "essentially asks, “Given the current state, what are the Q-values (predicted future\n",
      "rewards) for each possible action?” The target_f is an array containing the predicted\n",
      "Q-values for each action in the current state\n",
      "Embedding: [-0.06588724  0.05293392 -0.08757709  0.01833133  0.02129821  0.08902529\n",
      "  0.08737615  0.02735877 -0.00585834  0.01172688]...\n",
      "Sentence: The size of target_f is the size of the\n",
      "model’s output layer which has been set to the number of possible actions.\n",
      "Once an action has been taken\n",
      "target_f[0][action] = target\n",
      "updates the Q-value for the action that was actually taken\n",
      "Embedding: [ 0.03791958 -0.00952066 -0.01756088  0.05393807  0.04530011  0.08035286\n",
      "  0.00436842  0.04707443  0.05438755  0.03698023]...\n",
      "Sentence: The Q-value for this\n",
      "action, which was originally predicted by the model, is replaced with the target\n",
      "calculated earlier, and the model is retrained again with the better estimated Q-value.\n",
      "self.model.train_on_batch(state, target_f)\n",
      "The call to self.model.train_on_batch(state, target_f) updates the neural network’s\n",
      "weights to minimize the difference between its predicted Q-values and the target_f\n",
      "Q-values\n",
      "Embedding: [-0.08930526 -0.03056078  0.00929187  0.13133447 -0.03558616  0.04447654\n",
      "  0.00067894  0.01205919  0.00209752 -0.03917818]...\n",
      "Sentence: This update is done using backpropagation and an optimization algorithm\n",
      "Adam deﬁned in the model’s compilation step previously.\n",
      "GPU Utilization for RL\n",
      "The code written is not particularly optimized for GPU\n",
      "Embedding: [-0.07877955 -0.02816558 -0.02077933  0.02303839 -0.00286648 -0.0643735\n",
      " -0.06238256 -0.05503212 -0.10384945 -0.01989524]...\n",
      "Sentence: For reinforcement learning\n",
      "using DQN and ALE, it is known that the GPU will be underutilized, so in this\n",
      "particular instance, it is better to run the project using a fast CPU rather than relying\n",
      "on a GPU.\n",
      "8\n",
      "Using Pretrained Networks\n",
      "For some applications, it is almost mandatory to use networks that have been\n",
      "speciﬁcally pretrained to handle special tasks, such as large language models\n",
      "(LLMs), which involve complex natural language chatbots that are impossible for\n",
      "an individual to train\n",
      "Embedding: [-0.03623137 -0.06029879  0.05032694  0.02281983 -0.03153078  0.04271394\n",
      " -0.03930944  0.01847663  0.03396397 -0.03663225]...\n",
      "Sentence: These research networks are typically straightforward to use\n",
      "through their APIs\n",
      "Embedding: [-0.08036892 -0.06269778 -0.04677974  0.06675547  0.03677968 -0.03611809\n",
      " -0.09796448  0.07544163 -0.0075048  -0.03823478]...\n",
      "Sentence: The key is to thoroughly read and familiarize ourselves with\n",
      "the API documentation\n",
      "Embedding: [-0.08868682 -0.02785501 -0.05322625  0.02548755  0.01047937 -0.05813536\n",
      " -0.05178072  0.05433443 -0.02089405 -0.03230172]...\n",
      "Sentence: These documents provide detailed instructions on making\n",
      "requests to the API, including information about endpoints, parameters, and other\n",
      "crucial details.\n",
      "8.1\n",
      "GPT-4\n",
      "At the time of writing, OpenAI’s GPT-4 is a paid service that includes DALL-E\n",
      "and the speech recognition tool Whisper\n",
      "Embedding: [-0.09910919 -0.04403576 -0.00295597 -0.02027783  0.00195837 -0.02524789\n",
      "  0.02233423 -0.00683162  0.03240047 -0.113954  ]...\n",
      "Sentence: We must open an account with OpenAI\n",
      "and create an API key\n",
      "Embedding: [-0.02951702 -0.039577   -0.08643127  0.01187469 -0.01047043 -0.04188108\n",
      " -0.00169329 -0.00285658  0.07193407  0.02566719]...\n",
      "Sentence: Once this is completed, it is relatively straightforward to\n",
      "install and send queries\n",
      "Embedding: [-0.00447412 -0.04224239 -0.04235635  0.04714023 -0.06238241 -0.02775064\n",
      "  0.03444491 -0.01270841 -0.1042253  -0.00239117]...\n",
      "Sentence: Before GPT-4, it was necessary to use less sophisticated\n",
      "libraries to perform natural language processing tasks, such as sentiment analysis,\n",
      "spam ﬁltering, etc., but with GPT-4, these libraries have effectively became obsolete\n",
      "overnight\n",
      "Embedding: [-0.02121951 -0.02544784  0.01623596  0.01370085  0.07689029 -0.02347031\n",
      " -0.01709164  0.02632671  0.0118083  -0.02978457]...\n",
      "Sentence: We can install the API for Python using\n",
      "pip install openai\n",
      "After which, we can create a client to stream requests and get responses back.\n",
      "from openai import OpenAI\n",
      "client = OpenAI()\n",
      "stream = client.chat.completions.create(\n",
      "model=\"gpt-4\",\n",
      "messages=[\"role\": \"user\", \"content\": \"Hello AI world!\"],\n",
      "stream=True,\n",
      ")\n",
      "for chunk in stream:\n",
      "© Philip Hua 2024\n",
      "P\n",
      "Embedding: [-0.06843039 -0.01734155 -0.01489768  0.02364171  0.03969854 -0.08649607\n",
      "  0.01816278 -0.01016181  0.00176391 -0.03584683]...\n",
      "Sentence: Hua, Neural Networks with TensorFlow and Keras,\n",
      "https://doi.org/10.1007/979-8-8688-1020-6_8\n",
      "143\n",
      "144\n",
      "8\n",
      "Using Pretrained Networks\n",
      "if chunk.choices[0].delta.content is not None:\n",
      "print(chunk.choices[0].delta.content, end=\"\")\n",
      "Generating images with DALL-E from a prompt is also easy\n",
      "Embedding: [-0.06005315 -0.02449813  0.00908026  0.02391255  0.02001003 -0.00018376\n",
      " -0.01121426 -0.07283958 -0.03787132 -0.0910091 ]...\n",
      "Sentence: DALL-E will return\n",
      "an array of URLs, with the number determined by the parameter n = 1 in the code\n",
      "below\n",
      "Embedding: [-0.03685798  0.02775699 -0.0188889   0.02563879 -0.12117922  0.00221113\n",
      "  0.02618017 -0.06011857  0.04799503 -0.0845564 ]...\n",
      "Sentence: DALL-E 2 offers only “standard” quality, while the E-3 version includes an\n",
      "“HD” option.\n",
      "from openai import OpenAI\n",
      "client = OpenAI()\n",
      "response = client.images.generate(\n",
      "model=\"dall-e-3\",\n",
      "prompt=\"a white siamese cat\",\n",
      "size=\"1024x1024\",\n",
      "quality=\"standard\",\n",
      "n=1,\n",
      ")\n",
      "image_url = response.data[0].url\n",
      "Currently, only DALL-E 2 supports the creation of edited image versions through\n",
      "masking and generating image variations, as shown in Figures 8-1 and 8-2.\n",
      "from openai import OpenAI\n",
      "client = OpenAI()\n",
      "response = client.images.edit((\n",
      "model=\"dall-e-2\",\n",
      "image=open(\"sunlit_lounge.png\", \"rb\"),\n",
      "mask=open(\"mask.png\", \"rb\"),\n",
      "prompt=\"A sunlit indoor lounge area\n",
      "with a pool containing a flamingo\",\n",
      "n=1,\n",
      "size=\"1024x1024\"\n",
      ")\n",
      "image_url = response.data[0].url\n",
      "To create variation of an image, we would need to upload our own image.\n",
      "from openai import OpenAI\n",
      "client = OpenAI()\n",
      "response = client.images.create_variation(\n",
      "image=open(\"image_edit_original.png\", \"rb\"),\n",
      "n=2,\n",
      "size=\"1024x1024\"\n",
      ")\n",
      "image_url = response.data[0].url\n",
      "8.1\n",
      "GPT-4\n",
      "145\n",
      "Figure 8-1 OpenAI image generation using DALL-E [11]\n",
      "Figure 8-2 Another example of image generation using prompting [11]\n",
      "8.1.1\n",
      "Fine-Tuning ChatGPT\n",
      "One of the most powerful and useful applications using ChatGPT is the ability\n",
      "to ﬁne-tune the model with our own dataset\n",
      "Embedding: [ 0.01032007 -0.00691344  0.04373556  0.07041484  0.02850996 -0.0828974\n",
      " -0.05570061 -0.03900368  0.07673453 -0.05685689]...\n",
      "Sentence: Before ﬁne-tuning though, OpenAI\n",
      "suggests we should go through prompt engineering, prompt chaining (breaking\n",
      "complex tasks into multiple prompts), and API function calling ﬁrst as ﬁne-tuning\n",
      "does require time and effort and money.\n",
      "As an example, consider the following code example to ﬁne-tune English to\n",
      "Italian.\n",
      "8.1.1.1 Prepare the Dataset\n",
      "The dataset should be a collection of English prompts and their Italian translations.\n",
      "This could be in a CSV ﬁle with two columns: “english” and “italian.”\n",
      "146\n",
      "8\n",
      "Using Pretrained Networks\n",
      "Example dataset (italian_language_dataset.csv):\n",
      "english,italian\n",
      "\"Hello, how are you?\",\"Ciao, come stai?\"\n",
      "\"I am learning Italian.\",\"Sto imparando l’italiano.\"\n",
      "\"What is your name?\",\"Come ti chiami?\"\n",
      "...\n",
      "Then write a Python script to do the training:\n",
      "import openai\n",
      "import pandas as pd\n",
      "from sklearn.model_selection import train_test_split\n",
      "# Load our dataset\n",
      "df = pd.read_csv(’italian_language_dataset.csv’)\n",
      "# Split the dataset into training and validation sets\n",
      "train_df , valid_df = train_test_split(df, test_size=0.1)\n",
      "def format_data(row):\n",
      "return {\"prompt\": row[’english ’] + \"\\ n\",\n",
      "\"completion\": row[’italian ’] + \"\\ n\"}\n",
      "# Format the data for OpenAI\n",
      "train_data = list(train_df.apply(format_data , axis=1))\n",
      "valid_data = list(valid_df.apply(format_data , axis=1))\n",
      "# Set our API key\n",
      "openai.api_key = ’your-api-key’\n",
      "# Start the fine-tuning process\n",
      "fine_tuning_response = openai.FineTune.create(\n",
      "training_file=train_data ,\n",
      "validation_file=valid_data ,\n",
      "model=\"gpt-4\",\n",
      "# specify the model version\n",
      "n_epochs=3,\n",
      "# number of training epochs\n",
      "batch_size=4,\n",
      "# training batch size\n",
      ")\n",
      "print(fine_tuning_response)\n",
      "The number of epochs depends on the complexity of the dataset in the same manner\n",
      "as normal training\n",
      "Embedding: [ 0.01869365 -0.04746414 -0.06667763  0.0491172  -0.01874018 -0.02316504\n",
      "  0.02482413 -0.00250652 -0.02309242 -0.10009075]...\n",
      "Sentence: If the task is very different from what the model was originally\n",
      "trained on, or if it is particularly complex, more epochs might be necessary.\n",
      "Monitor the model’s performance on a validation set and stop the training when\n",
      "the performance on this set starts to degrade\n",
      "Embedding: [-0.01125812  0.00669595  0.0242834   0.00785305  0.04632588 -0.04077025\n",
      " -0.10817772 -0.03519642  0.00847687 -0.09769183]...\n",
      "Sentence: In practice, a common approach\n",
      "is to start with a relatively small number of epochs (like 3–5) and then adjust\n",
      "based on the model’s performance and whether it shows signs of overﬁtting or\n",
      "underﬁtting\n",
      "Embedding: [ 0.00652667  0.00022056  0.04653286  0.00018735  0.00155729 -0.05413278\n",
      " -0.162485    0.00930498 -0.06272542 -0.09978252]...\n",
      "Sentence: For ﬁne-tuning large models like GPT-4, it is especially important to\n",
      "monitor performance closely, as these models can quickly overﬁt to a small dataset.\n",
      "8.2\n",
      "VGG\n",
      "147\n",
      "8.2\n",
      "VGG\n",
      "There are two common VGG models, VGG-16 and VGG-19\n",
      "Embedding: [-0.02439789  0.01203256 -0.06297021  0.01266373  0.07060206 -0.06321241\n",
      " -0.02816614  0.076008   -0.00719718 -0.05129872]...\n",
      "Sentence: VGG stands for\n",
      "Visual Geometry Group; it is a standard deep convolutional neural network (CNN)\n",
      "architecture with multiple layers\n",
      "Embedding: [-0.08446383 -0.00654346 -0.07548467  0.00106748  0.02602619 -0.02844346\n",
      " -0.01371148  0.0208342   0.04292347 -0.08169258]...\n",
      "Sentence: The numbers 16 and 19 refer to the number of\n",
      "layers with VGG-16 or VGG-19 consisting of 16 and 19 convolutional layers,\n",
      "respectively.\n",
      "Both models are used for image recognition\n",
      "Embedding: [-0.05856051  0.00267151 -0.02915906 -0.0794144   0.05928496  0.05740746\n",
      " -0.01005307  0.04585209  0.0449089  -0.10139548]...\n",
      "Sentence: The VGGNet-16 supports 16 layers\n",
      "and can classify images into 1000 object categories, including keyboard, animals,\n",
      "pencil, mouse, etc\n",
      "Embedding: [ 0.02609064 -0.0695289   0.03071268 -0.03098169  0.06629522  0.01706165\n",
      " -0.06590522 -0.05484844 -0.0341531  -0.0007272 ]...\n",
      "Sentence: Both models take an input as an RGB image of size 224 ×\n",
      "224\n",
      "Embedding: [ 0.01977638 -0.09397599 -0.04797554 -0.01951065  0.00228855 -0.02597901\n",
      " -0.10621275  0.025689    0.01053053 -0.07495517]...\n",
      "Sentence: The network architecture and an example of the feature retention through\n",
      "the layers are shown in Figure 8-3\n",
      "Embedding: [-0.02604523 -0.03200696  0.06008377  0.04757766  0.07713606  0.04831941\n",
      " -0.00345177 -0.01666015 -0.01533516 -0.06706052]...\n",
      "Sentence: Notice that as we go through the layers, only\n",
      "important and abstract features are retained as shown in Figure 8-4\n",
      "Embedding: [-0.02840642  0.06484866  0.10752727  0.10101534  0.11889118  0.07015124\n",
      " -0.03871575 -0.04431361  0.02450353 -0.03733643]...\n",
      "Sentence: We can either\n",
      "use VGGNet pretrained weights to classify objects, ﬁne-tune the weights, or use a\n",
      "VGGNet pretrained layer to help with training our network as we did for the GAN\n",
      "project using VGG-19.\n",
      "Figure 8-3 An example of feature retention for VGG-16\n",
      "Figure 8-4 Network architecture for VGG-16 [12]\n",
      "148\n",
      "8\n",
      "Using Pretrained Networks\n",
      "8.3\n",
      "YOLO\n",
      "YOLO, which stands for “You Only Look Once,” is a popular series of models\n",
      "used for object detection in computer vision\n",
      "Embedding: [-0.06143706 -0.02763934  0.00208894  0.04681909  0.07759981  0.0355493\n",
      "  0.02303104 -0.04962096  0.00698293 -0.12284723]...\n",
      "Sentence: YOLO is renowned for its speed\n",
      "and accuracy, making it a preferred choice for real-time object detection systems.\n",
      "It represents a signiﬁcant shift from the traditional two-step approach of object\n",
      "detection (where one step identiﬁes objects and another classiﬁes them) to a single-\n",
      "step process.\n",
      "Using YOLO is similar to other pretrained networks, and the following template\n",
      "should be familiar to readers:\n",
      "import cv2\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "from tensorflow.keras.models import load_model\n",
      "# Load YOLO model assuming you\n",
      "# have converted YOLO weights\n",
      "# to a Keras model\n",
      "yolo_model = load_model(’yolo_model.h5’)\n",
      "# Function to process the image and return model’s input\n",
      "def process_image(image_path):\n",
      "image = cv2.imread(image_path)\n",
      "image = cv2.resize(image, (416, 416))\n",
      "image = image / 255.0\n",
      "# Normalize pixel values\n",
      "image = image[np.newaxis , ...]\n",
      "# Add batch dimension\n",
      "return image\n",
      "# Process an image\n",
      "input_image = process_image(’path_to_your_image.jpg’)\n",
      "# Run the model\n",
      "output = yolo_model.predict(input_image)\n",
      "# Output needs to be post-processed to get\n",
      "# bounding boxes and class labels\n",
      "# This step can be complex and depends\n",
      "# on the output format of your YOLO model\n",
      "# Usually involves thresholding ,\n",
      "# non-max suppression , etc.\n",
      "# For demonstration , let’s assume we have\n",
      "# a function to interpret the output\n",
      "boxes, scores, classes = process_yolo_output(output,\n",
      "threshold=0.5)\n",
      "# Function to draw the results (boxes, scores, classes)\n",
      "# on the image\n",
      "# This is a simplified version , actual\n",
      "# implementation may vary\n",
      "def draw_boxes(image, boxes, scores, classes):\n",
      "8.3\n",
      "YOLO\n",
      "149\n",
      "for box, score, class_id in zip(boxes, scores, classes):\n",
      "x, y, w, h = box\n",
      "cv2.rectangle(image, (x, y), (x + w, y + h),\n",
      "(255, 0, 0), 2)\n",
      "cv2.putText(image, f\"{class_id} {score:.2f}\",\n",
      "(x, y - 5), cv2.FONT_HERSHEY_SIMPLEX ,\n",
      "0.5, (255, 0, 0), 2)\n",
      "return image\n",
      "# Draw the boxes on the original image and display/save it\n",
      "output_image = draw_boxes(cv2.imread(’path_to_your_image.jpg’),\n",
      "boxes, scores, classes)\n",
      "cv2.imshow(\"Detection Output\", output_image)\n",
      "cv2.waitKey(0)\n",
      "cv2.destroyAllWindows()\n",
      "The only difference to note here is the conversion between YOLO and Keras\n",
      "Embedding: [-0.01314277  0.01983674  0.04390423 -0.02220591  0.05549907 -0.08389951\n",
      " -0.00063255  0.03333953 -0.01999775 -0.09442909]...\n",
      "Sentence: YOLO\n",
      "is implemented in Darknet which has a different framework structure than Keras.\n",
      "8.3.1\n",
      "Converting YOLO Weights to Keras\n",
      "•\n",
      "Obtain YOLO Weights and Conﬁg Files: First, we need the original YOLO\n",
      "weights and conﬁguration ﬁles\n",
      "Embedding: [-0.05466498 -0.00843477  0.01768535  0.01284109  0.01648756 -0.03912348\n",
      " -0.01947638  0.02079046 -0.02159815 -0.03938882]...\n",
      "Sentence: These are usually available from the ofﬁcial\n",
      "YOLO website or the repository of the speciﬁc YOLO version we are using.\n",
      "•\n",
      "Choose a Conversion Tool: There are tools and scripts available online that can\n",
      "convert YOLO weights (which are typically in a format speciﬁc to the Darknet\n",
      "framework) to a format compatible with Keras\n",
      "Embedding: [-0.01273278 -0.01671164 -0.01304787 -0.01669609 -0.00792236 -0.03199597\n",
      " -0.05650946  0.04118575 -0.05004764 -0.05776944]...\n",
      "Sentence: These tools read the Darknet\n",
      "conﬁguration and weights ﬁles and then build a corresponding model in Keras,\n",
      "transferring the weights.\n",
      "•\n",
      "Run the Conversion: Using the chosen tool, we can execute the conversion\n",
      "process\n",
      "Embedding: [-0.02290327 -0.05143159 -0.04090583  0.00703346 -0.02547676 -0.02278453\n",
      " -0.05203706 -0.02870361 -0.06171797 -0.06934811]...\n",
      "Sentence: This usually involves specifying the paths to the input Darknet ﬁles and\n",
      "the desired output path for the Keras model ﬁle\n",
      "Embedding: [-0.00052728 -0.08815699 -0.03613224  0.02309476  0.00245659  0.01762885\n",
      " -0.08901618 -0.03267521  0.02751799 -0.07974656]...\n",
      "Sentence: The output is typically a .h5 ﬁle\n",
      "that contains the architecture and weights of the Keras model.\n",
      "•\n",
      "Veriﬁcation: After conversion, it is important to verify that the model performs\n",
      "as expected\n",
      "Embedding: [-0.03319951  0.02498581 -0.04001502  0.00154699  0.04395298 -0.01063717\n",
      " -0.07028122 -0.05006722 -0.01231444 -0.09210949]...\n",
      "Sentence: This can be done by running the model on some test images and\n",
      "comparing the results with those obtained from the original YOLO model.\n",
      "An example of the conversion using YAD2K (Yet Another Darknet 2 Keras) is\n",
      "shown below:\n",
      "git clone https://github.com/allanzelener/YAD2K.git\n",
      "cd YAD2K\n",
      "python yad2k.py <yolo.cfg> <yolo.weights> <output_path.h5>\n",
      "This script takes the YOLO conﬁg ﬁle (yolo.cfg) and the weights ﬁle (yolo.weights)\n",
      "and produces a .h5 ﬁle that can be loaded in Keras.\n",
      "150\n",
      "8\n",
      "Using Pretrained Networks\n",
      "8.4\n",
      "Hugging Face\n",
      "We conclude this chapter with a summary of Hugging Face\n",
      "Embedding: [-0.05349206  0.00764869  0.0382717   0.0058961  -0.02373204 -0.05428553\n",
      " -0.07106759 -0.02688213 -0.04631785 -0.07110024]...\n",
      "Sentence: This is not technically\n",
      "a pretrained network but is an open source library with a comprehensive collection\n",
      "of pretrained models, including NLP, RL, and CNN.\n",
      "One of the key strengths of Hugging Face’s library is its user-friendly interface\n",
      "Embedding: [-0.07148047 -0.09908505  0.06365562  0.04930429  0.03843678  0.04930698\n",
      " -0.06925088 -0.04588293 -0.02609971 -0.07557018]...\n",
      "Sentence: It\n",
      "allows for easy integration of complex models into applications, which has lowered\n",
      "the barrier to entry for working with advanced NLP models.\n",
      "The library is too extensive to be fully covered in this book, but for readers\n",
      "interested in further ML studies, Hugging Face’s tools and resources are extensively\n",
      "used in both academic and industry settings, offering access to state-of-the-art NLP\n",
      "technology.\n",
      "8.5\n",
      "Prompt Engineering\n",
      "Up to now, we have been discussing the use of ﬁne-tuning to tailor the model for\n",
      "our own needs\n",
      "Embedding: [-0.00825018 -0.0234197   0.07038663  0.06795183  0.01331295 -0.00605557\n",
      " -0.02154702  0.00638491 -0.00297134 -0.02000823]...\n",
      "Sentence: Fine-tuning involves adjusting the pretrained weights of a model\n",
      "on a speciﬁc dataset to improve its performance on tasks related to that dataset.\n",
      "This process customizes the model to better understand and generate outcome that\n",
      "aligns with the nuances of the new data\n",
      "Embedding: [ 0.01091737 -0.02384367  0.01775328  0.02943186 -0.02298012 -0.04990656\n",
      "  0.03362999 -0.00343425 -0.0829764  -0.04352015]...\n",
      "Sentence: Fine-tuning is inﬂexible in the sense that\n",
      "each ﬁne-tuned model is tailored to a particular task or domain\n",
      "Embedding: [ 0.03431249 -0.11065975 -0.03631559 -0.01629796  0.01488812 -0.02516599\n",
      "  0.02102223 -0.0146091  -0.03865543 -0.02725329]...\n",
      "Sentence: Changing the task\n",
      "might require retraining the model with different data\n",
      "Embedding: [-0.01155644 -0.04178599  0.03311     0.03933406 -0.00342994  0.01878263\n",
      " -0.03806899 -0.0740611  -0.03184872 -0.02412252]...\n",
      "Sentence: It also requires signiﬁcant\n",
      "computational resources and expertise to retrain the model, especially for large\n",
      "language models\n",
      "Embedding: [ 0.03780805 -0.09972245  0.01990993  0.039074    0.00682044  0.01780942\n",
      " -0.11184176 -0.02074098  0.04194765 -0.05638415]...\n",
      "Sentence: This process can be time-consuming and expensive.\n",
      "Instead of ﬁne-tuning, prompt engineering focuses on effectively interacting\n",
      "with language models, like ChatGPT, through the design of textual prompts\n",
      "Embedding: [ 0.00899881 -0.02287424  0.04910813 -0.03077831 -0.01815898 -0.06301644\n",
      "  0.06313445  0.07528996  0.02259284 -0.00871031]...\n",
      "Sentence: It\n",
      "encompasses strategies and techniques for crafting questions or instructions that\n",
      "guide these LLMs to generate desired outputs or perform tasks more accurately.\n",
      "The core of prompt engineering lies in understanding how a language model\n",
      "processes and responds to input, enabling users to achieve better results, whether\n",
      "it be generating text, coding, creating art, or solving problems\n",
      "Embedding: [ 0.04385053  0.01649385  0.01564971 -0.06546945  0.02833753 -0.0263348\n",
      "  0.04786371  0.06570835  0.00693302 -0.0018228 ]...\n",
      "Sentence: Prompt engineering\n",
      "can be performed by end users with an understanding of the model’s capabilities\n",
      "and how it interprets language\n",
      "Embedding: [ 0.02573471  0.0049997  -0.00414569 -0.05469254 -0.00443503 -0.07156423\n",
      "  0.02576747  0.07503822 -0.01478219 -0.02140805]...\n",
      "Sentence: However, in practice, there may be preprocessing\n",
      "processes which require coding as we shall now discuss.\n",
      "We start with some prompting methods which are easily implemented\n",
      "Embedding: [-3.6524002e-02 -1.9669550e-02 -6.6484265e-02 -4.0349476e-02\n",
      " -1.4224871e-02 -5.2798074e-02 -5.7437974e-05  6.7615886e-03\n",
      " -6.3225701e-02  5.8532260e-02]...\n",
      "Sentence: The users\n",
      "generate the relevant text prompts to guide the models toward a better result without\n",
      "the use of any preprocessing of data.\n",
      "8.5.1\n",
      "Zero-Shot Learning\n",
      "In zero-shot learning, the model is given a task without any prior examples of how\n",
      "to perform it\n",
      "Embedding: [ 0.01653752  0.05194099  0.04201038  0.06211282  0.04690104 -0.0016818\n",
      " -0.02989882  0.0105617   0.01910878  0.01508322]...\n",
      "Sentence: The prompt must be self-explanatory, relying solely on the model’s\n",
      "pretrained knowledge\n",
      "Embedding: [ 0.07946336  0.02802868 -0.01165083  0.02765956  0.02561632  0.04812122\n",
      " -0.00695186  0.03185559  0.00657379 -0.00091169]...\n",
      "Sentence: This method is useful for general queries or tasks that do not\n",
      "8.5\n",
      "Prompt Engineering\n",
      "151\n",
      "require specialized knowledge beyond what the model was trained on\n",
      "Embedding: [-0.03852082  0.04594566  0.01062671  0.01129914 -0.01626887 -0.04652821\n",
      " -0.00094155  0.03790186 -0.10260426  0.0024789 ]...\n",
      "Sentence: For example,\n",
      "suppose we want to translate a sentence from English to French\n",
      "Embedding: [ 0.00401161  0.04072333 -0.0297955  -0.01902946  0.00123527  0.01555986\n",
      "  0.05154732  0.00235773  0.12444832 -0.00802242]...\n",
      "Sentence: We would simply\n",
      "input the task instruction (“Translate the following sentence into French:”) followed\n",
      "by the sentence\n",
      "Embedding: [-0.01276279  0.05324795 -0.00728253 -0.04161805 -0.02146916  0.04599039\n",
      "  0.02419167  0.06922801  0.03499626  0.00799652]...\n",
      "Sentence: The model uses its preexisting knowledge from training to perform\n",
      "the translation\n",
      "Embedding: [ 9.3516149e-04  9.9118771e-03 -2.7552217e-02  1.6250171e-02\n",
      " -4.8753559e-03  5.4785024e-02  2.3362674e-02  8.9362031e-03\n",
      "  8.3788902e-02 -7.1878851e-05]...\n",
      "Sentence: Zero-shot learning is powerful for tasks where the model’s training\n",
      "data likely covered similar ground, and the task can be clearly articulated without\n",
      "examples.\n",
      "8.5.2\n",
      "Few-Shot Learning\n",
      "Few-shot learning involves providing the model with a small number of examples\n",
      "(shots) to demonstrate how to perform a task\n",
      "Embedding: [ 0.04622491  0.03325841  0.05999797  0.0370529   0.08995523  0.01242149\n",
      "  0.00263719 -0.02181376  0.05001154 -0.00601684]...\n",
      "Sentence: These examples are included directly\n",
      "in the prompt, giving the model a context to infer the task’s requirements\n",
      "Embedding: [ 0.00477985  0.01193683 -0.0012134  -0.02135264  0.09507364  0.02702689\n",
      "  0.00935275  0.0407326  -0.04136561 -0.01803022]...\n",
      "Sentence: Few-\n",
      "shot learning is ideal for tasks where the model needs a bit of guidance on the\n",
      "task’s format or expected output but does not require extensive training data\n",
      "Embedding: [ 0.08952892  0.02891673  0.03697392  0.03607612  0.08256745  0.04673123\n",
      " -0.03403192 -0.03503806 -0.01968653 -0.00579   ]...\n",
      "Sentence: In the\n",
      "translation example, for few-shot learning, we would provide the model with a few\n",
      "examples of English-to-French sentences and give the textual prompt (“Given these\n",
      "English-to-French translations, translate this new sentence:”) and apply the pattern\n",
      "to the new input\n",
      "Embedding: [ 0.05137143  0.01356438  0.05250746 -0.01962421  0.06679613  0.11514059\n",
      "  0.04611533  0.02438292  0.05495467  0.03604404]...\n",
      "Sentence: Few-shot learning is useful when a bit of context can signiﬁcantly\n",
      "improve the model’s output by showing it exactly what is expected.\n",
      "8.5.3\n",
      "One-Shot Learning\n",
      "One-shot learning is similar to few-shot learning except that we are giving the model\n",
      "a single example and ask it to generate similar results\n",
      "Embedding: [ 0.02883388  0.02129701  0.08396643  0.06737433  0.14143096  0.03107087\n",
      "  0.02724531 -0.04218361  0.02703652 -0.02265184]...\n",
      "Sentence: Suppose we want the model\n",
      "to write jokes in a particular style\n",
      "Embedding: [-0.04057062 -0.05272246  0.01434147  0.01815859 -0.0233255   0.03224015\n",
      "  0.02373506 -0.00187253  0.05049073 -0.02710724]...\n",
      "Sentence: Here, the prompt would include a setup and\n",
      "punchline of a joke, followed by the task (“Write a joke in a similar style:”)\n",
      "Embedding: [-0.06930655  0.03477309  0.00053625 -0.00603931 -0.00010796 -0.02724167\n",
      "  0.05802965  0.02828961 -0.03696071 -0.02082117]...\n",
      "Sentence: The\n",
      "model uses this one example to understand both the structure and tone expected in\n",
      "its response\n",
      "Embedding: [-0.02309282 -0.04477604  0.03013344  0.02023524  0.02925954  0.00234525\n",
      " -0.00852331 -0.0282083   0.05678315  0.00494526]...\n",
      "Sentence: One-shot learning works well for tasks where a single example can\n",
      "clearly convey the task requirements and expected format.\n",
      "8.5.4\n",
      "Chain-of-Thought Prompting\n",
      "Chain-of-thought prompting encourages the model to break down complex prob-\n",
      "lems into smaller, more manageable steps\n",
      "Embedding: [ 0.02130535 -0.0098883   0.09826343 -0.00684627  0.07165468 -0.03330529\n",
      "  0.01014323  0.04561128 -0.0041347   0.02970686]...\n",
      "Sentence: This structured approach to problem-\n",
      "solving is akin to how humans tackle difﬁcult tasks, making it easier for the model\n",
      "to navigate through the complexities of a problem and arrive at a solution more\n",
      "systematically.\n",
      "LLMs are trained on vast amounts of text data, encompassing a wide range of\n",
      "topics and problem-solving strategies\n",
      "Embedding: [ 0.0305072   0.01280413  0.02815189  0.00138377  0.01847734 -0.04441968\n",
      " -0.01990898  0.02694651 -0.01302648  0.04201967]...\n",
      "Sentence: Chain-of-thought prompting leverages this\n",
      "preexisting knowledge by guiding the model to apply relevant information and\n",
      "reasoning patterns it has learned during training to the task at hand.\n",
      "152\n",
      "8\n",
      "Using Pretrained Networks\n",
      "By requiring the model to articulate each step in its reasoning process, chain-of-\n",
      "thought prompting makes the model’s thought process more transparent\n",
      "Embedding: [ 0.04433532 -0.01385861  0.0490676  -0.0022687   0.03505677 -0.00972963\n",
      "  0.04973203  0.06789278  0.06378    -0.00275518]...\n",
      "Sentence: This not\n",
      "only helps in understanding how the model arrived at a particular conclusion but\n",
      "also aids in identifying and correcting errors in the model’s reasoning\n",
      "Embedding: [-0.00774296  0.06629217  0.03455234  0.06361601  0.10175078  0.02392078\n",
      " -0.04847586  0.06488204  0.0296263   0.04556742]...\n",
      "Sentence: With each\n",
      "step of the thought process laid out, it becomes easier to identify where the model\n",
      "might have gone off track\n",
      "Embedding: [-0.00055508  0.01327923  0.04807491  0.01639294  0.17574129 -0.02134271\n",
      " -0.11398769  0.05048713  0.06859964 -0.00353896]...\n",
      "Sentence: This stepwise breakdown allows for targeted adjustments\n",
      "to the prompt or the reasoning process, facilitating more accurate outcomes.\n",
      "In some areas where LLMs are weak currently, such as mathematically reasoning\n",
      "and coding, guiding the model in several steps often yields more accurate and better\n",
      "results\n",
      "Embedding: [ 0.02074102 -0.01236702  0.05151416 -0.00691674  0.07568404 -0.0550001\n",
      " -0.07848872  0.08343295  0.05199333  0.04669524]...\n",
      "Sentence: In some cases, however, the model is unable to proceed any further and will\n",
      "provide the same incorrect answer but written in a different way\n",
      "Embedding: [-0.06189868 -0.0068692   0.0166163   0.06085675 -0.02141011 -0.03417395\n",
      " -0.10659441 -0.01206964  0.0571867   0.01093514]...\n",
      "Sentence: In such cases, it is\n",
      "necessary to tackle the problem differently by asking questions with different topics,\n",
      "which hopefully is addressable by the trained model.\n",
      "For example, instead of prompting the model to solve 2x + 3 = 7 directly, we\n",
      "ask it to “Explain step by step how to solve 2x + 3 = 7.” The model then breaks\n",
      "down the problem into a series of logical steps leading to the solution\n",
      "Embedding: [-0.0159468   0.04130358  0.02845757  0.02529719  0.02359391  0.00627963\n",
      " -0.03253943  0.02608712 -0.02469848 -0.01924023]...\n",
      "Sentence: This method\n",
      "is ideal for complex tasks requiring transparency in the problem-solving process,\n",
      "helping users follow the model’s reasoning and ensuring the solution’s correctness.\n",
      "8.5.5\n",
      "Role-Playing\n",
      "Role-playing prompting is a creative and effective approach in prompt engineering,\n",
      "especially useful when interacting with large language models (LLMs), like GPT-3\n",
      "or GPT-4\n",
      "Embedding: [-0.00686117  0.00221224  0.0879371  -0.0575852   0.01251148 -0.01390162\n",
      "  0.10769899  0.07721336 -0.02518197  0.00179648]...\n",
      "Sentence: This technique involves asking the model to assume a speciﬁc character,\n",
      "identity, or perspective when generating its responses\n",
      "Embedding: [-0.12203936  0.0471567  -0.04327916  0.01622279  0.01046469  0.01669949\n",
      "  0.01019873  0.00042538  0.10802694  0.00432632]...\n",
      "Sentence: By doing so, it inﬂuences\n",
      "not only the content of the model’s output but also its tone, style, and the type of\n",
      "information it prioritizes.\n",
      "A role-playing prompt would explicitly state the role (“Imagine you are a\n",
      "science teacher explaining the theory of relativity to a 10-year-old\n",
      "Embedding: [ 0.06543692 -0.00884838  0.01178213  0.01240083  0.03071672  0.04866317\n",
      " -0.01435966 -0.02290795  0.10006568 -0.06679873]...\n",
      "Sentence: How would you\n",
      "describe it?”)\n",
      "Embedding: [ 0.00039638  0.07997636 -0.02672691  0.0479028  -0.07730865 -0.03880372\n",
      "  0.02513763 -0.07460959  0.03085346 -0.0026658 ]...\n",
      "Sentence: This guides the model to adopt a speciﬁc tone, complexity level, and\n",
      "perspective, tailoring the response to ﬁt the role\n",
      "Embedding: [ 0.01527816 -0.03186432 -0.0153984  -0.01505273 -0.04844894  0.01420631\n",
      " -0.07168563  0.00180608  0.00565453  0.01623489]...\n",
      "Sentence: Role-playing enhances creativity\n",
      "and engagement, making it suitable for educational content, entertainment, and\n",
      "more\n",
      "Embedding: [ 0.0623471   0.00915561  0.06288779 -0.03288087 -0.0223338   0.08323635\n",
      "  0.05254474 -0.00239527  0.03313209  0.05595434]...\n",
      "Sentence: This prompt encourages the model to adopt a role (a science teacher) and\n",
      "a speciﬁc tone (friendly and enthusiastic) tailored to the audience (a 10-year-old\n",
      "child)\n",
      "Embedding: [ 0.01628335  0.02022339  0.05621638 -0.00544183  0.01601989  0.05063697\n",
      " -0.00786426  0.02573791 -0.02233148  0.04794597]...\n",
      "Sentence: The model’s response is likely to be more engaging, understandable, and\n",
      "appropriate for a young audience than a straightforward factual explanation.\n",
      "8.5.6\n",
      "Embedding Prompts\n",
      "The prompting methods up to now do not require coding\n",
      "Embedding: [-0.03534332 -0.04613744  0.08175358  0.0198415   0.08435437  0.05565228\n",
      " -0.05195357  0.09003153  0.04773014 -0.00688009]...\n",
      "Sentence: Unlike these methods,\n",
      "embedding prompting needs coding and a deeper understanding of how the LLMs\n",
      "work.\n",
      "Embedding prompts in the context of working with language models involve\n",
      "using vector representations of text (embeddings) to guide or inﬂuence the model’s\n",
      "8.5\n",
      "Prompt Engineering\n",
      "153\n",
      "responses, rather than relying solely on traditional text-based prompts\n",
      "Embedding: [ 0.05169984 -0.06316952  0.07009637 -0.02018175  0.05100376  0.04338577\n",
      "  0.00140413  0.05900926  0.02766412 -0.04057905]...\n",
      "Sentence: This\n",
      "approach can be particularly powerful for tailoring model outputs, improving\n",
      "relevance, and achieving more nuanced interactions\n",
      "Embedding: [-0.00191015 -0.01299753 -0.03214183  0.02960133  0.07608077  0.05591147\n",
      " -0.03852866  0.06189838  0.03660361 -0.07308464]...\n",
      "Sentence: We have seen how embedding\n",
      "is used in the Stable Diffusion model with the data being preprocessed into a latent\n",
      "space vector ﬁrst instead of being used directly\n",
      "Embedding: [-0.00276306 -0.11844087  0.01385684  0.00458366  0.06191999  0.0528163\n",
      " -0.04476269 -0.03035189  0.06335723  0.00326782]...\n",
      "Sentence: By compressing text prompts into\n",
      "dense vector representations of words, phrases, or longer texts, we are able to\n",
      "help the model to capture the semantic meaning in a high-dimensional space\n",
      "Embedding: [ 0.04273281 -0.02120828  0.02582315 -0.02140359  0.08284692  0.02845219\n",
      "  0.0030195  -0.00905541  0.11730586 -0.0184291 ]...\n",
      "Sentence: The\n",
      "process of embedding enables the model to capture nuanced relationships between\n",
      "different pieces of text.\n",
      "Here is a closer look at how embedding prompts work and some examples:\n",
      "•\n",
      "Semantic Search: Suppose we are building a system to ﬁnd relevant documents\n",
      "based on a query\n",
      "Embedding: [ 0.0365082  -0.04460277  0.01955166  0.03029152  0.07601664  0.07327343\n",
      " -0.02525239  0.01118189  0.13825966 -0.07105052]...\n",
      "Sentence: Instead of matching keywords, we use embeddings to represent\n",
      "the query and the documents\n",
      "Embedding: [-0.06025172  0.01313053  0.01424339  0.06380413  0.01812536  0.07285555\n",
      "  0.05220438  0.00431662  0.04469278 -0.03968032]...\n",
      "Sentence: The system then retrieves documents whose\n",
      "embeddings are closest to the query’s embedding, likely resulting in more\n",
      "relevant matches\n",
      "Embedding: [-0.01763193 -0.0050231   0.00932335  0.0420487   0.05576601  0.05991791\n",
      " -0.00356761  0.00817755  0.08919948 -0.05106878]...\n",
      "Sentence: For example, for a query “sustainable energy sources,” the\n",
      "system ﬁnds documents related to solar power, wind energy, etc., even if the\n",
      "exact phrase is not used.\n",
      "•\n",
      "Content Recommendation: In a recommendation engine, user preferences and\n",
      "item descriptions are represented as embeddings\n",
      "Embedding: [-0.04377078  0.02094238 -0.00278738  0.09637826  0.08455065  0.02083547\n",
      "  0.03311335  0.03310494  0.01324497 -0.06203698]...\n",
      "Sentence: The system recommends\n",
      "items by ﬁnding those whose embeddings are closest to the user’s preference\n",
      "embedding\n",
      "Embedding: [ 0.01709571 -0.04225646 -0.02068003 -0.0046813   0.07150991  0.09451547\n",
      "  0.08032296  0.06149184 -0.00052261 -0.00729132]...\n",
      "Sentence: For example, if a user likes articles about “space exploration,” their\n",
      "preference embedding might closely align with articles about Mars rovers or\n",
      "satellite launches, and those articles would be recommended.\n",
      "•\n",
      "Dialogue Systems: For generating contextually relevant responses in a chatbot,\n",
      "the embeddings of the conversation context and potential responses are used\n",
      "Embedding: [ 0.0190837  -0.09011783  0.04377552  0.00447962  0.04596808 -0.01179671\n",
      "  0.00584232  0.0931868   0.07208081 -0.01407624]...\n",
      "Sentence: The\n",
      "chatbot selects or generates a response whose embedding is most aligned with\n",
      "the context embedding, ensuring relevance and coherence in the conversation.\n",
      "For instance, if the conversation context involves discussing “favorite books,”\n",
      "the chatbot focuses its responses on literature-related content.\n",
      "8.5.7\n",
      "Knowledge Graphs\n",
      "It may seem counterintuitive that a knowledge graph can be fed into an LLM to\n",
      "guide the output, but it does work quite effectively.\n",
      "A knowledge graph is a type of graphical representation that uses nodes (vertices)\n",
      "to represent entities or concepts and edges to represent the relationships between\n",
      "them\n",
      "Embedding: [ 0.0201447  -0.05425758 -0.00790047  0.0544024   0.03067596 -0.03188324\n",
      "  0.01131444  0.03372817  0.02251467  0.01745545]...\n",
      "Sentence: These graphs can be directed or undirected and can include various types of\n",
      "relationships, such as hierarchical (parent-child), associative (related or connected\n",
      "ideas), or sequential (steps in a process)\n",
      "Embedding: [-0.00672552 -0.0745153  -0.05431499  0.00539669 -0.03638433 -0.00549102\n",
      " -0.08872353 -0.02416793  0.06813577  0.02045542]...\n",
      "Sentence: Relationship graphs, when used in the\n",
      "context of prompting language models, provide a structured way to represent and\n",
      "utilize the relationships between entities, concepts, or topics to guide the generation\n",
      "of text\n",
      "Embedding: [-0.00622202  0.00983685 -0.04363158 -0.00362139 -0.04013029  0.03859612\n",
      " -0.0056456   0.04414835  0.05736699 -0.04179959]...\n",
      "Sentence: This approach can signiﬁcantly enhance the relevance, coherence, and depth\n",
      "154\n",
      "8\n",
      "Using Pretrained Networks\n",
      "of the responses generated by AI models\n",
      "Embedding: [-0.01918437 -0.05185558  0.0295733   0.03603692  0.04100542  0.07330173\n",
      " -0.05787004 -0.01570032  0.0432058  -0.12735116]...\n",
      "Sentence: Some applications of knowledge graphs\n",
      "include\n",
      "•\n",
      "Educational Content Creation: When generating content on a historical event,\n",
      "a relationship graph could map out key ﬁgures, locations, causes, effects, and\n",
      "timelines\n",
      "Embedding: [ 0.03424048  0.04304671 -0.03998352  0.01242639  0.03510874  0.00585608\n",
      " -0.10106858  0.00176723  0.00855703  0.08364656]...\n",
      "Sentence: The prompt could guide the model to elaborate on these elements\n",
      "based on their connections, ensuring comprehensive coverage.\n",
      "•\n",
      "Storytelling: In creative writing, a relationship graph could outline characters,\n",
      "settings, plot points, and thematic elements\n",
      "Embedding: [ 0.04251158 -0.00639291  0.02272863  0.02856847  0.00783099  0.03471539\n",
      " -0.02742888 -0.01021647  0.09232593 -0.00254261]...\n",
      "Sentence: The model could then be prompted\n",
      "to weave a narrative that respects these relationships, enhancing plot coherence\n",
      "and character development.\n",
      "•\n",
      "Technical Documentation: For generating technical or scientiﬁc content, a graph\n",
      "could represent concepts, principles, applications, and examples\n",
      "Embedding: [ 0.02189748 -0.02735852 -0.03160752  0.00623984 -0.01594198 -0.01087596\n",
      " -0.08267599  0.01003401  0.10095613  0.03599162]...\n",
      "Sentence: Prompts could\n",
      "leverage this structure to produce detailed explanations that accurately reﬂect the\n",
      "complexity and hierarchy of technical knowledge.\n",
      "The current model of GPT-4 and similar AI models from OpenAI do not\n",
      "inherently “understand” visual data, including spider graphs, in the way humans\n",
      "do\n",
      "Embedding: [ 0.0199869  -0.07794889  0.00114226  0.02541098  0.08098986 -0.10076624\n",
      " -0.02706172  0.0074634   0.02324259 -0.01968717]...\n",
      "Sentence: These models are primarily designed to process and generate text-based\n",
      "information\n",
      "Embedding: [-0.02869805 -0.03273745 -0.03551     0.04918063  0.01308045  0.00760774\n",
      " -0.04505665  0.01832656  0.1237711  -0.0023907 ]...\n",
      "Sentence: However, GPT-4 can interpret descriptions of spider graphs (or any\n",
      "other visual information) provided in text format\n",
      "Embedding: [ 0.00029981  0.00345579 -0.01679513 -0.00488325  0.04321202 -0.03163615\n",
      " -0.05379843 -0.00361054 -0.01624246 -0.03809182]...\n",
      "Sentence: This means that while the model\n",
      "cannot directly analyze a spider graph image or its visual components, it can\n",
      "understand and respond to detailed textual descriptions of the data or insights that\n",
      "the spider graph is intended to convey.\n",
      "Suppose we have a spider graph comparing ﬁve different products across\n",
      "multiple criteria: price, quality, user interface, customer support, and feature set.\n",
      "We cannot show GPT-4 the graph directly but can describe it as follows:\n",
      "“Product A scores high on price and quality but low on user interface and\n",
      "customer support\n",
      "Embedding: [-0.01203112  0.00178918 -0.00019376 -0.0148219   0.06264332 -0.02736169\n",
      " -0.02969353  0.04062309 -0.04265183 -0.06964872]...\n",
      "Sentence: Product B has moderate scores across all criteria, with a slight\n",
      "edge in feature set\n",
      "Embedding: [ 0.06634833 -0.03632203 -0.00065551 -0.05168535  0.04488285  0.05548161\n",
      "  0.03196833  0.04778577 -0.10192899 -0.03438973]...\n",
      "Sentence: Products C and D excel in user interface and customer support,\n",
      "respectively, but fall short in quality\n",
      "Embedding: [-0.08371959 -0.00070062 -0.01114709 -0.10113124 -0.05472353  0.03199881\n",
      " -0.09436189  0.09722716  0.01807182  0.02266497]...\n",
      "Sentence: Product E is balanced but does not lead in any\n",
      "criterion.”\n",
      "Given this description, we could ask GPT-4 questions like\n",
      "“Which product offers the best balance across all criteria?” “Based on the\n",
      "description, which areas should Product A focus on improving?” “How might\n",
      "improving customer support impact the overall score of Product D?”\n",
      "8.6\n",
      "Retrieval-Augmented LLM\n",
      "One major problem of LLMs is the so-called knowledge cutoff\n",
      "Embedding: [-0.03241673 -0.01740676  0.02848937 -0.09495396  0.03729312  0.02560475\n",
      "  0.09457917  0.11257761 -0.05725044 -0.01957333]...\n",
      "Sentence: The system may\n",
      "have been trained on out-of-date data, or the data may be classiﬁed so that it does not\n",
      "have any context-dependent knowledge on the problem at hand\n",
      "Embedding: [-0.03050683  0.03979458 -0.02727013  0.04281993  0.0835374  -0.02869315\n",
      " -0.04341388  0.01217825 -0.03768044  0.01184329]...\n",
      "Sentence: The latest version\n",
      "of ChatGPT automatically searches the Internet if it cannot ﬁnd the relevant answer.\n",
      "In effect, it has changed into a retrieval-augmented LLM.\n",
      "8.7\n",
      "Best Practices for Prompt Engineering\n",
      "155\n",
      "Retrieval-augmented large language models (LLMs) are a class of AI that\n",
      "enhance traditional LLMs by integrating external data retrieval into the response\n",
      "generation process\n",
      "Embedding: [-0.05292175 -0.04520113  0.05985999  0.03591222  0.02303465  0.00800848\n",
      "  0.0561657   0.03562433  0.01126769 -0.01492061]...\n",
      "Sentence: This approach allows the models to access and incorporate\n",
      "real-time information or domain-speciﬁc knowledge from external databases or the\n",
      "Internet, thereby extending the model’s knowledge base beyond its initial training\n",
      "data\n",
      "Embedding: [-0.04787513 -0.07639489 -0.08631296  0.05088013  0.02429227  0.00828285\n",
      " -0.03316463  0.04889778 -0.03061187 -0.01700676]...\n",
      "Sentence: This augmentation signiﬁcantly improves the model’s ability to provide\n",
      "accurate, up-to-date, and contextually relevant answers, making it particularly useful\n",
      "for tasks requiring current knowledge or specialized information across various\n",
      "domains.\n",
      "To use a retrieval-augmented LLM for our own speciﬁc information, we would\n",
      "integrate the LLM with a system capable of querying our company’s databases,\n",
      "knowledge bases, or the Internet for real-time information\n",
      "Embedding: [-0.04361312 -0.10763217 -0.05028519  0.05445218  0.01781997  0.04454546\n",
      "  0.01874012  0.01735071 -0.04440801 -0.03827582]...\n",
      "Sentence: The LLM can then\n",
      "incorporate this fetched data into its generated text, providing accurate and up-to-\n",
      "date responses based on your company’s latest information\n",
      "Embedding: [-0.02774351 -0.00423723 -0.00940251  0.03576826  0.05347136  0.02666508\n",
      " -0.05816277  0.00011101 -0.02512199 -0.03187897]...\n",
      "Sentence: This could enhance\n",
      "customer support chatbots, automate content creation for marketing, or support\n",
      "decision-making by providing insights from the latest data\n",
      "Embedding: [-0.11131407 -0.06045001  0.02651858  0.03511271  0.03196931 -0.02218258\n",
      "  0.00437439  0.04267315 -0.02459471 -0.05442566]...\n",
      "Sentence: Implementing such a\n",
      "system requires technical expertise in AI, databases, and possibly API development\n",
      "for seamless integration.\n",
      "8.7\n",
      "Best Practices for Prompt Engineering\n",
      "These are the best prompt formats recommended by OpenAI taken from their\n",
      "website as of March 2024:\n",
      "•\n",
      "Put instructions at the beginning of the prompt and use ### or \"\"\" to separate\n",
      "the instruction and context.\n",
      "Less effective ✗:\n",
      "Summarize the text below as a bullet point list of the most important points.\n",
      "text input here\n",
      "Better ✓:\n",
      "Summarize the text below as a bullet point list of the most important points.\n",
      "Text: \"\"\" text input here \"\"\"\n",
      "•\n",
      "Be speciﬁc, descriptive, and as detailed as possible about the desired context,\n",
      "outcome, length, format, style, etc.\n",
      "Less effective ✗:\n",
      "Write a poem about OpenAI.\n",
      "Better ✓:\n",
      "Write a short inspiring poem about OpenAI, focusing on the recent DALL-E\n",
      "product launch (DALL-E is a text to image ML model) in the style of a famous\n",
      "poet.\n",
      "•\n",
      "Articulate the desired output format through examples.\n",
      "Less effective ✗:\n",
      "156\n",
      "8\n",
      "Using Pretrained Networks\n",
      "Extract the entities mentioned in the text below\n",
      "Embedding: [ 3.9329291e-03  3.1575449e-02 -6.7591674e-05  1.9465962e-04\n",
      "  3.6878534e-02  8.8593923e-03  2.0727323e-02  3.9720330e-02\n",
      "  5.5354461e-02 -6.5157786e-02]...\n",
      "Sentence: Extract the following 4 entity\n",
      "types: company names, people names, speciﬁc topics, and themes.\n",
      "Text: text\n",
      "Show and tell—the models respond better when shown speciﬁc format require-\n",
      "ments\n",
      "Embedding: [ 0.04658452  0.04286557  0.01416767 -0.00593067  0.08924969  0.07631384\n",
      "  0.01238158 -0.06029521  0.01506177 -0.03993924]...\n",
      "Sentence: This also makes it easier to programmatically parse out multiple outputs\n",
      "reliably.\n",
      "Better ✓:\n",
      "Extract the important entities mentioned in the text below\n",
      "Embedding: [ 0.05666333 -0.00485227 -0.01193482  0.02062137  0.07012106  0.00061102\n",
      "  0.04154052 -0.05411246  0.0470095  -0.02363475]...\n",
      "Sentence: First extract all\n",
      "company names, then extract all people names, then extract speciﬁc topics which\n",
      "ﬁt the content, and ﬁnally extract general overarching themes.\n",
      "Desired format: Company names: <comma-separated list of company names>\n",
      "People names: -||- Speciﬁc topics: -||- General themes: -||-\n",
      "Text: text\n",
      "•\n",
      "Start with zero-shot, then few-shot, neither of them worked, then ﬁne-tune.\n",
      "✓Zero-shot\n",
      "Extract keywords from the below text.\n",
      "Text: text\n",
      "Keywords:\n",
      "✓Few-shot: Provide a couple of examples.\n",
      "Extract keywords from the corresponding texts below.\n",
      "Text 1: Stripe provides APIs that web developers can use to integrate payment\n",
      "processing into their websites and mobile applications\n",
      "Embedding: [-0.05633367  0.1170697  -0.04644484 -0.03889054  0.05940196  0.02533787\n",
      "  0.09645636 -0.07376775 -0.01206647 -0.04821917]...\n",
      "Sentence: Keywords 1: Stripe,\n",
      "payment processing, APIs, web developers, websites, mobile applications ##.\n",
      "Text 2: OpenAI has trained cutting-edge language models that are very good\n",
      "at understanding and generating text\n",
      "Embedding: [-0.03090497 -0.06344459 -0.00750982  0.00942367  0.04369572 -0.03967956\n",
      "  0.02151968  0.03273239  0.0137959  -0.05601112]...\n",
      "Sentence: Our API provides access to these models\n",
      "and can be used to solve virtually any task that involves processing language.\n",
      "Keywords 2: OpenAI, language models, text processing, API\n",
      "Embedding: [-0.04216219 -0.06318422 -0.04250725 -0.00360218  0.01483247 -0.0264468\n",
      " -0.02106702  0.0150984   0.00321294 -0.03232382]...\n",
      "Sentence: ## Text 3: text\n",
      "Keywords 3:\n",
      "✓Fine-tune: See ﬁne-tune best practices; refer to their documentation at https://\n",
      "platform.openai.com/docs/guides/ﬁne-tuning.\n",
      "•\n",
      "Reduce “ﬂuffy” and imprecise descriptions\n",
      "Embedding: [ 0.02860413  0.01805121 -0.02478271  0.0216097   0.01843095 -0.03625632\n",
      "  0.09374121 -0.04970529 -0.01007783 -0.06879697]...\n",
      "Sentence: Less effective ✗:\n",
      "The description for this product should be fairly short, a few sentences only, and\n",
      "not too much more.\n",
      "Better ✓:\n",
      "Use a 3–5 sentence paragraph to describe this product.\n",
      "•\n",
      "Instead of just saying what not to do, say what to do instead.\n",
      "Less effective ✗:\n",
      "The following is a conversation between an agent and a customer\n",
      "Embedding: [ 0.03450787  0.07205792  0.11179319 -0.02462536  0.04122242 -0.03176982\n",
      "  0.06131042  0.03140089  0.02949697 -0.11373626]...\n",
      "Sentence: DO NOT ASK\n",
      "USERNAME OR PASSWORD\n",
      "Embedding: [-0.08783514  0.02968743 -0.01242208 -0.03837394 -0.04471561 -0.01017781\n",
      "  0.09741027 -0.03479765  0.11465036 -0.0640339 ]...\n",
      "Sentence: DO NOT REPEAT.\n",
      "Customer: I can’t log in to my account\n",
      "Embedding: [-5.1745819e-03 -2.9469404e-02  6.6485219e-03 -3.7464701e-02\n",
      " -5.9115682e-02 -4.6830693e-05  7.4734904e-02 -8.2573421e-02\n",
      "  6.7278259e-02 -6.4409532e-02]...\n",
      "Sentence: Agent:\n",
      "Better ✓:\n",
      "The following is a conversation between an agent and a customer\n",
      "Embedding: [-0.04486348  0.01075249 -0.02165918 -0.02575066 -0.0087475  -0.04939956\n",
      "  0.12705678 -0.00646965  0.05888443 -0.09684458]...\n",
      "Sentence: The agent will\n",
      "attempt to diagnose the problem and suggest a solution while refraining from\n",
      "asking any questions related to PII\n",
      "Embedding: [-0.01446382  0.06077691 -0.03933394 -0.03791679 -0.02616985 -0.0115243\n",
      "  0.04514082  0.00431385 -0.02506649 -0.0708828 ]...\n",
      "Sentence: Instead of asking for PII, such as username\n",
      "or password, refer the user to the help article: www.samplewebsite.com/help/faq.\n",
      "8.8\n",
      "Coding an AI Agent Using LangChain\n",
      "157\n",
      "Customer: I can’t log in to my account\n",
      "Embedding: [-0.07623713 -0.0350947  -0.06082846 -0.09859119 -0.05127094  0.02725035\n",
      "  0.03545048  0.01765518  0.00634659 -0.02117354]...\n",
      "Sentence: Agent:\n",
      "•\n",
      "Code Generation Speciﬁc: Use “leading words” to nudge the model toward a\n",
      "particular pattern.\n",
      "Less effective ✗:\n",
      "# Write a simple python function that # 1\n",
      "Embedding: [-0.0604932  -0.00886607 -0.0397887   0.02119234 -0.0291011  -0.01151942\n",
      "  0.00251681 -0.05576408 -0.01302223 -0.0184186 ]...\n",
      "Sentence: Ask me for a number in mile # 2\n",
      "Embedding: [ 0.06209135 -0.03252893  0.0517234  -0.01073147 -0.01714713  0.04424274\n",
      "  0.01852471  0.04398539  0.00707584 -0.10454798]...\n",
      "Sentence: It\n",
      "converts miles to kilometers\n",
      "In this code example below, adding “import” hints to the model that it should\n",
      "start writing in Python\n",
      "Embedding: [ 0.01323688 -0.00418517 -0.05879958  0.01069178 -0.00256936 -0.05227945\n",
      " -0.0749403   0.03891413 -0.03091391 -0.03762906]...\n",
      "Sentence: (Similarly, “SELECT” is a good hint for the start of a\n",
      "SQL statement.)\n",
      "Better ✓:\n",
      "# Write a simple python function that # 1\n",
      "Embedding: [ 0.0211468  -0.00106884  0.03183075  0.07199789 -0.0422987  -0.06047828\n",
      "  0.13843822  0.03019707 -0.0374741   0.0047208 ]...\n",
      "Sentence: Ask me for a number in mile # 2\n",
      "Embedding: [ 0.06209135 -0.03252893  0.0517234  -0.01073147 -0.01714713  0.04424274\n",
      "  0.01852471  0.04398539  0.00707584 -0.10454798]...\n",
      "Sentence: It\n",
      "converts miles to kilometers.\n",
      "import\n",
      "8.7.1\n",
      "Parameters\n",
      "Generally, we ﬁnd that model and temperature are the most commonly used\n",
      "parameters to alter the model output.\n",
      "model: Higher performance models are generally more expensive and may have\n",
      "higher latency.\n",
      "temperature: A measure of how often the model outputs a less likely token\n",
      "Embedding: [ 0.01028624 -0.0102084  -0.0389792   0.04183761  0.01340975 -0.02880767\n",
      " -0.06494012  0.05783254  0.03793036 -0.02387424]...\n",
      "Sentence: The\n",
      "higher the temperature, the more random (and usually creative) the output\n",
      "Embedding: [-0.03376278 -0.04016736 -0.03300973  0.07857016 -0.01126971 -0.04602362\n",
      "  0.00558704 -0.02126037  0.12823874  0.0070202 ]...\n",
      "Sentence: This,\n",
      "however, is not the same as “truthfulness.” For most factual use cases, such as data\n",
      "extraction and truthful Q&A, the temperature of 0 is best.\n",
      "max_tokens (maximum length): Does not control the length of the output, but a\n",
      "hard cutoff limit for token generation\n",
      "Embedding: [-0.02823878  0.04046029 -0.06515135  0.04240659 -0.01367107 -0.07778613\n",
      " -0.0321755  -0.03024534  0.04964149  0.01855689]...\n",
      "Sentence: Ideally, we will not hit this limit often, as our\n",
      "model will stop either when it thinks it is ﬁnished or when it hits a stop sequence\n",
      "we deﬁned.\n",
      "stop (stop sequences): A set of characters (tokens) that, when generated, will cause\n",
      "the text generation to stop.\n",
      "8.8\n",
      "Coding an AI Agent Using LangChain\n",
      "One useful application for LLMs is the ability to create intelligent and autonomous\n",
      "AI agents\n",
      "Embedding: [-0.02639283 -0.06939044  0.01640958 -0.04364676 -0.00521682  0.04624087\n",
      " -0.04721584 -0.00845426  0.09081635  0.0219337 ]...\n",
      "Sentence: An AI agent refers to a system or software that is capable of acting\n",
      "autonomously in an environment to meet its designed objectives or goals\n",
      "Embedding: [-0.00580082 -0.0144188  -0.06320856 -0.00454536  0.03782542 -0.06263807\n",
      "  0.03338774  0.03036632 -0.00964015  0.01911328]...\n",
      "Sentence: These\n",
      "agents can make decisions and perform actions without human intervention, based\n",
      "on the data they receive and their preprogrammed rules or learning algorithms\n",
      "Embedding: [ 0.00412224  0.01940204 -0.0967203  -0.02066058 -0.02895215  0.00127414\n",
      " -0.00332077 -0.01953174 -0.02783122  0.07797547]...\n",
      "Sentence: AI\n",
      "agents are capable of observing their environment through sensors and acting upon\n",
      "that environment with actuators.\n",
      "The capabilities of AI agents can range from simple, rule-based systems to\n",
      "complex, learning-based systems that utilize machine learning, deep learning, or\n",
      "reinforcement learning to adapt and improve their performance over time\n",
      "Embedding: [-0.00695467 -0.03727582  0.01505113  0.00278236  0.04642228 -0.02981152\n",
      "  0.04087971 -0.05031079 -0.04075428  0.0343024 ]...\n",
      "Sentence: AI agents\n",
      "158\n",
      "8\n",
      "Using Pretrained Networks\n",
      "are used in a wide array of applications, including virtual personal assistants,\n",
      "autonomous vehicles, smart home devices, game playing, ﬁnancial trading, health-\n",
      "care for diagnosis and treatment recommendations, and industrial automation for\n",
      "optimizing processes.\n",
      "We will make use of LangChain to create a simple AI agent\n",
      "Embedding: [-0.05670358 -0.05416938  0.00117097 -0.03659056 -0.02152171  0.0515322\n",
      "  0.02567259  0.0606501  -0.00809999 -0.05364062]...\n",
      "Sentence: LangChain is a\n",
      "powerful framework for quickly prototyping LLM applications by chaining together\n",
      "LLM tasks and running autonomous agents quickly and easily\n",
      "Embedding: [-0.01255731 -0.06541029  0.03412258 -0.11425265 -0.01261639 -0.03701323\n",
      " -0.04313134  0.02509857 -0.0079737  -0.01079609]...\n",
      "Sentence: LangChain consists\n",
      "of four main components:\n",
      "•\n",
      "LangChain Libraries: The Python and JavaScript libraries\n",
      "Embedding: [-0.03961536 -0.05950815  0.03250773 -0.03769633 -0.01439063 -0.03015727\n",
      " -0.0468981   0.01740038  0.0544161  -0.06561237]...\n",
      "Sentence: Contain interfaces and\n",
      "integrations for a myriad of components, a basic runtime for combining these\n",
      "components into chains and agents, and off-the-shelf implementations of chains\n",
      "and agents.\n",
      "•\n",
      "LangChain Templates: A collection of easily deployable reference architectures\n",
      "for a wide variety of tasks.\n",
      "•\n",
      "LangServe: A library for deploying LangChain chains as a REST API.\n",
      "•\n",
      "LangSmith: A developer platform that lets you debug, test, evaluate, and monitor\n",
      "chains built on any LLM framework and seamlessly integrates with LangChain.\n",
      "For our AI agent, we will implement code to augment OpenAI with information\n",
      "from our database\n",
      "Embedding: [-0.03924057 -0.03086247 -0.01727046 -0.03008143  0.01515959 -0.03513388\n",
      " -0.02110916  0.02185366 -0.01021795 -0.06347951]...\n",
      "Sentence: The process of bringing the appropriate information and inserting\n",
      "it into the model prompt is known as retrieval-augmented generation (RAG).\n",
      "LangChain has several tools to deal with questions and answers (Q&A) for\n",
      "unstructured data using RAG\n",
      "Embedding: [-0.07058991  0.05013878 -0.04511587  0.03924819 -0.05437793  0.05094555\n",
      " -0.02603911  0.01148853  0.00339519 -0.02472622]...\n",
      "Sentence: One such tool is Q&A over SQL data\n",
      "Embedding: [ 0.00123543 -0.03021408 -0.11570419  0.03603342 -0.13294117 -0.01331313\n",
      "  0.04959337 -0.01342636 -0.05284316  0.04583159]...\n",
      "Sentence: We will use this\n",
      "tool to build a simple application which embeds and stores data and then retrieves\n",
      "and generates answers using OpenAI LLM queries\n",
      "Embedding: [-0.01811014 -0.0688872  -0.09315757  0.09923048  0.03060218  0.0261711\n",
      " -0.04497068  0.01828194 -0.03004044 -0.02317795]...\n",
      "Sentence: The embedding and storing are\n",
      "done ofﬂine, while the data retrieval and answer generation are carried out in real\n",
      "time.\n",
      "Our RAG architecture is simple and is typical of a RAG application\n",
      "Embedding: [-0.08214349  0.02064523 -0.03961835 -0.01704415 -0.11189868  0.01788059\n",
      " -0.05617641  0.01975411  0.03321228 -0.01974636]...\n",
      "Sentence: It has two\n",
      "components:\n",
      "•\n",
      "Indexing: A pipeline for ingesting data from a source and indexing it\n",
      "Embedding: [-0.00423804  0.00607046 -0.04821708  0.03300715  0.04556981 -0.05033997\n",
      "  0.01147722 -0.00097387 -0.02743412 -0.00762298]...\n",
      "Sentence: This\n",
      "usually happens ofﬂine.\n",
      "•\n",
      "Retrieval and Generation: The actual RAG chain, which takes the user query at\n",
      "runtime and retrieves the relevant data from the index, then passes that to the\n",
      "model.\n",
      "8.8.1\n",
      "Indexing Using VectorDB\n",
      "For the indexing part, there are three steps involved as depicted in Figure 8-5\n",
      "Embedding: [-0.02563588  0.0172577   0.04096061  0.11362753 -0.00928144  0.01010093\n",
      "  0.01458868  0.02209364  0.00568334 -0.05972535]...\n",
      "Sentence: The\n",
      "data loading step loads data from a variety of sources, including PDFs, text, URLs,\n",
      "and images, and is done using the DocumentLoaders toolkit.\n",
      "The document loader has both built-in functions for loading text, CSV, PDF,\n",
      "image, JSON, and markup as well as third-party community libraries for loading\n",
      "8.8\n",
      "Coding an AI Agent Using LangChain\n",
      "159\n",
      "Figure 8-5 Indexing procedure in RAG [13]\n",
      "other types of data and websites, such as Wikipedia, WhatsApp chat, and YouTube.\n",
      "The Split toolkit is a text splitter which breaks large Documents into smaller\n",
      "chunks\n",
      "Embedding: [-0.10066401  0.04813103 -0.00876716  0.0072172   0.02936075 -0.06445042\n",
      " -0.08264089  0.06785464  0.00986322 -0.0236351 ]...\n",
      "Sentence: This is useful both for indexing data and for passing it in to a model, since\n",
      "large chunks are harder to search over and will not ﬁt in a model’s ﬁnite context\n",
      "window.\n",
      "The Vector Store and Embeddings models are responsible for embedding and\n",
      "storing vectors\n",
      "Embedding: [ 0.00276404  0.00397534 -0.03751523  0.04289322  0.1087258   0.0274996\n",
      " -0.0100754  -0.00396061  0.1121315  -0.02679667]...\n",
      "Sentence: These models transform data into a latent format speciﬁc to a\n",
      "particular large language model (LLM)\n",
      "Embedding: [ 0.02565169 -0.05073994 -0.02636116  0.00338788  0.04726948  0.07826232\n",
      " -0.09202596 -0.034093    0.03178984  0.00823208]...\n",
      "Sentence: For example, when using the ChatGPT\n",
      "model, data embedding is performed using the ChatGPT-speciﬁc embedding tech-\n",
      "nique\n",
      "Embedding: [-0.02860847 -0.09077542  0.03306957 -0.00341342 -0.00731053 -0.00590447\n",
      " -0.00434409  0.01925542  0.05399397 -0.03491312]...\n",
      "Sentence: Conversely, if the Gemini model is employed, data must be embedded using\n",
      "the embedding method unique to Gemini\n",
      "Embedding: [-0.03553385 -0.04010633  0.00254646 -0.00133603  0.01534869  0.03181578\n",
      " -0.08387813  0.00223806 -0.00227531 -0.0860379 ]...\n",
      "Sentence: Once the data is embedded, when we\n",
      "query the data at query time, we embed the unstructured query and retrieve the\n",
      "embedding vectors that are “most similar” to the embedded query\n",
      "Embedding: [-0.01078437 -0.01445106 -0.01148074  0.08131336  0.05552218  0.03661296\n",
      " -0.00626259 -0.01575276  0.02963652 -0.06058235]...\n",
      "Sentence: A diagrammatic\n",
      "view of storing and querying a vector store is shown in Figure 8-6\n",
      "Embedding: [-0.00439946  0.03579266 -0.1313653   0.02995922 -0.05379559  0.01998181\n",
      "  0.00565328  0.02970273 -0.00500921  0.0340761 ]...\n",
      "Sentence: The LangChain\n",
      "Indexing API syncs your data from any source into a vector store, helping us to\n",
      "avoid writing duplicated content into the vector store, rewriting unchanged content,\n",
      "and recomputing embeddings over unchanged content.\n",
      "A vector store takes care of storing embedded data and performing vector search\n",
      "for us\n",
      "Embedding: [-0.06278607  0.0191967   0.01622698  0.03486215  0.02881106  0.00367781\n",
      " -0.04789885 -0.02860759  0.07683606 -0.0519078 ]...\n",
      "Sentence: The vector store itself does not impose an embedding method\n",
      "Embedding: [-0.01898996 -0.00851764 -0.04709704  0.00843748 -0.00186942  0.05165417\n",
      " -0.06596967 -0.0036776   0.00142383  0.00851561]...\n",
      "Sentence: A vector\n",
      "store is simply a specialized database or storage system designed to efﬁciently store\n",
      "and manage vector embeddings\n",
      "Embedding: [-0.00728995 -0.00832238 -0.10332371  0.03612613  0.00278663  0.01699059\n",
      " -0.05340097 -0.00277974  0.0067905   0.02000783]...\n",
      "Sentence: Vector embeddings, as we have seen, are high-\n",
      "dimensional representations of data, typically text, images, or any form of content\n",
      "that has been converted into numerical vectors using various embedding techniques.\n",
      "These embeddings capture the semantic or contextual similarities between data\n",
      "points in a way that can be easily processed by algorithms.\n",
      "160\n",
      "8\n",
      "Using Pretrained Networks\n",
      "Figure 8-6 Querying a vector store [14]\n",
      "Vector stores are optimized to handle the speciﬁc challenges associated with\n",
      "storing and querying high-dimensional data\n",
      "Embedding: [ 0.01940529 -0.02755198 -0.0332101   0.0071221   0.02986857  0.05595047\n",
      " -0.03075063  0.01013264  0.00914334 -0.05712301]...\n",
      "Sentence: They support operations such as\n",
      "nearest neighbor search, which is the task of ﬁnding the most similar vectors in the\n",
      "store to a given query vector\n",
      "Embedding: [-0.04556934 -0.0245856  -0.08369396 -0.02935679  0.01503976 -0.00121115\n",
      " -0.00737487 -0.02268897  0.03065178  0.00233602]...\n",
      "Sentence: This is crucial in applications like recommendation\n",
      "systems, similarity searches, and clustering, where understanding the relationship\n",
      "between data points based on their embeddings is essential.\n",
      "There are many open source vector stores available which can be installed and\n",
      "run locally\n",
      "Embedding: [-0.01082906 -0.09305143 -0.05659194 -0.0246259   0.09390973  0.06593484\n",
      "  0.00179863  0.00096482  0.04645243 -0.09987871]...\n",
      "Sentence: For our example, we choose Chroma VectorDB because it is lightweight\n",
      "and easy to conﬁgure, although the FAISS vector database, which makes use of the\n",
      "Facebook AI Similarity Search (FAISS) library, is another possible candidate.1\n",
      "8.8.2\n",
      "Retrieval Mechanism in LangChain\n",
      "Once data is stored in the document storage, which in general could be a data store\n",
      "other than VectorDB, retrieving it effectively is crucial\n",
      "Embedding: [-0.08753201 -0.01088038 -0.04065752  0.00819393  0.02594377  0.04087499\n",
      " -0.04628441  0.07656965  0.03432877 -0.00334009]...\n",
      "Sentence: LangChain offers several\n",
      "retrieval algorithms, such as basic semantic search\n",
      "Embedding: [-0.00819678  0.02805013  0.01936353 -0.03107458 -0.01868617  0.02982305\n",
      " -0.01300444  0.03133442  0.03067847 -0.05120629]...\n",
      "Sentence: Beyond this basic approach,\n",
      "LangChain enhances performance with an array of advanced algorithms via its\n",
      "retrievers, including\n",
      "•\n",
      "Parent Document Retriever: Enhances retrieval ﬂexibility by generating multiple\n",
      "embeddings for each parent document\n",
      "Embedding: [-0.08304632  0.02248899  0.04991828 -0.00418037  0.02066026  0.00202601\n",
      " -0.0892743   0.00480634  0.08457642 -0.09062633]...\n",
      "Sentence: This feature enables queries on speciﬁc\n",
      "segments while providing results within a broader context.\n",
      "•\n",
      "Self-Query Retriever: Recognizes that user queries often entail more than\n",
      "semantic content, incorporating logical references that are best addressed through\n",
      "metadata ﬁltering\n",
      "Embedding: [ 0.01382078  0.03809234 -0.02609072  0.02016042  0.00831393 -0.04230737\n",
      "  0.06514748  0.0085701   0.00556055 -0.06910089]...\n",
      "Sentence: This retriever separates the semantic elements from metadata\n",
      "ﬁlters within a query, optimizing the retrieval process.\n",
      "1 FAISS is powerful but challenging to conﬁgure for a particular application.\n",
      "8.8\n",
      "Coding an AI Agent Using LangChain\n",
      "161\n",
      "Table 8.1 Overview of retrieval methods [15]\n",
      "Name\n",
      "Index type\n",
      "Uses LLM\n",
      "When to use\n",
      "Description\n",
      "Vector store\n",
      "Vector store\n",
      "No\n",
      "Getting\n",
      "started,\n",
      "simplicity\n",
      "preferred\n",
      "The simplest method,\n",
      "ideal for beginners.\n",
      "Involves creating\n",
      "embeddings for each\n",
      "text piece\n",
      "Parent\n",
      "document\n",
      "Vector store +\n",
      "document store\n",
      "No\n",
      "Distinct\n",
      "information in\n",
      "documents\n",
      "Indexes multiple\n",
      "chunks per document,\n",
      "retrieving the whole\n",
      "document for similar\n",
      "chunks\n",
      "Multivector\n",
      "Vector store +\n",
      "document store\n",
      "Sometimes\n",
      "Relevant\n",
      "information\n",
      "extraction\n",
      "Creates multiple vectors\n",
      "per document for\n",
      "diverse indexing\n",
      "strategies\n",
      "Self-query\n",
      "Vector store\n",
      "Yes\n",
      "Metadata-\n",
      "based\n",
      "queries\n",
      "Splits user queries into\n",
      "semantic searches and\n",
      "metadata ﬁlters\n",
      "Contextual\n",
      "compression\n",
      "Any\n",
      "Sometimes\n",
      "Reducing\n",
      "irrelevant\n",
      "information\n",
      "Applies post-processing\n",
      "to extract the most\n",
      "relevant information\n",
      "from documents\n",
      "Time-\n",
      "weighted\n",
      "vector store\n",
      "Vector store\n",
      "No\n",
      "Document\n",
      "recency is\n",
      "important\n",
      "Combines semantic\n",
      "similarity and\n",
      "timestamp data for\n",
      "retrieval\n",
      "Multi-query\n",
      "retriever\n",
      "Any\n",
      "Yes\n",
      "Complex\n",
      "queries\n",
      "Generates multiple\n",
      "queries from one to\n",
      "cover various topics\n",
      "Ensemble\n",
      "Any\n",
      "No\n",
      "Combining\n",
      "retrieval\n",
      "methods\n",
      "Uses multiple retrievers\n",
      "for comprehensive\n",
      "document fetching\n",
      "Long-context\n",
      "reorder\n",
      "Any\n",
      "No\n",
      "Attention to\n",
      "document\n",
      "context\n",
      "Reorders documents to\n",
      "highlight the most\n",
      "relevant information at\n",
      "the beginning and end\n",
      "•\n",
      "Ensemble Retriever: Designed for scenarios requiring document retrieval from\n",
      "varied sources or through multiple algorithms\n",
      "Embedding: [-0.01531848  0.03656248 -0.01909775  0.02863734  0.00990465  0.00672067\n",
      "  0.02493011  0.05022167  0.01132107 -0.00521283]...\n",
      "Sentence: This retriever streamlines the\n",
      "process, enabling efﬁcient and comprehensive document retrieval across diverse\n",
      "databases and methodologies.\n",
      "The website for LangChain provides a succinct table for the different retrieval\n",
      "methods and when to use them, which is displayed in Table 8.1.\n",
      "We end this section on LangChain by providing snippets of code to demonstrate\n",
      "the various stages in building an in-house AI agent to help with learning LangChain.\n",
      "The source of data will be web pages from Langchain.com, instructional videos, and\n",
      "162\n",
      "8\n",
      "Using Pretrained Networks\n",
      "PDFs\n",
      "Embedding: [-0.04687163 -0.01866602  0.01181977  0.00996479 -0.01156194  0.04501113\n",
      " -0.01209412  0.04436848 -0.02873415 -0.06871617]...\n",
      "Sentence: The downloaded data will be cleaned and stored in a VectorDB\n",
      "Embedding: [ 0.00544077  0.02704507 -0.1034132  -0.02004041  0.03720121 -0.05622736\n",
      "  0.03454838 -0.05522179 -0.02744148  0.01601859]...\n",
      "Sentence: We will then\n",
      "augment OpenAI with our database and send some pertinent queries to view the\n",
      "result.\n",
      "8.9\n",
      "Company Chatbot Using LangChain\n",
      "First, we install all the necessary packages\n",
      "Embedding: [-0.04506845 -0.05601189  0.00630478  0.02714404  0.01757135 -0.04951402\n",
      " -0.01692323  0.00266936  0.00605343 -0.04427458]...\n",
      "Sentence: In this exercise, we will use the OpenAI\n",
      "LLM, so you will need to subscribe to OpenAI and get the API key\n",
      "Embedding: [-0.00443216 -0.04140003 -0.07510561 -0.00937465  0.02138218 -0.00984159\n",
      " -0.02327712 -0.01596028 -0.00148094 -0.00869222]...\n",
      "Sentence: In addition, at\n",
      "least at the time of writing, you will also have to pay OpenAI a small fee to query\n",
      "its database.\n",
      "pip install langchain-openai\n",
      "pip install beautifulsoup4\n",
      "pip install unstructured\n",
      "pip install lxml\n",
      "The beautiful soup and unstructured packages are used to streamline and optimize\n",
      "the data processed around LLMs\n",
      "Embedding: [ 0.05879424 -0.06365291  0.0364313   0.02543756  0.02566272 -0.04609691\n",
      " -0.07629893  0.01021525 -0.01778802  0.02091704]...\n",
      "Sentence: The beautiful soup scrapes the web pages, while\n",
      "the unstructured library provides tools to preprocess text documents, PDFs, and\n",
      "HTMLs.\n",
      "def scrape_page_and_save(url, output_dir ,\n",
      "base_url , depth=0, max_depth=3):\n",
      "if depth >= max_depth:\n",
      "# Terminate recursion if maximum depth is reached\n",
      "return\n",
      "# Skip ’mailto’ URLs\n",
      "if url.startswith(’mailto:’) or not url.startswith(base_url):\n",
      "return\n",
      "try:\n",
      "response = requests.get(url)\n",
      "soup = BeautifulSoup(response.text, ’lxml ’)\n",
      "paragraphs = soup.find_all(’p’)\n",
      "# Check if the page has any content\n",
      "if not paragraphs:\n",
      "return\n",
      "# Skip empty pages\n",
      "filename = os.path.join(output_dir , url.\n",
      "split(’/’)[-1] + ’.txt’)\n",
      "with open(filename , ’w’, encoding=’utf-8’) as f:\n",
      "for paragraph in paragraphs:\n",
      "line = paragraph.text.strip() + ’\\n’\n",
      "try:\n",
      "f.write(line)\n",
      "f.flush()\n",
      "except Exception as e:\n",
      "print(f\"Error writing to file: {e}\")\n",
      "# Find links to other pages and recursively scrape them\n",
      "links = soup.find_all(’a’, href=True)\n",
      "for link in links:\n",
      "absolute_url = urljoin(url, link[’href ’])\n",
      "# Recursively scrape the subpage and save it\n",
      "8.9\n",
      "Company Chatbot Using LangChain\n",
      "163\n",
      "scrape_page_and_save(absolute_url ,\n",
      "output_dir , base_url , depth=depth +\n",
      "1, max_depth=max_depth)\n",
      "except requests.exceptions.RequestException as e:\n",
      "print(f\"Error occurred while scraping {url}: {e}\")\n",
      "The code above will recursively scrape all child pages and parent page\n",
      "Embedding: [-0.11974097  0.04123417  0.05040641  0.0314685   0.06796892 -0.10000072\n",
      " -0.11987845 -0.07860652  0.01339138 -0.02601239]...\n",
      "Sentence: However,\n",
      "it does not scrape external pages to the base URL to prevent links to GitHub via the\n",
      "code listing within the child pages.\n",
      "In addition to extracting data from web pages, a transcription of YouTube\n",
      "videos is occasionally required\n",
      "Embedding: [-0.1104177  -0.09550814 -0.03474638 -0.02177093  0.12274002 -0.04002904\n",
      " -0.08696494 -0.03462926 -0.00546605 -0.04247519]...\n",
      "Sentence: There are two main methods for accomplishing\n",
      "this\n",
      "Embedding: [ 0.03626987  0.00590151 -0.10685774 -0.02839669 -0.06951562  0.01420754\n",
      " -0.03698279  0.00029752 -0.04460069 -0.02162427]...\n",
      "Sentence: The ﬁrst method involves downloading the video via their API, followed by\n",
      "employing the OpenAI Whisper API to transcribe the text from the resulting audio\n",
      "ﬁle\n",
      "Embedding: [ 0.01315568 -0.05316022 -0.0829575  -0.03913976  0.12229514 -0.00974805\n",
      " -0.06980529 -0.00629086  0.06293261 -0.06879309]...\n",
      "Sentence: Alternatively, if a transcription is already available, tools like the youtube-\n",
      "transcript-api can be utilized to convert the text into English\n",
      "Embedding: [-0.03161358 -0.06315114 -0.06352503 -0.04819201  0.05282165  0.04977566\n",
      " -0.04079396 -0.00183246 -0.0159646  -0.01372448]...\n",
      "Sentence: One drawback of using\n",
      "the Whisper API is its cost, as it is a paid service, whereas the youtube-transcript-api\n",
      "is freely available as open source software.\n",
      "We will illustrate the transcription using both methods\n",
      "Embedding: [-0.10421314 -0.10617496 -0.01647842 -0.04031283  0.09032333  0.03280948\n",
      " -0.06309092 -0.03227238  0.05021114 -0.08076964]...\n",
      "Sentence: We begin by installing\n",
      "the packages as usual:\n",
      "pip install pytube moviepy openai-whisper\n",
      "pip install youtube-transcript-api\n",
      "The YouTube transcript API transcribes the text in a particular language and\n",
      "converts the data into a consistent string of a given format, such as a basic text (.txt),\n",
      "or even formats that have a deﬁned speciﬁcation, such as JSON (.json), WebVTT\n",
      "(.vtt), SRT (.srt), comma-separated format (.csv), etc.\n",
      "To demonstrate its application, we will transcribe a tutorial video from\n",
      "LangChain on creating an open source software (OSS) model retrieval agent with\n",
      "the help of Mistral and Nomic Embed Text\n",
      "Embedding: [-0.06053588 -0.08824225 -0.01233447 -0.03075097  0.08967346  0.00047844\n",
      " -0.06178172  0.04566617  0.04866581 -0.11396559]...\n",
      "Sentence: Initially, we’ll download the video and\n",
      "then use the youtube-transcript-api to transform it into text.\n",
      "def text_from_YouTube_video(video_id ,output_file):\n",
      "transcript = YouTubeTranscriptApi.\n",
      "get_transcript(video_id ,languages=[’en’])\n",
      "formatter = TextFormatter()\n",
      "text_format = formatter.format_transcript(transcript);\n",
      "# remove some characters from the transcript\n",
      "text_format = text_format.replace(’\\n’, ’ ’).\n",
      "replace(’um’, ’’).replace(’uh’, ’’)\n",
      "with open(output_file , ’w’, encoding=’utf-8’) as text_file:\n",
      "text_file.write(text_format)\n",
      "youtube_url = ’Ce03oEotdPs ’\n",
      "text_from_YouTube_video(youtube_url ,output_directory\n",
      "+ \"/langchainvideo.txt\")\n",
      "Often, numerous instances of “um” and “uh” are found, which are then elimi-\n",
      "nated by the .replace() line prior to saving to a text ﬁle.\n",
      "As an alternative to using the YouTubeTranscriptApi, we can employ the\n",
      "Whisper API to transcribe the audio portion of the video\n",
      "Embedding: [-0.05686346 -0.00435687  0.0133727  -0.03620584  0.01039678  0.04011303\n",
      "  0.01316198  0.03223085  0.03196621 -0.05431005]...\n",
      "Sentence: To transcribe a YouTube\n",
      "164\n",
      "8\n",
      "Using Pretrained Networks\n",
      "video using OpenAI’s Whisper API in Python, we will start by downloading the\n",
      "video from YouTube\n",
      "Embedding: [-0.03662496 -0.08749378 -0.02958274 -0.01717964  0.0562534  -0.04399198\n",
      " -0.03811052 -0.00571189  0.00256122 -0.07927542]...\n",
      "Sentence: This can be achieved through the pytube library, which allows\n",
      "for the retrieval of videos via their URLs\n",
      "Embedding: [-0.00732134 -0.10016212 -0.07788024 -0.03378373  0.09864733  0.03146571\n",
      " -0.10702623 -0.00612894  0.03659146 -0.12637515]...\n",
      "Sentence: After downloading the video, we may\n",
      "need to extract its audio component to ensure that the Whisper API can transcribe\n",
      "the spoken content accurately\n",
      "Embedding: [ 0.00194858 -0.0948984   0.00930868 -0.06572768  0.07581659 -0.00261399\n",
      " -0.05474257 -0.10878097  0.05070267 -0.06257703]...\n",
      "Sentence: The MoviePy tool can assist in converting the video\n",
      "ﬁle into an audio format, such as MP3, compatible with the Whisper API.\n",
      "After saving the audio ﬁle, the subsequent step involves using OpenAI’s Whisper\n",
      "model to transcribe the audio to text\n",
      "Embedding: [-0.00968052 -0.09546229 -0.05415705 -0.01466773  0.04935588  0.01636926\n",
      " -0.05871304 -0.02583813  0.00967058 -0.10021802]...\n",
      "Sentence: The Whisper Python package provides a\n",
      "straightforward method for loading the model and processing the audio ﬁle to\n",
      "generate a transcription\n",
      "Embedding: [-0.08465958 -0.1434943  -0.03066994 -0.01504052 -0.00586805 -0.01535317\n",
      " -0.0824555  -0.06253552 -0.01258682 -0.10199004]...\n",
      "Sentence: By indicating the path to the audio ﬁle, the API processes\n",
      "the content and delivers the transcribed text\n",
      "Embedding: [-0.03431643 -0.01429474 -0.10567091 -0.07300621 -0.00388303  0.03420443\n",
      " -0.03707881 -0.02554349  0.06253202 -0.11393151]...\n",
      "Sentence: We transcribe the same video as before\n",
      "and save it down so that the reader can compare the accuracy between the two\n",
      "conversion methods.\n",
      "def download_youtube_audio(youtube_url , filename):\n",
      "# Download YouTube video audio stream\n",
      "video = YouTube(youtube_url).streams.filter(only_audio=True).\n",
      "first()\n",
      "download_path = video.download()\n",
      "# This downloads the audio\n",
      "in its native format (usually .mp4 or .webm)\n",
      "base, ext = os.path.splitext(download_path)\n",
      "os.rename(download_path , filename)\n",
      "def transcribe_audio_with_whisper(filename ,output_file):\n",
      "# Load the Whisper model\n",
      "model = whisper.load_model(\"base\")\n",
      "# Transcribe the audio file\n",
      "result = model.transcribe(f\"{filename}\")\n",
      "text_format = result[’text’]\n",
      "text_format = text_format.replace(’\\n’, ’ ’).replace(’um’,\n",
      "’’).replace(’Um’, ’’).replace(’Uh’, ’’).replace(’uh’, ’’)\n",
      "with open(output_file , ’w’, encoding=’utf-8’) as text_file:\n",
      "text_file.write(text_format)\n",
      "Once the data downloading is completed, the next step is text preprocessing and\n",
      "feature extraction\n",
      "Embedding: [-0.00531941 -0.09899114 -0.00018302 -0.01999315  0.05602854 -0.05185617\n",
      "  0.01550524 -0.00891351  0.01618465 -0.06315641]...\n",
      "Sentence: Text data often comes with noise and formatting that may not be\n",
      "relevant for analysis\n",
      "Embedding: [ 0.0279487   0.05080789 -0.00572815  0.03790985  0.0181607  -0.03103217\n",
      " -0.00198276 -0.05033411  0.04874654 -0.01577265]...\n",
      "Sentence: Preprocessing aims to clean and standardize the text, which\n",
      "might include\n",
      "•\n",
      "Removing special characters and punctuation.\n",
      "•\n",
      "Lowercasing all text to maintain consistency.\n",
      "•\n",
      "Eliminating stopwords (common words that add little semantic value)\n",
      "Embedding: [ 0.02818392  0.085853    0.03592933 -0.02552828 -0.00526729 -0.00930604\n",
      " -0.04425925 -0.03586859 -0.04666582  0.0643106 ]...\n",
      "Sentence: For this\n",
      "task, we will use the Natural Language Toolkit (nltk) for stopword removal\n",
      "simply by using pip install nltk.\n",
      "•\n",
      "Segmenting longer documents into smaller chunks to ensure that embeddings\n",
      "accurately represent the document’s content.\n",
      "8.9\n",
      "Company Chatbot Using LangChain\n",
      "165\n",
      "A simple function to preprocess the data is shown below\n",
      "Embedding: [-0.0484334   0.08631279  0.05856112 -0.00340792  0.04960978 -0.03228803\n",
      "  0.0362426  -0.07517049 -0.01296653 -0.0296552 ]...\n",
      "Sentence: In a large-scale project,\n",
      "we might use a more sophisticated library to handle this task\n",
      "Embedding: [-0.04046796 -0.00573697 -0.07402933 -0.01172848  0.05560914 -0.06824695\n",
      " -0.04472283  0.01356161 -0.0627602  -0.00309382]...\n",
      "Sentence: Commercial tools\n",
      "like IBM Watson Natural Language Understanding or open-source libraries such\n",
      "as spaCy are highly robust and capable of managing a wide variety of textual\n",
      "inputs, making them versatile for processing raw or minimally processed text.\n",
      "However, customized preprocessing can ﬁne-tune the input data to better align with\n",
      "speciﬁc objectives, potentially enhancing the relevance and accuracy of the model’s\n",
      "responses.\n",
      "After preprocessing, we use OpenAI embedding and FAISS to store and index the\n",
      "tokens\n",
      "Embedding: [-0.00838779 -0.02977783 -0.00347791  0.06007025  0.04110457  0.02902757\n",
      " -0.01528522  0.02871685  0.02479706 -0.03905269]...\n",
      "Sentence: Technologies like FAISS play a crucial role in this component by enabling\n",
      "fast retrieval of similar embeddings\n",
      "Embedding: [-0.04918732 -0.06864636  0.00486468 -0.03703079  0.09297274  0.02924502\n",
      " -0.03255026 -0.03189218  0.09701066 -0.04056238]...\n",
      "Sentence: If you have a local GPU, then install FAISS\n",
      "using pip install faiss-gpu; otherwise, use pip install faiss-cpu.\n",
      "An embedding is a high-dimensional vector that represents text in a form that\n",
      "captures its semantic meaning\n",
      "Embedding: [ 0.04966645 -0.03103466 -0.06671576 -0.02053957  0.06587244 -0.05223665\n",
      " -0.05531972  0.03730559 -0.00835963 -0.07424843]...\n",
      "Sentence: OpenAI provides an embeddings API that supports\n",
      "various models optimized for embedding generation\n",
      "Embedding: [-0.02747009 -0.10402303 -0.00356284  0.06470788  0.09516349  0.04978368\n",
      " -0.13196938 -0.02367745  0.07874741 -0.08520244]...\n",
      "Sentence: Using this API, each document\n",
      "or text snippet is transformed into a vector\n",
      "Embedding: [-0.06946363  0.06601048 -0.05457121  0.04445332  0.07196351  0.02933086\n",
      " -0.05086492 -0.01433457  0.08750337 -0.01862309]...\n",
      "Sentence: We had to deal with a similar problem\n",
      "in our VAE model.\n",
      "The rest of the code to create a query agent is described below:\n",
      "import shutil\n",
      "import os\n",
      "from langchain.vectorstores.faiss import FAISS\n",
      "from langchain.prompts import ChatPromptTemplate\n",
      "from langchain.embeddings.openai import OpenAIEmbeddings\n",
      "from langchain.document_loaders import DirectoryLoader ,\n",
      "TextLoader\n",
      "from langchain.text_splitter import\n",
      "RecursiveCharacterTextSplitter\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "FAISS_PATH = \"~/AI/Data/Chatbot/faiss_index\"\n",
      "llm = ChatOpenAI(api_key=os.environ[’OPENAI_API_KEY ’])\n",
      "PROMPT_TEMPLATE = \"\"\"\n",
      "Use the following context to answer the question:\n",
      "{context}\n",
      "---\n",
      "Answer the question based on the above context: {query}\"\"\"\n",
      "def save_directory_text_to_store(path):\n",
      "text_loader_kwargs = {’autodetect_encoding ’: True}\n",
      "loader = DirectoryLoader(path, glob=\"**/*.txt\", loader_cls=\n",
      "TextLoader , loader_kwargs=text_loader_kwargs ,\n",
      "show_progress=True)\n",
      "documents = loader.load()\n",
      "text_splitter = RecursiveCharacterTextSplitter(chunk_size\n",
      "=2000, chunk_overlap=200, length_function=len,\n",
      "add_start_index=True)\n",
      "chunks = text_splitter.split_documents(documents)\n",
      "if os.path.exists(FAISS_PATH): shutil.rmtree(FAISS_PATH)\n",
      "db = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
      "db.save_local(FAISS_PATH)\n",
      "166\n",
      "8\n",
      "Using Pretrained Networks\n",
      "print(f\"Save {len(chunks)}\")\n",
      "return db\n",
      "def get_db():\n",
      "embedding_function = OpenAIEmbeddings()\n",
      "db = FAISS.load_local(FAISS_PATH , embedding_function)\n",
      "return db\n",
      "The function save_directory_text_to_store(path) loads text ﬁles from a speciﬁed\n",
      "directory(path), auto-detects their encodings, and reads their content\n",
      "Embedding: [-0.02678714  0.00929824  0.01255863  0.03358098 -0.07168522  0.03095207\n",
      "  0.05506624  0.07428341  0.07316397 -0.02693833]...\n",
      "Sentence: It then splits\n",
      "the documents into chunks using a RecursiveCharacterTextSplitter, which is conﬁg-\n",
      "ured to divide the text into segments with a speciﬁc chunk size and overlap, aiding\n",
      "in handling large documents and ensuring continuity of context across chunks.\n",
      "The reason why we need to overlap the text is to provide context for the model;\n",
      "otherwise, the individual chunks of text will be disjointed.\n",
      "If the FAISS index exists at FAISS_PATH, it deletes the existing index to prevent\n",
      "duplication\n",
      "Embedding: [-0.0484941   0.03337586  0.00313748  0.03515229  0.07317726 -0.01552524\n",
      "  0.00948865  0.01002909  0.08992606 -0.00713027]...\n",
      "Sentence: It also uses the FAISS module to create a new vector store from the\n",
      "document chunks, with embeddings generated via OpenAIEmbeddings.\n",
      "Finally, the function saves the newly created FAISS index to the local ﬁlesystem\n",
      "for later retrieval.\n",
      "As the reader can see, LangChain has hidden most of the complexity in\n",
      "preprocessing the data into its tools so that the user can concentrate on high-level\n",
      "coding.\n",
      "Once we have created a vector database and are able to query it, performing RAG\n",
      "with OpenAI can be done with the code below:\n",
      "def query_openai_and_faiss(store, query_text):\n",
      "# use the faiss vector store we saved to search the local\n",
      "document\n",
      "retriever = store.as_retriever(search_type=\"mmr\",\n",
      "search_kwargs={\"k\": 3})\n",
      "results = retriever.get_relevant_documents(query_text)\n",
      "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc\n",
      "in results])\n",
      "prompt_template = ChatPromptTemplate.from_template(\n",
      "PROMPT_TEMPLATE)\n",
      "prompt = prompt_template.format(context=context_text , query=\n",
      "query_text)\n",
      "print(prompt)\n",
      "response_text = llm.predict(prompt)\n",
      "sources = [doc.metadata.get(\"source\", None) for doc in\n",
      "results]\n",
      "index = [doc.metadata.get(\"start_index\", None) for doc in\n",
      "results]\n",
      "formatted_response = f\"Response: {response_text}\\nSources: {\n",
      "sources} index: {index}\"\n",
      "print(formatted_response)\n",
      "return response_text\n",
      "The program above outputs the following response to the query:\n",
      "8.9\n",
      "Company Chatbot Using LangChain\n",
      "167\n",
      "Answer the question based on the above context: How can I use LangChain to\n",
      "build a chatbot?\n",
      "Response: To build a chatbot using LangChain, you can follow the steps outlined\n",
      "in the quickstart guide provided\n",
      "Embedding: [-0.0269208   0.05057168 -0.05441256  0.0736588   0.02124909 -0.01677985\n",
      " -0.03650248  0.05103626  0.03731154 -0.06189018]...\n",
      "Sentence: First, you will need to install the LangChain\n",
      "Anthropic integration package and obtain an API key by creating an account.\n",
      "Then, you can set the API key as an environment variable or pass it directly when\n",
      "initializing the Anthropic Chat Model class.\n",
      "After setting up the integration package, you can initialize the LLM of your\n",
      "choice and use prompt templates to guide the responses\n",
      "Embedding: [ 0.01515926  0.02054138 -0.00321928 -0.03212834 -0.03609366  0.01769262\n",
      "  0.02428052  0.01762327  0.0207944   0.04146032]...\n",
      "Sentence: Additionally, you can\n",
      "utilize retrieval to provide additional context to the LLM by fetching relevant data\n",
      "from external sources.\n",
      "By following the instructions in the quickstart guide and utilizing features such as\n",
      "prompts, models, output parsers, and retrieval, you can successfully build a chatbot\n",
      "using LangChain\n",
      "Embedding: [-0.01437307 -0.06967899  0.04905972 -0.03667913  0.01486466 -0.03634347\n",
      " -0.00388848  0.04231056  0.02008092 -0.0399982 ]...\n",
      "Sentence: Remember to refer to the documentation for a deeper dive into\n",
      "the process and for more advanced techniques\n",
      "Embedding: [-0.01766604 -0.02746565 -0.0629081  -0.03075296 -0.01776997 -0.07513935\n",
      " -0.10093364  0.09884001 -0.11270025 -0.00074274]...\n",
      "Sentence: Sources:\n",
      "[’~/AI/Data/Chatbot/get_started.txt’,\n",
      "’~/AI/Data/Chatbot/quickstart#updating-retrieval.txt’\n",
      "’~/AI/Data/Chatbot/quickstart#setup.txt’]\n",
      "index: [0, 1775, 0]\n",
      "The function query_openai_and_faiss(store, query_text) converts the FAISS\n",
      "store into a document retriever with speciﬁc search conﬁgurations and executes\n",
      "a search in the FAISS index to ﬁnd documents relevant to the query_text\n",
      "Embedding: [-0.03195537  0.04604367 -0.04975404  0.08838847  0.0247252  -0.02784224\n",
      "  0.03931975  0.05490082  0.07384565 -0.01486066]...\n",
      "Sentence: It\n",
      "then constructs a context text from the retrieved documents, separating them with\n",
      "markers for clarity.\n",
      "In addition to retrieving content, we extract source and index metadata from\n",
      "the retrieved documents, formatting this information alongside the response for\n",
      "reference.\n",
      "The ChatPromptTemplate formats the ﬁnal prompt by injecting the constructed\n",
      "context and the original query before submitting the prompt to the ChatOpenAI\n",
      "model\n",
      "Embedding: [ 0.00296776  0.06055592  0.00417552  0.07192928  0.0677112   0.01285887\n",
      "  0.11906534  0.0248319   0.07362293 -0.01686147]...\n",
      "Sentence: The template instructs ChatGPT to summarize the answer using only the\n",
      "information returned in the context\n",
      "Embedding: [-0.03738783  0.13754049  0.04494083  0.007772    0.03861409  0.03788581\n",
      "  0.12323289  0.06882288  0.04794872 -0.00290427]...\n",
      "Sentence: It is possible to augment its knowledge with\n",
      "LangChain using our private data to provide answers, rather than relying solely on\n",
      "the context data.\n",
      "If we intend to use both OpenAI and FAISS data in the querying process, we\n",
      "need to integrate the embeddings generated by OpenAI with those stored in FAISS.\n",
      "This involves concatenating the embeddings from both sources and performing a\n",
      "similarity search on the combined set of embeddings, allowing for results from\n",
      "both OpenAI and FAISS data to be returned\n",
      "Embedding: [-0.02014442 -0.035027   -0.03835043  0.04001401  0.05430963  0.02627755\n",
      "  0.02667991  0.0258969   0.05807392 -0.0831594 ]...\n",
      "Sentence: However, alternative approaches to\n",
      "querying both OpenAI and FAISS data may provide more nuanced results or better\n",
      "performance\n",
      "Embedding: [ 0.04338313 -0.01600261 -0.06720534  0.05512604  0.09138582 -0.0408203\n",
      " -0.01719988  0.04325889  0.04732339 -0.0217355 ]...\n",
      "Sentence: One such approach is to perform separate queries to OpenAI and\n",
      "FAISS and then combine the results using techniques like fusion or reranking.\n",
      "It is perhaps worth clarifying the point on encoding and retrieval using a vector\n",
      "store\n",
      "Embedding: [ 0.02278952 -0.03617974 -0.09682109  0.0730415   0.02101397  0.01321417\n",
      " -0.01337765 -0.01122182  0.03565316 -0.05388967]...\n",
      "Sentence: In a retrieval-based system like RAG (retrieval-augmented generation), the\n",
      "encoding process used during retrieval must be consistent with the encoding process\n",
      "used during indexing to ensure compatibility and effectiveness.\n",
      "168\n",
      "8\n",
      "Using Pretrained Networks\n",
      "The two processes are conceptually distinct stages within the overall information\n",
      "retrieval pipeline\n",
      "Embedding: [-0.02855789 -0.0043094   0.00156891  0.02959533 -0.05680556  0.05733133\n",
      "  0.01065664 -0.00882718  0.03222531 -0.10082356]...\n",
      "Sentence: However, for the system to function effectively, the encoding\n",
      "process used during retrieval must align with the encoding process used during\n",
      "indexing.\n",
      "In the RAG framework, documents are encoded into dense embeddings using a\n",
      "retrieval vectorizer during indexing\n",
      "Embedding: [-0.02677743  0.01865149  0.00618212  0.00573546 -0.023358    0.05139453\n",
      "  0.01827924 -0.04374782  0.08890112 -0.04660716]...\n",
      "Sentence: These embeddings are then stored in a retrieval\n",
      "index (e.g., a FAISS index) for efﬁcient retrieval\n",
      "Embedding: [ 0.00939993 -0.07461243 -0.03417815  0.02173459  0.05388552  0.10946344\n",
      " -0.00941013 -0.01983125  0.10254195 -0.06571994]...\n",
      "Sentence: During retrieval, queries are also\n",
      "encoded into dense embeddings using the same retrieval vectorizer\n",
      "Embedding: [ 0.01321949 -0.05924841  0.00238004  0.05283257 -0.02472631  0.05285589\n",
      "  0.06114091 -0.04980824  0.0485548  -0.07771055]...\n",
      "Sentence: These query\n",
      "embeddings are then used to retrieve relevant documents from the index based on\n",
      "their similarity to the query embeddings\n",
      "Embedding: [-0.03009367  0.00725036 -0.00929435  0.075618    0.03778131  0.0934035\n",
      "  0.01319057 -0.00471934  0.07715644 -0.08846336]...\n",
      "Sentence: Therefore, it is crucial that the retrieval\n",
      "vectorizer used during retrieval is the same as (or compatible with) the one used\n",
      "during indexing\n",
      "Embedding: [-0.01929769  0.00174552 -0.00271518  0.00344923  0.07503007  0.05053694\n",
      "  0.06022508 -0.01855699  0.03892981 -0.09262498]...\n",
      "Sentence: This ensures that both queries and documents are represented in\n",
      "the same semantic space, allowing for accurate matching and retrieval of relevant\n",
      "documents.\n",
      "8.10\n",
      "Other AI Agent Software\n",
      "We have outlined a basic understanding of what AI agent software entails, deﬁning\n",
      "it as programs capable of performing tasks or services for users autonomously or\n",
      "semi-autonomously\n",
      "Embedding: [-0.06666043 -0.00369525 -0.02908077  0.04527836 -0.01152118 -0.0187284\n",
      "  0.03613113  0.02762769 -0.01219862 -0.032535  ]...\n",
      "Sentence: These software agents are underpinned by advanced artiﬁcial\n",
      "intelligence technologies, such as machine learning, natural language processing,\n",
      "and robotic process automation.\n",
      "The landscape of AI technology is rapidly evolving, with developments pro-\n",
      "gressing at an unprecedented pace\n",
      "Embedding: [-0.02491465 -0.08852202 -0.02316253 -0.03923972  0.02531179 -0.06562681\n",
      "  0.01141386  0.01287873 -0.01709851  0.02185079]...\n",
      "Sentence: Innovations are continually being introduced,\n",
      "with both open source and proprietary models expanding the capabilities and\n",
      "accessibility of AI agents\n",
      "Embedding: [-0.02258065 -0.13846311 -0.04846959  0.00218869  0.09226652  0.05312818\n",
      " -0.0697926   0.04436964  0.02060535 -0.01638267]...\n",
      "Sentence: A notable development in this space is Google’s AI\n",
      "Agent Builder platform\n",
      "Embedding: [-0.0918816  -0.0853753  -0.00945227 -0.06497067  0.02087161 -0.03397224\n",
      " -0.02855492 -0.00397268 -0.03077142  0.03348975]...\n",
      "Sentence: This platform includes a “model garden” featuring a range\n",
      "of popular tools for AI agent development, such as Gemini, Claude, Llama, Stable\n",
      "Diffusion, and PaLM 2\n",
      "Embedding: [-0.03621845 -0.09007099 -0.04071183 -0.04513587  0.09099384 -0.00344433\n",
      " -0.09928824  0.02450842  0.01191507  0.07636455]...\n",
      "Sentence: These tools are designed to streamline the creation of more\n",
      "sophisticated and user-friendly AI agents.\n",
      "The trend in AI development is shifting toward creating models that are\n",
      "increasingly intelligent and simpler for end users to interact with\n",
      "Embedding: [ 0.00404146 -0.11881799 -0.02502885  0.03629959  0.03642646 -0.02049273\n",
      " -0.0503668   0.0202589  -0.00731125 -0.01959983]...\n",
      "Sentence: This evolution\n",
      "means that intricate prompt engineering—once a critical aspect of programming\n",
      "AI—may become less essential\n",
      "Embedding: [-0.01755631  0.00250762  0.02675457  0.00673945  0.06821921 -0.09153715\n",
      " -0.0103939   0.05275364 -0.018122    0.01102926]...\n",
      "Sentence: Instead, the emphasis is likely to shift toward\n",
      "enhancing the creativity and practical applications of AI technologies\n",
      "Embedding: [-0.03341666 -0.057694    0.04277753  0.00269988  0.07015127  0.01529523\n",
      " -0.0427988  -0.02037711  0.03721052  0.00063987]...\n",
      "Sentence: We can\n",
      "expect to see signiﬁcant advancements in various types of AI agent software, such\n",
      "as more adept virtual personal assistants, enhanced customer service bots, smarter\n",
      "business management tools, and more effective robotic process automation systems.\n",
      "These next-generation AI agents are expected to exhibit human-like capabilities,\n",
      "delivering impressively contextual and nuanced responses across vast datasets.\n",
      "They will likely support natural speech interactions in multiple languages, further\n",
      "enhancing their usability and effectiveness\n",
      "Embedding: [-0.05197955 -0.08449675  0.00962087 -0.03720559 -0.00454736  0.00176202\n",
      "  0.02325918 -0.04683462 -0.01435063 -0.0620748 ]...\n",
      "Sentence: This progression points toward a\n",
      "future where AI agents not only replicate human tasks but do so with a level of\n",
      "sophistication that closely mimics human interaction and problem-solving abilities.\n",
      "8.11\n",
      "Concluding Remarks\n",
      "169\n",
      "8.11\n",
      "Concluding Remarks\n",
      "I trust this book has fulﬁlled its intended purpose—to provide readers with a foun-\n",
      "dational understanding of programming and training deep neural networks\n",
      "Embedding: [-0.09856411 -0.04337649  0.00935763  0.02527842 -0.05356818 -0.00494949\n",
      "  0.05900146 -0.01903388 -0.05546437 -0.07043538]...\n",
      "Sentence: While\n",
      "we have touched upon numerous applications and models, the intricacies of some\n",
      "remain beyond the scope of this book due to their complexity\n",
      "Embedding: [-0.1016893  -0.0933451  -0.02740709  0.02055844  0.0139229  -0.0755898\n",
      " -0.12007916  0.04162172  0.03964042  0.02542552]...\n",
      "Sentence: Nevertheless, readers\n",
      "should now possess the ability to comprehend the concepts and implementations of\n",
      "these advanced topics.\n",
      "As with any technical discipline, true mastery comes from hands-on practice.\n",
      "Even the simplest coding exercises can impart invaluable insights that transcend\n",
      "the conﬁnes of a book\n",
      "Embedding: [-0.0225512  -0.03189155 -0.03705899 -0.03345865 -0.09176466 -0.0608527\n",
      "  0.07050058  0.04719852 -0.02433352  0.02435519]...\n",
      "Sentence: My aspiration is that this book has sparked curiosity within\n",
      "readers, inspiring them to embark on their own coding journeys\n",
      "Embedding: [-0.0198731  -0.06173252 -0.02851326  0.05256303  0.00550897 -0.01057231\n",
      "  0.09637634  0.03385137 -0.01893989  0.02123391]...\n",
      "Sentence: For it is through\n",
      "experimentation and exploration that one truly solidiﬁes their understanding and\n",
      "hones their skills.\n",
      "A legitimate question to ask is if much of these technologies are still relevant\n",
      "given the advent of generative AI\n",
      "Embedding: [-0.00532254 -0.0530438   0.04283052 -0.03610997 -0.0442467  -0.03847529\n",
      " -0.00855218 -0.019362   -0.07725844  0.02405448]...\n",
      "Sentence: My view is that learning about older technologies,\n",
      "like support vector machines (SVMs) and generative adversarial networks (GANs),\n",
      "remains important and valuable, even in the era of advanced models like ChatGPT,\n",
      "for several reasons:\n",
      "•\n",
      "Fundamental Understanding: Learning these technologies provides a solid foun-\n",
      "dation in machine learning principles\n",
      "Embedding: [-0.0813746  -0.0156141   0.05184994  0.00615786  0.06157539 -0.01226631\n",
      " -0.02430543 -0.01268691 -0.0506461  -0.01077906]...\n",
      "Sentence: SVMs, for example, offer insight into\n",
      "classiﬁcation, regression, and support vector concepts, while GANs demonstrate\n",
      "principles of unsupervised learning, distribution generation, and the innovative\n",
      "concept of adversarial training\n",
      "Embedding: [-0.14841227 -0.08323715 -0.00776836  0.026366    0.06556281 -0.00794944\n",
      " -0.02370287 -0.08449802 -0.01697537 -0.01976646]...\n",
      "Sentence: This foundational knowledge is crucial for\n",
      "understanding how more complex models work.\n",
      "•\n",
      "Applicability and Efﬁciency: Not all problems require the ﬁrepower of large\n",
      "models like ChatGPT\n",
      "Embedding: [-0.03035414 -0.06493859  0.03804752  0.03591673  0.04457875 -0.05769761\n",
      " -0.05679048  0.05408854  0.09165327  0.03547229]...\n",
      "Sentence: SVMs are highly effective for certain classiﬁcation and\n",
      "regression problems, especially when dealing with small- to medium-sized\n",
      "datasets\n",
      "Embedding: [ 0.03022499 -0.01533037  0.02544187  0.03981112  0.0708855  -0.01435907\n",
      " -0.00246832 -0.00657627 -0.03745286  0.03122208]...\n",
      "Sentence: They can be more computationally efﬁcient and easier to deploy in\n",
      "resource-constrained environments\n",
      "Embedding: [-0.04011844 -0.00918054 -0.0227232  -0.04495078  0.07866617 -0.05314247\n",
      " -0.05689524  0.03119017  0.03465638  0.04169415]...\n",
      "Sentence: Similarly, GANs have unique capabilities\n",
      "in generating new data instances that can be invaluable for tasks like image\n",
      "generation, data augmentation, and more.\n",
      "•\n",
      "Creativity and Innovation: Learning about a wide variety of technologies encour-\n",
      "ages creativity and innovation\n",
      "Embedding: [-0.07328792 -0.05883943  0.01271641  0.00418869  0.00778996 -0.04369097\n",
      " -0.06841264 -0.07096224 -0.00113428 -0.04152813]...\n",
      "Sentence: By understanding the strengths and limitations of\n",
      "different approaches, researchers and practitioners can invent new models and\n",
      "algorithms that address the shortcomings of existing ones\n",
      "Embedding: [-0.00224058 -0.02057073 -0.02416124 -0.01554897  0.0018721  -0.05941895\n",
      " -0.14848128  0.0347468   0.03815403 -0.01344618]...\n",
      "Sentence: Many advancements\n",
      "in AI come from combining ideas from different areas in novel ways.\n",
      "•\n",
      "Customization and Control: Models like SVMs offer a level of transparency and\n",
      "control that is not always available in larger, more complex models\n",
      "Embedding: [ 0.05237342 -0.08341663  0.00027128  0.04012231  0.0477309  -0.00346151\n",
      " -0.0603184   0.01161645  0.05750688  0.05056734]...\n",
      "Sentence: For tasks\n",
      "requiring explainability and the ability to ﬁne-tune models based on speciﬁc\n",
      "criteria, these “older” technologies can be more suitable.\n",
      "•\n",
      "Research and Development: Ongoing research in ﬁelds like SVM and GAN can\n",
      "lead to signiﬁcant improvements and breakthroughs in machine learning\n",
      "Embedding: [-0.06651732 -0.07298831 -0.02536021 -0.00193757  0.02951284 -0.02461679\n",
      " -0.11300955 -0.071197   -0.07667613 -0.06000033]...\n",
      "Sentence: For\n",
      "170\n",
      "8\n",
      "Using Pretrained Networks\n",
      "instance, GANs continue to be a hot area of research for generating synthetic\n",
      "data, with applications in training models where real data is scarce or privacy-\n",
      "sensitive.\n",
      "In this dynamic landscape of technological advancement, it is essential to recognize\n",
      "the value of continuous learning and adaptability\n",
      "Embedding: [-0.08891138 -0.07315663 -0.01889818  0.04733394  0.00113303  0.03180302\n",
      " -0.07920035 -0.07597441  0.0015966  -0.101668  ]...\n",
      "Sentence: The journey through the realms of\n",
      "programming, deep learning, and machine learning is not a linear path but a cyclical\n",
      "process of learning, applying, and relearning\n",
      "Embedding: [-0.0813897  -0.08014207  0.01199527  0.00337884  0.01955239 -0.06127301\n",
      " -0.07157516 -0.06853963 -0.05436863 -0.0057677 ]...\n",
      "Sentence: As new models and techniques\n",
      "emerge, the foundational knowledge you’ve acquired from this book and beyond\n",
      "will serve as the bedrock upon which you can build, understand, and innovate.\n",
      "The future of AI and machine learning is incredibly bright, and its potential\n",
      "applications are virtually limitless\n",
      "Embedding: [-0.00744511 -0.11077011  0.00883404 -0.03556667  0.05850205  0.00211288\n",
      " -0.02371296 -0.0091679  -0.03504289 -0.02795704]...\n",
      "Sentence: From enhancing healthcare and advancing scien-\n",
      "tiﬁc research to improving environmental conservation efforts and revolutionizing\n",
      "industries, the possibilities are as vast as our collective imagination\n",
      "Embedding: [ 0.03304084  0.0459771   0.04675459  0.01164913  0.08686748 -0.00327295\n",
      " -0.0811756  -0.03908812  0.00533834  0.05025852]...\n",
      "Sentence: As you stand at\n",
      "the threshold of this exciting frontier, remember that each challenge you encounter\n",
      "is an opportunity for growth, and every failure is a stepping stone to success.\n",
      "Embrace the journey ahead with an open mind and a resilient spirit\n",
      "Embedding: [ 0.0523112  -0.02726018  0.00046839  0.02709403  0.05030171  0.03372277\n",
      "  0.01803188  0.00207378 -0.05876062 -0.04652487]...\n",
      "Sentence: Engage with\n",
      "the community, share your discoveries, and learn from the experiences of others.\n",
      "The ﬁeld of AI is not just about algorithms and data; it is about the collective effort of\n",
      "individuals around the globe striving to make a positive impact through technology.\n",
      "As we conclude this book, I hope it has not only imparted knowledge but\n",
      "also ignited a passion for exploring the uncharted territories of AI and machine\n",
      "learning\n",
      "Embedding: [-0.03975113 -0.02010916  0.01859896  0.03606907  0.03734906 -0.03573808\n",
      " -0.00199651 -0.02665774 -0.05230347  0.00705797]...\n",
      "Sentence: The path ahead is yours to shape\n",
      "Embedding: [ 0.02776285 -0.03430421 -0.01075404  0.0349816  -0.03769595  0.00846117\n",
      " -0.01090418 -0.02634663 -0.02296216  0.00844505]...\n",
      "Sentence: May you embark on this journey\n",
      "with conﬁdence, curiosity, and a relentless drive to contribute to the ever-evolving\n",
      "tapestry of technological innovation.\n",
      "Thank you for allowing me to be a part of your learning journey\n",
      "Embedding: [ 0.02070024 -0.02016277  0.06815656 -0.00529682  0.03134624 -0.03597578\n",
      "  0.07158654 -0.04002534 -0.04158824  0.03766091]...\n",
      "Sentence: Here is to the\n",
      "endless possibilities that await as you apply, challenge, and extend the knowledge\n",
      "you have gained.\n",
      "\n",
      "Embedding: [-0.03056984 -0.00369159 -0.00512173  0.01847983  0.01259385  0.03050772\n",
      " -0.00196736 -0.01600184 -0.07657866  0.0099613 ]...\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pdf_path = '../resource/pdf_to_extract.pdf'  # Replace with the actual path to your PDF file\n",
    "sentences, embeddings = process_pdf_and_get_embeddings(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1312,\n",
       " ['Neural Networks with TensorFlow and Keras\\nPhilip Hua\\nNeural Networks with\\nTensorFlow and Keras\\nTraining, Generative Models,\\nand Reinforcement Learning\\nPhilip Hua\\nGuildford, UK\\nISBN-13 (pbk): 979-8-8688-1019-0\\nISBN-13 (electronic): 979-8-8688-1020-6\\nhttps://doi.org/10.1007/979-8-8688-1020-6\\nCopyright © 2024 by Philip Hua\\nThis work is subject to copyright',\n",
       "  'All rights are reserved by the Publisher, whether the whole or part of\\nthe material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,\\nbroadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information\\nstorage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology\\nnow known or hereafter developed.\\nTrademarked names, logos, and images may appear in this book',\n",
       "  'Rather than use a trademark symbol\\nwith every occurrence of a trademarked name, logo, or image we use the names, logos, and images only\\nin an editorial fashion and to the beneﬁt of the trademark owner, with no intention of infringement of the\\ntrademark.\\nThe use in this publication of trade names, trademarks, service marks, and similar terms, even if they are\\nnot identiﬁed as such, is not to be taken as an expression of opinion as to whether or not they are subject\\nto proprietary rights.\\nWhile the advice and information in this book are believed to be true and accurate at the date of\\npublication, neither the authors nor the editors nor the publisher can accept any legal responsibility for\\nany errors or omissions that may be made',\n",
       "  'The publisher makes no warranty, express or implied, with\\nrespect to the material contained herein.\\nManaging Director, Apress Media LLC: Welmoed Spahr\\nAcquisitions Editor: Celestin Suresh John\\nDevelopment Editor: Laura Berendson\\nCoordinating Editor: Kripa Joseph\\nCover designed by eStudioCalamar\\nCover image designed by Unsplash\\nDistributed to the book trade worldwide by Springer Science+Business Media New York, 233 Spring\\nStreet, 6th Floor, New York, NY 10013',\n",
       "  'Phone 1-800-SPRINGER, fax (201) 348-4505, e-mail orders-\\nny@springer-sbm.com, or visit www.springeronline.com',\n",
       "  'Apress Media, LLC is a California LLC and\\nthe sole member (owner) is Springer Science+Business Media Finance Inc (SSBM Finance Inc)',\n",
       "  'SSBM\\nFinance Inc is a Delaware corporation.\\nFor information on translations, please e-mail booktranslations@springernature.com; for reprint, paper-\\nback, or audio rights, please e-mail bookpermissions@springernature.com.\\nApress titles may be purchased in bulk for academic, corporate, or promotional use',\n",
       "  'eBook versions and\\nlicenses are also available for most titles',\n",
       "  'For more information, reference our Print and eBook Bulk\\nSales web page at http://www.apress.com/bulk-sales.\\nAny source code or other supplementary material referenced by the author in this book can be found\\nhere: https://www.apress.com/gp/services/source-code.\\nIf disposing of this product, please recycle the paper\\nTo Kim Mai and Anson: Live a worthwhile\\nand happy life.\\nContents\\n1\\nIntroduction ..................................................................\\n1\\n2\\nUsing Tensors.................................................................\\n3\\n2.1\\nTensors and NumPy ...................................................\\n4\\n2.1.1\\nArray and Scalar .............................................\\n5\\n2.1.2\\nArrays with Different Dimensions ..........................\\n5\\n2.1.3\\nArrays with the Same Number of Dimensions .............\\n5\\n2.2\\nBasic Tensor Operations...............................................\\n6\\n2.2.1\\nCreating Tensors .............................................\\n6\\n2.2.2\\nMathematical Operations ....................................\\n6\\n2.2.3\\nReshaping Tensors ...........................................\\n7\\n2.3\\nParallelism .............................................................\\n9\\n2.4\\nMachine Learning Environment ......................................\\n10\\nPart I\\nConcepts and Basics of Machine Learning\\n3\\nHow Machine Learns Using Neural Network.............................\\n15\\n3.1\\nComponents of a Neural Network ....................................\\n17\\n3.1.1\\nNeurons: The Building Blocks ..............................\\n19\\n3.1.2\\nNeuron Initialization .........................................\\n25\\n3.2\\nNetwork Layers: Building a Hierarchy ...............................\\n27\\n3.3\\nThe Optimizer and the Loss Function ................................\\n28\\n3.3.1\\nThe Loss Function ...........................................\\n29\\n3.3.2\\nLoss Function for Regression ...............................\\n30\\n3.3.3\\nMean Squared Error .........................................\\n30\\n3.3.4\\nCosine Similarity.............................................\\n31\\n3.4\\nProbabilistic Losses ...................................................\\n33\\n3.4.1\\nBinary Cross-Entropy........................................\\n33\\n3.4.2\\nCategorical Cross-Entropy ..................................\\n33\\n3.4.3\\nSparse Categorical Cross-Entropy ..........................\\n34\\n3.5\\nNetwork Optimizer ....................................................\\n34\\n3.6\\nGeneralization Errors ..................................................\\n37\\n3.7\\nTensorBoard ...........................................................\\n37\\n3.8\\nUsing TensorBoard in Colab ..........................................\\n42\\nvii\\nviii\\nContents\\n4\\nNetwork Layers ..............................................................\\n43\\n4.1\\nDense (Fully Connected) Layers......................................\\n43\\n4.2\\nNormalization Layers..................................................\\n46\\n4.3\\nDropout Layers ........................................................\\n47\\n4.3.1\\nFlattening Layers.............................................\\n47\\n4.3.2\\nPooling Layers ...............................................\\n47\\n4.3.3\\nConvolutional Layers ........................................\\n49\\n4.3.4\\nCNN As an Input Layer .....................................\\n51\\n4.3.5\\nMultiple CNN Layers........................................\\n52\\n4.3.6\\nEmbedding Layers ...........................................\\n54\\n4.3.7\\nResidual Layers ..............................................\\n55\\n4.3.8\\nRecurrent Layers .............................................\\n55\\n4.3.9\\nActivation Function ..........................................\\n58\\n4.3.10\\nRecurrent Activation .........................................\\n59\\n4.3.11\\nOther Layers..................................................\\n59\\nPart II\\nImplementation Examples\\n5\\nThe Training Process ........................................................\\n63\\n5.1\\nData Loading...........................................................\\n63\\n5.1.1\\nLoading Images ..............................................\\n66\\n5.2\\nData Processing ........................................................\\n67\\n5.2.1\\nSplitting the Dataset: Training, Development, Test ........\\n68\\n5.2.2\\nCategorical Data .............................................\\n68\\n5.2.3\\nPreprocessing Images ........................................\\n70\\n5.2.4\\nNormalization and Standardization .........................\\n72\\n5.2.5\\nMissing Data .................................................\\n74\\n5.2.6\\nData Augmentation ..........................................\\n76\\n5.3\\nTuning Our Network...................................................\\n79\\n5.4\\nCustomizations ........................................................\\n84\\n5.5\\nFunctional API.........................................................\\n84\\n5.6\\nCustom Models ........................................................\\n85\\n5.7\\nModel Selection........................................................\\n88\\n5.8\\nModel Depth and Complexity.........................................\\n89\\n5.9\\nNeural Networks Applications ........................................\\n89\\n5.10\\nDense Network: Detection of Handwritten Digits Using\\nMNIST Dataset ........................................................\\n91\\n5.11\\nRNN Network: Modeling an AutoRegressive Integrated\\nMoving Average (ARIMA) Process ..................................\\n93\\n5.12\\nLSTM Network: BachBot .............................................\\n97\\n5.12.1\\nBackground...................................................\\n97\\n5.12.2\\nPreprocessing.................................................\\n98\\n5.12.3\\nModel Implementation and Training.......................',\n",
       "  '100\\n5.12.4\\nTeacher Forcing .............................................',\n",
       "  '100\\n5.12.5\\nBachBot Model .............................................',\n",
       "  '102\\nContents\\nix\\n6\\nGenerative Models ..........................................................',\n",
       "  '105\\n6.1\\nVariational Autoencoders.............................................',\n",
       "  '105\\n6.1.1\\nPreprocessing................................................',\n",
       "  '106\\n6.1.2\\nVAE Architecture ...........................................',\n",
       "  '107\\n6.1.3\\nMorphing Images ...........................................',\n",
       "  '111\\n6.1.4\\nFeature Disentanglement ...................................',\n",
       "  '112\\n6.2\\nCartoonGAN ..........................................................',\n",
       "  '115\\n6.2.1\\nGAN .........................................................',\n",
       "  '115\\n6.2.2\\nData Preparation ............................................',\n",
       "  '116\\n6.2.3\\nPreprocessing CartoonGAN ................................',\n",
       "  '117\\n6.2.4\\nThe Discriminator Model...................................',\n",
       "  '118\\n6.2.5\\nThe Generator Model .......................................',\n",
       "  '120\\n6.3\\nStable Diffusion.......................................................',\n",
       "  '122\\n6.3.1\\nText Embedding in Stable Diffusion .......................',\n",
       "  '123\\n6.3.2\\nGaussian Noise Injection and Removal ....................',\n",
       "  '124\\n6.3.3\\nThe U-Net Model ...........................................',\n",
       "  '127\\n7\\nReinforcement Learning ...................................................',\n",
       "  '131\\n7.1\\nExplanations of Reinforcement Learning ...........................',\n",
       "  '131\\n7.2\\nGymnasium Library ..................................................',\n",
       "  '132\\n7.2.1\\nInstalling Gymnasium ......................................',\n",
       "  '133\\n7.2.2\\nGymnasium .................................................',\n",
       "  '133\\n7.2.3\\nExplaining the Gymnasium Environment..................',\n",
       "  '134\\n7.2.4\\nThe Agent ...................................................',\n",
       "  '137\\n7.2.5\\nMemory Replay .............................................',\n",
       "  '139\\n8\\nUsing Pretrained Networks ................................................',\n",
       "  '143\\n8.1\\nGPT-4 .................................................................',\n",
       "  '143\\n8.1.1\\nFine-Tuning ChatGPT ......................................',\n",
       "  '145\\n8.2\\nVGG ...................................................................',\n",
       "  '147\\n8.3\\nYOLO .................................................................',\n",
       "  '148\\n8.3.1\\nConverting YOLO Weights to Keras .......................',\n",
       "  '149\\n8.4\\nHugging Face .........................................................',\n",
       "  '150\\n8.5\\nPrompt Engineering ..................................................',\n",
       "  '150\\n8.5.1\\nZero-Shot Learning .........................................',\n",
       "  '150\\n8.5.2\\nFew-Shot Learning..........................................',\n",
       "  '151\\n8.5.3\\nOne-Shot Learning..........................................',\n",
       "  '151\\n8.5.4\\nChain-of-Thought Prompting ..............................',\n",
       "  '151\\n8.5.5\\nRole-Playing ................................................',\n",
       "  '152\\n8.5.6\\nEmbedding Prompts ........................................',\n",
       "  '152\\n8.5.7\\nKnowledge Graphs..........................................',\n",
       "  '153\\n8.6\\nRetrieval-Augmented LLM ..........................................',\n",
       "  '154\\n8.7\\nBest Practices for Prompt Engineering ..............................',\n",
       "  '155\\n8.7.1\\nParameters ...................................................',\n",
       "  '157\\n8.8\\nCoding an AI Agent Using LangChain ..............................',\n",
       "  '157\\n8.8.1\\nIndexing Using VectorDB ..................................',\n",
       "  '158\\nx\\nContents\\n8.8.2\\nRetrieval Mechanism in LangChain........................',\n",
       "  '160\\n8.9\\nCompany Chatbot Using LangChain ................................',\n",
       "  '162\\n8.10\\nOther AI Agent Software.............................................',\n",
       "  '168\\n8.11\\nConcluding Remarks .................................................',\n",
       "  '169\\nBibliography .....................................................................',\n",
       "  '171\\nIndex..............................................................................',\n",
       "  '173\\nAbout the Author\\nPhilip Hua brings over 30 years of experience\\nin investment, risk management, and IT',\n",
       "  'He has\\nheld senior positions as a partner at a hedge fund,\\nled risk and IT departments at both large and\\nboutique ﬁrms, and cofounded a successful ﬁn-\\ntech company',\n",
       "  'Alongside Dr',\n",
       "  'Paul Wilmott, he\\ndeveloped the CrashMetrics methodology, a crucial\\ntool for evaluating severe market risk in portfolios.\\nPhilip holds a PhD in Applied Mathematics from\\nImperial College London, an MBA, and a BSc in\\nEngineering.\\nxi\\nAbout the Technical Reviewer\\nShibsankar Das is currently working as a Senior\\nData Scientist at Microsoft',\n",
       "  'He has 10+ years of\\nexperience working in IT where he has led several\\ndata science initiatives, and in 2019, he was recog-\\nnized as one of the top 40 data scientists in India.\\nHis core strength is in GenAI, deep learning, NLP,\\nand graph neural networks',\n",
       "  'Currently, he is focus-\\ning on his research on GraphRAG, a framework\\nthat leverages RAG along with a knowledge graph\\nto solve business problems',\n",
       "  'He has experience\\nworking in the domain of foundational research,\\nﬁntech, and ecommerce.\\nBefore Microsoft, he worked at Optum, Wal-\\nmart, Envestnet, Microsoft Research, and Capgem-\\nini',\n",
       "  'He pursued a master’s from the Indian Institute\\nof Technology, Bangalore.\\nxiii\\n1\\nIntroduction\\nMachine learning has become an integral part of our lives, inﬂuencing various\\naspects from virtual chatbots and voice assistants like Siri and Alexa to Tesla’s\\nautonomous vehicles and even the creative realms of music composition',\n",
       "  'Its\\napplications extend to personalized advertisements, product recommendations, and\\ninvestment advice',\n",
       "  'One of its remarkable achievements is DeepMind’s AlphaGo,\\nwhich showcases the ever-expanding capabilities of artiﬁcial intelligence (AI)',\n",
       "  'In\\nthis rapidly evolving ﬁeld, researchers are relentlessly pursuing the ultimate goal of\\nAI: creating machines capable of thinking and learning, potentially rivaling human\\nintelligence.\\nHowever, for those new to coding machine learning with Python, the plethora\\nof online articles and concepts can be daunting',\n",
       "  'Machine learning, unlike many\\ntraditional ﬁelds, fundamentally relies on mathematics, presenting a signiﬁcant\\nchallenge for those without a strong mathematical background.\\nFor experienced software developers and data scientists, however, it is entirely\\npossible to apply machine learning techniques to complex data challenges without\\ndelving deeply into mathematical complexities',\n",
       "  'The vast amount of available data\\ntoday enables the development of highly accurate machine learning models',\n",
       "  'The\\nkey challenge lies in designing analytical workﬂows that extract insights from raw\\ndata, a domain where machine learning algorithms excel',\n",
       "  'Python, with its extensive\\nnumerical libraries, data preparation tools, diverse models, and robust environment,\\nis an invaluable tool for training and scaling models for practical applications.\\nIn this book, I aim to guide you through the fundamental concepts to advanced\\ntechniques and algorithms in machine learning',\n",
       "  'The initial chapters will clarify key\\nconcepts and deﬁnitions, helping you understand the Python code in the subsequent\\nsections',\n",
       "  'This book is not a guide to building deep neural networks from scratch,\\nas that requires more advanced knowledge',\n",
       "  'Instead, it equips you with the skills to\\neffectively use machine learning algorithms and workﬂows in Python for complex\\ndata problems.\\n© Philip Hua 2024\\nP',\n",
       "  'Hua, Neural Networks with TensorFlow and Keras,\\nhttps://doi.org/10.1007/979-8-8688-1020-6_1\\n1\\n2\\n1\\nIntroduction\\nAssuming a basic familiarity with Python, this book will introduce you to impor-\\ntant libraries such as NumPy, Pandas, the deep learning framework TensorFlow, and\\nKeras',\n",
       "  'For more sophisticated applications, we will explore commercial software\\nAPIs and models such as GPT-4 and VGG',\n",
       "  'These are built on state-of-the-art models\\ntrained on extensive datasets, offering practical solutions for speciﬁc needs rather\\nthan modifying their internal mechanics.\\nWherever possible, I will utilize Google’s Colab, a free service providing\\naccessible computing resources, including GPUs and TPUs, for training machine\\nlearning models',\n",
       "  'In situations where Colab is not suitable, I will use the PyCharm\\nIDE with a local GPU',\n",
       "  'You are encouraged to use your preferred IDE',\n",
       "  'I recommend\\nPyCharm for its reliability and its availability in both free and paid versions',\n",
       "  'For\\nmachine learning coding, having a powerful laptop or PC with an external GPU is\\nbeneﬁcial, as these algorithms require substantial computational resources, and a\\nCPU alone may be insufﬁcient for anything but the simplest tasks.\\nThroughout this book, I have extensively used ChatGPT-4 to explain concepts,\\nprogramming syntax, and boilerplate code',\n",
       "  'While OpenAI’s GPT-4 is a highly\\nadvanced tool, it is not always the perfect ﬁt for every complex project',\n",
       "  'However, it\\nremains an invaluable resource for assistance, offering code that, even if not always\\nﬂawless, can serve as a faster starting point than writing from scratch.\\nLet’s begin your journey into machine learning with Python.\\n2\\nUsing Tensors\\nThe advent of deep learning has revolutionized the ﬁeld of artiﬁcial intelligence,\\nallowing machines to process vast amounts of data and solve problems that were\\nonce considered too complex',\n",
       "  'As models grew larger and datasets more expansive,\\nthe computational demands of training deep learning models began to outpace\\nthe capabilities of traditional computing systems',\n",
       "  'This challenge gave rise to the\\nneed for parallel computing—a method where multiple calculations are carried out\\nsimultaneously across different processors.\\nParallel computing allowed deep learning models to scale, but it also demanded\\nnew ways to efﬁciently represent and process data across multiple dimensions',\n",
       "  'This\\nis where tensors come into play.\\nTensors are mathematical structures that generalize the concept of vectors and\\nmatrices to higher dimensions, enabling efﬁcient computations over large-scale\\ndata',\n",
       "  'In deep learning, tensors allow for data to be represented as multidimensional\\narrays, with each dimension corresponding to a particular aspect of the data—\\nwhether it be pixels in an image, time steps in a sequence, or features in a dataset.\\nWhat sets tensors apart from standard arrays used in programming languages\\nis their optimization for parallel processing',\n",
       "  'They are designed to perform high-\\nperformance numerical computations, which makes them ideal for deep learning\\ntasks that require intensive calculations across millions of parameters',\n",
       "  'By utilizing\\ntensors, machine learning models can be trained on large datasets with a speed and\\nefﬁciency that would be impossible with traditional data structures.\\nIn this chapter, we will introduce tensors and their fundamental operations, laying\\nthe groundwork for building complex machine learning models',\n",
       "  'You’ll learn how\\ntensors can efﬁciently represent and manipulate data across multiple dimensions,\\nmaking them an indispensable tool in the world of deep learning.\\nTensorFlow and Keras take full advantage of tensors, enabling automatic differ-\\nentiation and the ability to distribute computations across multiple devices, such\\nas GPUs and TPUs',\n",
       "  'These frameworks provide extensive support for manipulating\\ntensors through parallel operations, allowing for faster data processing and more\\n© Philip Hua 2024\\nP',\n",
       "  'Hua, Neural Networks with TensorFlow and Keras,\\nhttps://doi.org/10.1007/979-8-8688-1020-6_2\\n3\\n4\\n2\\nUsing Tensors\\nefﬁcient memory usage',\n",
       "  'These features are key to building scalable machine\\nlearning models that handle large datasets, making tensors a powerful alternative\\nto conventional arrays.\\n2.1\\nTensors and NumPy\\nBefore we start discussing tensors, some comparisons between tensors and NumPy\\narrays are warranted as these two are often used interchangeably in code.\\nTensors, as used in TensorFlow, and NumPy arrays are both powerful tools for\\nhandling multidimensional data, and they share many similarities',\n",
       "  'However, there\\nare key differences that make them suitable for different applications, especially in\\nthe context of machine learning and deep learning',\n",
       "  'Here are some key differences\\nand commonality between the two libraries:\\n1',\n",
       "  'GPU Support: NumPy arrays are primarily designed for CPU-based computing,\\nwhich means they rely on single-threaded or multithreaded CPU operations.\\nHowever, deep learning models often require large-scale computations that are\\nfar more efﬁcient when distributed across multiple processors',\n",
       "  'This is where\\nparallel computing with GPUs becomes crucial',\n",
       "  'GPUs, with their thousands of\\nsmaller cores, are speciﬁcally built to handle many operations simultaneously,\\nmaking them ideal for the matrix and tensor operations common in deep learning.\\nTensors, in contrast to NumPy arrays, are optimized for parallel computing',\n",
       "  'They\\ncan efﬁciently distribute and run computations across GPUs and TPUs',\n",
       "  'This\\nallows for the simultaneous processing of multiple data points and operations,\\ndramatically accelerating the training of large models',\n",
       "  'By leveraging the par-\\nallelism of GPUs, tensors make it feasible to handle the complex, large-scale\\ncalculations that deep learning requires, signiﬁcantly improving efﬁciency and\\nscalability.\\n2',\n",
       "  'Mutable: NumPy arrays are mutable, meaning that their values can be changed\\nafter they are created',\n",
       "  'In TensorFlow, tensors are typically immutable but can\\nby mutable as well',\n",
       "  'If deﬁned as immutable, once created, their values cannot\\nbe changed',\n",
       "  'This immutability is beneﬁcial for optimization in computational\\ngraphs of the deep neural network.\\n3',\n",
       "  'Gradient Computation: Although NumPy is not inherently a deep learning\\nlibrary, it integrates well with various deep learning frameworks but lacks the\\nability to compute gradients, which are essential in training neural networks.\\nTensorFlow’s tensors are fully integrated with the TensorFlow ecosystem, allow-\\ning for automatic differentiation, which is essential for backpropagation in neural\\nnetwork training.\\n4',\n",
       "  'Eager Execution: It executes operations immediately (eager execution) in a\\nprocedural manner',\n",
       "  'TensorFlow supports both eager execution (like NumPy)\\nand graph execution',\n",
       "  'In graph execution, operations are deﬁned as a part of a\\ncomputational graph that can be optimized and run efﬁciently, which is a key\\nfeature for deep learning models.\\n2.1\\nTensors and NumPy\\n5\\n5',\n",
       "  'Broadcasting: Both NumPy array and tensor support broadcasting',\n",
       "  'Broadcasting\\nis a mechanism that allows us to work with arrays of different shapes when\\nperforming arithmetic operations',\n",
       "  'Fundamentally, broadcasting automates the\\nexpansion of the smaller array so that it matches the shape of the larger array.\\nFor broadcasting to work, the size of the trailing dimensions of the arrays must\\neither be the same or one of them must be one',\n",
       "  'If this condition is not met, a\\nbroadcasting error is raised',\n",
       "  'If the two arrays are suitable, broadcasting will stretch\\nthe dimensions of the two arrays to match, as shown in the following examples:\\n2.1.1\\nArray and Scalar\\nWhen performing operations between an array and a scalar value, broadcasting\\nallows the scalar to be “stretched” to match the shape of the array',\n",
       "  'Example:\\nnumpy_array + 3',\n",
       "  'Here, the scalar 3 is broadcasted to the shape of numpy_array.\\n2.1.2\\nArrays with Different Dimensions\\nIf one array has fewer dimensions than the other, it is padded with ones on its leading\\n(left) side',\n",
       "  'Example: If A has shape (3, 5) and B has shape (5,), then B is treated as\\nif it had the shape (1, 5)',\n",
       "  'During the operation, B is broadcasted to the shape (3, 5)\\nby repeating the same row.\\n2.1.3\\nArrays with the Same Number of Dimensions\\nBroadcasting compares their shapes element-wise',\n",
       "  'A dimension of length 1 can be\\nstretched to match the other shape',\n",
       "  'Example: If A has shape (2, 3, 1) and B has\\nshape (1, 3, 4), the shapes are compatible',\n",
       "  'They can be broadcasted to a common\\nshape of (2, 3, 4).\\nEven though tensors should be used for machine learning, there are occasions\\nwhen NumPy arrays are needed, particularly when integrating TensorFlow-based\\nmodels with data processing pipelines that utilize NumPy',\n",
       "  'Conversion between\\ntensors and NumPy arrays is straightforward',\n",
       "  'To convert a NumPy array to a\\nTensorFlow tensor, we can use tf.convert_to_tensor or simply pass a NumPy array\\nto TensorFlow operations, as most of them can automatically convert NumPy arrays\\nto tensors.\\nThe following is a sample code to convert a NumPy array to a tensor:\\nimport numpy as np\\nimport tensorflow as tf\\n# Create a NumPy array\\nnumpy_array = np.array([1, 2, 3, 4, 5])\\n6\\n2\\nUsing Tensors\\n# Convert to TensorFlow tensor\\ntensor_from_numpy = tf.convert_to_tensor(numpy_array)\\n# or simply\\ntensor_from_numpy = tf.constant(numpy_array)\\nTo convert a TensorFlow tensor back to a NumPy array, we can use the .numpy()\\nmethod of a tensor object',\n",
       "  'This method is available if TensorFlow is executing in\\neager mode, which is the default mode since TensorFlow 2.0',\n",
       "  'When converting\\nbetween NumPy arrays and TensorFlow tensors, a deep copy is typically performed.\\nThis means the original and the converted objects do not share memory, and\\nchanging one will not affect the other',\n",
       "  'The .numpy() method for tensors is available\\nin TensorFlow 2.x',\n",
       "  'In TensorFlow 1.x, the conversion process is less straightforward\\nas it involves running a session to evaluate the tensor.\\nWhile converting, ensure that the data types are compatible; otherwise, an error\\nwill occur',\n",
       "  'TensorFlow has its own set of data types, but they are largely compatible\\nwith NumPy’s data types.\\nThe following is a sample code to convert a tensor to a NumPy array using a\\nbuilt-in method.\\n# Create a TensorFlow tensor\\ntensor = tf.constant([1, 2, 3, 4, 5])\\n# Convert to NumPy array\\nnumpy_from_tensor = tensor.numpy()\\n# numpy_from_tensor is now a NumPy array\\n2.2\\nBasic Tensor Operations\\n2.2.1\\nCreating Tensors\\nimport tensorflow as tf\\n# Creating a constant tensor\\ntensor_const = tf.constant([[1, 2], [3, 4]])\\n# Creating a variable tensor\\ntensor_var = tf.Variable([[1, 2], [3, 4]])\\n2.2.2\\nMathematical Operations\\nMathematical Operations TensorFlow supports element-wise mathematical opera-\\ntions, such as addition, subtraction, multiplication, and division.\\n# Element-wise addition\\ntensor_add = tf.add(tensor_const, tensor_var)\\n2.2\\nBasic Tensor Operations\\n7\\n2.2.3\\nReshaping Tensors\\nReshaping and slicing are crucial for preparing data for various types of neural\\nnetwork layers',\n",
       "  'It is important to understand this section well.\\nReshaping a tensor from one shape to another while keeping the total number of\\nelements the same:\\nimport tensorflow as tf\\ntensor = tf.constant([[1, 2, 3], [4, 5, 6]])\\nreshaped_tensor = tf.reshape(tensor, [3, 2])\\n# Original shape: (2, 3)\\n# New shape: (3, 2)\\nFlattening converts a tensor to a 1D tensor',\n",
       "  'This is often used when transitioning\\nfrom convolutional layers to dense layers within a neural network:\\nflattened_tensor = tf.reshape(tensor, [-1])\\n# Original shape: (2, 3)\\n# New shape: (6,)\\nAdding a dimension is useful for adding a batch dimension or expanding dimensions\\nfor compatibility with certain operations, like broadcasting',\n",
       "  'When feeding a neural\\nnetwork data, the ﬁrst dimension is the number of batches, so this operation is used\\nvery frequently:\\nexpanded_tensor = tf.expand_dims(tensor, axis=0)\\n# Original shape: (2, 3)\\n# New shape: (1, 2, 3)\\nRemoving dimensions of size 1',\n",
       "  'This is often used after operations like\\ntf.reduce_sum with keepdims=True:\\nreduced_tensor = tf.reduce_sum(tensor, axis=1, keepdims=True)\\nsqueezed_tensor = tf.squeeze(reduced_tensor)\\n# Original shape of reduced_tensor: (2, 1)\\n# New shape after squeeze: (2,)\\nOften used in sequence models like RNNs where the input needs to be reshaped into\\n[batch_size, time steps, features]:\\nsequence_tensor = tf.reshape(tensor, [1, 2, 3])\\n# Original shape: (2, 3)\\n# New shape: (1, 2, 3) - 1 batch, 2 time steps, 3 features\\nIn the context of convolutional neural networks (CNNs), channels refer to the\\ndifferent layers of information in an image',\n",
       "  'For example, a typical color image\\nhas three channels: red, green, and blue (RGB)',\n",
       "  'Each channel contains data that\\nrepresents the intensity of that color at every pixel in the image.\\n8\\n2\\nUsing Tensors\\nWhen a CNN processes an image, it analyzes these channels separately to learn\\npatterns and features',\n",
       "  'The terms “channel last” and “channel ﬁrst” describe how the\\nimage data is arranged in memory.\\nChannel last is a format where the image data is stored as (height, width,\\nchannels), with the channels (such as RGB) being the last element',\n",
       "  'Channel ﬁrst\\nrefers to the format where the data is organized as (channels, height, width),\\nmeaning the channels come ﬁrst in the sequence.\\nTo switch between these formats, a technique called transposing is used, which\\nrearranges the order of the dimensions',\n",
       "  'This step is often necessary when working\\nwith different machine learning frameworks that use different conventions for\\nhandling image data:\\ntransposed_tensor = tf.transpose(tensor, perm=[1, 0])\\n# Original shape: (2, 3)\\n# New shape after transpose: (3, 2)\\nThe parameter perm=[1, 0] deﬁnes the new order of the dimensions',\n",
       "  'In TensorFlow,\\ndimensions are indexed starting from 0',\n",
       "  'So, in a 2D tensor (like a matrix), 0 refers\\nto the rows, and 1 refers to the columns.\\nperm=[1, 0] means that the ﬁrst dimension of the transposed tensor should be\\nthe second dimension (columns) of the original tensor, and the second dimension\\nof the transposed tensor should be the ﬁrst dimension (rows) of the original tensor.\\nThe tf.transpose operation rearranges the tensor according to the perm parameter.\\nEssentially, it switches the rows and columns of the tensor.\\nFor example, if we have the following 2D tensor:\\n[[1, 2, 3], [4, 5, 6]]\\nAfter applying tf.transpose(tensor, perm=[1, 0]), the tensor would be rearranged\\nto\\n[[1, 4], [2, 5], [3, 6]]\\nFor more complex neural network architectures, we might need to perform\\ncustom reshaping:\\ncomplex_tensor = tf.reshape(tensor, [3, -1, 1])\\n# Original shape: (2, 3)\\n# New shape: (3, 1, 1) - unspecified middle dimension\\n[3, –1, 1]: This is the new shape we want to give to the tensor',\n",
       "  'Here’s what each\\nelement in this shape array represents:\\n3: The ﬁrst dimension of the reshaped tensor will have a size of 3.\\n–1: This is a special value in TensorFlow’s reshape operation',\n",
       "  'When we specify\\n–1 for a dimension, TensorFlow automatically calculates the size of the second\\ndimension based on the total size of the tensor and the size of the other dimensions.\\nIt ensures that the total number of elements in the reshaped tensor is the same as the\\noriginal tensor',\n",
       "  'This is very useful when we are not sure about the size of a particular\\ndimension, but we know the sizes of the other dimensions.\\n2.3\\nParallelism\\n9\\n1: The third dimension of the reshaped tensor will have a size of 1.\\nFor example:\\n[[1, 2], [3, 4], [5, 6]]\\nThis is a tensor of shape (3,2) with three rows and two columns',\n",
       "  'After applying\\ntf.reshape(tensor, [3, –1, 1]), the tensor would be reshaped to [[[1]], [[2]], [[3]], [[4]],\\n[[5]], [[6]]]\\nwhich is (6,1,1)',\n",
       "  'The reshape function kept the original number of elements 3 ×\\n2 =6 and created a 3D tensor with the last dimension size one as required.\\n2.3\\nParallelism\\nAchieving maximum parallelism in TensorFlow generally involves leveraging its\\nbuilt-in capabilities for distributed computing and optimizing our code to utilize\\nthe available hardware resources effectively',\n",
       "  'This means using the built-in tensor\\noperations as much as possible and avoiding manual computations',\n",
       "  'For example,\\nuse Tensor matrix multiplication instead of writing a loop to perform element-wise\\nmultiplication',\n",
       "  'Similarly, it pays to spend time thinking about how to manipulate\\narrays using TensorFlow rather than writing our own code',\n",
       "  'TensorFlow is optimized\\nto run these operations efﬁciently, often leveraging parallelism on available hard-\\nware, such as GPUs or TPUs.\\nFor example, batch matrix multiplication is a common operation in deep learning.\\nTensorFlow’s tf.matmul or tf.linalg.matmul function can be used to perform matrix\\nmultiplications in parallel across batches:\\n# Create two batched tensors of shape (batch_size, n, m)\\n# and (batch_size, m, p)\\nbatch_tensor1 = tf.random.normal([64, 10, 20])\\nbatch_tensor2 = tf.random.normal([64, 20, 30])\\n# Batch matrix multiplication\\nresult_batch_matmul = tf.matmul(batch_tensor1, batch_tensor2)\\n# TensorFlow will perform these matrix multiplications\\n# in parallel across the batch\\nAchieving maximum parallelism in TensorFlow also involves leveraging its built-\\nin capabilities for distributed computing and optimizing our code to utilize the\\navailable hardware resources effectively',\n",
       "  'Here are some steps and code examples\\nto help write TensorFlow code for maximum parallelism:\\n1',\n",
       "  'Using Distributed Strategies\\nTensorFlow offers several distributed strategies to parallelize the com-\\nputation',\n",
       "  'The simplest one for single-machine, multi-GPU setups is the\\ntf.distribute.MirroredStrategy',\n",
       "  'Here’s an example of how to use it:\\n10\\n2\\nUsing Tensors\\nimport tensorflow as tf\\n# Define the distribution strategy\\nstrategy = tf.distribute.MirroredStrategy()\\n# Apply the strategy to a model creation\\nwith strategy.scope():\\nmodel = tf.keras.Sequential([\\ntf.keras.layers.Dense(512, activation=’relu’),\\ntf.keras.layers.Dense(10, activation=’softmax’)\\n])\\nmodel.compile(optimizer=’adam’,\\nloss=’sparse_categorical_crossentropy’,\\nmetrics=[’accuracy’])\\n...\\n2',\n",
       "  'Optimize Data Input Pipeline\\nTo ensure that the data input pipeline does not become a bottleneck, use\\nthe tf.data API for efﬁcient data loading and preprocessing',\n",
       "  'Caching with\\nAUTOTUNE is used frequently, although, in some cases, this does not work\\n100% correctly, and some other methods need to be substituted.\\n# Create a dataset\\ndataset = tf.data.Dataset.from_tensor_slices(\\ntrain_images, train_labels)\\n# Parallelize data preprocessing\\nAUTOTUNE = tf.data.experimental.AUTOTUNE\\ndataset = dataset.cache().shuffle(1000).batch(64).\\nprefetch(buffer_size=AUTOTUNE)\\n3',\n",
       "  'Utilize GPUs Efﬁciently\\nEnsure that TensorFlow is set up to use GPUs',\n",
       "  'TensorFlow will automatically\\ndistribute operations across available GPUs unless explicitly directed otherwise.\\n# Check if GPUs are available\\nprint(\"Num GPUs Available: \",\\nlen(tf.config.experimental.list_physical_devices(’GPU’)))\\n# TensorFlow will automatically use GPU if available\\n2.4\\nMachine Learning Environment\\nThese are my personal preferences when setting up a machine learning (ML)\\nenvironment',\n",
       "  'If you are familiar or happy with your current setup, then please feel\\nfree not to follow the setup below:\\n2.4\\nMachine Learning Environment\\n11\\n1',\n",
       "  'Hardware Requirements\\nCPU: Buy the fastest CPU with maximum RAM',\n",
       "  'You should have at least 16 GB\\nbut ideally 32 GB or more',\n",
       "  'GPU Support: For more intensive tasks, a GPU can\\nsigniﬁcantly accelerate the training of machine learning models',\n",
       "  'NVIDIA GPUs\\nare widely supported',\n",
       "  'Ensure you have a CUDA-compatible GPU with a rating\\nof 8+ and a minimum of 16 GB',\n",
       "  'However, my RTX 3080 graphics card only has\\n12 GB.\\n2',\n",
       "  'Operating System\\nTensorFlow is compatible with Windows, macOS, and Linux',\n",
       "  'Although Win-\\ndows is the most popular, using GPUs with it can be challenging due to the\\ndeprecation of certain libraries',\n",
       "  'Linux, especially Ubuntu is often preferred for\\ndeep learning tasks due to better support for GPUs and ease of environment setup.\\n3',\n",
       "  'TensorFlow Installation:\\nInstall TensorFlow using pip: pip install tensorﬂow',\n",
       "  'This command installs the\\nlatest version',\n",
       "  'If you have a compatible NVIDIA GPU, install the GPU version\\nusing pip install tensorﬂow-gpu',\n",
       "  'I use pip for all packages in this book, but it\\ncould also be done using Conda.\\n4',\n",
       "  'Integrated Development Environment (IDE)\\nUse an IDE or text editor that you’re comfortable with',\n",
       "  'Popular choices include\\nJupyter Notebook (great for experiments and visualization) or PyCharm',\n",
       "  'I ﬁnd\\nPyCharm community, which is free, is adequate for learning purposes.\\n3\\nHow Machine Learns Using Neural Network\\nThe Universal Approximation Theorem, ﬁrst demonstrated by George Cybenko in\\n1989 and later reﬁned by Kurt Hornik in 1991, forms the theoretical foundation\\nof machine learning',\n",
       "  'This theorem states that a feedforward neural network with a\\nsingle hidden layer can approximate any continuous function to arbitrary precision,\\ngiven the right activation function and a sufﬁcient number of neurons in the hidden\\nlayer.\\nThe important consequence of the theorem is that a machine can theoretically\\nlearn to produce almost any output from the input set of data',\n",
       "  'Even in the cases of\\ndiscontinuous functions, the neural network can still learn an approximation of the\\nfunction.\\nUnderstanding how a machine learns is the key to understand how to create\\napplications that can solve complex problems',\n",
       "  'A machine learning algorithm is\\ndifferent from a classical algorithm.\\nInstead of explicitly deﬁning rules or logic to produce an output from input data,\\na machine learning algorithm learns the underlying patterns by itself',\n",
       "  'The algorithm\\ntakes a set of input and corresponding output samples, then iteratively adjusts its\\ninternal parameters to minimize the difference between its predicted output and the\\nactual output',\n",
       "  'This process of minimizing the error or “loss” allows the algorithm\\nto automatically discover the rules or logic needed to generate the desired results,\\nwithout the programmer needing to specify them manually.\\nTo make this idea concrete, let’s take the following example',\n",
       "  'Suppose we are\\npresented with a set of input numbers, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, and the\\ncorresponding set of output numbers, 0, 1, 4, 9, 16, 25, 36, 49, 64, 81, and 100.\\nThe task is to predict the output number for an input number of 11.\\nNormally, one would write the following function to solve this problem in\\nPython:\\ndef predict(x): return x*x\\nprint(’output=’,predict(11))\\noutput= 121\\n© Philip Hua 2024\\nP',\n",
       "  'Hua, Neural Networks with TensorFlow and Keras,\\nhttps://doi.org/10.1007/979-8-8688-1020-6_3\\n15\\n16\\n3\\nHow Machine Learns Using Neural Network\\nIn this example, we guess from the list of input and output numbers that the correct\\nmapping function may be x →x2',\n",
       "  'In this speciﬁc case, identifying the correct\\nfunction was an educated guess',\n",
       "  'Had we use machine learning, the machine would\\nlearn that the correct mapping might be x →x2',\n",
       "  'The deduction process, however,\\nwould be more general and would take the following form:\\n•\\nCreate and conﬁgure a neural network as “supervised learning.”\\n•\\nFeed the neural network with the corresponding pairs of input and output\\nnumbers',\n",
       "  'For example, {0,0},{1,1},{2,4},',\n",
       "  '',\n",
       "  '',\n",
       "  '.,{10,100}.\\n•\\nTrain the neural network.\\n•\\nUse the trained neural network to predict the output using 11 as an input.\\nTo further differentiate between traditional and machine learning algorithms, let’s\\nextend this example by adding another set of data to the problem above',\n",
       "  'Let’s say\\nthat we have another set of data so that\\nDataset 1: {0,1,2,3,4,5,6,7,8,9} →{0,1,4,9,16,25,36,49,64,81}\\nDataset 2: {0,1,2,3,4,5,6,7,8} →{0,1,8,27,64,125,216,343,512}\\nThis problem is now a lot more interesting',\n",
       "  'The function y = x2 ﬁts the ﬁrst\\ndataset perfectly, while the second dataset has the mapping of the form y = x3.\\nThe graphs of y = x3 and y = x2 are shown in Figure 3-1',\n",
       "  'If we have to modify\\nour predict function above to ﬁt both datasets, we may decide on a curve between\\ny = x3 and y = x2 which may be of the form y = xn, where n is to be decided.\\nClearly, whichever parameter n is chosen, we cannot ﬁt both curves at the same\\ntime, so a decision has to be made how to select n to give the “best” curve.\\nFigure 3-1 y = x3 and y = x2\\n3.1\\nComponents of a Neural Network\\n17\\nOne possible idea is to choose n to ﬁt between the two curves to minimize the\\ndifferences (or the error) between the chosen function at x = {1, 2, ',\n",
       "  '',\n",
       "  '',\n",
       "  ', 10} to the\\ntwo curves y = x3 and y = x2.\\nA similar process takes place in our machine learning algorithm',\n",
       "  'At a high\\nlevel, a neural network can be considered a universal function approximator; it\\ncan approximate any given mathematical function using layers of computational\\n“nodes” or “neurons.” These nodes interact with each other to produce a function\\nwhich would match the output values as much as possible from the set of input data.\\nIt does this by updating the weight of each node to reduce the value of the error\\nfunction in a similar vein to what we have to do in our traditional algorithm',\n",
       "  'The\\nmain difference is that the process of choosing the weights for the nodes is iterative.\\nThe system updates the weights for the nodes iteratively for each pair of input and\\noutput data, {0, 0}, {1, 1}, {2, 4}..{10, 100} and {0, 0}, {1, 1}, {2, 8}, ..{10, 1000}.\\nWell, that is the theory anyway',\n",
       "  '',\n",
       "  '',\n",
       "  'In practice, if we execute the code written in\\nKeras using a simple neural network to solve the problem above, we will need to\\nsupply the model with many data points before it could approximate the function\\nclosely (Code 3-1).\\nThe results from the neural network are shown in Figure 3-2 For the time being,\\nthere is no need to worry about the details of the code',\n",
       "  'Simply note that setting up\\nand training a network in Python requires only a few lines of code',\n",
       "  'Also, note that the\\nnetwork will initially approximate a problem with straight lines; the reason for this\\nwill become apparent when we examine the internal structure later on',\n",
       "  'Of course,\\nthe power of machine learning is not limited to numerically approximating a simple\\nfunction',\n",
       "  'At a high level, the neural network has just been trained to ﬁnd something\\n“similar” to the input data',\n",
       "  'As long as we can express the problem numerically, the\\nsame procedure can be used to classify images, text, sounds, translate languages, etc.\\nWe may have to use different neural network topologies to solve speciﬁc problems,\\nbut it does not invalidate the idea of using a universal numerical approximator as a\\n“learner.”\\n3.1\\nComponents of a Neural Network\\nThis section delves into the intricate components that constitute a neural network.\\nWe wish to understand each element’s role and how they collectively contribute to\\nthe network’s ability to learn from data and make intelligent predictions or decisions.\\nOur exploration will cover the architecture of neurons and the building blocks of\\nneural networks and extend to the various layers and connections that form these\\ncomplex systems.\\nWe will dissect the core components, including input layers that receive data,\\nhidden layers that perform computations, and output layers that provide the ﬁnal\\ndecision or prediction',\n",
       "  'We will also shed light on the weights and biases, crucial\\nparameters that the network adjusts during training to improve its performance.\\nAdditionally, we will examine activation functions, which introduce nonlinear\\nproperties essential for the network’s ability to solve complex problems.\\n18\\n3\\nHow Machine Learns Using Neural Network\\nCode 3-1 Approximating y = x2 code\\nFurthermore, we will discuss the signiﬁcance of network architecture and\\nhow different designs can be tailored to speciﬁc types of problems, from simple\\nbinary classiﬁcations to intricate tasks, like image recognition and natural language\\nprocessing',\n",
       "  'We will explore how these components are trained using algorithms like\\nbackpropagation and optimized through methods such as gradient descent.\\nThis section is designed to provide a comprehensive understanding of the\\ncomponents of a neural network, laying a solid foundation for grasping how these\\n3.1\\nComponents of a Neural Network\\n19\\nFigure 3-2 Approximating y = x2 using a neural network\\nextraordinary systems function and are engineered to tackle some of the most\\nchallenging problems.\\n3.1.1\\nNeurons: The Building Blocks\\nAt the core of a neural network are its neurons',\n",
       "  'These artiﬁcial neurons are inspired\\nby the biological transmitters and receptors found in the human brain and play\\na pivotal role in processing and transmitting information within the network',\n",
       "  'In\\na typical neural network, particularly for image processing, we may encounter\\nhundreds of thousands or millions of these neurons',\n",
       "  'Although each neuron can\\nbe thought of as the basic computing unit in a neural network, we rarely discuss\\nindividual neurons as such',\n",
       "  'Instead, we concentrate on getting the correct weights\\nand bias terms of all the neurons in the network simultaneously:\\n•\\nInput Weights: Neurons receive multiple inputs from other neurons or external\\ndata sources',\n",
       "  'These inputs are not processed equally; instead, they are associated\\n20\\n3\\nHow Machine Learns Using Neural Network\\nwith individual weights',\n",
       "  'These weights determine the strength of the connections\\nbetween neurons',\n",
       "  'During training, the network adjusts these weights to learn and\\nadapt to the underlying patterns in the data.\\n•\\nActivation Function: After receiving weighted inputs, a neuron applies an acti-\\nvation function',\n",
       "  'This function introduces nonlinearity into the neural network,\\nenabling it to capture complex relationships within the data',\n",
       "  'Activation functions\\ntransform the neuron’s input into an output value, which is then passed on to\\nsubsequent neurons',\n",
       "  'Common activation functions include the sigmoid function,\\nhyperbolic tangent (tanh), and rectiﬁed linear unit (ReLU).\\n•\\nBias Term: In addition to input weights and activation functions, each neuron\\ntypically includes a bias term',\n",
       "  'The bias term allows the network to account\\nfor possible offsets or biases in the data',\n",
       "  'It provides ﬂexibility by allowing the\\nnetwork to ﬁt the data more accurately.\\nA stylized diagram for a neuron is shown in Figure 3.1.1',\n",
       "  'In this example,\\nthere are three inputs x1, x2, x3',\n",
       "  'Each input can either be the data from an external\\nsource, such as the pixel values of an image, or the output from a preceding neuron.\\nThe main purpose when training the network is to ﬁnd the values for the weights\\nw1, w2, w3 such that the output y is correct',\n",
       "  'In mathematical terms\\ny = f (w1 ∗x1 + w2 ∗x2 + w3 ∗x3 + b)\\nThe activation function f plays an important role to introduce nonlinearity into the\\nnetwork; otherwise, the output is simply a linear weighted sum of the input values.\\nThis is why f is always one of the nonlinear functions shown in Figure 3-3.\\nThe choice of activation functions, such as sigmoid, tanh, ReLU, and Leaky\\nReLU, depends on the neural network’s architecture and the problem being\\naddressed',\n",
       "  'These four activation functions are very popular, and most network will\\nuse one or more of these activation functions.\\n3.1\\nComponents of a Neural Network\\n21\\nFigure 3-3 Commonly used activation functions include the sigmoid σ(z) and the hyperbolic\\ntangent tanh(z)',\n",
       "  'More recently used activation functions are the RELU and Leaky RELU\\nThe Sigmoid Function\\nThe formula for the sigmoid function is σ(x) =\\n1\\n1+e−x ',\n",
       "  'This function outputs\\nvalues between 0 and 1, making it suitable for models that predict probabilities,\\nsuch as in binary classiﬁcation',\n",
       "  'It is often used in the ﬁnal layer of a binary\\nclassiﬁcation network to represent the probability of the predicted label being\\ncorrect',\n",
       "  'For example, if we feed an image of a dog through a canine image detection\\nnetwork, an output value of 0.8 means that the model predicts that the image is a\\ndog with 80% certainty.\\nOne drawback of the sigmoid function is that it is prone to the “vanishing gradient\\nproblem.”\\nTo train this network, we need to adjust the weights of the neurons based on\\nfeedback regarding the accuracy of the predicted values compared to the actual\\noutputs',\n",
       "  'This adjustment is done by gradients, which are essentially signals sent\\nback through the network telling each layer how to change the weights of its neurons\\nto improve the network’s performance.\\nThe vanishing gradient problem occurs when these gradient signals get increas-\\ningly smaller as they are passed back through each layer',\n",
       "  'Imagine if the message\\nwe are sending back through each layer gets fainter and fainter, so by the time it\\nreaches the ﬁrst layers, it is almost nonexistent',\n",
       "  'This issue arises because the earlier\\nlayers, which often capture fundamental information, receive minimal guidance on\\nadjusting their weights.\\n22\\n3\\nHow Machine Learns Using Neural Network\\nIf the layers of the network do not receive strong enough signals to learn, the\\nentire network doesn’t learn effectively',\n",
       "  'This is especially problematic in deep\\nnetworks with many layers, where the early layers might not learn well, leading\\nto poor overall performance.\\nThe Tanh Function\\nAn alternative to the sigmoid function, particularly popular in neural networks, is\\nthe tanh function, also known as the hyperbolic tangent',\n",
       "  'This has the formula:\\ntanh(x) = ex −e−x\\nex + e−x\\n(3.1)\\nThe tanh function is similar to the sigmoid function; however, it outputs values\\nbetween –1 and 1',\n",
       "  'This means the outputs are zero-centered, which makes the\\ntraining of the model easier and more efﬁcient',\n",
       "  'It is often used in hidden layers\\nof a neural network as it can model complex relationships more effectively than\\nthe sigmoid',\n",
       "  'However, like the sigmoid, the tanh function also suffers from the\\nvanishing gradient problem.\\nThe ReLU (Rectiﬁed Linear Unit) Function\\nThe formula for the ReLU function is very simple: it is x if x > 0 and zero for\\nvalues of x ≤0',\n",
       "  'The function has gained considerable popularity, and it is the most\\nwidely used activation function for training deep neural networks and convolutional\\nneural networks (image processing) because of its simplicity and efﬁciency.\\nReLU (rectiﬁed linear unit) helps mitigate the vanishing gradient problem by\\nmaintaining a nonzero gradient for positive input values during backpropagation,\\nwhich ensures that gradients do not shrink too rapidly as they propagate through the\\nnetwork.\\nIn the ReLU function, for any input value greater than zero, the gradient is\\nconstant and equal to one',\n",
       "  'This means that during backpropagation, the weights\\nof the network receive sufﬁcient gradient updates, allowing the model to learn\\neffectively',\n",
       "  'In contrast, activation functions like the sigmoid or tanh have gradients\\nthat become very small for large input values, which leads to the vanishing gradient\\nproblem as updates diminish over layers.\\nHowever, it can suffer from the “dying ReLU” problem, where neurons can\\nsometimes become inactive and output zero for any input.\\nLeaky ReLU\\nAnother popular activation function to discuss is the Leaky ReLU, similar in concept\\nto the standard ReLU but designed to address its shortcomings',\n",
       "  'It is similar to ReLU\\nbut allows a small, nonzero gradient when the unit is not active to solve the dying\\nReLU problem',\n",
       "  'By allowing a small gradient α when the unit is not active, it ensures\\nthat the neurons never die',\n",
       "  'The downside is that the value of α needs to be carefully\\nset',\n",
       "  'If it is too large, it can lead to high variance during training.\\n3.1\\nComponents of a Neural Network\\n23\\nTo understand concretely why the activation function is needed, we should\\nconsider the ﬂow of signal passing through a node.\\nWhen an input signal is received at a node, it generates an output y using the\\nfollowing formula:\\ny = f (x1w1 + x2w2 + x3w3 + b)\\n(3.2)\\nHere, x1, x2, x3 are the outputs of all the nodes joining this node from the\\npreceding hidden layer (or the input layer); w1, w2, w3 are the weights between\\nthese interconnected nodes',\n",
       "  'The node sums the product of the weights and the\\ninput values, add a number, a (bias), and then apply the activation function f to\\nthe weighted sum to produce y.\\nWhy does a node compute data this way?\\nRecall that the main purpose of a neural network is to act as a function\\napproximator',\n",
       "  'If you have ever done a course on linear algebra, you may recall\\nthat a multiple linear regression model that approximates any set of data points with\\na straight line has a form of\\nypredict = b + w1x1 + w2x2 + w3x3 ',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '+ wnxn\\n(3.3)\\nThe linear regression equation has the same form as the formula for a node except\\nthat, in the case of a neuron, the activation function is applied after the weighted\\nsum is calculated',\n",
       "  'Without the activation function, the neural network could only\\napproximate a function with a straight line, in the same way as a linear regressor\\ndoes',\n",
       "  'However, by using a nonlinear activation function, we can approximate any\\nnonlinear target, that is, complex patterns, with less errors',\n",
       "  'The activation function\\nalso serves another purpose, that is, to activate or deactivate the next neuron',\n",
       "  'To turn\\noff the next neuron, we just simply set the output of the activation function to zero.\\nHowever, if the input to the next neuron is always zero, it would never be activated\\nand become dead to the network.\\nChoosing the activation function for complex network is not an easy task and is\\na topic of research',\n",
       "  'In the early days, the sigmoid function was the most popular\\ndue to its nonlinearity',\n",
       "  'However, researchers found that using the sigmoid activation\\nintroduces the vanishing gradient problem for deeper networks where the weights\\nwill stop changing after some iterations, hence stopping the network from learning.\\nThe rectiﬁed linear unit activation function, ReLU, over time, became the default\\nchoice, but this too has problems as it causes dead nodes with some network\\nconﬁgurations.\\nThere are many activation functions available in Keras, and it is even possible to\\ncreate custom activation functions using callable, but in practice, we will only need\\nto use the following popular functions for most cases: ReLU, sigmoid, softmax, and\\ntanh.\\n24\\n3\\nHow Machine Learns Using Neural Network\\nIn Keras, there are two ways to set the activation of a layer: activations can either\\nbe used through an activation layer or through the activation argument in the dense\\nlayer itself as in the following example:\\nmodel = Sequential()\\nmodel.add(Dense(784, activation=’relu’,input_shape=(784,)))\\nmodel.add(Dense(784))\\nmodel.add(activation.ReLU(threshold=0.0))\\nThe activation function is available for all forward layers, so we could also deﬁne it\\ndirectly in the dense layer itself:\\n# without parameters\\nmodel.add(layers.Dense(64, activation=’relu’))\\nor\\n# with parameters from keras import activations\\nmodel.add(Dense(784,lambda x:\\nactivations.relu(x,threshold=0.1)))\\nNote we have to use a lambda function as the ﬁrst parameter of the ReLU function\\nis a tensor or variable.\\nThe decision of which activation function to use is tricky',\n",
       "  'The nonlinearity of\\nthe backpropagation algorithm means it is not obvious to know which function will\\nwork best in advance',\n",
       "  'For most classiﬁcation problems, I would try ReLU ﬁrst, then\\ntanh or softmax for the hidden layer.\\nThe consideration for the activation function in the output layer is more scientiﬁc\\nas it depends on the type of result we are expecting for the problem',\n",
       "  'For multiple\\ncategorical choices, we should use softmax',\n",
       "  'This activation function will assign a\\nprobability to each output node, and Keras would simply choose the node with the\\nhighest probability as the most probable choice',\n",
       "  'In the MNIST example, when the\\nnetwork processes an image of a digit, it will assign a probability of the input image\\nmatching the ten output nodes {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}.\\nOf course, being a probability, the sum of output node values will be one',\n",
       "  'It is\\nalso possible to use the sigmoid function in a multi-label classiﬁcation problem, but\\nthe outputs of the nodes will not sum to one',\n",
       "  'Instead, each output represents the\\nprobability of that outcome occurring',\n",
       "  'This is useful in cases where the outcomes\\nare not mutually exclusive',\n",
       "  'For example, a patient could have multiple symptoms of\\nthe same underlying disease.\\nWhen we have a binary classiﬁer, that is, if the output only has two mutually\\nexclusive outcomes, then a sigmoid function should be used instead',\n",
       "  'The sigmoid\\nfunction, similarly to the softmax used in the case of multi-label problems, returns\\nthe probability of the input matching the output',\n",
       "  'This means that the output node\\nwill not simply be either zero or one but a real number between zero and one.\\nTo give a concrete example of how to use a binary classiﬁer, let us again use the\\nMNIST database, but this time, we will only use one output node to check if the\\nhandwritten digit is eight',\n",
       "  'Of course, we would have to change the target array so\\nthat the target arrays yT rain and yT est elements are zero for any digit other than\\neight and one otherwise',\n",
       "  'The code now becomes\\n3.1\\nComponents of a Neural Network\\n25\\n# load mnist dataset\\n# 60,000 images for xTrain, 10,000 for xTest\\nmnist = tf.keras.datasets.mnist\\n(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\\n# convert the 28x28 input matrix to a vector of length 784\\nxTrainFlattened = xTrain.reshape(len(xTrain),784)\\nxTestFlattened = xTest.reshape(len(xTest),784)\\n#set yTrain and yTest to 1 where the digit is 8\\n#and 0 for others\\nyTrain = np.where(yTrain!=8,0,1)\\nyTest = np.where(yTest!=8,0,1)\\n# change the number of output node to 1 and\\n# define the loss function as binary_crossentrophy\\nmodel = Sequential()\\nmodel.add(Dense(784, activation=’relu’,\\ninput_shape =(784,)))\\nmodel.add(Dense(784,activation=’relu’))\\n# sigmoid gives the probability of the digit is 8\\nmodel.add(Dense(1,activation=’sigmoid’))\\nmodel.compile(optimizer=Adam(),\\nloss=’binary_crossentropy’,\\nmetrics=[’accuracy’])\\nmodel.fit(xTrainFlattened, yTrain, epochs=5)\\nyPredict = model.predict(xTestFlattened)\\n# test the accuracy using the xTest\\nmodel.evaluate(xTestFlattened,yTest)\\n313/313 [==============================] -\\n2s 5ms/step - loss: 0.0278 - accuracy: 0.9904\\n[0.027823645621538162, 0.9904000163078308]]\\nThe network identiﬁes the ﬁgures 8 in the test set with 99% accuracy',\n",
       "  'There are\\n974 ﬁgures 8 in the test dataset, so there should be ten incorrectly classiﬁed images.\\nThese ﬁgures are shown in Figure 3-4',\n",
       "  'Perhaps it is more understandable why the\\nﬁgures 3 would be misclassiﬁed, but the ﬁgure 1 is rather more obvious, and we\\nwould expect the network to classify this correctly even when the network is not\\ntuned.\\n3.1.2\\nNeuron Initialization\\nBefore we start using the network, we need to initialize the weights and biases of the\\nneurons',\n",
       "  'In Keras, the default initialization of weights varies depending on the type\\nof layer we are using, although for common layers, such as Dense, convolutional,\\nand RNN, the Glorot Uniform, also known as Xavier Uniform initialization, is used\\nfor the weights',\n",
       "  'This default initializer is designed to keep the scale of the gradients\\nequal in all layers.\\n26\\n3\\nHow Machine Learns Using Neural Network\\nFigure 3-4 Images where\\nNN failed to correctly\\nidentify the number\\nBiases are normally set to zero except for some RNN layers, such as LSTM\\nwhere special initialization is required.\\nThe choice of these defaults is based on general best practices and empirical\\nevidence suggesting that they work well in a wide range of scenarios',\n",
       "  'However,\\nKeras allows us to customize these initializers by specifying the kernel and bias\\ninitializer arguments in the layer constructor as shown in the example below:\\nmodel = Sequential([\\nDense(64, input_shape=(20,), activation=’relu’,\\nkernel_initializer=RandomNormal(mean=0.0, stddev=0.05),\\nbias_initializer=Constant(value=0.4)),\\nDense(1, activation=’sigmoid’,\\nkernel_initializer=RandomNormal(mean=0.0, stddev=0.05),\\nbias_initializer=Constant(value=0.4))])\\nThe list of common initialization methods include\\n•\\nZero Initialization: Setting all weights to zero',\n",
       "  'This is generally not recom-\\nmended because it leads to the problem of neurons learning the same features.\\n•\\nRandom Initialization: Setting weights to random values',\n",
       "  'This is more common,\\nbut the scale of randomness needs to be controlled',\n",
       "  'Too high values can lead to\\nexploding gradients, while too low might lead to vanishing gradients.\\n•\\nXavier/Glorot Initialization: A popular method for initializing weights, espe-\\ncially in networks with sigmoid or tanh activation functions',\n",
       "  'It sets the weights\\nbased on the number of inputs and outputs of each neuron, aiming to keep the\\nvariance of outputs of each layer approximately equal.\\n•\\nHe Initialization: Similar to Xavier, but it’s designed for layers with ReLU\\nactivation functions',\n",
       "  'It sets the weights considering only the number of inputs,\\nwhich keeps the variance higher, a necessity for ReLUs.\\n•\\nOrthogonal Initialization: This involves setting the weights of each layer as\\northogonal matrices',\n",
       "  'It’s believed to help in maintaining the stability of signals\\nacross different layers of deep networks.\\n3.2\\nNetwork Layers: Building a Hierarchy\\n27\\nThe choice of initialization often depends on the type of activation function used\\nin the network',\n",
       "  'For instance, He initialization is preferred with ReLUs, while\\nXavier is often used with sigmoid or tanh',\n",
       "  'Sometimes, it is beneﬁcial to ﬁne-tune\\nthe initialization method based on the speciﬁc characteristics of our network and\\nthe problem we are solving',\n",
       "  'Often, the best way to determine the most effective\\ninitialization method is through experimentation and observing how quickly and\\naccurately the network learns.\\n3.2\\nNetwork Layers: Building a Hierarchy\\nWhile individual neurons are powerful, in practice it is the structure of the network\\nlayers that an ML engineer is more concerned with',\n",
       "  'Neural network layers serve\\nas functional blocks, each with a speciﬁc role in processing and transforming data.\\nThe network consists of different types of layers, and their arrangement forms the\\nnetwork’s architecture.\\nThe topology of a neural network can get complicated, particularly for natural\\nlanguage processing and moving image recognition, but we will discuss them later.\\nIn the meantime, the most basic neural network is a feedforward network, which we\\nused in our previous examples, shown in Figure 3-5.\\nA basic neural network has interconnected nodes, represented by circles in\\nFigure 3-5 in three layers: an input layer, a hidden layer, and an output layer',\n",
       "  'Deep\\nneural networks may have several hidden layers interconnected with each other\\nbefore reaching the output layer',\n",
       "  'In TensorFlow and Keras, the feedforward layer\\nis referred to as a dense layer',\n",
       "  'If we refer to the code in Code 3-1, we can see that a\\ndense layer is deﬁned with the number of nodes and an activation function:\\nmodel.add(Dense(10, activation=’relu’))\\nFigure 3-5 A three-layer feedforward network with three input, ﬁve hidden, and two output nodes\\n28\\n3\\nHow Machine Learns Using Neural Network\\nThe hidden layers may have millions of nodes capable of mapping any input type\\nto any output type',\n",
       "  'Of course, the more nodes we have, the more data and time are\\nneeded to train the network',\n",
       "  'A reasonably complicated deep learning network may\\nneed millions of data points rather than thousands or hundreds of thousands, so it is\\nnormally best practice to keep the network structure as lean as possible.\\nIn a feedforward network, information ﬂows from left to right, that is, from the\\ninput layer to the hidden layer(s) and then ﬁnally to the output layer',\n",
       "  'A number,\\ncalled weight, represents a connection between two nodes, shown as an arrow in\\nFigure 3-5.\\nThis means that each node in the hidden or output layer receives the output\\nweights of the nodes from the preceding layer as input, does some predeﬁned\\ncomputation, and then passes the result as a number, or weight, to the next hidden\\nor output layer',\n",
       "  'This weight is an important number',\n",
       "  'An “important” node will have\\na higher weight, while a node which produces a zero weight all the time is useless\\nand is called a dead node.\\nA feedforward network uses a feedback process to improve its prediction over\\ntime',\n",
       "  'Each time we supply the network with a new input, it predicts the output value\\nusing the weights and then compares how close the predicted value is to the actual\\noutput value using a loss function',\n",
       "  'The network then adjusts the weights of the nodes\\nin the hidden layer(s) using an algorithm called backpropagation (or backprop for\\nshort) to reduce the error',\n",
       "  'This process is repeated until all the inputs are processed\\nand the weights are updated accordingly.\\nIt should be clear that three components are very important for a feedforward\\nnetwork: the activation function, the loss functions, and the feedback algorithm.\\nTogether they determine how a network gets to learn quickly and correctly.\\n3.3\\nThe Optimizer and the Loss Function\\nOther than the activation function, we need to discuss the optimizer and the loss\\nfunction for a neural network',\n",
       "  'We may see this in the previous code as\\nmodel.compile(optimizer=Adam(), loss=’binary_crossentropy’,\\nmetrics=[’accuracy’])\\nBoth of these components are essential to using a neural network',\n",
       "  'Unfortunately, we\\nwill need to have a mathematical background to understand the concepts properly.\\nHowever, I will illustrate the ideas with analogies as much as possible without\\nresorting to complicated mathematical formulas.\\nThe key idea here is that we need to “train” our network to achieve what we want\\nit to do',\n",
       "  'For each predicted output, we need to (1) identify how close we are to the\\nactual output and (2) change the weights of the neurons after each predicted output\\nto (hopefully) inch the network toward the correct solution',\n",
       "  'Step 1 is done using the\\nloss function, while it is the job of the optimizer via the backpropagation algorithm\\nin step 2 to improve the accuracy of the network.\\n3.3\\nThe Optimizer and the Loss Function\\n29\\n3.3.1\\nThe Loss Function\\nThe loss function provides the backpropagation algorithm of an estimate of the\\nsize of the error in the current state of the model',\n",
       "  'It provides the backpropagation\\noptimization algorithm with a single number to minimize',\n",
       "  'The smaller the error, the\\nbetter the model is at ﬁtting the training data',\n",
       "  'However, for reasons which will be\\ndiscussed later, it is not necessarily the case that we would want the lowest error\\nduring the training process as the model may not perform as well during testing or\\nproduction because it has overﬁtted the training data.\\nIn Keras, there are three types of loss functions',\n",
       "  'Which one we should use\\ndepends on the type of problem under consideration',\n",
       "  'For regression, that is,\\napproximating real valued functions, we should use a regression loss',\n",
       "  'With problems\\nwhere we need to determine the probability of occurrence, then use one of the\\nprobabilistic loss functions',\n",
       "  'The third type, called hinged losses, is speciﬁcally\\ndesigned for “maximum-margin” classiﬁcation problems',\n",
       "  'Underlying any loss\\nfunction is the concept of proximity measure, which gives a mathematical metric\\nof how close, or equivalently how similar, two objects are to each other.\\nAll losses are available in Keras via a class handle and a function handle.\\nThe class handles enable us to pass conﬁguration arguments to the constructor as\\nfollows.\\nUsing a Function Handle\\nWhen we use a function handle, we typically specify the loss function by its string\\nname when compiling the model:\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\n# Define a simple model\\nmodel = Sequential([\\nDense(64, activation=’relu’, input_shape=(10,)),\\nDense(1)\\n])\\n# Compile the model using a function handle for the loss\\nmodel.compile(optimizer=’adam’, loss=’mean_squared_error’)\\nIn this case, the mean squared error is the string identiﬁer for the mean squared error\\nloss function.\\nUsing a Class Handle\\nWhen using a class handle, we instantiate a loss class with any required conﬁgura-\\ntion parameters and then pass this instance to the compile method of the model',\n",
       "  'This\\napproach provides more ﬂexibility, as we can pass additional parameters to the loss\\nfunction if the loss function supports such parameters',\n",
       "  'Here is an example using the\\nMeanSquaredError class:\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.losses import MeanSquaredError\\n30\\n3\\nHow Machine Learns Using Neural Network\\n# Define a simple model\\nmodel = Sequential([\\nDense(64, activation=’relu’, input_shape=(10,)),\\nDense(1)])\\n# Instantiate the class with desired configuration\\nmse_loss = MeanSquaredError(reduction=’auto’,\\nname=’mean_squared_error’)\\n# Compile the model using the class handle for the loss\\nmodel.compile(optimizer=’adam’, loss=mse_loss)\\n3.3.2\\nLoss Function for Regression\\nRegression problems are a set of problems where the model predicts a real value\\nas output',\n",
       "  'For example, predicting house prices, company proﬁts, or future stock\\nprices',\n",
       "  'Keras provides both class functions to instantiate objects and set parameters,\\nas well as loss functions that can be called directly',\n",
       "  'In either case, the mean squared\\nerror is by far the most popular loss function used to solve regression problems,\\nwhile cosine similarity is frequently used in natural language processing to measure\\nhow similar words are',\n",
       "  'We will discuss these two functions below',\n",
       "  'If you are\\ninterested in learning more, here is the complete list of loss functions implemented\\nin Keras: https://keras.io/api/losses/.\\n3.3.3\\nMean Squared Error\\nThe mean squared error (MSE) is frequently used in statistics and machine learning\\nto measure the average of the squares of the errors, essentially quantifying the\\ndifference between predicted and actual values',\n",
       "  'Let’s suppose that we have the\\nactual values for our problem as\\nY = {10.2, 11.0, 12.5, 1.0, −6.5, 0.0}\\nand the predicted values from our network are\\nYpredict = {9.9, 12.2, 12.5, 0.0, 1.0, 1.0}\\nthen the MSE is given by\\nMSE = 1\\n6[(10.2 −9.9)2 + (11.0 −12.2)2 + (12.5 −12.5)2+\\n(1.0 −0.0)2 + (−6.5 −1.0)2 + (0.0 −1.0)2] = 9.963333\\n(3.4)\\n3.3\\nThe Optimizer and the Loss Function\\n31\\nAs each term in the MSE formula is squared, the error function is always positive,\\nensuring that the function focuses on the magnitude of errors',\n",
       "  'It becomes zero only\\nwhen the predicted values match the target values exactly',\n",
       "  'Calculating MSE in Keras\\nis straightforward and gives the same result as above.\\nimport numpy as np\\nimport tensorflow as tf\\ny= [10.2,11,12.5,1,-6.5,0]\\nyPredicted = [9.9,12.2,12.5,0,1,1]\\nmse = tf.keras.losses.MeanSquaredError()\\nprint(mse(y,yPredicted).numpy())\\n9.963333\\nThis loss function can be speciﬁed in the machine learning function compile as\\nfollows:\\nmodel.compile( loss=tf.keras.losses.MeanSquaredError())\\n3.3.4\\nCosine Similarity\\nIn contrast to regression, which deals with numerical predictions, cosine similarity\\nis used to measure the similarity between two vectors, commonly in applications\\ninvolving text or sequences',\n",
       "  'For example, suppose we want to compare two similar\\nsentences in the popular nursery rhymes “Humpty Dumpty”:\\n“Humpty Dumpty sat on a wall” and “Humpty Dumpty had a great fall”\\nOne way to do this is to vectorize each sentence using 0 and 1 to indicate if a word\\nis in the dictionary as shown in Figure 3-6',\n",
       "  'Once vectorized, the cosine of the angle\\nα between the two vectors is a number representing how close (or similar) they are\\nto each other',\n",
       "  'The cos() function has values ranging from –1 to 1',\n",
       "  'An angle of zero\\ndegrees (cos(0) = 1) indicates two vectors pointing in the same direction, signifying\\nmaximum similarity',\n",
       "  'Conversely, cos(180 degrees) equals –1, indicating vectors in\\nopposite directions, signifying maximum dissimilarity, as shown in Figure 3-7c.\\nThe advantage of using the cosine similarity metric is that it is very easy and fast\\nto calculate',\n",
       "  'We simply compute the dot product of the two vectors and divide by\\ntheir lengths as follows:\\ncosα =\\nA.B\\n||A||||B||\\nwhere ||A|| denotes the length of vector A',\n",
       "  'For example, the angle between the\\nvector {3, 4, 5} and {−3, 5, 4} is\\ncosα =\\n3.(−3) + 4.5 + 5.4\\n√\\n32 + 42 + 52.\\n\\x02\\n(−3)2 + 52 + 42 = 0.62\\n(3.5)\\n32\\n3\\nHow Machine Learns Using Neural Network\\nFigure 3-6 Vectorizing\\nsentences\\na\\nb\\nc\\nFigure 3-7 Cosine similarity between two vectors\\nKeras has a built-in function to perform the same calculation:\\nimport numpy as np\\nimport tensorflow as tf\\ny= [3.0,4.0,5.0]\\nyPredicted = [-3.0,5.0,4.0]\\ncosineLoss = tf.keras.losses.CosineSimilarity()\\nprint(cosineLoss(y,yPredicted).numpy())\\n-0.6199999\\nWe can use this in the compile function as follows:\\nmodel.compile(optimizer=’Adam’,\\nloss=tf.keras.losses.CosineSimilarity(axis=1))\\nWe may notice the parameter axis=1',\n",
       "  'This tells the algorithm to calculate the cosine\\nsimilarity of the vector to the feature axis',\n",
       "  'We will explore the idea of a feature axis\\nand what it means later on when we discuss the use of a convoluted neural network\\n(CNN) for image processing.\\n3.4\\nProbabilistic Losses\\n33\\n3.4\\nProbabilistic Losses\\nFor categorical problems, that is, for problems which require us to identify classes of\\nobjects, for example, images of dogs, cats, birds, ﬁsh, etc., we may require the neural\\nnetwork to output the probabilities of the input object belonging to each class',\n",
       "  'Keras\\nprovides many loss functions to do this, but the most popular options are binary,\\ncategorical cross-entropy, and sparse categorical cross-entropy classes, which we\\nwill discuss below.\\n3.4.1\\nBinary Cross-Entropy\\nUse this entropy function for classiﬁcation problems where the output has only two\\noutcomes, for example, a picture of a dog or cat, the word “happy” or “sad.” For a\\nbinary classiﬁcation model, the output is the probability of a sample belonging to\\none of the two classes, usually represented as 0 or 1',\n",
       "  'The binary cross-entropy loss\\nfunction measures how far the model’s predictions are from the actual labels',\n",
       "  'For a\\nsingle sample, it is deﬁned as\\nL(y) = −y log(p) −(1 −y) log(1 −p)\\n(3.6)\\nFor many data points, the loss function is simply the arithmetic average of the\\ntotal loss for all data points',\n",
       "  'p is the predicted probability coming from our neural\\nnetwork',\n",
       "  'Note that since y can only be 1 or 0, only one part of the equation can be\\nactivated',\n",
       "  'When y = 1, L(1) = −log(p)',\n",
       "  'If the predicted probability p = 1, the\\nL(1) = 0, so there is no loss',\n",
       "  'If the probability p is ≈0, −log(p) >> 1, so the\\nloss value is very high',\n",
       "  'The same logic works in the case of y = 0 for L(0).\\nIf we use Keras to calculate binary cross-entropy for our neural network, it\\nfollows the same format as before',\n",
       "  'That is, we need to set the parameter loss in\\nthe compile function.\\nlossFunction = BinaryCrossentropy()\\nmodel.compile(loss=lossFunction,optimizer=’adam’,\\nactivation=’sigmoid’,metrics=[’accuracy’])\\nUse the activation function sigmoid for a binary cross-entropy loss function.\\n3.4.2\\nCategorical Cross-Entropy\\nThis is the same as the binary cross-entropy loss except that it is used for multi-\\nclass outcomes instead of binary',\n",
       "  'For example, the output could be a picture of a\\ncat, a dog, a bird, or others',\n",
       "  'If we use Keras categorical cross-entropy, we will need\\nto vectorize the output ﬁrst so that each output is either 1 or 0',\n",
       "  'This is done by\\nusing one-hot encoding',\n",
       "  'Simply put, one-hot encoding assigns a unique one and\\nzero vector for each category as shown in Figure 3-8.\\n34\\n3\\nHow Machine Learns Using Neural Network\\nFigure 3-8 One-hot\\nencoding for the three\\ncategories: red, yellow, and\\nblue\\nThe sof tmax is a suitable activation function for categorical cross-entropy.\\nThe softmax function converts the output of the neural network into probability\\ndistributions, ensuring that the sum of the probabilities of all output nodes is equal\\nto one.\\n3.4.3\\nSparse Categorical Cross-Entropy\\nThe sparse categorical cross-entropy function is similar to categorical cross-entropy,\\nwith the key difference being that it does not require one-hot encoding of output\\nlabels',\n",
       "  'Instead, the labels can be directly assigned as integers',\n",
       "  'For example:\\nred = 1, yellow = 2, blue = 3',\n",
       "  'The advantage of using sparse cross-entropy is that\\nit saves time and memory as each class is an integer and not a whole vector.\\n3.5\\nNetwork Optimizer\\nIn machine learning, optimization refers to the process of iteratively reﬁning the\\nmodel parameters to improve its accuracy and reduce error.\\nAs mentioned, this is done using an optimizer in the backpropagation process.\\nThe main objective of the optimizer is to minimize the value of the loss function after\\neach iteration by changing the weights of the neurons',\n",
       "  'It achieves this iteratively\\nusing a numerical search algorithm that estimates the next set of weight values\\nbased on the loss function',\n",
       "  'The new estimated weights should reduce the loss over\\niterations, but there is no guarantee that it will converge or, if it converges, that it\\nwill converge to a global maximum.\\nThe algorithm to optimize the weights is normally based on one of the popular\\nalgorithms called gradient descent',\n",
       "  'To understand the intuition behind this algo-\\nrithm, imagine that we are lost on a hill walk and it is now dark',\n",
       "  'One strategy to ﬁnd\\nthe bottom of the hill is to explore the immediate surrounding and walk a few steps\\nin the direction of the steepest slope, then check for direction again and repeat until\\nwe get stuck in some hole or got the bottom of the hill',\n",
       "  'The strategy requires two\\nparameters: the number of steps before we check for direction (or equivalently, the\\nsize of each step if we check after every step) and the direction of descent at each\\nstep.\\nChoosing a small step size would slow convergence',\n",
       "  'Conversely, a step size that\\nis too large could mean that we miss the nuances of the ground topology and end\\nup walking randomly up and down the hill',\n",
       "  'The optimal step size depends on each\\n3.5\\nNetwork Optimizer\\n35\\napplication, but one thing which would help the optimizer, in machine learning and\\nnot in real life, is to normalize the data so that a similar step size could be used for\\nmany problems',\n",
       "  'We will discuss this point in more detail in later sections.\\nThe direction of the steepest gradient for the optimizer aligns with the local\\ngradient of the loss function, which is why we need to choose a loss function for\\nevery problem',\n",
       "  'Different variants of the gradient descent algorithm may improve\\nthe process by adapting the step size depending on the steepness of the gradient.\\nThey may also introduce a random walk now and again to avoid getting stuck in a\\nhole, but the basic idea remains the same.\\nThere are several optimizers to choose in Keras, but they fall into two categories:\\nbasic and adaptive gradient descent algorithms',\n",
       "  'We can read the different types on\\nthe Internet if we are curious, but in practice, the two most used ones are mini batch\\ngradient descent and Adam.\\nWe often use Adam ﬁrst for our training, as it is considered one of the best among\\nthe adaptive optimizers',\n",
       "  'However, the mini batch gradient is also worth trying if\\nconvergence is slow or if there are memory limitations',\n",
       "  'The mini batch term refers\\nto taking the average of the loss function after a batch of input data before updating\\nthe weights',\n",
       "  'There is no magic formula for the batch size, but we will discuss some\\nconsideration for choosing the value for this parameter later on.\\nAn important hyperparameter for an optimizer is the learning rate and its\\nschedule',\n",
       "  'The learning rate is a critical hyperparameter that controls how much the\\nweights in the network are adjusted with respect to the loss gradient',\n",
       "  'A smaller\\nlearning rate makes the network learn slower, but it can help the network reach a\\nbetter or more precise ﬁnal performance',\n",
       "  'A larger learning rate makes the network\\nlearn faster, but it can overshoot the optimal values',\n",
       "  'Keras also provides a facility to\\nchange the active learning rate (or its schedule) via the use of a callback function.\\nTo deﬁne the optimizer, use\\nadam = Adam(learning_rate=0.001)\\nThe model is then set up to use the optimizer by compiling\\nmodel.compile(optimizer=adam, loss=’binary_crossentropy’,\\nmetrics=[’accuracy’])\\nIn Keras, learning rate schedules are mechanisms used to adjust the learning rate\\nduring training, allowing for dynamic adaptation based on the model’s performance.\\nThis can lead to better performance of the model, as it allows for a more reﬁned\\ntuning of the optimization process',\n",
       "  'To illustrate, common types of learning rate\\nschedules include time-based decay, step decay, and exponential decay, each with\\nits own strategy for adjusting the learning rate',\n",
       "  'Here are examples of each.\\nTime-Based Decay\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nfrom tensorflow.keras.optimizers import Adam\\nfrom tensorflow.keras.callbacks import LearningRateScheduler\\nimport numpy as np\\n36\\n3\\nHow Machine Learns Using Neural Network\\n# Sample model\\nmodel = Sequential([Dense(64, activation=’relu’,\\ninput_shape=(20,)),\\nDense(1, activation=’sigmoid’)])\\n# Initial learning rate\\ninitial_learning_rate = 0.01\\n# Define the scheduler function\\ndef scheduler(epoch, lr):\\ndecay = 0.1\\nreturn initial_learning_rate / (1 + decay * epoch)\\n# Compile the model with the initial learning rate\\nmodel.compile(\\noptimizer=Adam(learning_rate=initial_learnin_rate),\\nloss=’binary_crossentropy’, metrics=[’accuracy’])\\n# Fit the model with the learning rate scheduler\\nmodel.fit(X_train, y_train, epochs=100,\\ncallbacks=[LearningRateScheduler(scheduler)])\\nStep Decay\\nStep decay reduces the learning rate by a factor every few epochs.\\n# Define the scheduler function for step decay\\ndef step_decay(epoch):\\ninitial_lr = 0.01\\ndrop_rate = 0.5\\nepochs_drop = 10.0\\nreturn initial_lr * np.power(drop_rate,\\nnp.floor((1+epoch)/epochs_drop))\\n# Compile and fit as before\\nmodel.compile(optimizer=Adam(learning_rate=0.01),\\nloss=’binary_crossentropy’,\\nmetrics=[’accuracy’])\\nmodel.fit(X_train, y_train, epochs=100,\\ncallbacks=[LearningRateScheduler(step_decay)])\\nExponential Decay\\n# Define the scheduler function for exponential decay\\ndef exponential_decay(epoch):\\ninitial_lr = 0.01\\nk = 0.1\\nreturn initial_lr * np.exp(-k*epoch)\\n# Compile and fit as before\\nmodel.compile(optimizer=Adam(learning_rate=0.01),\\nloss=’binary_crossentropy’,\\nmetrics=[’accuracy’])\\nmodel.fit(X_train, y_train, epochs=100,\\ncallbacks=[LearningRateScheduler(exponential_decay)])\\n3.7\\nTensorBoard\\n37\\n3.6\\nGeneralization Errors\\nIf a network performs well on the training set but generalizes badly, it is\\noverf itting the data',\n",
       "  'A network might overﬁt if the training set contains accidental\\nregularities in the input data',\n",
       "  'For instance, in our MNIST training dataset, if the\\nhandwritten digit was from a single person, then any quirks in the way a digit is\\nwritten could be taken as gospel truth in our trained network, fooling it to failing to\\ndistinguish the handwriting from other people',\n",
       "  'Equally, suppose we have a diverse\\nhandwritten dataset from millions of people, a simple network with few neurons\\nwill not have the capacity to remember the information in its training data',\n",
       "  'In other\\nwords, the number of neurons and possibly the architecture of the network are\\ninsufﬁcient to capture the complexity of the data',\n",
       "  'When a network fails to learn this\\nway, it is underf itting the data',\n",
       "  'An overﬁtting error is also known as variance\\nerror',\n",
       "  'A network with a high overﬁtting error is said to exhibit a high variance.\\nSimilarly, an underﬁtting error is known as bias error',\n",
       "  'A high level of underﬁtting\\nmeans a high level of bias',\n",
       "  'We can deduce from the argument above that over-\\nand underﬁtting errors are related',\n",
       "  'We reduce the overﬁtting error by reducing the\\ncapacity of the network or adding additional training examples',\n",
       "  'However, if a model\\nis underﬁtting, adding data does not help',\n",
       "  'No matter how much we reduce these two\\ntypes of error, we should understand that for real-world problems, the network can\\nnever predict with 100% accuracy, so it is a compromise of accepting a low error\\nrate rather than achieving perfection.\\nA learning curve, illustrated in Figure 3-9, is a graphical representation of the\\nrelationship between a model’s performance and a measure of experience, such as\\nthe number of training instances or iterations',\n",
       "  'It visualizes how effectively the model\\nlearns over time and highlights potential issues like overﬁtting or underﬁtting.\\nKeras and other machine learning languages have tools to measure and reduce\\ngeneralization errors, which we will discuss next',\n",
       "  'It is important to keep in mind\\nthat the overall objective of these tools and procedure is to make the best use of the\\ntraining dataset and reduce the generalization errors.\\n3.7\\nTensorBoard\\nIt is imperative that during training, we keep track of how well a model is doing.\\nFor very simple model, it may sufﬁce to include debugging statements to show the\\naverage loss per epoch',\n",
       "  'A better and more informative way to track the performance\\nof the model is to use TensorBoard.\\nTensorBoard, provided by TensorFlow, Google’s open source machine learning\\nframework, is a visualization toolkit designed for machine learning experimentation.\\nIt facilitates the inspection and understanding of machine learning workﬂows.\\nIt offers a suite of web applications that help us visualize and understand our\\nTensorFlow runs and graphs',\n",
       "  'TensorBoard is particularly useful in the training and\\nﬁne-tuning of neural networks.\\n38\\n3\\nHow Machine Learns Using Neural Network\\nFigure 3-9 The learning curve\\nSetting up and using TensorBoard is straightforward, typically involving the\\nintegration of a few lines of code within the TensorFlow training script to enable\\nlogging and visualization',\n",
       "  'It does not impose a signiﬁcant amount of performance\\npenalties, so it is a practical tool to use in many instances',\n",
       "  'I personally prefer to ﬁrst\\ndevelop and test the model and then integrate TensorBoard for detailed monitoring\\nduring actual training runs.\\nKey Features of TensorBoard\\n•\\nVisualization of Metrics: It allows us to track and visualize metrics such as loss\\nand accuracy during the training process',\n",
       "  'We can see these metrics in real time,\\nwhich helps in understanding how our model is performing and when it begins\\nto overﬁt or underﬁt.\\n•\\nGraph Visualization: TensorBoard provides a way to visualize our model archi-\\ntecture',\n",
       "  'This can help in understanding the TensorFlow graph, observing how\\ntensors ﬂow through the graph, and debugging if necessary.\\n•\\nViewing Histograms of Weights and Biases: We can see the distribution of\\nweights and biases across different layers in the network over time',\n",
       "  'This can\\ngive insights into how the network is learning.\\n•\\nProjector for Embeddings: TensorBoard includes a tool for visualizing high-\\ndimensional embeddings',\n",
       "  'This feature is particularly useful for tasks like word\\nembeddings in natural language processing.\\n3.7\\nTensorBoard\\n39\\n•\\nImage and Audio Visualization: If we are working with image or audio data,\\nTensorBoard can show actual images or play audio directly within the dashboard,\\nwhich can be useful for monitoring the outputs of our model.\\n•\\nHyperparameter Tuning: With the HParams dashboard, we can visualize hyper-\\nparameter tuning experiments with Keras Tuners (or another tuning library).\\nWe can record the hyperparameters (like learning rate, number of layers) and\\nmetrics (like loss, accuracy) and then compare different runs to see which\\nhyperparameters work best.\\n•\\nPerformance Proﬁling: TensorBoard also offers tools to proﬁle the model, help-\\ning us understand where the bottlenecks in computation are and how efﬁciently\\nour model is running.\\nTo use TensorBoard, we typically start by modifying our TensorFlow code to write\\nlog ﬁles containing the metrics, embeddings, etc., to a speciﬁed directory',\n",
       "  'Then\\nwe launch TensorBoard and point it to this log directory and visualize in the web\\nbrowser.\\nHere are some basic examples of how to use TensorBoard with a TensorFlow/\\nKeras model:\\nMetric Visualization\\nimport tensorflow as tf\\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\\nfrom tensorflow.keras.callbacks import TensorBoard\\nimport datetime\\n# Prepare dataset (example with MNIST)\\nmnist = tf.keras.datasets.mnist\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\nx_train, x_test = x_train / 255.0, x_test / 255.0\\n# Add a channels dimension\\nx_train = x_train[..., tf.newaxis]\\nx_test = x_test[..., tf.newaxis]\\n# Build the model\\nmodel = tf.keras.models.Sequential([\\nConv2D(32, 3, activation=’relu’, input_shape=(28, 28, 1)),\\nFlatten(),\\nDense(128, activation=’relu’),\\nDense(10)\\n])\\n# Compile the model\\nmodel.compile(optimizer=’adam’,\\nloss=tf.keras.losses.\\nSparseCategoricalCrossentropy(from_logits=True),\\nmetrics=[’accuracy’])\\n# Set up the TensorBoard callback\\nlog_dir = \"logs/fit/\" +\\n40\\n3\\nHow Machine Learns Using Neural Network\\ndatetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\\ntensorboard_callback = TensorBoard(log_dir=log_dir,\\nhistogram_freq=1)\\n# Train the model\\nmodel.fit(x=x_train,\\ny=y_train,\\nepochs=5,\\nvalidation_data=(x_test, y_test),\\ncallbacks=[tensorboard_callback])\\nGraph Visualization\\nThe model architecture is automatically logged by TensorBoard',\n",
       "  'We can view it in\\nthe Graphs tab.\\nHistograms of Weights and Biases\\nThe histogram freq=1 parameter in the TensorBoard callback logs the distribution\\nof weights and biases',\n",
       "  'These can be viewed in the Histograms tab in TensorBoard.\\nEmbedding Visualization\\nFor embedding visualization, we need to have an embedding layer in our model and\\nuse the TensorBoard callback with an embedding layer speciﬁed.\\n# Assuming ’model’ has an embedding layer\\ntensorboard_callback = TensorBoard(log_dir=log_dir,\\nhistogram_freq=1, embeddings_freq=1)\\nTo visualize images, we need to modify the TensorBoard callback:\\nfile_writer = tf.summary.create_file_writer(log_dir + ’/img’)\\nwith file_writer.as_default():\\ntf.summary.image(\"Training data\", x_train, step=0)\\nPerformance Proﬁling\\ntensorboard_callback = TensorBoard(log_dir=log_dir,\\nhistogram_freq=1, profile_batch=’500,520’)\\nThe HParams dashboard, a feature within TensorBoard, offers a specialized\\ninterface to visualize and analyze the results of hyperparameter tuning experiments,\\naiding in the selection of the most effective model conﬁgurations',\n",
       "  'It allows us to\\ninteractively compare the performance of different sets of hyperparameters, making\\nit easier to identify the most effective conﬁgurations for our machine learning\\nmodels.\\nTo use the HParams dashboard, we need to log hyperparameters and metrics\\nduring our model’s training process',\n",
       "  'Essentially, we need to loop through the set of\\nparameters and record the results for each run using TensorBoard as shown below:\\nfrom tensorboard.plugins.hparams import api as hp\\n3.7\\nTensorBoard\\n41\\nHP_NUM_UNITS = hp.HParam(’num_units’, hp.Discrete([16, 32]))\\nHP_DROPOUT = hp.HParam(’dropout’, hp.RealInterval(0.1, 0.2))\\nHP_OPTIMIZER = hp.HParam(’optimizer’,\\nhp.Discrete([’adam’, ’sgd’]))\\nMETRIC_ACCURACY = ’accuracy’\\nwith tf.summary.create_file_writer(\\n’logs/hparam_tuning’).as_default():\\nhp.hparams_config(\\nhparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\\nmetrics=[hp.Metric(METRIC_ACCURACY,\\ndisplay_name=’Accuracy’)],)\\ndef train_test_model(hparams, session_num):\\nmodel = tf.keras.models.Sequential([\\ntf.keras.layers.Dense(hparams[HP_NUM_UNITS],\\nactivation=’relu’),\\ntf.keras.layers.Dropout(hparams[HP_DROPOUT]),\\ntf.keras.layers.Dense(10, activation=’softmax’)])\\nmodel.compile(\\noptimizer=hparams[HP_OPTIMIZER],\\nloss=’sparse_categorical_crossentropy’,\\nmetrics=[’accuracy’],)\\n# Run with the hparams\\nmodel.fit(x_train, y_train, epochs=10) # example values\\n_, accuracy = model.evaluate(x_test, y_test)\\nreturn accuracy\\nsession_num = 0\\nfor num_units in HP_NUM_UNITS.domain.values:\\nfor dropout_rate in (HP_DROPOUT.domain.min_value,\\nHP_DROPOUT.domain.max_value):\\nfor optimizer in HP_OPTIMIZER.domain.values:\\nhparams =\\nHP_NUM_UNITS: num_units,\\nHP_DROPOUT: dropout_rate,\\nHP_OPTIMIZER: optimizer,\\nrun_name = \"run-%d\" % session_num\\nprint(’--- Starting trial: %s’ % run_name)\\nprint(h.name: hparams[h] for h in hparams)\\naccuracy = train_test_model(hparams, session_num)\\nsession_num += 1\\n# Log an hparams summary with the metrics.\\nwith tf.summary.create_file_writer(’logs/hparam_tuning/’\\n+ run_name).as_default():\\nhp.hparams(hparams) #record the values used\\ntf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\\n42\\n3\\nHow Machine Learns Using Neural Network\\nRun TensorBoard and navigate to the HParams tab, then use\\ntensorboard --logdir logs/hparam_tuning\\n',\n",
       "  'Open the browser and go to http://localhost:6006/',\n",
       "  'In the HParams dashboard, we\\ncan\\n•\\nView tables and visualizations of runs\\n•\\nFilter and sort based on hyperparameters and metrics\\n•\\nExplore parallel coordinates and scatter plot views to analyze relationships\\nbetween hyperparameters and model performance\\n3.8\\nUsing TensorBoard in Colab\\nWhen using TensorBoard within Google Colab, the procedure remains largely\\nthe same as outlined earlier',\n",
       "  'However, it’s important to enable “allow third-party\\ncookies” in the browser settings to avoid encountering a “403 Error.”\\n%tensorboard --logdir logs_directory\\nUse Colab’s ﬁle manager to locate the path of the logs and use that path for the\\nlogs_directory variable',\n",
       "  'The TensorBoard log contains enough of data for other\\nmetrics such as confusion matrix to be calculated, but we will have to search add-ins\\non the Internet.\\nNote that if we wish to view the model graph, then select the Graphs tab.\\nBy default, the model is shown inverted with data ﬂowing from bottom to top.\\nThe default graph is slightly different to the model produced by Keras’s function\\nplot_model(), but it is perhaps more intuitive than the standard view, but if we\\nneed to see the same model as Keras, then select the conceptual graph.\\nSometimes, we may run into an error with TensorBoard blocking the port 6006\\nbecause it has been occupied',\n",
       "  'If this is the case, we will need to kill the existing\\nprocess on the port',\n",
       "  'Unless we have a Colab pro subscription which gives access to\\nthe terminal app, one way to ﬁnd the correct PID to kill is to create an instance of a\\nterminal using the following commands:\\n!pip install colab-xterm\\n%load_ext colabxterm\\n%xterm\\nType lsof -i:6006 in the terminal to bring up the PID number and use the\\ndisplayed PID to kill the process with the command kill PID.\\n4\\nNetwork Layers\\nIn the context of machine learning, and more speciﬁcally in neural networks,\\n“layers” refer to various levels or stages of processing units',\n",
       "  'These layers are\\nfundamental in extracting and transforming features from input data, each serving a\\ndistinct functional purpose in the learning process',\n",
       "  'Each type of layer is designed to\\nperform a speciﬁc kind of operation on its input data',\n",
       "  'Here are some common types\\nof layers we will encounter in machine learning models.\\nThese are the most basic type of layer in neural networks, where each neuron\\nis connected to every neuron in the preceding and subsequent layers',\n",
       "  'They are\\ntypically used for learning nonspatial hierarchies of features.\\n4.1\\nDense (Fully Connected) Layers\\nA dense layer, characterized by its fully connected nature, can be versatilely used as\\nan input layer, a hidden layer, or an output layer in a neural network, depending on\\nthe speciﬁc architecture and requirements of the model',\n",
       "  'We deﬁne the dense layer\\nfor the three cases below:\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\n# Create a Sequential model\\nmodel = Sequential()\\n# Adding the input layer\\n# Assume input_dim is the size of the input features\\nmodel.add(Dense(units=64, activation=’relu’,\\ninput_dim=100))\\n© Philip Hua 2024\\nP',\n",
       "  'Hua, Neural Networks with TensorFlow and Keras,\\nhttps://doi.org/10.1007/979-8-8688-1020-6_4\\n43\\n44\\n4\\nNetwork Layers\\n# Adding a hidden layer\\nmodel.add(Dense(units=32, activation=’relu’))\\n# Adding the output layer\\n# Assuming it’s for a binary classification problem\\nmodel.add(Dense(units=1, activation=’sigmoid’))\\nIn the example above\\n•\\nNumber of Units (Neurons): The units parameter in a dense layer speciﬁes the\\nnumber of neurons',\n",
       "  'The appropriate number of units can vary depending on the\\ncomplexity of the task and is generally determined through experimentation.\\n•\\nActivation Function: ReLU is commonly used in hidden layers because it\\nhelps with the vanishing gradient problem and allows the model to learn\\ncomplex patterns',\n",
       "  'The sigmoid function in the output layer is typical for binary\\nclassiﬁcation.\\n•\\nInput Dimensions: The “input_dim” parameter is crucial for the ﬁrst layer in a\\nsequential model as it speciﬁes the shape of the input data',\n",
       "  'In most deep learning\\nframeworks, like TensorFlow/Keras and PyTorch, we generally do not explicitly\\nspecify the batch size dimension when deﬁning the input shape for layers in\\nour model, including the dense (fully connected) layers',\n",
       "  'The batch dimension\\nis typically assumed to be dynamic, allowing us to process different batch sizes\\nwithout needing to redeﬁne the model',\n",
       "  'When we deﬁne a dense layer in a Keras\\nmodel, we can use the “input_shape” parameter to specify the shape of the input\\ndata, excluding the batch size',\n",
       "  'For example:\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\nmodel = Sequential()\\nmodel.add(Dense(64, activation=’relu’,\\ninput_shape=(input_dimension,)))\\n# ..',\n",
       "  'more layers ...\\nHowever, when we are actually feeding data into the model during training or\\ninference, our data needs to have the appropriate batch dimension',\n",
       "  'This means\\nthe input data should be shaped with the batch size as the ﬁrst dimension',\n",
       "  'In the\\nexample above, note that the single input dimension above is now fed with a 2D\\ndata array with the ﬁrst dimension being the batch size.\\nimport numpy as np\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\n# Define the model\\ninput_dimension = 20\\n# Example input dimension\\nmodel = Sequential()\\n4.1\\nDense (Fully Connected) Layers\\n45\\nmodel.add(Dense(64, activation=’relu’,\\ninput_shape=(input_dimension,)))\\nmodel.add(Dense(10, activation=’softmax’))\\n# Compile the model\\nmodel.compile(optimizer=’adam’,\\nloss=’categorical_crossentropy’,\\nmetrics=[’accuracy’])\\n# Generate dummy data for demonstration\\nbatch_size = 32\\n# Example batch size\\n# Create a batch of input data\\n# (32 samples, each with 20 features)\\ninput_data = np.random.random((batch_size,\\ninput_dimension))\\n# Create corresponding dummy labels\\n# (32 samples, 10 classes for output)\\nlabels = np.random.randint(10, size=(batch_size, 1))\\nlabels = tf.keras.utils.to_categorical(labels,\\nnum_classes=10)\\n# Feed the data to the model\\nmodel.fit(input_data, labels, epochs=5,\\nbatch_size=batch_size)\\n•\\nOutput Layer Conﬁguration: The conﬁguration of the output layer depends on\\nthe speciﬁc problem (e.g., number of classes in classiﬁcation tasks)',\n",
       "  'If it is a\\nbinary classiﬁcation, the number of units equals one',\n",
       "  'For categorical outputs, the\\nnumber of units will be the number of categories.\\nIn particular, for multi-class classiﬁcation output, the activation function will be\\n“softmax.” It turns the output into a probability distribution over the classes,\\nwhere the output of each neuron corresponds to the probability that the input\\nbelongs to the respective class.\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\n# Number of output categories\\nnum_categories = 10\\n# Create a Sequential model\\nmodel = Sequential()\\n# Add hidden layers...\\n# Adding the output layer for categorical outputs\\nmodel.add(Dense(units=num_categories,\\nactivation=’softmax’))\\n46\\n4\\nNetwork Layers\\nOften, we need to add a BatchNormalization layer after the dense layer and\\nbefore the output layer, so we do not specify all the parameters for the dense\\nlayer in a single line.\\nfrom keras.layers import Dense, BatchNormalization,\\nActivation\\nmodel.add(Dense(units=64))\\nmodel.add(BatchNormalization())\\nmodel.add(Activation(’relu’))\\n4.2\\nNormalization Layers\\nThe normalization technique normalizes the inputs of each mini batch to have a\\nmean of zero and a variance of one',\n",
       "  'It is often used to stabilize and accelerate the\\ntraining of deep neural networks',\n",
       "  'Keras provides two types of normalization:\\n1',\n",
       "  'Batch Normalization: These layers apply a transformation that maintains the\\nmean output close to zero and the output standard deviation close to one.\\nThe normalization is used to reduce internal covariate shift',\n",
       "  'This refers to the\\nchange in the distribution of network activations due to the change in network\\nparameters during training which can slow down the training process since layers\\ncontinuously need to adapt to new distributions',\n",
       "  'This is why Batch Normalization\\nis typically applied after a layer, but before its activation function.\\n2',\n",
       "  'Layer Normalization is another technique used in neural networks, similar\\nin purpose to Batch Normalization but with key differences in its approach\\nand applications',\n",
       "  'It was introduced in a 2016 paper by Jimmy Lei Ba, Jamie\\nRyan Kiros, and Geoffrey Hinton titled “Layer Normalization.” Unlike Batch\\nNormalization, which normalizes across the batch dimension, Layer Normal-\\nization normalizes across the features',\n",
       "  'In other words, for a given layer, Layer\\nNormalization computes the mean and variance used for normalization from all\\nof the summed inputs to the neurons in that layer.\\nLayer Normalization does not rely on the batch dimension; it works well with\\ndifferent batch sizes and is particularly effective in tasks where the batch size\\nis small or varies',\n",
       "  'Layer Normalization can be applied similarly to Batch\\nNormalization, typically after the linear transformation and before the activation\\nfunction:\\nmodel.add(Dense(64))\\nmodel.add(LayerNormalization())\\nmodel.add(Activation(’relu’))\\n4.3\\nDropout Layers\\n47\\n4.3\\nDropout Layers\\nThe dropout layers randomly set a fraction of input units to zero at each update\\nduring training time, which helps prevent overﬁtting',\n",
       "  'The key parameter for a\\ndropout layer is the dropout rate, which speciﬁes the fraction of the input units to be\\ndropped during training',\n",
       "  'For example, rate = 0.2 means approximately 20% of the\\ninput units are set to 0 at each update during the training phase',\n",
       "  'The choice of the\\ndropout rate is crucial: a rate that is too high may lead to underﬁtting, while a rate\\nthat’s too low might not effectively prevent overﬁtting.\\nIt is commonly used in fully connected (dense) layers of a network and is\\ntypically applied to the outputs of intermediate layers, but it can be used after any\\nlayer except the input layer.\\nWhile dropout can be used in convolutional layers, it is less common',\n",
       "  'Other\\nregularization techniques, like data augmentation and batch normalization, are often\\npreferred in convolutional neural networks (CNNs).\\nDuring testing or inference, usually a dropout is not applied',\n",
       "  'The network uses\\nall its units, and the weights are scaled appropriately based on the dropout rate used\\nduring training',\n",
       "  'This scaling is typically handled automatically by frameworks like\\nKeras.\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense, Dropout\\nmodel = Sequential()\\nmodel.add(Dense(64, activation=’relu’))\\nmodel.add(Dropout(0.5))\\n# Applying 50% dropout\\nmodel.add(Dense(10, activation=’softmax’))\\n4.3.1\\nFlattening Layers\\nIf we want to use a custom output layer to classify speciﬁc categories, we will need\\nto add a ﬂatten layer to the end of the hidden layers and a custom output layer',\n",
       "  'In the\\nMNIST handwritten example, we ﬂatten the input layer explicitly using the reshape\\nmethod:\\nxTrainFlattened = xTrain.reshape(len(xTrain),784)\\nUsing a ﬂatten layer does exactly the same transformation; it simply reshapes a\\nmultidimensional vector to a 1D vector as illustrated in Figure 4-1.\\n4.3.2\\nPooling Layers\\nMaxPooling and Average Pooling are two operations commonly used in the\\ncontext of convolutional neural networks (CNNs)',\n",
       "  'They are types of pooling layers\\nthat reduce the spatial dimensions (i.e., width and height) of the input feature\\nmaps, effectively downsampling the input',\n",
       "  'This reduction helps to decrease the\\n48\\n4\\nNetwork Layers\\nFigure 4-1 Graphical\\nrepresentation of ﬂattening\\nFigure 4-2 Diagram showing MaxPooling2D with pool size=(2,2) and strides=(2,2)\\nFigure 4-3 Diagram showing AveragePooling2D with pool size=(2,2) and strides=(2,2)\\ncomputational load, control overﬁtting by providing an abstracted form of the\\nrepresentation, and improve the network’s ability to extract dominant features.\\nMaxPooling operates on each feature map independently',\n",
       "  'This process involves\\nsliding a window (of a speciﬁed size and stride) over the input and outputting the\\n4.3\\nDropout Layers\\n49\\nmaximum value within the window at each position',\n",
       "  'This process emphasizes the\\nmost pronounced features in each region of the feature map.\\nfrom keras.layers import MaxPooling2D\\nmax_pool = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))\\nRefer to Figure 4-2',\n",
       "  'In this example, pool size=(2, 2) means that the MaxPooling\\noperation is applied over 2 × 2 windows, and strides=(2, 2) means that the window\\nis moved 2 pixels across and 2 pixels down for each operation',\n",
       "  'This will effectively\\nreduce the spatial dimensions of the feature map by a factor of 2.\\nAverage Pooling also operates on each feature map independently',\n",
       "  'Similar to\\nMaxPooling, it uses a window of a speciﬁed size and stride, but instead of taking\\nthe maximum value, it computes the average of the values in the window as shown\\nin Figure 4-3.\\nfrom keras.layers import AveragePooling2D\\n# Example of an AveragePooling layer in Keras\\naverage_pool = AveragePooling2D(pool_size=(2, 2),\\nstrides=(2, 2))\\nHere, the term “pool size=(2, 2)” indicates that the Average Pooling is applied over\\n2 × 2 windows, and strides=(2, 2) moves the window 2 pixels over and 2 pixels\\ndown',\n",
       "  'This reduces the spatial dimensions like MaxPooling, but it averages the\\nvalues instead of taking the maximum.\\nMaxPooling is more commonly used because it generally performs better,\\nfocusing on the most salient features',\n",
       "  'It’s especially effective in scenarios where\\nthe background of the input data is relatively uniform or less important.\\nAverage Pooling can be more beneﬁcial when we need to preserve background\\ninformation or when the importance is more uniformly distributed across the feature\\nmap.\\nBoth types of pooling help to make the representation approximately invariant\\nto small translations, a desirable property in many vision tasks',\n",
       "  'The choice\\nbetween them often depends on the speciﬁc requirements of the task and empirical\\nperformance.\\n4.3.3\\nConvolutional Layers\\nWe will almost certainly encounter convolutional layers when dealing with image\\nprocessing as they are used extensively for upsampling and downsampling images.\\nConvolutional layers are the core building blocks of CNNs',\n",
       "  'They perform a\\nmathematical operation called convolution, which involves sliding a ﬁlter (or kernel)\\nover the input data (like an image)',\n",
       "  'As the ﬁlter moves across the input, it performs\\nelement-wise multiplication with the part of the input it covers and sums up these\\nproducts to produce a feature map',\n",
       "  'This process extracts important features from the\\ninput, such as edges, textures, or speciﬁc shapes.\\n50\\n4\\nNetwork Layers\\nFigure 4-4 Convolving a 3 × 3 kernel over a 4 × 4 input using unit strides with no padding\\n[1, p',\n",
       "  '68]\\nRefer to Figure 4-4',\n",
       "  'In this example, the 3 × 3 kernel is shown in dark blue.\\nWith a unit stride, the model takes the values from the input image shown in dark\\nblue and performs mathematical convolution with the kernel',\n",
       "  'At each position, an\\nelement-wise multiplication is performed between the values in the kernel and the\\ncorresponding values in the image it covers',\n",
       "  'The results of these multiplications\\nare then summed up to get a single number',\n",
       "  'This sum is the output for the current\\nposition of the kernel',\n",
       "  'The operation results in an output of size (2,2) shown in\\ngreen.\\nThe weights of the kernels are learned during the training process',\n",
       "  'The network\\nadjusts these weights to minimize the difference between its predictions and the\\nactual data.\\nStride refers to the number of units the ﬁlter moves across the input matrix',\n",
       "  'With\\na stride of one, the ﬁlter moves one unit at a time',\n",
       "  'This results in a detailed feature\\nmap, capturing more information',\n",
       "  'With a stride of two, the ﬁlter moves two units\\neach time',\n",
       "  'This leads to a smaller feature map as it skips over more of the input.\\nStrides greater than one are used for downsampling the input.\\nPadding for a convolutional layer is the process of adding extra pixels around\\nthe edge of the input',\n",
       "  'The most common types of padding are padding=“valid” (no\\npadding) and padding=“same”.\\nWith no padding (valid padding), the size of the feature map is reduced as the\\nﬁlter cannot move beyond the edge of the input',\n",
       "  'padding=“same” padding adds\\nzeros around the input so that the output feature map has the same dimensions as\\nthe input',\n",
       "  'Refer to Figure 4-5',\n",
       "  'In this example, we introduce padding to enlarge the\\nsize of the 5 × 5 input in blue to an output size of 6 × 6 shown in green.\\nDeclaring a convolutional layer in Keras is straightforward',\n",
       "  'The convolutional\\nlayer we will most commonly encounter is the Conv2D layer, which is typically\\nused for processing images.\\nfrom keras.layers import Conv2D\\nconv_layer = Conv2D(filters, kernel_size, strides=(1, 1),\\npadding=’valid’, activation=’relu’, input_shape)\\nFilters The number of ﬁlters (kernels) in the convolutional layer',\n",
       "  'Each ﬁlter\\nextracts different features from the input',\n",
       "  'In our previous example, we use a single\\n4.3\\nDropout Layers\\n51\\nFigure 4-5 Convolving a 4 × 4 kernel over a 5 × 5 input padded with a 2 × 2 border of zeros\\nusing unit strides [1, p',\n",
       "  '14]\\nﬁlter, but there is no reason for that',\n",
       "  'Multiple ﬁlters are often use in many cases on\\nthe image.\\nKernel Size The size of the ﬁlter',\n",
       "  'Common choices include (3, 3) or (5, 5)',\n",
       "  'This\\nparameter can be an integer in which case a square kernel is implied or a tuple of\\ntwo integers to explicitly specify the x and y ﬁlter dimension.\\n4.3.4\\nCNN As an Input Layer\\nWhen used as an input layer in a neural network, the ﬁrst convolutional layer\\ntypically processes the raw input data.\\nThis layer must be conﬁgured with the shape of the input data (e.g., image\\ndimensions and color channels), for example, an input shape of (28, 28, 1) for\\ngrayscale images of size 28 × 28 pixels or (224, 224, 3) for color images of size\\n224 × 224 pixels with three color channels (RGB)',\n",
       "  'Note that the arrangement of\\ndimensions for an RGB image can be speciﬁed in Keras using channel_ﬁrst or\\nchannel_last format so that a (224, 224, 3) image is still valid as a (3, 224, 224)\\ntensor if the parameter data_format= “channel_ﬁrst” is speciﬁed',\n",
       "  'If a grayscale\\nimage is used, then the number of channels is one instead of three',\n",
       "  'An example\\nof using the CNN as the ﬁrst layer with the channel_ﬁrst option is shown below:\\nfrom keras.models import Sequential\\nfrom keras.layers import Conv2D\\nmodel = Sequential()\\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation=’relu’,\\ninput_shape=(1, 28, 28), data_format=’channels_first’))\\nThe pixels in an RGB image is usually normalized to tensor with a range of [0,1]\\nor [–1,1] before feeding into a CNN input layer',\n",
       "  'If the original pixel values are in\\n52\\n4\\nNetwork Layers\\nthe range of [0,255], one common approach is to scale these values down to a range\\nbetween 0 and 1 by dividing all pixel values by 255, for example:\\nnormalized image = image\\n255.0\\nAnother common technique involves subtracting the mean and dividing by the stan-\\ndard deviation of the pixel values, either globally or per channel',\n",
       "  'This standardizes\\nthe pixel values to have a mean of zero and a standard deviation of one by subtracting\\nthe mean and dividing by the standard deviation:\\nnormalized image = (image −mean)\\nσ\\nThe mean and standard deviation can be computed over the entire dataset.\\nIf we are using a pretrained model, it is important to normalize the images in\\nthe same way the model was originally trained',\n",
       "  'For example, models trained on\\nthe ImageNet dataset often use speciﬁc mean and standard deviation values for\\nnormalization',\n",
       "  'If unnormalized images are fed into a pretrained model, bizarre\\nresults can be seen with color shifts or patches of wrong colors appearing in the\\noutput.\\nNormalizing the input values helps accelerate training and improve performance\\nby stabilizing the distribution of values within the network.\\n4.3.5\\nMultiple CNN Layers\\nAlthough we have shown a single CNN layer for illustration, in practice a series of\\nCNN layers of different kernel sizes, strides, padding, etc., are used to upsample\\nand downsample an image',\n",
       "  'Instead of using the image at its original size, the\\nimage is ﬁrst “upsampled” via the use of nearest neighbor, bilinear interpolation,\\nor transposed convolution to increase the effective resolution of the image',\n",
       "  'Toward\\nthe end of the CNN layer chain, the upsampled image is then downsampled to the\\noutput size.\\nThe initial layers of a CNN typically learn to recognize simple patterns, like\\nedges and basic textures',\n",
       "  'As we progress deeper into the network, later layers learn\\nto recognize more complex features, like shapes or speciﬁc objects, by combining\\nthe simpler features extracted in earlier layers',\n",
       "  'This is why when we select a layer to\\nuse in a pretrained network, such as VGG-16, as shown in Figure 4-6, we can choose\\nto use a layer in an earlier layer such as “conv2_1” or a deeper block to extract more\\nabstract feature such as “conv4_3.” One common problem with using CNN layers is\\nthe “checkerboard” issue, often referred to as “checkerboard artifacts, particularly in\\ntasks involving image generation like autoencoders, generative adversarial networks\\n(GANs), and super-resolution',\n",
       "  'These artifacts manifest as a checkerboard pattern\\nin the generated images as shown in Figure 4-7',\n",
       "  'The issue primarily arises due\\n4.3\\nDropout Layers\\n53\\nFigure 4-6 VGG-16 network block diagram [2, p',\n",
       "  '3]\\nFigure 4-7 Examples of checkerboard artifacts from a CNN layer [3]\\nto the use of strided convolutions or transposed convolutions (sometimes called\\ndeconvolutions) for upsampling.\\nThe checkerboard problem is caused when using strided or transposed convolu-\\ntions for upsampling; the overlap in the convolution operation can be uneven',\n",
       "  'This\\nuneven overlap can lead to certain pixels being updated more frequently than others,\\ncreating a visible grid-like pattern in the output.\\n54\\n4\\nNetwork Layers\\nThe solution to this is to use a different non-overlapping stride sizes, change the\\nkernel size, or alternative upsampling techniques',\n",
       "  'Often, we will ﬁnd the researcher\\nadding a convolutional layer to smear out the checkerboard effect with bilinear\\ninterpolation.\\nThe GAN project included in this book also suffers from this problem, and the\\nsolution was to generate a more diverse set of data, including augmented cartoon\\nimages and longer training time.\\n4.3.6\\nEmbedding Layers\\nAn embedding layer is a specialized layer in neural networks, used primarily in the\\nﬁeld of natural language processing (NLP), but also applicable in other areas where\\ndata can be converted into discrete tokens',\n",
       "  'For example, the BachBot application in\\nthis book uses an embedding layer.\\nThe main function of an embedding layer is to convert these tokens (like words\\nin text) into dense vectors of ﬁxed size, which are more meaningful and suitable\\nfor performing various machine learning tasks, although in the case of BachBot,\\nembedding the input did not produce a signiﬁcant improvement in the results.\\nIn text processing, words or phrases are typically represented as discrete tokens\\nor integers',\n",
       "  'Each unique word in our vocabulary is assigned a unique integer ID.\\nThe embedding layer transforms these integer tokens into dense vectors of a\\nspeciﬁed size',\n",
       "  'This size is a hyperparameter (that is chosen by us) and represents\\nthe dimensions of the embedding space.\\nUnlike one-hot encoded vectors which are high-dimensional and sparse, embed-\\nding vectors are low-dimensional and dense, containing real-valued numbers.\\nThe vectors obtained from an embedding layer capture more information about\\nwords, including semantic meaning and contextual relationships',\n",
       "  'During training,\\nthese vectors are learned and adjusted to reduce the model’s prediction error, making\\nthe embeddings contextual to the speciﬁc task.\\nOften, pretrained word embeddings, such as Word2Vec and Glove, are used in\\nthe embedding layer',\n",
       "  'These embeddings are trained on large datasets and capture a\\nvast amount of semantic information.\\nHere is a simple example of how to use an embedding layer in Keras:\\nfrom keras.models import Sequential\\nfrom keras.layers import Embedding\\nmodel = Sequential()\\nmodel.add(Embedding(input_dim=vocab_size,\\noutput_dim=embedding_dim, input_length=max_length))\\n4.3\\nDropout Layers\\n55\\n4.3.7\\nResidual Layers\\nThe key idea behind residual layers is the introduction of skip connections, also\\ncalled shortcut connections or residual connections',\n",
       "  'These connections allow the\\ninput to a layer or a set of layers to be added to its output',\n",
       "  'This is typically done by\\nadding the output of a convolutional block to its input so that the output of the block\\nis the sum of the two',\n",
       "  'For instance, in a basic residual block, if the input is x and\\nthe output of the convolutional layers is F(x), the ﬁnal output of the block will be\\nF(x) + x.\\nThese skip connections help in easing the ﬂow of gradients during backpropaga-\\ntion because they provide an alternative pathway for the gradient',\n",
       "  'This architecture\\nalleviates the vanishing gradient problem and allows for training much deeper\\nnetworks.\\nThe skip connections often perform identity mapping, where the input is passed\\nthrough unchanged to the output',\n",
       "  'When the input and output dimensions differ, a\\nlinear projection might be applied to match the dimensions.\\nfrom keras.layers import Input, Conv2D,\\nBatchNormalization, Add\\nfrom keras.models import Model\\n# Input tensor\\ninput_tensor = Input(shape=(256, 256, 3))\\n# First convolutional layer\\nconv1 = Conv2D(64, (3, 3), activation=’relu’,\\npadding=’same’)(input_tensor)\\nconv1 = BatchNormalization()(conv1)\\n# Second convolutional layer\\nconv2 = Conv2D(64, (3, 3), activation=’relu’,\\npadding=’same’)(conv1)\\nconv2 = BatchNormalization()(conv2)\\n# Skip Connection (identity mapping)\\nskip_connection = Add()([conv2, input_tensor])\\n# Creating the model\\nmodel = Model(inputs=input_tensor,\\noutputs=skip_connection)\\n4.3.8\\nRecurrent Layers\\nAn RNN layer is designed to deal with sequential and temporal problems, such\\nas language translation, natural language processing (NLP), music generation, and\\nimage captioning.\\nLet’s take an idiom, such as “Easier said than done,” which is taken to mean\\nnot as easy as it appears to be',\n",
       "  'In order for the idiom to make sense, it needs to be\\n56\\n4\\nNetwork Layers\\nexpressed in that speciﬁc order',\n",
       "  'As a result, recurrent networks need to account for\\nthe position of each word in the idiom and use that information to predict the next\\nword in the sequence.\\nA recurrent layer is a sweeping term referring to a group of specialized layers in\\nKeras',\n",
       "  'There are too many variants to describe in detail here, so it is best to refer\\nto the Keras manual for more speciﬁc details, but here is a brief description of what\\neach type is used for:\\n1',\n",
       "  'LSTM Layer: Ideal for capturing long-term dependencies in sequential data.\\nCommonly used in time series forecasting, natural language processing, and\\nsequence prediction tasks',\n",
       "  'The BachBot project implementation in this book uses\\nLSTM layers to capture music sequences.\\n2',\n",
       "  'GRU Layer: Similar to LSTM, but with a simpler architecture',\n",
       "  'Used for tasks\\nlike text generation, speech recognition, and time series analysis',\n",
       "  'Requires fewer\\nparameters than LSTM, making it more efﬁcient while still capturing long-term\\ndependencies effectively.\\n3',\n",
       "  'SimpleRNN Layer: The most basic form of RNN, suitable for sequences where\\nshort-term context is sufﬁcient',\n",
       "  'Useful in simpler sequence tasks.\\n4',\n",
       "  'TimeDistributed Layer: Applies a speciﬁed layer to each time step of a sequence\\nindependently',\n",
       "  'Commonly used with CNN layers in sequence-to-sequence tasks,\\nlike video processing or time series classiﬁcation.\\n5',\n",
       "  'Bidirectional Layer: Wraps around another RNN layer (like LSTM or GRU) to\\nprocess the sequence in both forward and backward directions',\n",
       "  'Widely used in\\nNLP tasks like sentiment analysis and machine translation.\\n6',\n",
       "  'ConvLSTM1D, ConvLSTM2D, ConvLSTM3D: Used for a sequence of images\\nor videos.\\nA distinguishing characteristic of recurrent networks is that they share parame-\\nters across each layer of the network',\n",
       "  'While feedforward networks have different\\nweights across each node, recurrent neural networks share the same weight param-\\neter within each layer of the network',\n",
       "  'These weights are still adjusted in through\\nthe processes of backpropagation through time and gradient descent to facilitate\\nlearning.\\nThe backpropagation through time (BPTT) algorithm is slightly different from\\ntraditional backpropagation as it is speciﬁc to sequence data',\n",
       "  'The principles of\\nBPTT are the same as traditional backpropagation, where the model trains itself\\nby calculating errors from its output layer to its input layer',\n",
       "  'BPTT differs from\\nthe traditional approach in that BPTT sums errors at each time step, whereas\\nfeedforward networks do not need to sum errors as they do not share parameters\\nacross each layer.\\nThrough this process, RNNs tend to run into two problems, known as exploding\\ngradients and vanishing gradients',\n",
       "  'These issues are deﬁned by the size of the\\ngradient, which is the slope of the loss function along the error curve',\n",
       "  'When the\\ngradient is too small, it continues to become smaller, updating the weight parameters\\nuntil they become insigniﬁcant—that is, zero',\n",
       "  'When that occurs, the algorithm is no\\n4.3\\nDropout Layers\\n57\\nlonger learning',\n",
       "  'Exploding gradients occur when the gradient is too large, creating\\nan unstable model',\n",
       "  'In this case, the model weights will grow too large, and they\\nwill eventually be represented as NaN',\n",
       "  'One solution to these issues is to reduce\\nthe number of hidden layers within the neural network, eliminating some of the\\ncomplexity of the RNN model.\\nWe will look at an example of an LSTM layer:\\nfrom keras.models import Sequential\\nfrom keras.layers import LSTM\\n# Define the model\\nmodel = Sequential()\\n# Add an LSTM layer\\n# ’units’ refers to the number of neurons\\n# in the LSTM layer\\n# ’input_shape’ should match the shape of our\\n# training data\\nmodel.add(LSTM(units=50, activation=’tanh’,\\nrecurrent_activation=’sigmoid’,\\ninput_shape=(time steps, features)))\\n# model.add(Dense(1))\\n# Example for a regression problem\\nIt is important to understand what the parameters mean as they can be rather\\nconfusing with RNN',\n",
       "  'Refer to Figure 4-8',\n",
       "  'The subscript t1, t, t +1 refers to the time\\nstep',\n",
       "  'The Xt−1, Xt, Xt+1 are the input tensors at each time step; yt−1, yt, yt+1 are\\nthe outputs',\n",
       "  'The ht−1, ht, ht+1 are the outputs of the hidden states which are used\\nin conjunction with the inputs Xs to get Ys',\n",
       "  'The W is the common weight tensor of\\nthe hidden states.\\nEach hidden state hi has a number of units of hidden cells, four in this case, and\\nthis is the hyperparameter units needed for deﬁning the LSTM layer.\\nFigure 4-8 An RNN-LSTM network\\n58\\n4\\nNetwork Layers\\nFigure 4-9 The block diagram of an LSTM cell\\nThere are two activation functions speciﬁed in the example, activation=’tanh’ and\\nrecurrent_activation=’sigmoid’',\n",
       "  'Unfortunately (because it is complex) to understand\\nthese terms, we need to examine the conﬁguration of an LSTM unit.\\nRefer to Figure 4-9',\n",
       "  'The hidden state ht is referred to as the actual output of the\\nLSTM cell for each time step',\n",
       "  'It is derived from the cell state but is not the same as\\nthe cell state',\n",
       "  'The hidden state is calculated using the cell state and the output of the\\noutput gate',\n",
       "  'It’s typically passed to subsequent layers in the network or used as the\\nﬁnal output in sequence processing tasks.\\nThe cell state ct is the internal memory of the LSTM cell',\n",
       "  'It carries information\\nacross time steps and is updated at each time step based on the previous cell state,\\nthe current input, and the outputs of the forget and input gates',\n",
       "  'The cell state is used\\nas an internal mechanism that allows the LSTM to maintain a memory over time, so\\nwe do not refer to it as an output of the LSTM cell.\\nAt each time step, the LSTM cell takes the previous cell state ct−1 and the\\nprevious hidden state ht−1, along with the current input xt, to calculate the new\\ncell state ct and the new hidden state ht',\n",
       "  'The new hidden state ht is then propagated\\nforward in two directions: horizontally to the next time step t + 1 in the sequence\\nand vertically to the next layer if the LSTM is part of a stacked LSTM architecture.\\nNotice that there are two activation functions for an LSTM cell, and these are the\\nparameters required when setting up an LSTM layer in Keras.\\n4.3.9\\nActivation Function\\nThis parameter refers to the activation function used for the LSTM cell’s output',\n",
       "  'The\\nactivation function is applied to the cell state before it is outputted',\n",
       "  'This is akin to\\nthe activation function in a traditional feedforward neural network layer',\n",
       "  'Common\\n4.3\\nDropout Layers\\n59\\nchoices for the activation function are nonlinear functions, like tanh or ReLU',\n",
       "  'tanh\\nis the most common choice in LSTMs, as it outputs values in a range between –1\\nand 1, which is useful for normalizing the output of the LSTM.\\n4.3.10 Recurrent Activation\\nThe recurrent_activation argument applies to the input, forget, and output gates.\\nThe recurrent activation function is used to calculate the state of these gates and\\nthus regulates the ﬂow of information through the cell.\\nThe common choice for the recurrent activation function is the sigmoid function.\\nThe sigmoid function outputs values between zero and one, making it suitable for\\ngating purposes (like deciding how much of the previous state to keep or how much\\nof the new state to write).\\nThe parameters b, V, W are respectively biases, input weights, and recurrent\\nweights',\n",
       "  'In the LSTM architecture, the forget gate uses the output of the previous\\nhidden state cell to control the cell state Ct to remove irrelevant information',\n",
       "  'On the\\nother hand, the input gate and input unit add new information to Ct from the current\\ninput.\\n4.3.11 Other Layers\\nThere are other types of specialized layers which are out of scope for this book',\n",
       "  'In\\nparticular, the attention layer is used extensively for large language models (LLMs).\\nThese layers allow the model to focus on speciﬁc parts of the input sequentially,\\nrather than using the entire input at once',\n",
       "  'They are a key component in transformer\\nmodels, which are used in various NLP tasks.\\n5\\nThe Training Process\\nAs much as we would like to throw the data into a machine learning model and\\nget instant insights into the data, this is not the way it will work',\n",
       "  'In most cases, the\\ndata have to be scrubbed, transformed into model-readable format, and augmented.\\nIn addition, we also need to select and design an appropriate machine learning\\nalgorithm for the task.\\nData preprocessing is a relatively standard procedure in most cases',\n",
       "  'Selecting the\\nright algorithm can be overwhelming, particularly when the model neural network\\nnames are highly complex',\n",
       "  'For example, we will show examples of convoluted,\\nrecurrent, long short-term memory, and generative adversarial neural networks in\\nthis book',\n",
       "  'The naming convention, although confusing at ﬁrst, will be helpful as a\\nmemory aid once we have understood the intended functionalities as the name often\\nrefers to the topology of the network itself',\n",
       "  'Refer to Figure 5-1',\n",
       "  'The diagram shows a\\ntypical end-to-end machine learning process',\n",
       "  'The data loading and productionizing\\nof the model stages are the same as for other IT projects, although we will discuss\\nsome data types in Python which would make the data loading easier for machine\\nlearning',\n",
       "  'The middle three stages are speciﬁc to machine learning, which we will\\ndiscuss in detail below.\\n5.1\\nData Loading\\nIn a commercial environment, it is most likely that the data for the project would\\nbe stored in a relational database and would require coding using SQL for retrieval.\\nFor learning and smaller datasets stored in a CSV ﬁle or online via a URL, we can\\nuse NumPy or Pandas to read the data in directly.\\n© Philip Hua 2024\\nP',\n",
       "  'Hua, Neural Networks with TensorFlow and Keras,\\nhttps://doi.org/10.1007/979-8-8688-1020-6_5\\n63\\n64\\n5\\nThe Training Process\\nFigure 5-1 End-to-end machine learning process\\nFor this demonstration, the COVID-19 database from Kaggle will be used',\n",
       "  'The\\nCOVID-19 database can be downloaded from Kaggle using the URL to the current\\nlocal directory:\\nhttps://www.kaggle.com/datasets/meirnizri/covid19-dataset\\nThe dataset is approximately 5MB in size, in CSV format, making it manageable\\nfor processing',\n",
       "  'We will be using this dataset as a project later on, so we would just\\nbe loading it for now.\\nUsing Pandas to load data into a pandas.DataFrame is probably the most ﬂexible\\nway, allowing us to summarize the data immediately',\n",
       "  'If using Google Colab, upload\\nthe ﬁle by dragging it into a Colab directory',\n",
       "  'As an example, use the procedure\\nbelow to upload the ﬁle /content/sample_data/Covid Data.csv to Colab.\\nThe ﬁrst line in the ﬁle contains the column headings, so we assign\\ndata.columns = iloc[0]; otherwise, we would have to assign the column\\nnames explicitly as\\npandas.DataFrame(data,columns=[’USMER’,’MEDICAL_UNIT’,...]\\nimport pandas\\nfilename = \"/content/sample_data/Covid Data.csv\"\\ndata = pandas.read_csv(filename)\\npandas.columns = data.iloc[0] # use the first row as names\\ndata = data[1:]\\nprint(data.shape)\\nprint(data.head(5))\\n(1048574, 21)\\nUSMER\\nMEDICAL_UNIT\\nSEX\\nPATIENT_TYPE\\nDATE_DIED ...\\n1\\n2\\n1\\n2\\n1\\n03/06/2020\\n...\\n2\\n2\\n1\\n2\\n2\\n09/06/2020\\n...\\n3\\n2\\n1\\n1\\n1\\n12/06/2020\\n...\\n4\\n2\\n1\\n2\\n1\\n21/06/2020\\n...\\n5\\n2\\n1\\n1\\n2\\n9999-99-99\\n...\\nAGE\\nPREGNANT\\nDIABETES\\n...\\nASTHMA\\nINMSUPR\\n5.1\\nData Loading\\n65\\n1\\n72\\n97\\n2\\n...\\n2\\n2 ...\\n2\\n55\\n97\\n1\\n...\\n2\\n2 ...\\n3\\n53\\n2\\n2\\n...\\n2\\n2 ...\\n4\\n68\\n97\\n1\\n...\\n2\\n2 ...\\n5\\n40\\n2\\n2\\n...\\n2\\n2 ...\\nCARDIOVASCULAR\\nOBESITY\\nRENAL_CHRONIC\\nTOBACCO ...\\n1\\n2\\n1\\n1\\n2\\n...\\n2\\n2\\n2\\n2\\n2\\n...\\n3\\n2\\n2\\n2\\n2\\n...\\n4\\n2\\n2\\n2\\n2\\n...\\n5\\n2\\n2\\n2\\n2\\n...\\n[5 rows x 21 columns]\\ndata.describe()\\nUSMER\\nMEDICAL_UNIT\\nSEX\\nPATIENT_TYPE ...\\ncount\\n77064.000000\\n77064.000000\\n77064.000000 ...\\nmean\\n1.486271\\n3.740956\\n1.567243 ...\\nstd\\n0.499815\\n0.456079\\n0.495461 ...\\nmin\\n1.000000\\n1.000000\\n1.000000 ...\\n25%\\n1.000000\\n3.000000\\n1.000000 ...\\n50%\\n1.000000\\n4.000000\\n2.000000 ...\\n75%\\n2.000000\\n4.000000\\n2.000000 ...\\nmax\\n2.000000\\n4.000000\\n2.000000 ...\\nPandas has several useful functions to give a high-level view of the data.\\ndata.describe() gives the overall statistics for the data',\n",
       "  'It is not particularly\\nuseful in this case since the data is mostly categorical but would prove beneﬁcial\\nfor other numerical datasets',\n",
       "  'data.info() tells us if the columns have null values.\\n<class ’pandas.core.frame.DataFrame’>\\nRangeIndex: 77064 entries, 1 to 77064\\nData columns (total 21 columns):\\n#\\nColumn\\nNon-Null Count\\nDtype\\n---\\n------\\n--------------\\n-----\\n0\\nUSMER\\n77064 non-null\\nint64\\n1\\nMEDICAL_UNIT\\n77064 non-null\\nint64\\n2\\nSEX\\n77064 non-null\\nint64\\n3\\nPATIENT_TYPE\\n77064 non-null\\nint64\\n4\\nDATE_DIED\\n77064 non-null\\nobject\\n5\\nINTUBED\\n77064 non-null\\nint64\\n6\\nPNEUMONIA\\n77064 non-null\\nint64\\n7\\nAGE\\n77064 non-null\\nint64\\n8\\nPREGNANT\\n77064 non-null\\nint64\\n9\\nDIABETES\\n77064 non-null\\nint64\\n10\\nCOPD\\n77064 non-null\\nint64\\n11\\nASTHMA\\n77064 non-null\\nint64\\n12\\nINMSUPR\\n77064 non-null\\nint64\\n13\\nHIPERTENSION\\n77064 non-null\\nint64\\n14\\nOTHER_DISEASE\\n77064 non-null\\nint64\\n15\\nCARDIOVASCULAR\\n77064 non-null\\nint64\\n16\\nOBESITY\\n77063 non-null\\nfloat64\\n17\\nRENAL_CHRONIC\\n77063 non-null\\nfloat64\\n66\\n5\\nThe Training Process\\n18\\nTOBACCO\\n77063 non-null\\nfloat64\\n19\\nCLASIFFICATION_FINAL\\n77063 non-null\\nfloat64\\n20\\nICU\\n77063 non-null\\nfloat64\\ndtypes: float64(5), int64(15), object(1)\\nmemory usage: 12.3+ MB\\nNone\\nWe can see from the summary that columns 16 to 20 have missing data',\n",
       "  'A\\nmore accurate way to count the total number of missing data is by using\\ndata.isnull().sum().sum()',\n",
       "  'This returns ﬁve missing data points as expected.\\nOnce we know there are null values, we can use\\nnullValues = data[data[’OBESITY’].isnull()]\\nto return the rows with missing values for a particular column',\n",
       "  'The isnull()\\nfunction works for NaN data as well, so there is no need to use isna() separately.\\nIt is possible to use a pandas DataFrame anywhere a NumPy array is used if we\\nhave a data type of real or integer',\n",
       "  'This works because the pandas.DataFrame class\\nsupports the __array__ protocol, and TensorFlow’s tf.convert_to_tensor\\nfunction accepts objects that support the protocol',\n",
       "  'Alternatively, we can convert the\\ndataframe directly to NumPy array or tensor using the following commands:\\nnumpy.array(data)\\nor\\ntf.convert_to_tensor(data)\\nIn many cases, we need to transform or rescale the input data before using the model.\\nThis is normally done by adding column(s) to the original dataset using\\nDataFrame.insert(loc=location, column=\"column name\")\\nand applying the necessary logic to create the new data',\n",
       "  'For example, in the COVID-\\n19 dataset, we may want to create a column to specify if the patient has existing\\nmedical conditions as\\ndata.insert(column=\"PreExisting Condition\")\\nLoading the data via a URL is also straightforward using Pandas, and the code is\\nthe same except that instead of passing the path of the local ﬁle, we would pass the\\nURL to the read_csv() method',\n",
       "  'As before though, if we use Colab, then the ﬁle\\nneeds to be uploaded onto Google Drive before it can be read.\\n5.1.1\\nLoading Images\\nIn image classiﬁcation tasks, it’s common to train models using hundreds of\\nthousands of images with convolutional neural networks',\n",
       "  'Fortunately, Keras offers\\nseveral utilities to streamline the process of image loading and preprocessing',\n",
       "  'If the\\ndirectory structure is\\nmain_directory\\n\\\\ class a\\n5.2\\nData Processing\\n67\\nimage 1.jpg\\nimage 2.jpg\\n\\\\ class b\\nimage 3.jpg\\nimage 4.jpg\\n...\\nthen calling tf.keras.utils.image_dataset_from_directory() will gener-\\nate a dataset from the ﬁles in the subdirectories and assign automatic labels to\\neach group of images, so it will return tuples in the form of images,labels',\n",
       "  'The\\ncomplete list of parameters is explained under:\\nhttps://keras.io/api/data_loading/image/\\nMost parameters are self-explanatory; however, the following ones require further\\nexplanation:\\n•\\nLabels: There are three options',\n",
       "  '“inferred” labels are generated from the direc-\\ntory structure, for example, class a, class b, in conjunction with the param-\\neter label mode',\n",
       "  'If the label mode is int, the labels will be encoded as\\nintegers to be used with sparse_categorical_crossentropy loss func-\\ntion',\n",
       "  '“categorical” label mode means the labels will be one-hot encoded for\\ncategorical_crossentropy loss',\n",
       "  'When there are only two classes, “binary”\\nshould be used with binary_entropy loss function.\\n•\\nBatch size: A machine learning algorithm normally processes images in batches\\nand updates the neuron weights after each batch size instead of a single image.\\n•\\nValidation Split: If this is set to 1, then the subset parameter will need to be\\nspeciﬁed as below.\\n•\\nSubset: One of “training,” “validation,” or “both.” When subset=“both”, it returns\\na tuple of training and validation datasets.\\nThe Keras utility also allows the loading of individual images using\\ntf.keras.utils.load_img()',\n",
       "  'The point to note is that the utility returns a\\nPIL image instance, and this needs to be converted to a NumPy array using\\ntf.keras.utils.img_to_array as data for the input layer',\n",
       "  'This process is\\ntypically sufﬁcient in most cases',\n",
       "  'However, when working with pretrained networks,\\nadditional preprocessing may be required to ensure the images are in the correct\\nformat',\n",
       "  'Since there is no standardization for this step, it is essential to consult the\\nspeciﬁc instructions for the input layer of each pretrained network.\\n5.2\\nData Processing\\nAfter loading the data, it is necessary to prepare the data in a format that could be\\nfed into the neural network',\n",
       "  'The main objective for the data preparation is to clean\\nthe data as much as possible so that they can be passed as features into the model',\n",
       "  'In\\nsome cases, particularly when we do not have enough data for the machine to train,\\n68\\n5\\nThe Training Process\\nsome data augmentation is also necessary to improve the model’s accuracy',\n",
       "  'There\\nare many issues with data, but the common ones are dealt with below.\\n5.2.1\\nSplitting the Dataset: Training, Development, Test\\nMachine learning is an iterative process',\n",
       "  'Choosing the right model with the right set\\nof parameters at the outset is impossible, so practically we have to try out different\\nmodels and parameters and reﬁne them until our goals are achieved',\n",
       "  'When we\\napproach machine learning this way, it is standard practice to split the dataset into\\nseparate training, development, and test datasets as shown in Figure 5-2.\\nThe idea is that we use the training dataset to experiment with different models\\nand try out different parameters',\n",
       "  'The development dataset, also called the holdout or\\ncross-validation dataset, is then used to compare the generalization performance of\\ndifferent models on unseen data',\n",
       "  'We do not use the training dataset for this purpose\\nto avoid the risk of shortlisting the best overﬁtted models as discussed in the previous\\nsection',\n",
       "  'The development dataset is also used for ﬁne-tuning hyperparameters\\nof the models, such as the step size or the optimization algorithm',\n",
       "  'We do not\\nuse the training data to select model parameters as this will lead to suboptimal\\nhyperparameters, giving bias toward models that will overﬁt.\\nThe best model selected from the development set is then evaluated using the\\ntest data',\n",
       "  'If we have a smallish dataset, say less than 10,000 data points, then\\nthe split between the three training/dev/test datasets is normally in the ratio of\\n60%:20%:20%',\n",
       "  'Commercial projects with 1,000,000+ samples use much more data\\nto train and less to tune and validate, so the ratio could even be in the order of\\n99%:0.5%:0.5% or even less for the development and test data.\\nTo build a well-performing model, it is essential to train and test the data which\\ncame from the same distribution',\n",
       "  'This means, for instance, that we should be looking\\nbroadly at the same type and quality of data: clear pictures of cats taken in similar\\nsurrounding for the datasets',\n",
       "  'What we want to avoid in this example is to have the\\nmodel trained on domestic cats and evaluated on blurry pictures of lynxes',\n",
       "  'In some\\ncases, it may not be possible to have a big dataset for the model to train on',\n",
       "  'For\\nthese cases, there are tricks that we could use to augment the data, which will be\\ndiscussed in Section 5.2.6.\\n5.2.2\\nCategorical Data\\nWhen data is represented as a list of categories or ﬁnite objects, for example,\\n{apples, oranges, strawberries, bananas, grapes}, some algorithms, such as decision\\ntrees, can deal with the text directly, and there is no need for any data encoding.\\nFor many other algorithms, the data needs to be converted into a list of numerical\\nIDs',\n",
       "  'It may be sufﬁcient to assign a numeric ID to each item, for example,\\n{apples=1,oranges=2,...}',\n",
       "  'However, integer encoding may lead the algorithm to\\nimbue a spurious relationship between different categories because of numerical\\n5.2\\nData Processing\\n69\\nFigure 5-2 Splitting the data into training, development, and test datasets\\nordering',\n",
       "  'Assuming natural ordering between the numerical categories may result\\nin poor performance and/or unexpected results.\\nOne-hot encoding is a binary encoding scheme where each item in the list of\\ncategories is assigned a value of one if true and zero if not',\n",
       "  'The unique list of\\ncategories stored in the rows is translated as columns in Pandas and assigns a\\ncorresponding one and zero using the method get_dummies() as in the following\\nexample:\\nimport pandas\\ndata = pandas.DataFrame(list([’apples’,’oranges’,\\n’strawberries’,’bananas’,’grapes’]), columns = [’fruits’])\\nconverted = pandas.get_dummies(data.fruits, prefix=’onehot’)\\nprint(data)\\nprint(converted)\\nfruits\\n0\\napples\\n1\\noranges\\n2\\nstrawberries\\n3\\nbananas\\n4\\ngrapes\\nonehot_ onehot_\\nonehot_ onehot_\\nonehot_\\napples\\nbananas\\ngrapes\\noranges\\nstrawberries\\n1\\n0\\n0\\n0\\n0\\n0\\n0\\n0\\n1\\n0\\n0\\n0\\n0\\n0\\n1\\n0\\n1\\n0\\n0\\n0\\n0\\n0\\n1\\n0\\n0\\nThe term “dummy” refers to the use of a statistical dummy variable in regression\\nanalysis',\n",
       "  'In statistics, a dummy variable acts like a switch in a regression equation,\\nturning the parameter on and off by setting one or zero without the need to write\\nmultiple equations with different variables.\\n70\\n5\\nThe Training Process\\n5.2.3\\nPreprocessing Images\\nTraining a neural network to classify images normally means loading a custom\\ndataset with image ﬁles in one of JPEG, BMP, or PNG format',\n",
       "  'The pixels then\\nhave to be converted into a NumPy array or tensor of type ﬂoat and resized to match\\nthe size of the input layer of the neural network',\n",
       "  'Although not strictly necessary, the\\npixel values are normally rescaled to the range 0 to 1 or −1 to 1, which may speed\\nup the training process',\n",
       "  'As an example, we will use the VGG-16 pretrained network\\nin Keras to classify pictures of cats and dogs.\\nA number of pretrained networks are available in Keras as applications in\\ntwo parts: model architecture and weights',\n",
       "  'The model architectures are already\\ndownloaded when we installed Keras; the weights are stored in large ﬁles which\\nneed to be downloaded when we instantiate a model',\n",
       "  'The reader can read up on the\\ndifferent models in Keras on the ofﬁcial website:\\nhttps://keras.io/api/applications/\\nAs we will be using the VGG-16 network, let’s discuss some of its properties\\nwhich we need to know so that we can use it correctly.\\nThe VGG-16 network is a convoluted neural network (CNN) which is designed\\nfor image recognition',\n",
       "  'It is used for object detection and image classiﬁcation able\\nto classify 1000 different classes of objects with 92% accuracy.\\nThe list of classes can be found at\\nhttps://image-net.org/challenges/LSVRC/2014/browse-synsets\\nwhich includes classes of animals, such as cats, dogs, whales, etc.\\nThe network was trained on color images of size 224 by 224 pixels with three\\ncolor channels, so we need to convert our input images to this size',\n",
       "  'In addition to\\nadjusting the image size, we also need to use the\\nkeras.applications.preprocess_input()\\nmethod to convert the RGB colors for the input data to BGR, which is the color\\nformat used by VGG-16.\\nWe do not need to do anything to the hidden layers other than to use the pretrained\\nweights and tell the network to predict our image as one of the 1000 different classes.\\nIn Code 5-1 below, the parameter include_top=True means we are using the\\ncomplete network',\n",
       "  'It is possible just to use the pretrained network hidden layers and\\nspecify custom-sized input and output layers by setting this parameter to false',\n",
       "  'The\\npretrained network then can be repurposed and further trained on our own set of\\ndata.\\nUsing a pretrained network this way is called transfer learning',\n",
       "  'It allows the\\nmodel trained on one task to be repurposed for a related task with much quicker\\nretraining',\n",
       "  'The variable predictionLabels is a list containing triplets in the\\nformat below',\n",
       "  'The ﬁrst item is the label code, the second is the label text, and the\\nnumber is the prediction probability.\\n<class ’list’> [(’n02123045’, ’tabby’, 0.560446)|\\n5.2\\nData Processing\\n71\\nCode 5-1 Using the VGG-16 pretrained network to classify cats and dogs\\nThe network returns the list sorted by probability from high to low, so the\\nﬁrst item in the list is the highest probability',\n",
       "  'This is why we can use\\npredictionLabels[0][0][1] to get the label name for the most likely class\\nof animal.\\n72\\n5\\nThe Training Process\\nIt is quite remarkable that we are able to use a sophisticated network to predict\\npictures of cats and dogs using a single line of code',\n",
       "  'Upon reviewing the model’s\\nresults, it becomes evident that while effective, the model is not 100% perfect',\n",
       "  'Some\\nmisclassiﬁed pictures are clearly wrong to the viewer but perhaps forgivable if we\\nview at the process for what it is—the detection of similar patterns in new pictures\\nusing weights which have been trained on a group of images.\\n5.2.4\\nNormalization and Standardization\\nIt is often the case that the input variables have different scales',\n",
       "  'For example, a\\ncompany’s proﬁt in dollars could be in billions, while its proﬁt margin is expressed\\nin percentage',\n",
       "  'Input variables may also have different units, such as cm, km, or\\nmiles.\\nWhen we model a problem with input of different scales, the weights for the\\nmodel may also be large',\n",
       "  'After all, we are trying to approximate a function that ﬁt\\nthe data points',\n",
       "  'The optimizer used in the backpropagation algorithm also works\\nbetter when the scales are uniformed across the different variables',\n",
       "  'The goal of\\nnormalization is to change the values of numeric columns in the dataset to use\\n5.2\\nData Processing\\n73\\na common scale, without distorting differences in the ranges of values without\\nlosing information',\n",
       "  'Normalization and standardization are crucial steps in data\\npreprocessing, ensuring that each input feature contributes equally to the analysis.\\nTransformation can be done manually by using\\nsklearn.preprocessing\\ntransformation or standardization methods on the input column(s), or we can use\\na Normalize layer in Keras to perform rescaling for us',\n",
       "  'If we transform data, it is\\nimportant that the parameters are calculated for the training set and then used for\\nthe development and test datasets.\\nThere are several transformation methods in sklearn, but two useful methods are\\nfit_transform() and transform() for the MinMaxScaler and StandardScaler\\nclasses',\n",
       "  'StandardScaler normalizes data to a mean of 0 and a standard deviation\\nof 1, making it suitable for algorithms that assume data is centered around zero.\\nMinMaxScaler, on the other hand, scales data to a speciﬁed range, often [0, 1],\\nwhich is useful in neural network applications.\\nThe StandardScaler fit_transform() uses the following formula:\\nxtransform = x −μ\\nσ\\n(5.1)\\nwhere μ is the average value of the dataset and σ is the standard deviation, whereas\\nthe MinMaxScaler will use\\nxtransform =\\nx −xx min\\nxmax −xmin\\n(5.2)\\nFor example, we can see below that the transformed data using the standard scaler\\nhas mean zero and a unit standard deviation regardless of the original data, whereas\\nthe MinMaxScaler will scale differently and is more values dependent',\n",
       "  'However,\\nthe MinMaxScaler is useful for image processing when we want to compress the\\n[0,255] color range down to [0,1].\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom sklearn.preprocessing import StandardScaler\\nimport numpy as np\\ntrainingData = np.array([1.0,2.0,3.0,4.0,5.0,6.0])\\nscaler = StandardScaler()\\ntransformedData = scaler.fit_transform(trainingData.\\nreshape(-1,1))\\nprint(transformedData.mean())\\nprint(transformedData.std())\\nmmScaler = MinMaxScaler()\\nmmTransformed = mmScaler.fit_transform(trainingData.\\nreshape(-1,1))\\nprint(mmTransformed)\\nprint(mmTransformed.std())\\n74\\n5\\nThe Training Process\\n-3.700743415417188e-17\\n1.0\\n[[0',\n",
       "  ']\\n[0.2]\\n[0.4]\\n[0.6]\\n[0.8]\\n[1',\n",
       "  ']]\\n0.34156502553198664\\nFor convenience, Keras allows the scaler to work with Pandas DataFrame directly,\\nso it is easier to perform transformation on the data columns directly.\\nscaler = StandardScaler()\\ndfScaled = pandas.DataFrame(scaler.\\nfit_transform(data[[’AGE’]]))\\n5.2.5\\nMissing Data\\nHandling missing data is a common preprocessing challenge',\n",
       "  'Strategies include\\nremoving rows or columns with missing values or imputing these values based\\non the rest of the dataset',\n",
       "  'Missing data in columns or rows can be dealt with by\\nremoving the relevant row(s) or column(s) if they are not signiﬁcant to the whole\\ndataset, or we can look to use an algorithm in Keras/Pandas to impute missing\\nvalues.\\nIn the ﬁrst instance, we can use a dropna() method in Pandas to delete any row\\nor column in a DataFrame which has missing values',\n",
       "  'For example:\\nimport pandas as pd\\nimport numpy as np\\nmissingData = ’col1’:[1, 2,3],’col2’:[3, np.NaN,5],\\n’col3’:[6,7,np.NaN]\\ndf = pd.DataFrame(data=missingData)\\nprint(df)\\nnoMissingRow= df.dropna(axis=0)\\nprint(’No missing row’,noMissingRow)\\nnoMissingCol= df.dropna(axis=1)\\nprint(’No missing col’,noMissingCol)\\ncol1\\ncol2\\ncol3\\n0\\n1\\n3.0\\n6.0\\n1\\n2\\nNaN\\n7.0\\n2\\n3\\n5.0\\nNa\\nN\\nNo missing row col1\\ncol2\\ncol3\\n0\\n1\\n3.0\\n6.0\\nNo missing col col1\\n5.2\\nData Processing\\n75\\n0\\n1\\n1\\n2\\n2\\n3\\nPandas also has a method fillna() to ﬁll in missing data',\n",
       "  'Backﬁlling can be done\\nfor the dataframe or by rows and columns',\n",
       "  'The syntax for this method has several\\nuseful options, including ﬁlling missing data using data from the ﬁrst available data\\nbefore or after the missing column or row.\\ndataframe.fillna(value, method, axis, inplace, limit,\\ndowncast)\\nThis returns a new dataframe if the inplace parameter is false and None if it is true.\\nSome examples of fillna() are shown below:\\nimport numpy as np\\nimport pandas as pd\\ndf1 = pd.DataFrame(’Column1’: [1.0,2.0,None],\\n’Column2’: [3.0,None,5.0],\\n’Column3’: [None,6.0,7.0])\\ndf1.fillna(0)\\ndf1.fillna(value=’Column1’: 0.1,’Column2’: 0.2)\\n#original dataframe\\nprint(df1,’original dataframe’)\\n# forward fill using available number in the previous row\\ndff = df1.fillna(method=’ffill’,axis=’rows’)\\nprint(dff,’forward fill’)\\n# backward fill using available number in the row after\\ndfb= df1.fillna(method=’bfill’,axis=’rows’)\\nprint(dfb,’backward fill’)\\nColumn1\\nColumn2\\nColumn3\\n0\\n1.0\\n3.0\\nNaN\\n1\\n2.0\\nNaN\\n6.0\\n2\\nNaN\\n5.0\\n7.0 original dataframe\\nColumn1\\nColumn2\\nColumn3\\n0\\n1.0\\n3.0\\nNaN\\n1\\n2.0\\n3.0\\n6.0\\n2\\n2.0\\n5.0\\n7.0 forward fill\\nColumn1\\nColumn2\\nColumn3\\n0\\n1.0\\n3.0\\n6.0\\n1\\n2.0\\n5.0\\n6.0\\n2\\nNaN\\n5.0\\n7.0 backward fill\\nUsing dropna() simpliﬁes the dataset but can lead to loss of valuable information.\\nﬁllna(), while preserving data, requires careful choice of imputation strategy to\\navoid introducing bias.\\nAs well as Pandas, the scikit-learn library offers a convenient way to impute\\nvalues by calling the SimpleImpute class',\n",
       "  'One of the most common interpolation\\ntechniques is mean imputation where we simply replace the missing values in each\\ncolumn with the column’s mean or median value',\n",
       "  'The scikit-learn SimpleImputer\\n76\\n5\\nThe Training Process\\nmethod is more ﬂexible as it offers more backﬁll option and can work on nparray\\ndata type as well as a dataframe.\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.impute import SimpleImputer\\nmissingData = ’col1’:[1, 2,3,3,3,3],’col2’:[3,\\nnp.NaN,5,4,4,4],\\n’col3’:[6,7,np.NaN,8,8,8]\\ndf = pd.DataFrame(data=missingData)\\nprint(df)\\nsim = SimpleImputer(missing_values=np.nan, strategy=’mean’)\\nsimMedian = SimpleImputer(missing_values=np.nan,\\nstrategy=’median’)\\nimputedData = sim.fit_transform(df.values)\\nimputedMedian = simMedian.fit_transform(df.values)\\nprint(’imputed mean’)\\nprint(imputedData)\\nprint(’imputed median’)\\nprint(imputedMedian)\\ncol1\\ncol2\\ncol3\\n0\\n1\\n3.0\\n6.0\\n1\\n2\\nNaN\\n7.0\\n2\\n3\\n5.0\\nNaN\\n3\\n3\\n4.0\\n8.0\\n4\\n3\\n4.0\\n8.0\\n5\\n3\\n4.0\\n8.0\\nimputed mean\\n[[1.\\n3.\\n6',\n",
       "  ']\\n[2.\\n4.\\n7',\n",
       "  ']\\n[3.\\n5.\\n7.4]\\n[3.\\n4.\\n8',\n",
       "  ']\\n[3.\\n4.\\n8',\n",
       "  ']\\n[3.\\n4.\\n8',\n",
       "  ']]\\nimputed median\\n[[1',\n",
       "  '3',\n",
       "  '6.]\\n[2',\n",
       "  '4',\n",
       "  '7.]\\n[3',\n",
       "  '5',\n",
       "  '8.]\\n[3',\n",
       "  '4',\n",
       "  '8.]\\n[3',\n",
       "  '4',\n",
       "  '8.]\\n[3',\n",
       "  '4',\n",
       "  '8.]]\\n5.2.6\\nData Augmentation\\nData augmentation is a powerful technique to enhance the size and quality of\\ntraining datasets by introducing variations',\n",
       "  'This is especially important in ﬁelds\\nlike image processing, audio analysis, and natural language processing.\\nIt is useful to create more input data with transformed data using augmentation.\\nBy applying augmentation, we can increase the model’s capacity to generalize and\\n5.2\\nData Processing\\n77\\nmake better predictions',\n",
       "  'Data augmentation can be used for many applications,\\nincluding text, audio, and images',\n",
       "  'For images, we can perform geometric trans-\\nformation such as scaling, rotating, ﬂipping, cropping, kernel ﬁltering (sharpening\\nor blurring), or mixing images.\\nFor audio, we can shift tone, balance, or speed or inject noise into an audio\\ntranscript to simulate dropout',\n",
       "  'We can even use an advanced library, such as Dolby\\nnoise reduction, to remove background noises.\\nFor natural language processing, it is more difﬁcult to augment data due to the\\ngrammatical structure of the text',\n",
       "  'Augmentation can be performed at character,\\nword, or sentence level.\\nSome common techniques are used to create synthetic sentences, such as back\\ntranslation, that is, we translate an English sentence into a foreign language and\\nthen back-translate the foreign sentence into English again to hopefully generate\\na different sentence from the original one',\n",
       "  'One commonly used and effective\\ntechnique is synonym replacement via word embedding',\n",
       "  'The N-word embedding\\nalgorithm, for example, replaces N non-stopwords by pretrained synonyms.\\nSeveral libraries are available to use for this purpose, but they are divided into\\ntwo categories: for non-contextual word embedding, models such as Glove and\\nWord2Vec',\n",
       "  'The more advanced models, which use so-called transformer layers\\nfor learning contextual information, are BERT and RoBERTa from Google.\\nImplementing data augmentation in Keras is straightforward; we can either\\nuse the TensorFlow library to perform the necessary transformation, such\\nas image rotation or word embedding, and use them as extra input data, or\\nwe can use Keras preprocessing layers for data augmentation, for example,\\ntf.keras.layers.RandomCrop or tf.keras.layers.RandomRotation, and\\nmake the processing layers part of our model',\n",
       "  'Note that the data augmentation\\nshould only be active during training and not in production as we wish to supplement\\nthe input data to train the model to improve its score and not to create fake live data.\\nWe will now look at some code snippets to augment images, sound, and sen-\\ntences',\n",
       "  'In Keras, data augmentation can be easily implemented using preprocessing\\nlayers',\n",
       "  'Below is an example of how to resize and rotate images using these layers.\\nExample 1: The example below uses the Keras preprocessing layer to resize\\nand randomly rotate images of roses for the input layer before sending them to\\nthe next layer in the network',\n",
       "  'With this option, preprocessing will happen on the\\ndevice, synchronously with the rest of the model execution, so that it will maximize\\nGPU acceleration',\n",
       "  'If we are training on a GPU, this is the best option for the\\nnormalization, image preprocessing, and data augmentation layers',\n",
       "  'The second\\noption is to loop through each image and save them as new images as shown by\\nthe augment() function',\n",
       "  'An example of the output from the augment() function\\napplied to a rose image is shown in Figure 5-3.\\nimport tensorflow as tf\\nimport pathlib\\nimport matplotlib.pyplot as plt\\nimport matplotlib.image as mpimg\\nfrom PIL import Image\\nfrom keras import layers\\n78\\n5\\nThe Training Process\\nimport numpy as np\\ndef augment(oldImage):\\nimage = oldImage.copy()\\nimage = tf.image.random_crop(image, size=[128, 128, 3])\\nimage = tf.image.random_flip_left_right(image)\\nreturn image\\nimage = Image.open(\"/content/drive/MyDrive/Data/rose.jpg\")\\ntensor = np.array(image)\\nsizeScaleRotate = tf.keras.Sequential([\\nlayers.Resizing(128, 128),\\nlayers.Rescaling(1./255),\\nlayers.RandomRotation(np.pi)\\n])\\nimageAfter = sizeScaleRotate(tensor)\\nfig = plt.figure(figsize=(10, 7))\\nplt.subplot(1,3,1)\\nplt.imshow(image)\\nplt.subplot(1,3,2)\\nplt.imshow(imageAfter)\\nmodel = tf.keras.Sequential([\\n# Add the preprocessing layers\\nsizeScaleRotate,\\n# the rest of the model\\nlayers.Dense(32, activation=’relu’)\\n])\\n# augment data separately\\nimageAfter2 = augment(tensor)\\nplt.subplot(1,3,3)\\nplt.imshow(imageAfter2)\\nFigure 5-3 Original image (left), resize and rotate (middle), crop and ﬂip left-right (right)\\n5.3\\nTuning Our Network\\n79\\n5.3\\nTuning Our Network\\nThe machine learning process is highly iterative',\n",
       "  'Given that it is relatively easy\\nto code up a simple neural network in Python, it is often the case that we would\\ncode up, evaluate, and recode until our objectives are met',\n",
       "  'An important part of this\\niterative process is the ability to evaluate the current model and the knowledge to\\nimprove it if needed.\\nThere are several parameters to choose when we are designing a model, namely,\\nthe number of units, layers, choice of loss functions, optimization procedure,\\nnumber of epochs, the activation function, and the learning rate of the model.\\nThere are two types of parameters in machine learning: model and algorithm\\nhyperparameters.\\n•\\nModel Hyperparameters: These are parameters for our model, such as the number\\nof nodes and layers.\\n•\\nAlgorithm Hyperparameters: These are usually the parameters for the backprop-\\nagation algorithm, such as the learning rate.\\nSpecialized networks will include additional parameters to select, but the parameters\\nmentioned are the basic parameters in most deep neural network (DNN) models.\\nA common discussion on the network performance is the trade-off between the\\nlevel of bias and variance',\n",
       "  'This is just a technical term for the degree of overﬁtting\\n(high variance) versus underﬁtting (high bias)',\n",
       "  'As mentioned before, a high variance\\nnetwork will have a low error rate with the training dataset but a high error rate with\\nthe validation dataset because it does not generalize well',\n",
       "  'Underﬁtting or high bias\\nmeans the network is not sufﬁciently complex to deal with the problem.\\nA network with high bias and variance will have a large error both in the training\\nand validation datasets',\n",
       "  'Of course, we want a low bias, low variance network if\\npossible, but, usually, reducing the error for one means increasing the error for the\\nother, hence the commonly known “bias-variance trade-off” in machine learning.\\nIt is a fallacy to assume that a highly complex network will have high variance\\n(i.e., prone to overﬁtting)',\n",
       "  'A large language model, such as GPT-4, can have billions\\nof parameters but generalize exceptionally well when compared to lesser models.\\nWe only need to compare the answers from GPT-4 to a lesser model to know that\\nthis is true.\\nThe basic recipes for dealing with the bias-variance problem are as follows:\\n•\\nGet as much data as possible.\\n•\\nIf we have a high bias problem (underﬁt), then use a bigger network, train longer,\\nor change the architecture.\\n•\\nThe high variance problem is usually a more common and difﬁcult one to solve.\\nFor high variance error (overﬁtting with the validation dataset), then consider\\nusing regularization in our network, get more data, or change the architecture.\\nWe will use regularization in many of our examples later on in the book and\\n80\\n5\\nThe Training Process\\nwill discuss them later, but if you come across terms like ridge regression, lasso,\\ndropout, batch norm, or teacher forcing, then do not be overly concerned with\\nknowing the exact details, they are just techniques to reduce high variance error\\nand are relatively easy to implement in Keras.\\nFortunately, Keras provides a tuner library to help pick the optimal set of parameters\\nfor our model',\n",
       "  'The Keras Tuner class has four tuners available: Random Search,\\nHyperband, BayesianOptimization, and Sklearn',\n",
       "  'The Sklearn tuner is used for\\nSklearn only; if we only use Keras machine learning models, then select one of\\nthe other three tuner classes: Random Search, Hyperband, BayesianOptimization.\\nThe tuner class can tune many parameters at the same time, including the\\nselection for the number of nodes and layers',\n",
       "  'In addition, model parameters, such as\\nthe learning rate, can also be tuned',\n",
       "  'We build our model and tell the tuner to tune the\\ndeﬁned parameters',\n",
       "  'It will return the “best” model(s) to use along with a summary\\nof the results.\\nThe tuner serves an efﬁcient way to select the hyperparameters',\n",
       "  'The main\\ndisadvantage in using a tuner is the long runtime, but it is quicker than trying to do\\nit manually! Out of the three methods, Hyperband is the most efﬁcient in resource\\nallocation, and in practice, we should use either the Hyperband or the Bayesian\\nalgorithm.\\nWe can see how the tuner works by using it on our Modiﬁed National Institute\\nof Standards and Technology (UNIST) project',\n",
       "  'For convenience, the original code\\nis repeated here followed by the new code tuned by Keras.\\nfrom keras import activations\\nimport numpy as np\\nimport keras\\nimport tensorflow as tf\\nimport matplotlib.pyplot as plt\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras import activations\\nfrom keras.optimizers import Adam\\nfrom google.colab import files\\n# load mnist dataset\\n# 60,000 images for xTrain, 10,000 for xTest\\nmnist = tf.keras.datasets.mnist\\n(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\\n#convert the 28x28 input matrix to a vector of length 784\\nxTrainFlattened = xTrain.reshape(len(xTrain),784)\\nxTestFlattened = xTest.reshape(len(xTest),784)\\n#set yTrain and yTest to 1 where the digit is 8 and\\n#0 for others\\nyTrain8 = np.where(yTrain!=8,0,1)\\nyTest8 = np.where(yTest!=8,0,1)\\nprint(\"Count of yTrain = 8\",(yTrain8 == 1).sum(),\\n\" out of \",len(yTrain))\\n5.3\\nTuning Our Network\\n81\\nprint(\"Count of yTest = 8\",np.sum(yTest8 == 1),\\n\" out of \",len(yTest))\\n#create the neural network as before\\nmodel = Sequential()\\nmodel.add(Dense(784, activation=’relu’,\\ninput_shape = (784,)))\\nmodel.add(Dense(784,activation=’relu’))\\n# the sigmoid activation will show\\n#the probability of each digit\\nmodel.add(Dense(1,activation=’sigmoid’))\\nmodel.compile(optimizer=Adam(),\\nloss=’binary_crossentropy’,\\nmetrics=[’accuracy’]) # show the accuracy of prediction\\nmodel.fit(xTrainFlattened, yTrain8, epochs=5)\\nyPredict = model.predict(xTestFlattened)\\n# test the accuracy using the xTest\\nmodel.evaluate(xTestFlattened,yTest8)\\nWe will tune the code above using the Keras tuner',\n",
       "  'Before we can use it, we may\\nneed to install the tuner package using the following command on Colab or our local\\nterminal if we run the code locally on our PC:\\n!pip install keras-tuner\\nOnce the library is installed, we can deﬁne a hypermodel by two methods.\\nEither\\n•\\nCreating a model builder function and passing a hyperparameter instance as a\\nparameter to that function',\n",
       "  'The model builder function returns a compiled model\\nand uses hyperparameters we deﬁne inline to tune the model',\n",
       "  'Once we have\\ndeﬁned the search space, we can select a tuner class, such as Hyperband or\\nBayesianOptimization, to start the search.\\n•\\nSubclassing the HyperModel class of the Keras Tuner API.\\nIn addition to these two methods, we can also use the two predeﬁned HyperModel\\nclasses, HyperXception and HyperResNet, but since these are mainly used for\\ncomputer vision applications only, we will not be addressing them here.\\nAs an example of how to create a model builder function, we will use the tuner\\nto choose the number of units, the activation function, and the learning rate in our\\nUNIST application.\\nfrom keras import activations\\nimport numpy as np\\nimport keras\\nimport tensorflow as tf\\nimport matplotlib.pyplot as plt\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import Dropout\\nfrom keras import activations\\n82\\n5\\nThe Training Process\\nfrom keras.optimizers import Adam\\nfrom google.colab import files\\n#import the tuner\\nimport keras_tuner\\n# load mnist dataset\\n# 60,000 images for xTrain, 10,000 for xTest\\nmnist = tf.keras.datasets.mnist\\n(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\\nxTrainFlattened = xTrain.reshape(len(xTrain),784)\\nxTestFlattened = xTest.reshape(len(xTest),784)\\n#set yTrain and yTest to 1 where the digit is 8 and\\n#0 for others\\nyTrain8 = np.where(yTrain!=8,0,1)\\nyTest8 = np.where(yTest!=8,0,1)\\nprint(\"Count of yTrain = 8\",(yTrain8 == 1).sum(),\\n\" out of \",len(yTrain))\\nprint(\"Count of yTest = 8\",np.sum(yTest8 == 1),\\n\" out of \",len(yTest))\\n#create the neural network as before\\ndef buildModel(hp):\\nmodel = Sequential()\\nmodel.add(Dense(784, activation=’relu’,\\ninput_shape = (784,)))\\n#define the search space\\nfor i in range(hp.Int(\"num_layers\", 1, 5)):\\nmodel.add(\\nDense(\\n# Tune number of units separately.\\nunits=hp.Int(f\"layerUniti\", min_value=2^4,\\nmax_value=2^10, step=2^3),\\nactivation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),))\\nif hp.Boolean(\"dropout\"): model.add(Dropout(rate=0.25))\\n# choice of learning rates\\nlearningRate = hp.Choice(\"lr\", values=[1e-2, 1e-3, 1e-4])\\nmodel.add(Dense(1,activation=’sigmoid’))\\nmodel.compile(optimizer=Adam(learning_rate=learningRate),\\nloss=’binary_crossentropy’, metrics=[’accuracy’])\\nreturn model\\nbuildModel(keras_tuner.HyperParameters())\\ntuner = keras_tuner.Hyperband(buildModel,\\nobjective=’val_accuracy’,\\nmax_epochs=10,\\nfactor=3)\\ntuner.search_space_summary()\\ntuner.search(xTrainFlattened, yTrain8, epochs=5,\\nvalidation_data=(xTestFlattened, yTest8))\\ntuner.results_summary()\\n5.3\\nTuning Our Network\\n83\\nBest val_accuracy So Far: 0.9947999715805054\\nTotal elapsed time: 00h 30m 38s\\nResults summary\\nResults in ./untitled_project\\nShowing 10 best trials\\nTrial summary\\nHyperparameters:\\nnum_layers: 1\\nlayerUnit0: 8\\nactivation: relu\\ndropout: False\\nlr: 0.001\\nlayerUnit1: 7\\nlayerUnit2: 6\\nlayerUnit3: 7\\nlayerUnit4: 7\\ntuner/epochs: 10\\ntuner/initial_epoch: 4\\ntuner/bracket: 2\\ntuner/round: 2\\ntuner/trial_id: 0012\\nScore: 0.9947999715805054\\nTrial summary\\nHyperparameters:\\nnum_layers: 1\\nlayerUnit0: 7\\nactivation: relu\\ndropout: False\\nlr: 0.0001\\nlayerUnit1: 6\\nlayerUnit2: 8\\nlayerUnit3: 6\\nlayerUnit4: 8\\ntuner/epochs: 10\\ntuner/initial_epoch: 4\\ntuner/bracket: 2\\ntuner/round: 2\\ntuner/trial_id: 0015\\nScore: 0.992900013923645\\nTrial summary\\nHyperparameters:\\nnum_layers: 5\\nlayerUnit0: 8\\nactivation: relu\\ndropout: True\\nlr: 0.0001\\nlayerUnit1: 6\\nlayerUnit2: 6\\nlayerUnit3: 8\\nlayerUnit4: 6\\ntuner/epochs: 10\\ntuner/initial_epoch: 4\\ntuner/bracket: 1\\ntuner/round: 1\\n84\\n5\\nThe Training Process\\nThe optimizer took about 30 mins to complete all the epochs and completed its\\nsearch for the “best” hyperparameters',\n",
       "  'I have included the ﬁrst few best trials in the\\noutput above',\n",
       "  'We can either recreate our model using these parameters manually or\\nretrieve it from the optimizer and save it down.\\n5.4\\nCustomizations\\nIn this section, we delve into the various ways Keras enables the customization of\\nneural network architectures, focusing on the distinct approaches and the ﬂexibility\\neach offers for building tailored deep learning models.\\nIn Keras, there are essentially three ways to use APIs to deﬁne a neural network:\\nsequential, functional, and model subclassing',\n",
       "  'The sequential API is the easiest\\nto implement, but it is the most restrictive with each layer only connecting to the\\nsubsequent layer in a linear fashion.\\nThe functional API provides greater ﬂexibility, allowing branches of layers,\\nmultiple inputs and outputs',\n",
       "  'A model such as ResNet or Inception is easily\\nimplemented using this method',\n",
       "  'In most cases, using the functional API is all we\\nneed to implement very sophisticated networks.\\nLastly, model subclassing provides complete control over the training procedure:\\nfrom customizing transfer function, custom layers, and models to monitoring and\\nstopping the training process early using callbacks',\n",
       "  'Such ﬂexibility comes with\\nincreasing complexity in coding and the removal of some useful utilities, such as\\nprintsummary(), etc.\\n5.5\\nFunctional API\\nThe main idea of the functional API is a way to build graphs of layers',\n",
       "  'Instead of\\nthe sequential model where each layer follows the previous one in a linear fashion,\\nthe functional API can handle models with nonlinear topology, shared layers, and\\nmultiple inputs or outputs',\n",
       "  'In the functional API, models are created by specifying\\ntheir inputs and outputs in a graph of layers',\n",
       "  'That means that a single graph of layers\\ncan be used to generate multiple models',\n",
       "  'This ﬂexibility is essential when we wish\\nto implement the more advanced models, such as RNN, GAN, or CNN, in later\\nchapters.\\n5.6\\nCustom Models\\n85\\nThe key idea of the functional API is the use of one layer as a parameter input\\nto another layer, so we can easily use one layer as input to several other layers and\\nallow for branching in a network',\n",
       "  'To have several input layers into one layer, Keras\\nprovides a concatenate layer which merges the input layers into a single list to\\nfeed into the next layer.\\nOnce the model is deﬁned using the functional API, training, evaluation, and\\ninference work exactly in the same way for models built using the functional API as\\nfor sequential models.\\nWe will explain the use of the functional API by providing examples of how to\\ncreate customized layers, models, and loss functions in the next few sections.\\n5.6\\nCustom Models\\nCustom models are created simply by feeding a layer with a preceding layer as an\\ninput',\n",
       "  'For example, let us deﬁne two inputs with two output models with a dense\\nlayer in between using the functional API',\n",
       "  'The code would be as follows:\\nimport tensorflow as tf\\nimport keras\\nfrom keras.layers import *\\nfrom keras.models import Sequential, Model\\nfrom keras.optimizers import Adam, RMSprop\\nimport numpy as np\\nfrom keras.utils import plot_model\\ninput1 = Input(shape=(32,),name=\"input1\")\\ninput2 = Input(shape=(128,),name=\"input2\")\\nx1 = Dense(2, name = \"dense1\")(input1)\\nx = Dense(1,name = \"dense2\")(input2)\\nx2 = Dense(1,name = \"dense2_2\")(x)\\nconcatted = Concatenate(name=\"concatted\")([x1, x2])\\nmodel = Model(inputs=[input1, input2], outputs=concatted)\\nplot_model(model, show_shapes=True,\\nshow_layer_names=True, to_file=’modelconcat.png’)\\nThe plot_model function gives the following diagram which is a mapping of what\\nwe have just coded.\\n86\\n5\\nThe Training Process\\nThe functional API offers remarkable ﬂexibility due to its ability to use a layer\\nas an input to another layer',\n",
       "  'This feature allows us to create complex branching in\\nthe hidden layers and provides the ﬂexibility to process various types of input data,\\nsuch as numeric, categorical, and images, through different paths, merging them at\\nthe ﬁnal layer',\n",
       "  'While we have omitted the activation function on the dense layer for\\nclarity, it functions identically to a sequential network.\\nIn later chapters, we will extensively use the functional API to introduce different\\nnetwork topologies',\n",
       "  'Regardless of how intricate the layers may seem, they are\\nconstructed in the same manner as described here.\\nMoreover, the functional API empowers us to override Keras’s model base class,\\nenabling the creation of customized models',\n",
       "  'A customized model groups layers with\\na set of input nodes, hidden layers, and output',\n",
       "  'This approach proves beneﬁcial when\\nthe same group of layers needs to be repeated numerous times in a complex network.\\nBy deﬁning a customized model, we can reuse the code without duplicating the layer\\nstructure.\\nFor instance, let’s consider the construction of a Siamese network using the\\nfunctional API',\n",
       "  'A Siamese network comprises two identical subnetworks feeding\\ninto a comparator layer at the output',\n",
       "  'These subnetworks share the same architecture\\nand parameters and are essentially mirror images of each other',\n",
       "  'If the weights\\nof one subnetwork are updated, the weights of the other subnetwork are updated\\naccordingly.\\nThe Siamese network topology is often utilized to compute the degree of\\nsimilarity between two items, such as images, words, or sounds',\n",
       "  'In this example,\\nwe will create a network to compare two images',\n",
       "  'This involves constructing two\\nidentical CNN subnetworks (referred to as Siamese sisters)',\n",
       "  'Each network outputs\\na vector, which is then fed into a ﬁnal comparative layer to assess the degree of\\ndissimilarity.\\n5.6\\nCustom Models\\n87\\nimport tensorflow as tf\\nfrom tensorflow.keras.layers import Input, Conv2D,\\nMaxPooling2D, Flatten, Dense, Lambda\\nfrom tensorflow.keras.models import Model\\nimport tensorflow.keras.backend as K\\ndef initialize_base_network():\\n#Define the base network (shared layers)\\ninput = Input(shape=(input_shape,),\\nname=\"base_input\")\\nx = Conv2D(64, (3, 3), activation=’relu’)(input)\\nx = MaxPooling2D((2, 2))(x)\\nx = Conv2D(128, (3, 3), activation=’relu’)(x)\\nx = MaxPooling2D((2, 2))(x)\\nx = Flatten()(x)\\nx = Dense(128, activation=’relu’)(x)\\nreturn Model(inputs=input, outputs=x)\\ndef euclidean_distance(vectors):\\n#Define the Euclidean distance function\\nx, y = vectors\\nsum_square = K.sum(K.square(x - y), axis=1,\\nkeepdims=True)\\nreturn K.sqrt(K.maximum(sum_square, K.epsilon()))\\ninput_shape = (105, 105, 1)\\n# Example input shape\\n# Create the base network\\nbase_network = initialize_base_network()\\n# Create the left input and point to\\n#the base network\\ninput_a = Input(shape=input_shape, name=\"left_input\")\\nprocessed_a = base_network(input_a)\\n# Create the right input and point to\\n#the same base network\\ninput_b = Input(shape=input_shape, name=\"right_input\")\\nprocessed_b = base_network(input_b)\\n# Calculate the distance between the\\n# two encoded inputs\\ndistance = Lambda(euclidean_distance,\\noutput_shape=(1,),\\nname=\"distance\")([processed_a, processed_b])\\n# Create the Siamese network model\\nmodel = Model(inputs=[input_a, input_b],\\noutputs=distance)\\n# Define the optimizer and compile the model\\nmodel.compile(loss=\"contrastive_loss\",\\noptimizer=\"adam\")\\n88\\n5\\nThe Training Process\\n# Now the model is ready to be trained with\\n# pairs of inputs and a label indicating\\n# their similarity\\n5.7\\nModel Selection\\nModel selection seems daunting as there are so many alternatives to choose from,\\nbut in practice, it is often the case that real-world requirements and constraints would\\nhelp to guide us to the most appropriate model',\n",
       "  'As surprising as it may seem, it is\\noften ﬁne-tuning and experimentation that often take a long time to master and get\\nright.\\nThe considerations for model selection in this section are mainly based on learn-\\ning and research-based requirements',\n",
       "  'Commercial projects often require complex\\nand larger models, which are beyond the scope of this book',\n",
       "  'As an anecdote sidenote\\non model selection in a commercial environment, several software companies allow\\nthe user to run the data against hundreds of different models and parameters and\\nchoose the model with the best results',\n",
       "  'While this is a valid approach, it would not\\nwork well with less time and resources.\\nFor many tasks, especially in computer vision and natural language processing,\\npretrained models are available',\n",
       "  'These can be a good starting point and can be\\nﬁne-tuned on your speciﬁc dataset',\n",
       "  'At the very least, examining these pretrained\\nmodels would give us a good idea of what a simpliﬁed architecture should be for our\\nproblem',\n",
       "  'For instance, if the pretrained model uses predominantly CNN or ResNet\\nlayers with good result, then a similar type of layers should be used for our project.\\nSpeed requirement is an important factor to consider',\n",
       "  'For applications requiring\\nreal-time responses, like mobile or web applications, lightweight models are\\npreferable, but for tasks where accuracy is paramount and response time is less\\ncritical, like medical image analysis, more complex models can be used to get better\\nresults.\\nThe complexity of the model is a double-edged sword',\n",
       "  'More complex models\\nhave greater power and ﬂexibility but are prone to overﬁtting, especially when\\nthe data size is limited',\n",
       "  'Techniques such as dropout, regularization, and data\\naugmentation are employed to combat overﬁtting',\n",
       "  'Conversely, too simple a model\\nmight not capture the complexity of the data, resulting in underﬁtting and poor\\noverall performance.\\nAt the core of model selection is the speciﬁcity of the task',\n",
       "  'For instance, deep\\nconvolutional neural networks (CNNs) are often the go-to choice for image or\\nspeech recognition tasks, leveraging their ability to capture spatial hierarchies.\\nOn the other hand, sequence modeling tasks, like language translation or time-\\nseries prediction, beneﬁt from the temporal dynamics captured by recurrent neural\\nnetworks (RNNs), long short-term memory networks (LSTMs), or gated recurrent\\nunits (GRUs)',\n",
       "  'In regression tasks where the goal is to predict numerical values,\\nsimpler DNN architectures might sufﬁce, though complex data might still require\\n5.9\\nNeural Networks Applications\\n89\\nthe sophistication of CNNs or RNNs',\n",
       "  'Additionally, for generative tasks like image\\ngeneration or style transfer, models like generative adversarial networks (GANs) or\\nvariational autoencoders (VAEs) are typically used.\\nThe characteristics of the data also play a pivotal role in model selection',\n",
       "  'Large\\ndatasets can often support deeper and more complex networks, but this comes with\\nincreased computational demands',\n",
       "  'High-dimensional data, such as high-resolution\\nimages, may necessitate more sophisticated models to effectively capture underlying\\npatterns',\n",
       "  'The quality and diversity of the training data are equally important; noisy,\\nimbalanced, or unrepresentative datasets can lead to poor model performance,\\nmaking data preprocessing and augmentation crucial.\\nIn summary, while the selection of an appropriate model can be a complex task,\\nunderstanding the speciﬁc requirements and constraints of our project is crucial in\\nguiding you toward the most effective and efﬁcient model choice.\\n5.8\\nModel Depth and Complexity\\nEach layer in a DNN extracts a level of abstraction of the data',\n",
       "  'In general, more\\nlayers allow the network to learn more complex patterns',\n",
       "  'For instance, in a CNN\\nthat is used for image recognition, initial layers might detect edges, while deeper\\nlayers could identify more complex structures, like shapes or speciﬁc objects.\\nThe complexity and volume of your data are key indicators when choosing the\\nmodel depth and complexity',\n",
       "  'Simple patterns and smaller datasets often require\\nfewer layers, as a deep network might overﬁt, learning noise rather than useful\\npatterns',\n",
       "  'Conversely, complex data such as high-resolution images or intricate\\nlanguage structures might beneﬁt from deeper architectures.\\nAlthough we have not discussed the transformer layer in this book due to its\\ncomplexity, using transformer layers in a neural network architecture is particularly\\nadvantageous for certain types of problems, especially those involving sequential\\ndata or requiring the understanding of long-range dependencies',\n",
       "  'The transformer\\nmodel, introduced in the seminal paper “Attention Is All You Need” by Vaswani\\net al., has revolutionized the ﬁeld of natural language processing (NLP) and is\\nincreasingly being adapted for other applications, such as computer vision.\\nIn conclusion, the depth and complexity of a neural network model should be\\ncarefully tailored to the speciﬁc characteristics of our data and the nature of the task\\nat hand, balancing the ability to learn intricate patterns with the risk of overﬁtting,\\nto achieve optimal performance.\\n5.9\\nNeural Networks Applications\\nWe will now present some applications which were state-of-the-art models a few\\nyears ago',\n",
       "  'The main purpose of presenting my own implementation of these research\\nprojects is to illustrate two important points:\\n90\\n5\\nThe Training Process\\n•\\nThe reader should, hopefully, be able to follow and understand the code now.\\n•\\nGain insights into the subtle but crucial considerations researchers must account\\nfor when designing innovative models.\\nThese applications, demand signiﬁcant computing resources',\n",
       "  'All of them take days,\\nif not several weeks, to run on a normal PC with a decent GPU, so be prepared to\\ninvest the time to experiment.\\nIn most cases, it is a trade-off between time and the quality of training',\n",
       "  'For\\nexample, suppose we want to train the agent to play the Space Invaders game “well,”\\nwe would need to deﬁne, monitor, and understand how well the model is learning\\nand when to adjust or stop training',\n",
       "  'Here are some strategies to effectively monitor\\nthe performance:\\n•\\nTrack Cumulative Rewards per Episode: The most direct measure of performance\\nin reinforcement learning is the cumulative reward obtained in each episode.\\nPlotting this over episodes gives a clear view of whether the agent is improving.\\n•\\nEvaluate Loss During Training: Keep an eye on the loss of the neural network\\nduring the training process',\n",
       "  'A decreasing loss trend indicates that the model\\nis learning, but if the loss plateaus or increases, it might signal issues with the\\ntraining process.\\n•\\nUse a Running Average: Due to the inherent variability in reinforcement learning,\\nit’s useful to look at a running average of the rewards over a set number of\\nepisodes (e.g., the last 100 episodes)',\n",
       "  'This smooths out the noise and gives a\\nclearer trend.\\n•\\nTest in a Fixed Environment: Periodically test our agent in a controlled environ-\\nment where the starting conditions are ﬁxed',\n",
       "  'This can give us a more consistent\\nbasis for comparison.\\n•\\nPerformance Thresholds: Set performance benchmarks or thresholds',\n",
       "  'For exam-\\nple, if the agent achieves a certain score or survives a certain number of frames\\nconsistently, it can be a sign of adequate learning.\\n•\\nVisual Inspection: Occasionally watch the agent play the game',\n",
       "  'This can give our\\nqualitative insights into its learning progress and strategy development.\\n•\\nLog and Review Training Data: Regularly log important metrics, like rewards,\\nloss, epsilon values, and speciﬁc actions taken',\n",
       "  'Reviewing these logs can help\\nidentify patterns or issues.\\n•\\nCompare Against Baselines: If available, compare our agent’s performance\\nagainst known baselines or benchmarks for the game',\n",
       "  'This gives a context to\\nthe performance.\\n•\\nUse Validation Episodes: Separate training and validation episodes can be useful.\\nTrain the agent for a number of episodes, then test it on different episodes\\nwithout learning (i.e., no weights update during these test episodes)',\n",
       "  'This helps\\nin understanding how well the model generalizes.\\n•\\nEarly Stopping: Implement an early stopping mechanism',\n",
       "  'If the performance\\ndoes not improve or starts to degrade over a certain number of episodes, stop the\\ntraining to prevent overﬁtting or wasting resources.\\n5.10\\nDense Network: Detection of Handwritten Digits Using MNIST Dataset\\n91\\nFigure 5-4 MNIST 28 × 28\\nmatrix of digit 5\\n5.10\\nDense Network: Detection of Handwritten Digits Using\\nMNIST Dataset\\nJust to illustrate this point further, let us consider the problem of recognizing\\nhandwritten digits',\n",
       "  'This problem at ﬁrst seems nothing like the problem in the\\nprevious example, but with some minor code changes to digitize the images, we\\ncan use the same type of neural network to solve it.\\nWe are going to use the popular MNIST dataset',\n",
       "  'The MNIST dataset is so widely\\nused in machine learning that it has been included as part of Keras’s standard built-in\\ndatasets',\n",
       "  'The dataset consists of 60,000 images of digits ranging from zero to nine,\\nwhere each digit is represented as a 28×28 matrix of grayscale pixels',\n",
       "  'In addition to\\nthe 60,000 training images, the dataset includes 10,000 images for testing purposes.\\nAn example of an MNIST digit is shown in Figure 5-4',\n",
       "  'Since this is a grayscale\\nimage, each pixel represents a brightness value from 0 (black) to 255 (white)',\n",
       "  'The\\nyTrain and yText arrays contain the actual number of the digit itself, so for the\\nimage, yTrain=5',\n",
       "  'To use the model, we need to convert the 28 × 28 array of each\\ninput image to a vector of length 28*28=784 using the method reshape on the\\nNumPy array so that the neural network can accept it',\n",
       "  'The particular type of neural\\nnetwork we are using for the example requires this input format, so we need to do\\nthe conversion',\n",
       "  'The input layer differs for different networks, so there is no one\\nﬁxed format, but they all required numerical inputs.\\nThe code for the project is shown below:\\nimport numpy as np\\nimport keras\\nimport tensorflow as tf\\nimport matplotlib.pyplot as plt\\nfrom keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.optimizers import Adam\\nfrom google.colab import files\\n92\\n5\\nThe Training Process\\n# load mnist dataset\\n# 60,000 images for xTrain, 10,000 for xTest\\nmnist = tf.keras.datasets.mnist\\n(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\\nxTrainFlattened = xTrain.reshape(len(xTrain),784)\\nxTestFlattened = xTest.reshape(len(xTest),784)\\n#create the neural network as before\\nmodel = Sequential()\\nmodel.add(Dense(784, activation=’relu’,\\ninput_shape = (784,)))\\nmodel.add(Dense(784, activation=’relu’))\\nmodel.add(Dense(10,activation=’softmax’))\\nmodel.compile(optimizer=Adam(),\\nloss=’sparse_categorical_crossentropy’,\\nmetrics=[’accuracy’])\\nmodel.fit(xTrainFlattened, yTrain, epochs=5)\\n# test the accuracy using the xTest\\nmodel.evaluate(xTestFlattened,yTest)\\n313/313 [==============================] -\\n1s 4ms/step - loss: 0.1969 - accuracy: 0.9597\\n[0.19687649607658386, 0.9596999883651733]\\nAs we can see, the model setup is very similar to the previous example, although two\\ndifferences are worth noting that the model uses “sparse_categorical_crossentropy”\\nas the loss function and “softmax” for the activation of the output layer.\\nDo not worry about these parameters or what they mean for the time being',\n",
       "  'We\\nwill discuss these topics in the next few sections',\n",
       "  'The point to note here is how the\\nsame type of neural network could be used for two seemingly unrelated applications.\\nUsing just a few lines of code, we have managed to identify handwritten digits with\\n96% accuracy.\\nIf we (correctly) feel that the whole machine learning process is relatively simple\\nup to now, it is only because the complexity of machine learning has been wrapped\\nup in the Keras library',\n",
       "  'This is an important point; in practice, if we are only\\ninterested in using machine learning in applications, then we only need to master\\na few important things:\\n•\\nUnderstand the whole process and the tools from beginning to end.\\n•\\nLearn to preprocess the input data to feed the models effectively.\\n•\\nSelect and conﬁgure different models.\\n•\\nKnow how to evaluate the model to improve its accuracy.\\nHowever, while Keras simpliﬁes the machine learning process, it is important\\nnot to underestimate the complexity of the built-in libraries and to recognize the\\ncomplex algorithms and computations that operate behind the scenes, making such\\nsimplicity possible.\\n5.11\\nRNN Network: Modeling an AutoRegressive Integrated Moving Average...\\n93\\n5.11\\nRNN Network: Modeling an AutoRegressive Integrated\\nMoving Average (ARIMA) Process\\nSo far, our discussions have revolved around the simplest type of deep neural net-\\nwork known as the feedforward neural network (FNN)',\n",
       "  'In this network, information\\nﬂows only in the forward direction: from the input layer, through various hidden\\nlayers, and to the output layer',\n",
       "  'The backpropagation algorithm is used to update the\\nweights of the feedforward network, and it does not involve creating loops or cycles\\nin the physical connections between nodes.\\nFeedforward networks are primarily employed for supervised learning tasks,\\nsuch as object classiﬁcation or pattern recognition',\n",
       "  'They excel at creating classi-\\nﬁcation boundaries between different classes of objects, particularly when the data\\nto be learned is not time dependent nor sequential',\n",
       "  'However, for time series analysis\\nor models that require self-learning, more complex network structures are necessary.\\nIn such cases, loops in the network are used to enforce dependencies between the\\ncurrent state and previous states of the network.\\nRecurrent networks are typically used for time series analysis, such as an\\nencoder-decoder network for sequence-to-sequence prediction problems',\n",
       "  'Addition-\\nally, other networks, like generative and diffusion models, are utilized to generate\\nadditional instances similar to the training data',\n",
       "  'Many renowned applications, such\\nas ChatGPT, DALL-E, and other large language models (LLMs), currently employ\\nvariants of generative models with massive training data and computational power,\\nresulting in impressive effects.\\nOne of the simplest alternative neural network structures is a recurrent neural\\nnetwork (RNN)',\n",
       "  'RNN is widely used to model time series and sequential tasks',\n",
       "  'A\\nsequential task involves input and output data sequences, such as text streams, stock\\nprices, or video clips, which can be modeled using RNNs.\\nIf we look at Figure 5-5, the small diagram on the left shows the recurrent nature\\nof the network',\n",
       "  'That is, it is a set of layers, with each input fed by the output of the\\npreceding hidden layer',\n",
       "  'The diagram on the right displays the exact structure of the\\nnetwork',\n",
       "  '{x1, x2, x3 ',\n",
       "  '',\n",
       "  '',\n",
       "  ', xt} represents the sequence of input values which feed into\\nFigure 5-5 Diagram showing a naive RNN network\\n94\\n5\\nThe Training Process\\nthe hidden neural network layer denoted by A',\n",
       "  'The node A represents the memory\\nstate at time t such that\\nA(t) = f (w1Xt + w2A(t −1))\\nIn simpler terms, the current memory state at time t, denoted as A(t), is a nonlinear\\nfunction f of the input value at time t, denoted as Xt, and the previous state value\\nat time t −1',\n",
       "  'Each h0, h1, ',\n",
       "  '',\n",
       "  '',\n",
       "  ', ht represents the output value at each step of the\\nsequence',\n",
       "  'Notably, ht corresponds to the ﬁnal output of the sequence',\n",
       "  'Structurally,\\nnode A can contain one or multiple layers, but for ease of implementation, all nodes\\nA typically share the same activation function and hyperparameters.\\nSo far, we have not deﬁned the speciﬁc structure for node A',\n",
       "  'However, it’s worth\\nmentioning that RNN networks often encounter the vanishing gradient problem\\nin practice',\n",
       "  'To mitigate this issue, a type of RNN called long short-term memory\\n(LSTM) is commonly used.\\nThe structure of an RNN (recurrent neural network) enables it to effectively\\nmodel both linear and nonlinear relationships',\n",
       "  'One signiﬁcant advantage of using\\nan RNN model is its capability to handle different time series without the need to\\nselect alternative (linear and nonlinear) models',\n",
       "  'Moreover, an RNN model possesses\\nmemory, making it particularly suitable for modeling autoregressive (AR) models,\\nwhere the value of the output Yt at time t depends on previous q values.\\nTo illustrate the effectiveness of RNNs in time series analysis, we will compare\\nits forecasting performance against the ARIMA(p, d, q) model using 20 years of\\nthe Standard & Poor’s 500 closing prices.\\nTo begin with, let us model the time series using an ARIMA(p, d, q) model.\\nThis model has three parameters:\\nYt =\\np\\n\\x02\\ni=1\\nωt−iYt−i +\\nq\\n\\x02\\nj=1\\nθt−jϵt−j\\nIn this equation, Yt is the predicted value at time t',\n",
       "  'The model combines three\\nkey components:\\n•\\nAutoregressive (AR) terms represented by \\x03p\\ni=1 ωt−iYt−i, where p is the\\nnumber of lag observations included in the model; ωt−i are the coefﬁcients for\\nthe lags of the series at times t −1, t −2, ',\n",
       "  '',\n",
       "  '',\n",
       "  ', t −p; and Yt−i are the lagged\\nvalues of the series.\\n•\\nDifferencing order d, which is the number of times the data have had past values\\nsubtracted (not explicitly shown in the equation).\\n•\\nMoving average (MA) terms represented by \\x03q\\nj=1 θt−jϵt−j, where q is the size\\nof the moving average window, θt−j are the coefﬁcients for the lagged forecast\\nerrors in the prediction equation, and ϵt−j are the lagged forecast errors at times\\nt −1, t −2, ',\n",
       "  '',\n",
       "  '',\n",
       "  ', t −q.\\n5.11\\nRNN Network: Modeling an AutoRegressive Integrated Moving Average...\\n95\\nThe ARIMA model thus captures the dynamics of a time series through a combi-\\nnation of these autoregressive and moving average terms, adjusted by the level of\\ndifferencing to ensure stationarity.\\nWe can use statistical tests, such as the Augmented Dickey-Fuller (ADF) and\\nCanova-Hansen (CH), or (partial) autocorrelation tests (PACE and ACE) to choose\\nthe parameters’ values.\\nStock prices are usually nonstationary, so differencing using the d parameter\\nis often necessary to stationary',\n",
       "  'In practice, this condition is hard to achieve, and\\nﬁnding the right values for p, d, and q often requires experimentation.\\nWe will use 90% of the dataset for training and 20% for forecasting.\\nLet’s implement the ARIMA model using Python’s statsmodels library:\\nimport pandas as pd\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom statsmodels.tsa.arima.model import ARIMA\\nfrom sklearn.metrics import mean_squared_error\\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\\ndata = pd.read_csv(’sp500_data.csv’,\\nindex_col=’Date’,parse_dates=True)\\nts_data = data[’Close’]\\ntrain_size = int(len(ts_data) * 0.8)\\ntrain, test = ts_data[:train_size], ts_data[train_size:]\\n# Plot ACF and PACF\\nplot_acf(ts_data, lags=20)\\nplot_pacf(ts_data, lags=20)\\nplt.show()\\nP = 1\\nd = 1\\nq = 1\\nmodel = ARIMA(train, order=(p,d,q))\\nmodel_fit = model.fit()\\nNow, let’s model the same time series using an RNN for comparison',\n",
       "  'Instead of\\nusing ARIMA, we can use RNN to do the same task:\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense, LSTM\\nimport matplotlib.pyplot as plt\\ndata = pd.read_csv(’sp500_data.csv’)\\nprices = data[’Close’].values.reshape(-1, 1)\\n# Scale the data to values between 0 and 1\\nscaler = MinMaxScaler(feature_range=(0, 1))\\nscaled_prices = scaler.fit_transform(prices)\\n96\\n5\\nThe Training Process\\n# Define the number of time steps for the RNN\\ntime_steps = 30\\n# Create sequences for the RNN\\nX, y = [], []\\nfor i in range(len(scaled_prices) - time_steps):\\nX.append(scaled_prices[i : i + time_steps])\\ny.append(scaled_prices[i + time_steps])\\nX, y = np.array(X), np.array(y)\\n# Split the data into training and testing sets\\ntrain_size = int(0.8 * len(X))\\nX_train, X_test = X[:train_size], X[train_size:]\\ny_train, y_test = y[:train_size], y[train_size:]\\nmodel = Sequential()\\nmodel.add(LSTM(50, return_sequences=True,\\ninput_shape=(X_train.shape[1], 1)))\\nmodel.add(LSTM(50))\\nmodel.add(Dense(1))\\nmodel.compile(optimizer=’adam’,\\nloss=’mean_squared_error’)\\nmodel.fit(X_train, y_train, epochs=50, batch_size=32,\\nverbose=1)\\n# Predict using the test data\\npredicted_prices = model.predict(X_test)\\npredicted_prices = scaler.\\ninverse_transform(predicted_prices)\\n# Transform the original test data back\\n# to the original scale\\ny_test = scaler.inverse_transform(y_test)\\n# Calculate Mean Squared Error (MSE)\\nmse = np.mean((predicted_prices - y_test) ** 2)\\nprint(\"Mean Squared Error:\", mse)\\n# Plot the predictions against the actual values\\nplt.figure(figsize=(12, 6))\\nplt.plot(y_test, label=\"Actual Prices\", color=\"blue\")\\nplt.plot(predicted_prices, label=\"Predicted Prices\",\\ncolor=\"red\")\\nplt.xlabel(\"Time\")\\nplt.ylabel(\"S&P 500 Index Price\")\\nplt.title(\"S&P 500 Index Prediction using RNN\")\\nplt.legend()\\nplt.show()\\n5.12\\nLSTM Network: BachBot\\n97\\n5.12\\nLSTM Network: BachBot\\nBachBot is a research application written by Feynman Liang [4] at Cambridge\\nUniversity, UK, to compose classical musical chorales in the style of composer\\nJ.S',\n",
       "  'Bach using an LSTM network',\n",
       "  'The code presented here is the basic version\\nof the model inline with Feynman’s published paper and his thesis',\n",
       "  'The original\\nimplementation was written in PyTorch and Lua and is a more sophisticated imple-\\nmentation with more functionalities, including harmonization',\n",
       "  'The implementation\\nin this book is not a straight conversion of the code but written from scratch using\\nKeras',\n",
       "  'I am grateful to Feynman for useful discussions and for allowing me to use\\nsome of his MusicXML utility code.\\n5.12.1 Background\\nJohann Sebastian Bach’s music is often described as mathematical due to its\\nstructure, precision, and the way it adheres to speciﬁc musical forms and rules.\\nBach, a master of counterpoint, skillfully interwove multiple independent melodies\\nthat harmonized with each other',\n",
       "  'This technique, especially evident in his fugues,\\nrequires meticulous planning and a deep understanding of harmonic and melodic\\nstructures',\n",
       "  'The mathematical aspect lies in how these independent melodies ﬁt\\ntogether in a precise, logical way, often following strict rules.\\nJ.S',\n",
       "  'Bach’s 400+ chorales are hymn tunes written to be sung by a congregation\\nin a German Protestant church service',\n",
       "  'In Bach’s time, these hymns were often\\nharmonized for four voices (soprano, alto, tenor, and bass) for performance by a\\nchoir or used as the basis for more complex compositions',\n",
       "  'The text of chorales is\\nusually in German and reﬂects Lutheran religious themes, often based on biblical\\nscriptures or liturgical texts.\\nBach’s chorales are known for their rich harmonic texture and complex coun-\\nterpoint',\n",
       "  'Each voice part is melodically interesting and contributes to the overall\\nharmonic structure',\n",
       "  'An example of his chorales is shown below',\n",
       "  'Note that the four\\nstaffs are notes for the four voices: soprano (top), alto, tenor, and bass (bottom).\\nAdditionally, each chorale contains a series of phrases which Bach delimited using\\nfermatas',\n",
       "  'Choosing an LSTM (long short-term memory) network for a project like\\nBachBot, which is focused on generating music in the style of Johann Sebastian\\nBach, makes sense due to several key characteristics of LSTM networks that\\nare particularly well suited for handling music and sequential data in general.\\nSpeciﬁcally\\n•\\nHandling of Sequential Data: Music is inherently sequential, with each note or\\nchord depending on what came before',\n",
       "  'LSTM networks excel at processing and\\ngenerating sequential data because they can maintain information in “memory”\\nover long sequences, which is crucial for capturing the structure and progression\\nin music.\\n98\\n5\\nThe Training Process\\nFigure 5-6 J.S',\n",
       "  'Bach—BWV 649—Ach bleib bei uns, Herr Jesu Christ',\n",
       "  'Notice phrasing using\\nfematas [4]\\n•\\nLong-Term Dependencies: Bach’s compositions often contain long-term depen-\\ndencies, where themes or motifs are developed and revisited over time',\n",
       "  'LSTMs\\nare speciﬁcally designed to capture such long-term dependencies in sequences,\\nunlike traditional neural networks which struggle with long-range data depen-\\ndencies.\\n•\\nLearning Patterns in Time: LSTMs can learn patterns in time-series data',\n",
       "  'Bach’s\\nmusic, with its complex rhythms, harmonies, and counterpoints, presents a rich\\ntemporal structure that LSTMs can learn and model.\\n•\\nVariability in Sequence Length: Musical pieces can vary signiﬁcantly in length,\\nand LSTMs can handle this variability effectively',\n",
       "  'They can be trained on\\nsequences of varying lengths and generate sequences that are not ﬁxed in size.\\n•\\nFlexibility in Modeling Different Elements: LSTMs can be used to model various\\naspects of music, such as melody, harmony, rhythm, and dynamics, by learning\\nfrom a diverse range of musical features encoded in the input data.\\n5.12.2 Preprocessing\\nOnce the network topology is chosen, Feynman encodes Bach’s music for digiti-\\nzation in a very particular format',\n",
       "  'Firstly, all chorales are transposed to the key\\nC-major for major scores and A-minor for minor ones',\n",
       "  'The C-major or A-minor\\n5.12\\nLSTM Network: BachBot\\n99\\nFigure 5-7 Sample of a J.S',\n",
       "  'Bach chorale [4]\\nkey is chosen to make the encoding process easier by removing all the sharps and\\nﬂats in the original key signature.\\nTime quantization is also performed',\n",
       "  'Each note duration is transformed into\\na multiple of a semibreve duration, neglecting changes in timing (e.g., ritardan-\\ndos), dynamics (e.g., crescendos), and additional notation (e.g., accents, staccatos,\\nlegatos)',\n",
       "  'The pitch of each note is represented in MIDI speciﬁcation from 0 to 127\\nrepresenting ten octaves',\n",
       "  'Although articulation marks are removed, the fermata,\\ndenoted by the symbol (.), is retained to help the model learn phrasing.\\nFinally, akin to bar lines in standard music notation, a frame delimiter\\n(|||)\\nis used to segment the music into timing measures.\\nThe end result of the preprocessing stage is a series of tokens shown in\\nFigure 5-8',\n",
       "  'A (true) boolean value in the token denotes a tied note.\\nThe generation of a corpus of token ﬁles for the 400+ Bach chorales is where we\\nstart',\n",
       "  'Although this process only needs to be performed once, it completes quickly.\\nTherefore, the code is kept in the program to run each time, avoiding additional\\nlogic that could clutter the main program.\\n100\\n5\\nThe Training Process\\nFigure 5-8 An example of\\nthe tokenized ﬁle for the J.S.\\nBach score BWV 133.6\\n5.12.3 Model Implementation and Training\\nThe Keras model for BachBot is shown below',\n",
       "  'Feynman’s thesis detailed the\\nhyperparameters for PyTorch',\n",
       "  'Fortunately, the corresponding Keras parameters are\\ncompatible, which makes the implementation much easier',\n",
       "  'One particular aspect of\\nthe training process that is nonstandard is the use of teacher forcing for the RNN\\nnetwork.\\n5.12.4 Teacher Forcing\\nTeacher forcing is a training methodology where, instead of using the model’s\\nown predictions as inputs during training, the model is provided with the actual\\nor expected output from the previous time step',\n",
       "  'In other words, during training, the\\nnetwork is “forced” to consider the correct output (as provided by the teacher, which\\nin this case is the training data) at each step, instead of its own predictions.\\nIn standard RNN training without teacher forcing, the predicted output from the\\nprevious time step is fed back into the network as input for the next time step',\n",
       "  'Instead\\n5.12\\nLSTM Network: BachBot\\n101\\nof using the RNN’s own predictions from the previous step, teacher forcing uses the\\nactual previous output from the training dataset.\\nThe advantages of teacher forcing include faster convergence and stability during\\ntraining',\n",
       "  'However, a major drawback of teacher forcing is the discrepancy between\\ntraining and inference',\n",
       "  'During training, the model always sees the correct previous\\noutput, but at inference, it must generate sequences based on its own predictions.\\nThis difference can lead to issues such as exposure bias, where the model may not\\nperform well during inference.\\ndef teacher_forcing_encode(corpus, files, time_steps):\\n# Tokenize the corpus\\ncorpus_tokens = corpus.split(’@’)\\ntokenizer = Tokenizer(filters=’’, split=’@’,\\nlower=False)\\ntokenizer.fit_on_texts(corpus_tokens)\\n# Convert tokens to numeric values\\nsequences = tokenizer.texts_to_sequences(corpus_tokens)\\nd_tokens = np.array([item for sublist in sequences\\nfor item in sublist])\\n# Unique tokens and vocabulary size\\nunique_tokens = tokenizer.word_index\\nvocabulary_size = len(unique_tokens)\\n# Prepare X and Y\\nnum_files = len(files)\\nX = []\\nY = []\\n# Find start and end indices for each file\\nstart_indices = [i for i, x in enumerate(corpus_tokens)\\nif x == ’START’]\\nend_indices = [i for i, x in enumerate(corpus_tokens)\\nif x == ’END’]\\nend_token = 0\\nfor i in range(num_files):\\nfile_seq = d_tokens[start_indices[i]:end_indices[i]]\\nX.append(np.array(file_seq[:-1]))\\nY.append(np.array(file_seq[1:]))\\nx_chunks_list = [split_and_pad_sequence(seq,\\ntime_steps,end_token) for seq in X]\\nX = [chunk for sublist in x_chunks_list for chunk\\nin sublist]\\nX = np.array(X)\\ny_chunks_list = [split_and_pad_sequence(seq,\\ntime_steps, end_token) for seq in Y]\\nY = [chunk for sublist in y_chunks_list for chunk\\nin sublist]\\nY = np.array(Y)\\n# Convert labels to one-hot encoding\\n102\\n5\\nThe Training Process\\nY_train_one_hot = to_categorical(Y,\\nnum_classes=vocab_size+1)\\nreturn X, Y_train_one_hot, tokenizer, corpus_tokens\\nThe code above does set up the conditions for implementing teacher forcing during\\nthe training of the LSTM model, although the actual implementation of teacher\\nforcing happens within the model’s training process itself.\\nThe function teacher_forcing_encode prepares the training data (X_train and\\nY_train) in a format suitable for teacher forcing',\n",
       "  'In this setup, for each sequence\\nin X_train, the corresponding sequence in Y_train is the same sequence but shifted\\nby one time step, providing the “next token” as the target for each input sequence.\\nThe model is trained using X_train and Y_train',\n",
       "  'During training, the LSTM\\nmodel receives a sequence from X_train and learns to predict the next token in the\\nsequence',\n",
       "  'The correct next token is always the corresponding element in Y_train.\\nThis means the model is trained with the actual next token from the training data as\\nthe target for each time step, which is the essence of teacher forcing.\\nThe create_bachbot_lstm_model function constructs the LSTM model using the\\nspeciﬁed parameters',\n",
       "  'When this model is trained with the X_train and Y_train data,\\nit implicitly uses teacher forcing because of how the training data is structured.\\nI found that the implementation works well when producing music when the\\ninitial feed from Bach’s choral works but not so when asked to produce long\\npassages of music',\n",
       "  'Scheduled sampling is a recent alternative training method for\\nresolving this discrepancy, but it is a matter of experimentation and is beyond the\\nscope of the project.\\n5.12.5 BachBot Model\\nThe model used by BachBot is a fairly standard LSTM model to generate music\\nsequences.\\ndef create_bachbot_lstm_model(num_layers, rnn_size,\\nembedding_dim, seq_length, dropout_rate,\\nvocab_size):\\nmodel = Sequential()\\nmodel.add(Embedding(input_dim=vocab_size,\\noutput_dim=embedding_dim, input_length=seq_length))\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(dropout_rate))\\nfor _ in range(num_layers):\\nmodel.add(LSTM(rnn_size, return_sequences=True))\\nmodel.add(BatchNormalization())\\nmodel.add(Dropout(dropout_rate))\\nmodel.add(TimeDistributed(Dense(vocab_size+1,\\nactivation=’softmax’)))\\n5.12\\nLSTM Network: BachBot\\n103\\nusing these following constants as parameters as speciﬁed in the research paper:\\nnum_layers = 3, rnn_size = 256, embedding_dim = 32, seq_length = 128,\\nand dropout_rate = 0.3.\\nEssentially, this is a sequential RNN model with 128 time steps',\n",
       "  'The rnn_size,\\nsets to 256, deﬁnes the number of units in each LSTM layer, which is three in this\\ncase',\n",
       "  'Before the input data enters the LSTM network, it is embedded to a lower\\ndimension of 32',\n",
       "  'Although embedding is used to reﬂect the conﬁguration of the\\npaper, in practice it does not affect the result signiﬁcantly and can be removed to\\nimprove the speed if needed.\\nWhen we set return_sequences=True for an LSTM layer in a neural network, it\\nmeans that the layer will return the full sequence of outputs for each time step in the\\ninput sequence',\n",
       "  'This is in contrast to the default setting (return_sequences=False),\\nwhere the LSTM layer only returns the output of the last time step.\\nWith return_sequences=True, the LSTM layer produces an output for each\\ntime step in the input data, preserving the temporal sequence information',\n",
       "  'This is\\nessential when subsequent layers in the model also expect time series data, such as\\nin sequence-to-sequence models, or when we are stacking multiple LSTM layers in\\nthis case.\\nThe TimeDistributed layer is used in combination with a dense layer',\n",
       "  'This setup\\nis used so that after processing the sequence data through LSTM layers, we want\\nto make a decision for each note at each time step of the sequence, rather than\\ncollapsing the entire sequence into a single output at the end.\\nThe dense layer with a softmax activation is applied to each time step output\\nof the preceding LSTM layer',\n",
       "  'This setup allows the model to make predictions of\\nthe next musical note at each step in the sequence',\n",
       "  'After training, the result can be\\nexported to an xml ﬁle format and read and played using a software package, such as\\nMuseScore',\n",
       "  'An example of the BachBot’s composition using the program is shown\\nin Figure 5-9.\\n104\\n5\\nThe Training Process\\nFigure 5-9 BachBot’s musical composition\\n6\\nGenerative Models\\nSo far in this book, we have introduced several architectures predominantly to clas-\\nsify objects',\n",
       "  'These models aim to minimize the differences between the predicted\\nobject and the trained ones to make accurate predictions',\n",
       "  'Recently, there have been\\nhuge interests in machine learning, not to classify objects but to generate new\\ncontents based on learned ideas',\n",
       "  'This class of machine is referred to as generative\\nAI.\\n6.1\\nVariational Autoencoders\\nGenerative AI refers to a class of artiﬁcial intelligence systems that are capable\\nof generating new content that resembles some input data they were trained on.\\nThese systems use machine learning algorithms, particularly deep learning, to learn\\npatterns and structures from existing data and then use that knowledge to create new\\ncontent.\\nAs of 2023, the primary architectures in generative AI include generative adver-\\nsarial networks (GANs), variational autoencoders (VAEs), and diffusive models.\\nThe three architectures are very different, and each model is preferred for alternative\\napplications',\n",
       "  'The diffusive model class is the newest and is the most complicated,\\nbut it requires a very large dataset and is extremely computing intensive and time-\\nconsuming to train.\\nThe main idea behind VAEs is to sample data from a learned distribution of\\ntrained data',\n",
       "  'A VAE model consists of two parts: an encoder and a decoder',\n",
       "  'The\\njob of the encoder is to encode data into a smaller set of data, often referred to\\nas the latent space, using a feedforward neural network as before',\n",
       "  'However, the\\nencoder output is not an encoded vector but the parameters of a distribution',\n",
       "  'Often,\\nthe output parameters are the mean μ and the standard deviation σ that represent a\\ncompressed Gaussian distribution of the input data',\n",
       "  'The latent space can be thought\\nof as encoding the most important features of the data',\n",
       "  'To ﬁne-tune our newly\\n© Philip Hua 2024\\nP',\n",
       "  'Hua, Neural Networks with TensorFlow and Keras,\\nhttps://doi.org/10.1007/979-8-8688-1020-6_6\\n105\\n106\\n6\\nGenerative Models\\ngenerated data, we often need these features to be independent from one another.\\nThis sometimes can be done using disentanglement techniques, which are beyond\\nthe scope of this book.\\nThe decoder part of the network then draws a sample from the latent space and\\npasses through another neural network to get an approximation of a reconstructed\\nversion of the data',\n",
       "  'This allows us to sample from the approximated distribution to\\ngenerate new data.\\nTo aid understanding of a VAE network, think of an example of Identikit',\n",
       "  'A\\nlikeness of a person’s face constructed from descriptions given to police uses a set\\nof transparencies of various facial features that can be combined to build up a picture\\nof the person sought',\n",
       "  'The encoder basically generates the set of facial features for\\nthe decoder to choose from.\\nMore formally, in probabilistic terms, the encoder outputs the parameters set λ\\nfor the Gaussian probability density function qλ(z|x), where z is the latent variable\\nfor input x',\n",
       "  'The decoder takes the latent input z and output the trained PDF p(ˆx|z)\\nfrom which new data is generated.\\nThe loss function that we want to optimize is called ELBO (evidence lower\\nbound) rather than the common mean squared error (MSE) which does not make\\nsense for the purposes of VAEs',\n",
       "  'This loss function guides the VAE to learn a balance\\nbetween accurately reconstructing the input data and maintaining a structured latent\\nspace.\\nThe ELBO function has two parts:\\n•\\nA Log-Likelihood: This is used to minimize the difference between the input\\ndata and the trained output.\\n•\\nA KL Divergence: This metric measures the difference between the latent\\ndistribution and the reconstructed distribution',\n",
       "  'It takes in two distributions as\\narguments and outputs the KL divergence.\\nTo see how a VAE works in practice, we can use it to create new faces by training\\nthe model using the CelebFaces dataset images, which can be downloaded from the\\nInternet.\\n6.1.1\\nPreprocessing\\nThe images are normalized to [0,1] as input tensors using the following line of code:\\nvalidationData = utils.image_dataset_from_directory(\\nos.path.dirname(\"C:/AI/Data/VAE/validation\"),\\nimage_size=(img_height,img_width),batch_size=batch_size)\\ndsValidation = validationData.map(lambda x, y: x/255.0)\\n6.1\\nVariational Autoencoders\\n107\\n6.1.2\\nVAE Architecture\\nThe encoder, a convolutional neural network, encodes input images into a latent\\nspace representation',\n",
       "  'It outputs two vectors: z_mean and z_log_var',\n",
       "  'The sampling\\nlayer samples from the latent space using the reparameterization trick, which is\\nthen passed to the decoder which decodes the latent space representation back into\\nimages.\\ndef compute_loss(self, x):\\nz_mean, z_log_var = self.encoder(x)\\nz = self.sampling((z_mean, z_log_var))\\nx_reconstructed = self.decoder(z)\\nreconstruction_loss = tf.reduce_mean(\\ntf.keras.losses.binary_crossentropy(x, x_reconstructed)\\n) * 64 * 64 * 3\\n# fig, axes = plt.subplots(1, 2, figsize=(10, 5))\\n# Display the first image in the first subplot\\n# axes[0].imshow(tf.keras.backend.eval(x[1].numpy()))\\n# axes[1].imshow(tf.keras.backend.eval(x_reconstructed[1]\\n.numpy()))\\n# plt.tight_layout()\\n# tf.print(\"reconstruct:\",reconstruction_loss)\\nkl_loss = -0.5 * tf.reduce_sum(1 + z_log_var -\\ntf.square(z_mean) - tf.exp(z_log_var), axis=1)\\nkl_loss = tf.reduce_mean(kl_loss)\\n#tf.print(\"kl loss:\",kl_loss)\\nvae_loss = reconstruction_loss + kl_loss\\nreturn vae_loss\\nIn the code above, the compute_loss function in our script is designed to calculate\\nthe loss for a variational autoencoder (VAE)',\n",
       "  'This function implements the key\\ncomponents of the VAE loss, which includes both the reconstruction loss and the\\nKullback-Leibler (KL) divergence:\\n•\\nz_mean, z_log_var = self.encoder(x): This line encodes the input data x using\\nthe VAE’s encoder to get the mean, z_mean, and log variance, z_log_var, of the\\nlatent variables.\\nz = self.sampling( z_mean, z_log_var)\\nThe sampling layer uses z_mean and z_log_var to generate a sample z from the\\nlatent space.\\nx_reconstructed = self.decoder(z)\\nThe sampled latent variables z are then decoded back into the reconstructed\\ndata',\n",
       "  'The reconstruction loss is computed using binary cross-entropy between\\nthe original input x and the reconstructed output x_reconstructed.\\nThis loss measures how well the VAE can reconstruct the input data from the\\nlatent variables',\n",
       "  'It is scaled by the dimensions of the input data (64 * 64 * 3), to\\naccount for the total number of pixels and color channels in the input images.\\n108\\n6\\nGenerative Models\\nFigure 6-1 Left to right: Generated faces after 50 and 1000 epochs\\n•\\nKL Divergence Loss\\nkl_loss = –0.5 * tf.reduce_sum(1 + z_log_var – tf.square(z_mean) –\\ntf.exp(z_log_var), axis=1)\\nThis line computes the KL divergence between the approximate posterior deﬁned\\nby z_mean and z_log_var and the prior distribution which is assumed to\\nbe a standard normal distribution',\n",
       "  'The KL divergence acts as a regularizer,\\nencouraging the distribution of the latent variables to be close to a standard\\nnormal distribution.\\nThis is crucial for ensuring a well-structured and meaningful latent space.\\nkl_loss = tf.reduce_mean(kl_loss)\\nThe KL divergence is averaged over the batch.\\n•\\nTotal VAE Loss\\nvae_loss = reconstruction_loss + kl_loss\\nThe total loss for the VAE is the sum of the reconstruction loss and the KL\\ndivergence',\n",
       "  'This combined loss function is what the VAE will try to minimize\\nduring training.\\nThe output of generated faces from the VAE networks is shown in Figure 6-1.\\nMore realistic faces will be produced with longer training and more experimentation\\nwith hyperparameters',\n",
       "  'Figure 6-2 shows the original and reconstructed face images.\\nOne major disadvantage of VAEs is that they can have a problem known as\\nposterior collapsing where the resultant images are blurred',\n",
       "  'There are techniques\\nto minimize this, but generally a GAN will produce higher-quality images at the\\ncost of training time.\\n6.1\\nVariational Autoencoders\\n109\\nFigure 6-2 VAE image reconstruction\\n110\\n6\\nGenerative Models\\nThe Python code supplied provides one interesting tool for visualizing the\\ndistribution of data points in the latent space of a neural network that is worth noting:\\n# Function to plot the latent space\\ndef plot_latent_space(model, data, num_samples=1000):\\nsampled_data = data.take(num_samples)\\nimages = []\\nfor img, _ in sampled_data:\\nimages.append(img)\\nimages = tf.concat(images, axis=0)\\nz_mean, _ = model.encoder.predict(images)\\ntsne = TSNE(n_iter=300, perplexity=30,\\nlearning_rate=200)\\nz_mean_reduced = tsne.fit_transform(z_mean)\\nplt.scatter(z_mean_reduced[:,0],z_mean_reduced[:,1])\\nplt.xlabel(’Dimension 1’)\\nplt.ylabel(’Dimension 2’)\\nplt.title(’Latent Space Visualization’)\\nplt.show()\\nThe purpose of this code is to provide a visual representation of how data points\\nare distributed in the latent space of the VAE after encoding',\n",
       "  'It can help you gain\\ninsights into the structure and separability of the latent space, which is useful for\\nassessing the quality of the learned representations and understanding how well the\\nVAE has disentangled the underlying factors of variation in the data.\\nThe provided code deﬁnes a function to plot the latent space of a variational\\nautoencoder (VAE) or similar neural network model',\n",
       "  'Here’s a breakdown of what\\nthe code does.\\nThe function takes three arguments:\\nModel This argument represents the VAE model or a similar model that has an\\nencoder capable of encoding data into a latent space.\\nData This argument represents a TensorFlow dataset (data) containing input data\\nsamples.\\nNum Samples This argument speciﬁes the number of samples to use for visualiza-\\ntion',\n",
       "  'The default value is set to 1000.\\nThe function starts by sampling a subset of data points from the dataset',\n",
       "  'It takes\\nthe ﬁrst numsamples samples from the dataset.\\nFor the sampled data, it encodes the data using the VAE’s encoder\\n(model.encoder) to obtain the mean (zmean) of the latent space representation.\\nThen, it applies t-Distributed Stochastic Neighbor Embedding (t-SNE), a\\ndimensionality reduction technique, to reduce the dimensionality of the latent\\nspace representation from its original dimensionality to a two-dimensional space.\\nAfter reducing the dimensionality, it creates a scatter plot of the two-dimensional\\nlatent space',\n",
       "  'Each point in the scatter plot represents a data point, and its position is\\ndetermined by the reduced latent space representation obtained using t-SNE.\\n6.1\\nVariational Autoencoders\\n111\\nFinally, it displays the scatter plot, allowing you to visualize the distribution and\\nclustering of data points in the latent space.\\nThe purpose of this code is to provide a visual representation of how data points\\nare distributed in the latent space of the VAE after encoding',\n",
       "  'It can help you gain\\ninsights into the structure and separability of the latent space, which is useful for\\nassessing the quality of the learned representations and understanding how well the\\nVAE has disentangled the underlying factors of variation in the data.\\n6.1.3\\nMorphing Images\\nMorphing images in the latent space from one image to another is a fascinating\\napplication using VAE',\n",
       "  'Morphing in a variational autoencoder (VAE) involves\\nsmoothly transitioning between two input images by navigating the latent space\\nof the VAE',\n",
       "  'Normally, morphing between two images involves linear interpolation\\nbetween the two vectors representing the two from-and-to images, but the interpo-\\nlation can follow other paths depending on the desired transitional effect',\n",
       "  'Using\\na pretrained VAE network for morphing is straightforward using the following\\nsteps:\\n•\\nLoad our pretrained VAE model.\\n•\\nEncode the source and target images to obtain their latent representations.\\n•\\nLinearly interpolate between the latent vectors and decode them to produce a\\nsequence of morphed images.\\n•\\nFinally, we display or save the morphed images.\\nThe resulting images will smoothly transition from the source to the target, creating\\na morphing effect',\n",
       "  'We can adjust the number of frames and interpolation method\\nto control the smoothness and speed of the morphing',\n",
       "  'Using our pretrained VAE\\ncode, we can perform morphing from one face to another',\n",
       "  'The result is shown in\\nFigure 6-3\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom keras.models import load_model\\n# Load your pre-trained VAE model\\nvae = load_model(’celeb_vae_model.h5’)\\n# Encode source and target images\\nsource_image = ...\\n# Load your source image\\ntarget_image = ...\\n# Load your target image\\nlatent_source, _ = vae.encoder.predict(source_image)\\nlatent_target, _ = vae.encoder.predict(target_image)\\n# Specify the number of frames for morphing\\nnum_frames = 10\\n112\\n6\\nGenerative Models\\nFigure 6-3 Transition from one image to another in latent space\\n# Linear interpolation in latent space\\nmorphed_images = []\\nfor alpha in np.linspace(0, 1, num_frames):\\ninterpolated_latent = (1 - alpha) *\\nlatent_source + alpha * latent_target\\ndecoded_image = vae.decoder.predict(interpolated_latent)\\nmorphed_images.append(decoded_image)\\n# Display or save morphed images\\nfor i, image in enumerate(morphed_images):\\nplt.imshow(image.squeeze(), cmap=’gray’)\\nplt.axis(’off’)\\nplt.title(f’Interpolation Step {i}’)\\nplt.show()\\n6.1.4\\nFeature Disentanglement\\nAs we perform morphing using the above code, it is clear that the latent space\\nusing VAE is highly entangled',\n",
       "  'Features are added to the intermediate steps in\\nan uncontrolled fashion',\n",
       "  'Disentangled VAEs have become a prominent area of\\nresearch in machine learning due to their potential for creating more interpretable\\nand controllable generative models.\\nHaving disentangled latent space is potentially very useful',\n",
       "  'The latent space\\nlearned by these models can have practical applications in areas such as image\\nmanipulation, style transfer, and data generation',\n",
       "  'By changing the values of\\nindividual dimensions in the latent space, we can control speciﬁc attributes of\\nthe generated data',\n",
       "  'For example, in image generation, we might have separate\\ndimensions for factors like pose, color, and style.\\nCurrently, achieving perfect disentanglement is still an area of research',\n",
       "  'How-\\never, there are various approaches to produce reasonable disentanglement in VAEs,\\nincluding\\n•\\nConditional VAE (CVAE): A CVAE extends the VAE to condition the latent\\nspace on certain variables or features',\n",
       "  'You can design the model to generate a\\nlatent space representation that explicitly encodes these features',\n",
       "  'This is often\\nused in conditional image generation tasks.\\n•\\nDisentangled VAE (β-VAE, Factor-VAE): These are variations of VAEs that\\naim to encourage the latent dimensions to capture independent and interpretable\\n6.1\\nVariational Autoencoders\\n113\\nfactors of variations in the data',\n",
       "  'While they may not directly encode separate fea-\\ntures, they can help create more interpretable and disentangled representations.\\n•\\nInfoGAN: Information Maximizing Generative Adversarial Networks (Info-\\nGANs) are a type of VAE-GAN hybrid that introduces an auxiliary network\\nto explicitly maximize the mutual information between a subset of the latent\\nvariables and the generated data',\n",
       "  'This encourages those variables to capture\\nspeciﬁc attributes of the data.\\n•\\nJoint-VAE: Joint-VAE combines a VAE with a clustering algorithm to encourage\\nthe model to learn a more disentangled representation.\\nTo see how factor disentanglement works in practice, we can modify our VAE\\nmodel to implement the Factor-VAE, a model proposed by Hyunjik Kim and\\nAndriy Mnih in their paper “Disentangling by Factorising.” Implementing Factor-\\nVAE using Keras involves modifying a standard variational autoencoder (VAE)\\nloss function slightly to include a factor disentanglement term in the loss function.\\nThe disentanglement term encourages the VAE to learn a more structured and\\ndisentangled latent representation as below',\n",
       "  'The remaining code for the VAE\\nprogram remains as before:\\ndef compute_loss(self, x):\\nz_mean, z_log_var = self.encoder(x)\\nz = self.sampling((z_mean, z_log_var))\\nx_reconstructed = self.decoder(z)\\nreconstruction_loss = tf.reduce_mean(\\ntf.keras.losses.\\nbinary_crossentropy(x, x_reconstructed)\\n) * img_width * img_height * 3\\nkl_loss = -0.5 * tf.reduce_sum(1 + z_log_var -\\ntf.square(z_mean) - tf.exp(z_log_var), axis=1)\\nkl_loss = tf.reduce_mean(kl_loss)\\n# Factor disentanglement term\\nfactor_disentanglement_loss = tf.\\nreduce_mean(tf.abs(z_mean))\\nvae_loss = reconstruction_loss + kl_loss +\\nfactor_disentanglement_loss\\nreturn vae_loss\\nOnce we have encoded the data, it will not be obvious to determine what each\\nencoded dimension actually represents',\n",
       "  'In general, Factor-VAE, and other VAE\\nmodels, cannot produce an independent axis of feature representation, so if we\\nexamine a particular dimension, it is unlikely that the single dimension is a unique\\nfeature',\n",
       "  'The metric for measuring disentanglement is not straightforward but is\\nneeded for commercial work',\n",
       "  'For educational purposes however, it is sufﬁcient to\\nview visually the effect along feature changes to guess the resultant purpose of each\\n114\\n6\\nGenerative Models\\nlatent dimension',\n",
       "  'The code below does this by looping through all dimensions and\\nmodifying one dimension at a time to see the result:\\nimport tensorflow as tf\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n# Load your trained FactorVAE model and encoder here\\nfactorvae = tf.keras.models.load_model(’vae_model.h5’)\\nencoder = tf.keras.models.load_model(’encoder_model.h5’)\\n# Load or generate an input data point for reconstruction\\ninput_data = np.random.randn(1, input_dim)\\n# Encode the input data\\nlatent_representation = encoder.predict(input_data)\\n# Get the dimensionality of the latent space\\nlatent_dim = latent_representation.shape[1]\\n# Initialize an empty array to store\\n# reconstructed data along each dimension\\nreconstructed_data_per_dim = []\\n# Loop through each dimension and\\n# modify it while keeping others fixed\\nfor dim_index in range(latent_dim):\\n# Create a copy of the original latent representation\\nmodified_latent_representation =\\nlatent_representation.copy()\\n# Set a new value for the current dimension\\n# You can modify this value based\\n# on your desired transformation\\nnew_value = 2.0\\n# Example: Set a new value\\n# Modify the current dimension\\nmodified_latent_representation[0, dim_index] = new_value\\n# Decode the modified latent representation\\n# to generate reconstructed data\\nreconstructed_data = factorvae.decoder.\\npredict(modified_latent_representation)\\n# Append the reconstructed data to the list\\nreconstructed_data_per_dim.append(reconstructed_data)\\n# Plot the original data and reconstructed\\n# data along each dimension\\nplt.figure(figsize=(4 * latent_dim, 4))\\nfor dim_index in range(latent_dim):\\nplt.subplot(1, latent_dim, dim_index + 1)\\nplt.imshow(reconstructed_data_per_dim[dim_index][0].\\n#reshape(image_shape), cmap=’gray’)\\n6.2\\nCartoonGAN\\n115\\nplt.title(f’Dimension {dim_index}’)\\nplt.axis(’off’)\\nplt.tight_layout()\\nplt.show()\\n6.2\\nCartoonGAN\\nThe project “CartoonGAN: Generative Adversarial Networks for Photo Cartooniza-\\ntion” was proposed by Yang Chen et al',\n",
       "  '[5] as a solution for transforming photos\\nof real-world scenes into cartoon-style images',\n",
       "  'There have been many previous\\nattempts to do the same, but they tend to use pair images and cartoons which are very\\ntime-consuming to generate',\n",
       "  'Often, this process would involve an artist drawing the\\nrequired cartoon to pair up the original image.\\nThese following points are taken from their published paper, which states the\\nmain contributions of the model:\\n•\\n(1) We propose a dedicated GAN-based approach that effectively learns the\\nmapping from real-world photos to cartoon images using unpaired image sets\\nfor training',\n",
       "  'Our method is able to generate high-quality stylized cartoons, which\\nare substantially better than state-of-the-art methods',\n",
       "  'When cartoon images from\\nindividual artists are used for training, our method is able to reproduce their\\nstyles.\\n•\\n(2) We propose two simple yet effective loss functions in GAN-based archi-\\ntecture',\n",
       "  'In the generative network, to cope with substantial style variation\\nbetween photos and cartoons, we introduce a semantic loss deﬁned as an L1\\nsparse regularization in the high-level feature maps of the VGG network',\n",
       "  'In\\nthe discriminator network, we propose an edge-promoting adversarial loss for\\npreserving clear edges.\\n•\\n(3) We further introduce an initialization phase to improve the convergence of\\nthe network to the target manifold',\n",
       "  'Our method is much more efﬁcient to train\\nthan existing methods.\\n6.2.1\\nGAN\\nGANs consist of two neural networks, a generator and a discriminator, which are\\ntrained simultaneously through adversarial processes',\n",
       "  'The generator generates data\\nthat is as realistic as possible, while the discriminator evaluates this data, trying to\\ndistinguish between real and generated (fake) data.\\nThe goal of GANs is to generate data, often images but also other data types, that\\nare indistinguishable from real data',\n",
       "  'As training progresses, the generator improves\\nin producing more realistic data, while the discriminator becomes better at telling\\nreal from fake.\\n116\\n6\\nGenerative Models\\nFigure 6-4 The CartoonGAN architecture [5]\\nGANs are primarily used in tasks involving data generation, such as image and\\nvideo generation, style transfer, data augmentation, and more.\\nThe architecture for CartoonGAN in Figure 6-4 is relatively standard',\n",
       "  'Both\\ngenerator and discriminator networks are CNN networks as shown below, which we\\nhave implemented in Keras',\n",
       "  'In their original paper, the authors use pictures taken\\nfrom the ﬁlm Spirited Away, which for copyright reasons, we cannot include in our\\ndataset',\n",
       "  'However, we will now discuss the tools needed to replicate the data used in\\nthe research paper from Flickr and the movie for the interested reader.\\n6.2.2\\nData Preparation\\nThe research paper used images from two sources: Flickr and Spirited Away',\n",
       "  'Both\\nof these sources have limited distribution rights, so we would need to create our own\\nset of data using the procedure below to train the model.\\nFor Flickr, Jeff Heaton [6] provided an excellent and easy-to-use utility to\\nautomate the download which have been included in the source ﬁle',\n",
       "  'However,\\nwe need to edit the conﬁg_ﬂickr.ini ﬁle to search for the images required',\n",
       "  'In this\\ninstance, I have downloaded images related to the theme “nature” of size 256 × 256\\ninto the local directory /home/philip/AI/Data/CartoonGAN/PhotoFlickr.\\n[FLICKR]\\nid = your account id\\nsecret = your secret id\\n[Download]\\npath = /home/philip/AI/Data/CartoonGAN/PhotoFlickr\\n6.2\\nCartoonGAN\\n117\\nsearch = Nature\\nprefix = Nature\\nupdate_minutes = 1\\nlicense = 0,1,2,3,4,5,6,7,8,9,10\\nmax_download = 100000\\nsources_file = sources.csv\\n[Process]\\nprocess = True\\ncrop_square = True\\nmin_width = 256\\nmin_height = 256\\nscale_width = 256\\nscale_height = 256\\nimage_format = jpg\\nRunning the ﬂickr-download.py code should download approximately 4000–5000\\nimages into the local directories.\\nCapturing frames from the movie Spirited Away is trickier',\n",
       "  'We would need to\\nhave the movie in .mov format on the local drive, then download FFmpeg, and use\\nthe following command to extract frames every four seconds (or whatever interval\\nwe need):\\nffmpeg -i input.mov -r 0.25 output_%04d.jpg\\nWe would need to remove the blank images at the beginning and end',\n",
       "  'These should\\nbe placed into a separate directory.\\nThe next step is to crop these images to 256 × 256 using the function\\ncrop_images_in_directory() in pre_process.py',\n",
       "  'These cropped images are then\\naugmented using augment_images(), which ﬂips the images left to right to create\\nmore images.\\nCartoonGAN requires smooth images, which can be done by running smooth.py\\nwith the appropriate directory for the captured cartoon images',\n",
       "  'Ensure that the\\noutput directory is different to the unsmoothed images.\\nWe should now have three separate directories containing the photos, cartoons,\\nand smoothed cartoons; each image of size 256 × 256 is nearly ready to be fed into\\nthe model',\n",
       "  'The directories for these images should be set in main.py under three\\nseparate directories',\n",
       "  'For example:\\nphoto_paths_norm = ’~/AI/Data/CartoonGAN/PhotoNorm/’\\ncartoon_paths_norm = ’~/AI/Data/CartoonGAN/CartoonNorm/’\\nsmoothed_paths_norm = ’~/AI/Data/CartoonGAN/CartoonSmoothNorm/’\\n6.2.3\\nPreprocessing CartoonGAN\\nThe images are normalized in create_dataset() to a range of [−1,1]',\n",
       "  'This range is\\nneeded because we are using tanh as the activation function instead of sof tmax.\\ntanh is generally used in hidden layers or in recurrent network structures to\\nnormalize and regulate the ﬂow of data, whereas softmax is used in the output layer\\nfor classiﬁcation tasks to represent the likelihood of the input belonging to each\\n118\\n6\\nGenerative Models\\nclass',\n",
       "  'However, the difference in result is marginal in this case, and either activation\\nfunction could be used.\\ndef create_dataset(image_directory, batch_size=1):\\nimage_paths = [os.path.join(image_directory, fname)\\nfor fname in sorted(os.listdir(image_directory))\\nif os.path.isfile(os.path.join(image_directory, fname))\\nand fname.lower().endswith(’.jpg’)]\\n# Define a function to process the images\\ndataset = tf.data.Dataset.\\nfrom_tensor_slices(image_paths)\\ndataset = dataset.map(lambda x:\\nload_and_preprocess_image(x, 256, 256))\\ndataset = dataset.batch(batch_size)\\n.prefetch(tf.data.AUTOTUNE)\\nreturn dataset\\ndef load_and_preprocess_image(path,target_height,\\ntarget_width):\\nimage = tf.io.read_file(path)\\nimage = tf.image.decode_jpeg(image, channels=3)\\nimage = tf.image.convert_image_dtype(image,\\ndtype=tf.float32)\\nimage = (image - 0.5) * 2\\n# Scale to [-1, 1]\\nreturn image\\nThe AUTOTUNE parameter is used to optimize data transfer in batches in Tensor-\\nFlow',\n",
       "  'When loading and preprocessing large datasets, the efﬁciency of operations\\nlike data fetching, batching, and preprocessing can signiﬁcantly impact training\\nspeed',\n",
       "  'AUTOTUNE allows TensorFlow to automatically determine the optimal\\nnumber of batches to process in parallel and the best conﬁguration for other\\nperformance-related settings.\\nThe tensors created by the code above are suitable for the generator and\\ndiscriminator models deﬁned in the project',\n",
       "  'However, CartoonGAN uses a VGG\\nnetwork for training content in the generator, and this model needs tensors of size\\n224 × 224 in the range of [0,1], so our tensors need to be converted',\n",
       "  'This is done in\\nthe function preprocess_for_vgg().\\ndef preprocess_for_vgg(image):\\n# Resize to VGG input size\\nimage = tf.image.resize(image, (224, 224))\\nimage = (image + 1) / 2\\n# convert [-1,1] to [0,1]\\nreturn preprocess_input(image)\\n# Normalize for VGG\\n6.2.4\\nThe Discriminator Model\\nOf the two, the discriminator model is the simpler one',\n",
       "  'The topology of the neural\\nnetwork follows closely the discriminator structure stated in the research paper [5].\\n6.2\\nCartoonGAN\\n119\\nThe loss function needs more explaining, although, in general, it follows the form\\nof a typical GAN model except for the loss due to the smoothing of images.\\ndef loss(real_images, g_generated_images, smoothed_images):\\nreal_output = discriminator(real_images,training=True)\\nfake_output = discriminator(g_generated_images,\\ntraining=True)\\nedge_output = discriminator(smoothed_images,\\ntraining=True)\\nreal_losstf.keras.losses.BinaryCrossentropy\\n(from_logits=False)\\n(tf.ones_like(real_output), real_output)\\nfake_loss= tf.keras.losses.BinaryCrossentropy\\n(from_logits=False)\\n(tf.zeros_like(fake_output), fake_output)\\nedge_loss = tf.keras.losses.BinaryCrossentropy\\n(from_logits=False)\\n(tf.zeros_like(edge_output), edge_output)\\ndiscriminator_loss = real_loss +fake_loss +edge_loss\\nreturn discriminator_loss\\nThe function takes three parameters: real_images are images from the Flickr\\ndataset, g_generated_images are the fake images generated by the generator, and\\nsmoothed_images are the cartoon images which have been smoothed',\n",
       "  'At ﬁrst\\nglance, it is counterintuitive to consider that we do not need to feed the same images\\ninto the discriminator',\n",
       "  'However, it makes sense when we realize that the model is\\ntargeting style and feature transfer, and the loss due to content, fake_loss, is only\\none of the three losses being considered.\\nSetting training=True indicates that the model should run in training mode, which\\nmight include behaviors like dropout.\\nThe loss calculation calculates three different types of losses for the images\\ngenerated by the discriminator using binary cross-entropy, a common loss function\\nfor binary classiﬁcation tasks:\\n•\\nreal_loss: Measures how well the discriminator can identify real images',\n",
       "  'It\\ncompares the discriminator’s output for real images (real_output) with a tensor\\nof ones (tf.ones_like(real_output)), representing the correct classiﬁcation of real\\nimages.\\n•\\nfake_loss: Measures how well the discriminator can identify fake images gen-\\nerated by the generator',\n",
       "  'It compares the discriminator’s output for fake images\\n(fake_output) with a tensor of zeros (tf.zeros_like(fake_output)), representing the\\ncorrect classiﬁcation of fake images since all generator images are fake.\\n•\\nedge_loss: This is an additional loss term for the smoothed images',\n",
       "  'This is one\\nof the features of CartoonGAN where real cartoons are distinguished from the\\nreal images by sharp edges, so the edge_loss can be considered as a style loss.\\n120\\n6\\nGenerative Models\\n6.2.5\\nThe Generator Model\\nThe generator role is to produce realistic cartoons to fool the discriminator',\n",
       "  'In a\\ntypical GAN, the initial images are usually just random noise',\n",
       "  'For CartoonGAN,\\nthe initialization stage relies on the VGG network to initialize the network weights\\nto produce reasonably realistic images so that the second phase mainly deals with\\nstyle transfer.\\nHence, for the initialization phase, no discriminator is involved',\n",
       "  'We simply make\\nuse of the deep layer “block4_conv3” in VGG-19 to teach the generator to learn\\nimportant features of the images',\n",
       "  'Once this is completed, the adversarial nature of\\nthe GAN starts',\n",
       "  'We see the logic for the two phases in the main loop.\\nfor cartoon_images, photo_images, smoothed_images in\\nzip(cartoon_dataset,\\nphoto_dataset, smoothed_dataset):\\nif is_initialization:\\n# Generator Initialization Phase\\ngen_loss, content_loss = generator.init_train(\\nphoto_images,content_lambda)\\ndisc_loss = 0\\nadversarial_loss = 0\\nstyle_loss = 0\\nelse:\\n# Adversarial Training Phase\\ngen_loss, content_loss, adversarial_loss,\\nstyle_loss =\\ngenerator.train(discriminator.discriminator,\\nphoto_images, cartoon_images,\\ng_adv_lambda, content_lambda,\\nstyle_lambda)\\ndisc_loss = discriminator.train(generator.generator,\\nphoto_images, smoothed_images)\\nwith writer.as_default():\\n# Log discriminator metrics\\ntf.summary.scalar(’Discriminator Loss’,\\ndisc_loss, step=n)\\ntf.summary.scalar(’Generator Loss’,\\ngen_loss, step=n)\\ntf.summary.scalar(’Content Loss’,\\ncontent_loss, step=n)\\ntf.summary.scalar(’Adversarial Loss’,\\nadversarial_loss, step=n)\\ntf.summary.scalar(’Style Loss’, style_loss, step=n)\\nn += 1\\nprint(f\"epoch, n, g_loss:gen_loss,\\nd_loss:disc_loss,\\nc_loss:content_loss,\\nadv_loss:adversarial_loss,\\nstyle_loss:style_loss\")\\ncheckpoint_manager.save()\\ntest_picture = next(iter(photo_dataset.take(1)))\\nprint(test_picture.shape)\\npreprocess.generate_and_save_images(\\ngenerator.generator,\\ntest_picture, epoch)\\n6.2\\nCartoonGAN\\n121\\nIn the initial phase, the model returns the generator loss, which is the content loss\\nproduced from the VGG-19 network.\\nIn the second phase, both the generator and discriminator are trained',\n",
       "  'This time,\\nhowever, several losses are computed: content, adversarial, and style losses are all\\ncalculated.\\nContent loss ensures the generated image content resembles the real images,\\nadversarial loss makes the generated images indistinguishable from real ones, and\\nstyle loss ensures the generated images have the desired artistic style.\\nEach loss is associated with a hyperparameter that adjusts its weight, thereby\\ndetermining its importance in the overall loss calculation',\n",
       "  'In practice, by varying\\nthe ratios, we can produce a spectrum of images—from realistic looking photos to\\nabstract blobs of color cartoons.\\nThrough these two phases, the CartoonGAN model adeptly balances content\\nﬁdelity and artistic stylization, enabling the creation of a diverse range of images,\\nfrom photorealistic to highly stylized cartoons.\\ndef train(discriminator, real_photos, cartoons,\\ng_adv_lambda,content_lambda, style_lambda):\\nwith tf.GradientTape() as tape:\\ngenerated_images = generator(real_photos,\\ntraining=True)\\nd_g_generated_images = discriminator(generated_images,\\ntraining=False)\\ncont_loss = content_lambda *\\ncontent_loss(real_photos,\\ngenerated_images)\\nadv_loss = g_adv_lambda *\\nadversarial_loss(d_g_generated_images)\\ns_loss = style_lambda *\\nstyle_loss(cartoons, generated_images)\\ntotal_generator_loss = adv_loss +cont_loss +s_loss\\ngradients = tape.gradient(total_generator_loss,\\ngenerator.trainable_variables)\\noptimizer.apply_gradients(zip(gradients,\\ngenerator.trainable_variables))\\nreturn total_generator_loss,cont_loss,adv_loss,s_loss\\nThe style loss included in the code uses the Gram matrix to help with style transfer.\\nA Gram matrix is a mathematical representation used to measure the correlation\\nbetween different feature maps in a convolutional neural network (CNN)',\n",
       "  'It is\\ncalculated by multiplying a matrix of feature maps by its transpose',\n",
       "  'If we have a\\nset of feature maps, which can be thought of as different ﬁlters applied to an image,\\nthe Gram matrix gives us a measure of how these feature maps activate together,\\nessentially capturing the texture or style information of the image.\\nThe output of the network after the initialization and the second phase are shown\\nbelow in Figure 6-5',\n",
       "  'As can be seen, the image after the initialization phase is\\nquite close to the original photo but contains some stripey artifacts from the CNN\\nnetwork.\\n122\\n6\\nGenerative Models\\nFigure 6-5 Left to right: Original image, after initialization and ﬁnal output\\nThe second phase image is much more cartoon like',\n",
       "  'As stated below, the\\nappearance can be changed by altering the parameters of the losses and rerunning\\nthe model as the quality or style of the output is achieved or, more likely, our\\npatience runs out!\\n6.3\\nStable Diffusion\\nIn concluding our chapter on generative models, we turn our attention to the\\nstate-of-the-art Stable Diffusion AI model',\n",
       "  'Released in 2022, Stable Diffusion is\\nan advanced deep learning model designed for text-to-image conversion, utilizing\\ndiffusion techniques',\n",
       "  'A notable distinction from its contemporaries like DALL-E\\nand Midjourney, which operate as cloud services, is Stable Diffusion’s ability to\\nfunction on consumer PCs equipped with a GPU boasting at least 4 GB of RAM.\\nA key aspect of this model is its utilization of techniques discussed earlier in\\nthis chapter, speciﬁcally latent embedding, variational autoencoders (VAEs), and a\\nconvolutional neural network architecture known as U-Net',\n",
       "  'Originally developed for\\nbiomedical image segmentation, U-Net has been effectively adapted for generating\\nimages with ﬁne-grained details, which are crucial for Stable Diffusion.\\nThe training process of diffusion models is centered around the strategic addition\\nand subsequent removal of Gaussian noise from training images',\n",
       "  'The Stable\\nDiffusion model operates in three distinct phases:\\n•\\nFirst, a variational autoencoder (VAE) compresses the image into a latent space,\\ncapturing the semantic relationships within the image.\\n•\\nDuring the forward diffusion stage, Gaussian noise is incrementally added to this\\nlatent representation',\n",
       "  'The U-Net architecture then comes into play, de-noising\\nthe diffused representation in the latent space, aiming to produce an output that\\naligns with the intended text association.\\n6.3\\nStable Diffusion\\n123\\n•\\nFinally, the VAE decoder reconstructs the image from the latent space back into\\npixel space.\\nThe integration of a diffusion model alongside a VAE might raise questions.\\nOne could hypothesize about embedding the text prompt with the image directly\\nin the latent space and generating the image using solely a VAE network',\n",
       "  'However,\\nemploying a diffusion network has several advantages.\\nDiffusion models have demonstrated superior capabilities in generating images\\nof high quality and resolution',\n",
       "  'This excellence stems from their adeptness at\\nmodeling complex, high-dimensional data distributions, enabling them to capture\\nand reproduce ﬁne details and a wide variety of image features.\\nThese models beneﬁt from a more stable training process',\n",
       "  'By transforming the\\ndata into Gaussian noise in a controlled manner and subsequently learning to reverse\\nthis process, diffusion models exploit the well-understood properties of Gaussian\\nnoise',\n",
       "  'This approach provides signiﬁcant control over the image generation process,\\nwhich can be ﬁnely tuned by adjusting the levels of noise and the sampling\\nmethodology.\\nThe VAE encoder and decoder are similar to the previous example; hence, we\\nwill focus on the two remaining components of the model: injecting and removing\\nnoise and the U-Net topology.\\n6.3.1\\nText Embedding in Stable Diffusion\\nIn the context of generative models, like Stable Diffusion, a latent space is a\\nhigh-dimensional space where complex data (like images) are represented in a\\ncompressed, abstract form',\n",
       "  'This latent space captures the essential characteristics\\nand variations of the data, making it easier for the model to manipulate and generate\\nnew data instances.\\nIn Stable Diffusion, images are ﬁrst encoded into this latent space using a\\nvariational autoencoder (VAE)',\n",
       "  'The VAE compresses an image into a lower-\\ndimensional latent representation, which retains the key features and semantic\\ncontent of the original image',\n",
       "  'This process facilitates the manipulation of the\\nimage at a more abstract level, which is computationally efﬁcient and conceptually\\npowerful.\\nThe latent space is designed to have desirable properties, like continuity and\\nsmoothness, meaning small changes in the latent representation result in small\\nand predictable changes in the output image',\n",
       "  'This is crucial for the gradual\\ntransformation and generation processes in the model.\\nFor text prompt integration, the model receives textual descriptions or prompts\\nas input',\n",
       "  'These prompts describe the desired output image, such as “a sunny beach”\\nor “a futuristic cityscape.”\\nThe challenge lies in mapping these text prompts to the latent space',\n",
       "  'This is\\ntypically achieved using a text encoder, which converts the text prompt into a feature\\n124\\n6\\nGenerative Models\\nFigure 6-6 Stable diffusion architecture [7]\\nvector in the same latent space or a compatible one',\n",
       "  'This encoding captures the\\nsemantic meaning of the text.\\nThe encoded text prompt and the latent image representation are combined or\\naligned in such a way that the text inﬂuences the image generation process',\n",
       "  'This\\ncould involve conditioning the diffusion process on the text features or directly\\nmodifying the latent image representation based on the text features.\\nThe integrated text prompt guides the de-noising process of the diffusion model.\\nAs the model iteratively removes noise from the latent representation, it is inﬂuenced\\nby the text features, leading it to generate an image that corresponds to the textual\\ndescription.\\nThe text conditioning process in Stable Diffusion is shown graphically in\\nFigure 6-6',\n",
       "  'The output of the text transformer is used after word embedding',\n",
       "  'It\\nis used to generate conditioning text that describes the desired attributes, features,\\nor content that the diffusion model should produce',\n",
       "  'For example, if you want to\\ngenerate images of “red apples,” the text transformer might generate the prompt “a\\npicture of a red apple.”\\n6.3.2\\nGaussian Noise Injection and Removal\\nAdding Gaussian noise to an image is straightforward in TensorFlow',\n",
       "  'If we have an\\nimage as a NumPy array, we can simply generate a random tensor from the normal\\ndistribution and add the two tensors together:\\nimport tensorflow as tf\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimage = image.astype(’float32’) / 255.0\\ndef add_noise(img, noise_level):\\nnoise = tf.random.normal(shape=img.shape,\\n6.3\\nStable Diffusion\\n125\\nmean=0.0, stddev=noise_level)\\nnoisy_img = img + noise\\n# Clip the values to maintain them within [0, 1]\\nnoisy_img = tf.clip_by_value(noisy_img,\\nclip_value_min=0.0, clip_value_max=1.0)\\nreturn noisy_img\\nnoise_level = 0.1\\n# Adjust the noise level as needed\\nnoisy_image = add_noise(image, noise_level)\\nThe amount of noise at each stage and the total number of stages are important to\\nthe model and the nature of the dataset',\n",
       "  'More time steps generally allow for a more\\ngradual and controlled diffusion process, potentially leading to better-quality image\\ngeneration',\n",
       "  'However, this comes at the cost of increased computational complexity\\nand longer training times',\n",
       "  'Typical values for the number of time steps range from\\n25 to several thousands',\n",
       "  'More stages and carefully tuned noise levels can lead to\\nhigher ﬁdelity in generated images, but also require more complex and potentially\\nslower models',\n",
       "  'Datasets with more complex and varied images might beneﬁt from\\nmore stages and a carefully designed noise schedule.\\nGenerally, we would start a low number of time steps, observe the quality of\\nthe result, and then increase gradually according to a noise schedule',\n",
       "  'The noise\\nschedules can be linear or nonlinear',\n",
       "  'A linear schedule increases the noise linearly\\nover time, whereas a nonlinear schedule might increase noise more quickly or\\nslowly at different stages',\n",
       "  'Nonlinear schedules are often used because they can better\\nmodel the data distribution of natural images.\\nThe code shown above is actually a simpliﬁcation of the noise injection process\\nin a forward diffusion process',\n",
       "  'The actual code used is coded slightly differently to\\nallow better control of noise injection',\n",
       "  'Denoting the current image at step t as xt,\\nthen we create the image at t + 1 as a combination of the original image xt and\\nGaussian noise, where the proportion of noise versus the original data is determined\\nby the time step t and the parameter βt\\nMathematically, the image xt+1 at time t + 1 is expressed in a form xt+1 =\\n√1 −βtxt + βtϵ where βt is the noise level at time step t and ϵ is a noise term\\nsampled from a normal distribution N(0, 1)',\n",
       "  'A nice property for Gaussian noise\\nis that it is additive, meaning that instead of calculating xt from xt−1, xt could be\\ncalculated from x0 directly as follows:\\nLet αt = 1 −βt, then\\nx1 = √α1.x0 + ϵ\\n\\x02\\n1 −α1\\nx2 = √α2(√α1.x0 +\\n\\x02\\n1 −α1.ϵ) +\\n\\x02\\n1 −α2.ϵ\\nx2 = √α2α1.x0 + ϵ(\\n\\x02\\n1 −α2 +\\n\\x02\\nα2(1 −α1))\\n126\\n6\\nGenerative Models\\nThe additive variance noise property for a Gaussian noise means that we can add\\nthe two terms together to give\\nϵ(\\n\\x02\\n1 −α2 +\\n\\x02\\n(α2(1 −α1))) = ϵ\\n\\x02\\n1 −α1α2\\nsuch that we can express xt in terms of x0 succinctly as follows:\\nxt = x0\\nt\\x03\\ni=1\\n√αi + ϵ\\n\\x04\\n\\x05\\n\\x05\\n\\x061 −\\nt\\x03\\ni=1\\nαi\\nSo in Python, we have two ways of implementing noise injection',\n",
       "  'The original\\nequation is clearer to code, so I prefer to use it.\\nimport numpy as np\\ndef forward_diffusion(x_0, beta_schedule, t):\\nx_t = x_0\\nfor i in range(1, t+1):\\nbeta_t = beta_schedule[i-1]\\nnoise = np.random.normal(size=x_0.shape)\\nx_t = np.sqrt(1 - beta_t) *\\nx_t + np.sqrt(beta_t) * noise\\nreturn x_t\\nUsing either method produces a sequence of noise-added images as shown in\\nFigure 6-7.\\nThis process of adding controlled noise is referred to as reparameterization trick.\\nIn the context of Stable Diffusion, it is thus a crucial technique for the effective\\ntraining of the diffusion process',\n",
       "  'It allows the model to learn how to add noise in\\na controlled manner and, more importantly, how to reverse this process during the\\ngeneration phase',\n",
       "  'This technique helps in maintaining differentiability of the model,\\nwhich is essential for training deep learning models using gradient descent.\\nThe process of de-noising a noisy image involves the reverse process of the\\nforward diffusion',\n",
       "  'The de-noising process, which is the core of image generation\\nFigure 6-7 Adding noise to an image [8]\\n6.3\\nStable Diffusion\\n127\\nin Stable Diffusion, involves iteratively removing this noise to reconstruct an image\\nor generate a new one.\\nBegin with a highly noisy image, which could be the result of the forward\\ndiffusion process applied to an original image, or it could be a randomly initialized\\nnoise image if we are generating new images',\n",
       "  'Similar to the forward diffusion\\nprocess, the de-noising process is iterative and goes through the time steps in reverse\\norder, starting from the last time step and going back to the ﬁrst',\n",
       "  'At each time step,\\nthe model predicts the noise that was added at that particular step during the forward\\nprocess and subtracts it from the current image state.\\nA neural network, typically a U-Net architecture, is used for the de-noising task.\\nThis network is trained to predict the noise that was added to the image at each\\ntime step',\n",
       "  'During the reverse process, the U-Net takes the noisy image and possibly\\nadditional conditioning information (like text embeddings in text-to-image models)\\nas input and outputs an estimate of the noise that needs to be removed.\\nThe estimated noise is then subtracted from the noisy image, resulting in a less\\nnoisy version of the image',\n",
       "  'This process is repeated at each time step, progressively\\nreducing the noise and bringing the image closer to a clear state.\\nBy the end of this reverse process, the image has undergone a series of\\nreﬁnements, and, ideally, we are left with a clear, coherent image that either closely\\nresembles the original (in case of image reconstruction) or represents a new image\\ngenerated based on the provided conditioning (like a text description).\\nThe efﬁciency and quality of de-noising depend heavily on the training and\\narchitecture of the U-Net model, as well as on the accuracy of the noise prediction at\\neach step',\n",
       "  'A high-level extract for the de-noising process is shown below',\n",
       "  'It assumes\\nwe have a pretrained model which can make predictions on the noise.\\ndef denoise_image(noisy_image, model, num_timesteps,\\nconditioning_info=None):\\ncurrent_image = noisy_image\\nfor time step in reversed(range(num_timesteps)):\\n# U-Net model predicts the noise\\npredicted_noise = model.predict(current_image,\\ntime step, conditioning_info)\\n# Subtract the predicted noise from the image\\ncurrent_image = current_image - predicted_noise\\nreturn current_image\\nAt this stage, it is worth to pause the explanation on the de-noising process and\\ndiscuss the architecture of the U-Net model and how its network is used to predict\\nthe noise process.\\n6.3.3\\nThe U-Net Model\\nThe U-Net model is a type of convolutional neural network (CNN) that is partic-\\nularly effective for tasks like image segmentation and, as seen in recent advance-\\nments, for de-noising in diffusion models.\\n128\\n6\\nGenerative Models\\nImage segmentation is a process in computer vision where an image is divided\\ninto multiple segments (sets of pixels, also known as superpixels)',\n",
       "  'The goal of\\nimage segmentation is to simplify or change the representation of an image into\\nsomething that is more meaningful and easier to analyze',\n",
       "  'It is used to locate objects\\nand boundaries (lines, curves, etc.) in images',\n",
       "  'In contrast to image classiﬁcation,\\nwhich provides a label to the whole image, segmentation adds labels to each pixel\\nor superpixels, thereby splitting (or segmenting) the image into signiﬁcant parts.\\nThere are different types of segmentation: semantic, instance, and panoptic, for\\nexample',\n",
       "  'They differ mainly in the way the pixels are classiﬁed',\n",
       "  'Semantic segmenta-\\ntion categorizes the pixels into predeﬁned classes; instance segmentation categorizes\\neach class into different instances of the same class',\n",
       "  'Instance segmentation in the\\ncontext of Stable Diffusion models would involve generating or modifying an image\\nbased on text input, where the model not only recognizes and manipulates different\\nobjects within the image but also distinguishes between individual instances of the\\nsame type of object',\n",
       "  'For example, if the prompt text is to generate “picture of\\na garden with tulips, roses, and daffodils,” instance segmentation would need to\\nidentify that the picture needs ﬂowers of different types and generate the image for\\neach ﬂower separately.\\nPanoptic segmentation combines both semantic and instance segmentation and\\nguides the model to generate or modify an image based on text input where\\nthe model recognizes, differentiates, and visually represents both “thing” classes\\n(countable objects like animals, vehicles, furniture) and “stuff” classes (uncountable\\nregions like grass, sky, water) in a single coherent image.\\nStable Diffusion employs a U-Net network in the backward diffusion process\\nto de-noise the image',\n",
       "  'The U-Net architecture is characterized by a symmetric “U”\\nshape, which includes a contracting path to capture global context (this is equivalent\\nto an encoder network) and an expansive or decoding path that enables precise local\\ninformation collection',\n",
       "  'The output of the last layer in the expansive path is usually\\npassed through a 1 × 1 convolution to map the feature vector to the desired number\\nof output classes or dimensions.\\nLinking the encoder and the decoder networks is the skip connections',\n",
       "  'They\\nconnect the feature maps from the contracting path to the expansive path',\n",
       "  'Skip\\nconnections help in transferring ﬁne-grained details and context information, which\\nis essential for precise localization in tasks like segmentation or for detailed feature\\nreconstruction in de-noising.\\nThe architecture is often modiﬁed to include additional inputs, like text embed-\\ndings in text-to-image models, allowing the U-Net to condition its predictions on\\nexternal information',\n",
       "  'A diagram of a U-Net network is shown in Figure 6-8.\\n6.3\\nStable Diffusion\\n129\\nFigure 6-8 Diagram of a typical U-Net architecture',\n",
       "  'Note the use of skip connections between\\nthe encoder and the decoder networks [9]\\n7\\nReinforcement Learning\\nReinforcement learning (RL) is a type of machine learning where an agent learns\\nto make decisions by performing actions in an environment that maximized the\\nreward',\n",
       "  'The learning process involves the agent interacting with the environment,\\nreceiving feedback in terms of rewards or penalties, and using this feedback to reﬁne\\nits decision-making process',\n",
       "  'Gymnasium (formerly known as Gym), developed by\\nOpenAI, is a popular toolkit for developing and comparing reinforcement learning\\nalgorithms',\n",
       "  'It provides a variety of environments ranging from simple toy tasks to\\ncomplex real-world problems.\\nRL is a very useful tool in machine learning, but it does involve understanding a\\nfair bit of mathematics to comprehend why the model chooses certain actions',\n",
       "  'If the\\nreader is not familiar with Q-learning and deep network Q-learning, then I suggest\\nthe reader studies relevant literature before proceeding',\n",
       "  'Here, we will only discuss\\nthe RL at a high level, so the reader can follow the code.\\n7.1\\nExplanations of Reinforcement Learning\\nReinforcement learning primarily revolves around the concepts of Markov decision\\nprocesses (MDPs), providing a formal framework for decision-making where\\noutcomes are partly random and partly under the agent’s control',\n",
       "  'RL algorithms\\nseek to learn “optimal” policies in this context',\n",
       "  'The optimal policy, in this context,\\nmaximizes the average of future rewards.\\nImagine trying to deal with a discrete state problem where we are trying to act\\nin an optimal way to maximize future rewards',\n",
       "  'Discrete state means considering\\ndiscrete time steps and a manageable number of outcomes at any time step',\n",
       "  'These\\ntwo assumptions are necessary to ensure that the problem is solvable',\n",
       "  'We further\\nassume that future states depend only on the current state, known as the Markov\\nprocess’s memoryless assumption.\\n© Philip Hua 2024\\nP',\n",
       "  'Hua, Neural Networks with TensorFlow and Keras,\\nhttps://doi.org/10.1007/979-8-8688-1020-6_7\\n131\\n132\\n7\\nReinforcement Learning\\nEquation 7-1 Bellman’s equation in general form\\nThe main point of these assumptions is that the optimal policy for reinforcement\\nlearning is speciﬁc to the Markov process',\n",
       "  'If we were to follow the same strategy\\nfor our daily life activities, such as making future investments, the optimal strategy\\nwould not be one suggested by Bellman’s equation',\n",
       "  'Equation 7-1 states that the\\noptimal value Q, following a policy π in state S with action a, is the immediate\\nreward after taking action a plus the discounted sum of future rewards, which needs\\nto be estimated',\n",
       "  'There are several ways to estimate this, including storing a very\\nlarge table for every state-action pair S and A or run simulation.\\nFor deep neural network learning, DQN uses a deep neural network to approxi-\\nmate the Q-value function in Equation 7-1',\n",
       "  'This network takes the state as input and\\noutputs Q-values for all possible actions.\\nThe network is trained by minimizing the loss function deﬁned as the difference\\nbetween the current Q-value estimate and the target Q-value from Bellman’s\\nequation',\n",
       "  'The loss function often used is the mean squared error:\\nL(θ) = E(Rt + γ maxa′Qπ(St+1, a′|St = s, a; θ) −Q(St, At; θ))2\\n(7.1)\\nθ are the weights in the neural network',\n",
       "  'In a standard DQN setup, there are\\ntwo neural networks: the main network and the target network',\n",
       "  'The main network\\nestimates the Q-values, while the target network, which is a delayed copy of the\\nmain network, provides the target Q-values for the loss calculation',\n",
       "  'This separation\\nhelps mitigate the problem of moving targets in the training process.\\nHowever, to simplify our code, we only use one neural network both for training\\nand targeting, so it will take longer to train and be less stable, but it will still work\\nas intended.\\n7.2\\nGymnasium Library\\nFor the purposes of reinforcement learning, we will be using the Gymnasium\\nlibrary, provided by the Farama Foundation',\n",
       "  'The Farama Foundation is a nonproﬁt\\norganization dedicated to advancing the ﬁeld of reinforcement learning through\\npromoting better standardization and open source tooling for both researchers and\\nindustry.\\nThe Gymnasium project’s API contains four key functions: make, reset, step,\\nand render',\n",
       "  'At the core of Gymnasium is Env, a Python class representing a Markov\\ndecision process (MDP) from reinforcement learning theory',\n",
       "  'Within Gymnasium,\\nenvironments are implemented as Env classes, along with wrappers, which provide\\nhelpful utilities to alter the environment without writing boilerplate code',\n",
       "  ...])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-01 20:47:13,221] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0401 20:47:15.277000 11700 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "# After the model is downloaded, you can save it locally\n",
    "model.save(\"D:/mr_document/all_models/all-MiniLM-L6-v2-original/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_venv",
   "language": "python",
   "name": "rag_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
